Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Tradenames,Manufacturers,Funding Details,Funding Text 1,Funding Text 2,Funding Text 3,Funding Text 4,Funding Text 5,Funding Text 6,Funding Text 7,Funding Text 8,Funding Text 9,Funding Text 10,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Tchuinkou Kwadjo D., Nghonda Tchinda E., Mandebi Mbongue J., Bobda C.","57204844063;57693871100;57202819809;6603104702;","Towards a component-based acceleration of convolutional neural networks on FPGAs",2022,"Journal of Parallel and Distributed Computing","167",,,"123","135",,,"10.1016/j.jpdc.2022.04.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130093750&doi=10.1016%2fj.jpdc.2022.04.025&partnerID=40&md5=17b8fcff869894b176f196ea328034c6","Electrical and Computer Engineering Department, University of Florida, Gainesville, FL  32603, United States","Tchuinkou Kwadjo, D., Electrical and Computer Engineering Department, University of Florida, Gainesville, FL  32603, United States; Nghonda Tchinda, E., Electrical and Computer Engineering Department, University of Florida, Gainesville, FL  32603, United States; Mandebi Mbongue, J., Electrical and Computer Engineering Department, University of Florida, Gainesville, FL  32603, United States; Bobda, C., Electrical and Computer Engineering Department, University of Florida, Gainesville, FL  32603, United States","In recent years, Convolution Neural Networks (CNN) have been extensively adopted in broad Artificial Intelligence (AI) applications and have demonstrated ability and effectiveness in solving learning problems. However, developing high-performance hardware accelerators on Field Programmable Gate Array (FPGA) for CNNs often demands skills in hardware design and verification, accurate distribution localization, and long development cycles. Besides, the depth of CNN architectures increases by reusing and replicating several layers. In this work, we take advantage of the replication of CNN layers to achieve improvement in design performance and productivity. We propose a programming flow for CNNs on FPGA to generate high-performance accelerators by assembling CNN pre-implemented components as a puzzle based on the graph topology. Using pre-implemented components allows us to use minimum of resources, predict the performance, and gain in productivity since there is no need to synthesize any Hardware Description Language (HDL) source code. Furthermore, the pre-implemented components are reused for different range of applications, reducing the engineering time. Through prototyping, we demonstrate the viability and relevance of our approach. Experiments show a productivity improvement of up to 69% compared to a traditional FPGA implementation while achieving over 1.75× higher Fmax with lower resources and higher energy efficiency. © 2022 Elsevier Inc.","CNN inference; Data flow graph; FPGA; Pre-implemented flow","Computer hardware description languages; Convolution; Data flow analysis; Data flow graphs; Energy efficiency; Graphic methods; Integrated circuit design; Neural networks; Productivity; Component based; Convolution neural network; Convolution neural network inference; Convolutional neural network; Dataflow graphs; High-performance hardware; Learning problem; Network inference; Performance; Pre-implemented flow; Field programmable gate arrays (FPGA)",,,,,"National Science Foundation, NSF: CNS 2007320","This work was funded by the National Science Foundation (NSF) under Grant CNS 2007320 .",,,,,,,,,,"Abdelouahab, K., Pelcat, M., Serot, J., Berry, F., Accelerating cnn inference on fpgas: a survey (2018), preprint; Ahmad, A., Pasha, M.A., Towards design space exploration and optimization of fast algorithms for convolutional neural networks (cnns) on fpgas (2019) 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 1106-1111. , IEEE; Bhowmik, P., Pantho, J.H., Mbongue, J.M., Bobda, C., Esca: event-based split-cnn architecture with data-level parallelism on ultrascale+ fpga (2021) 2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), pp. 176-180. , IEEE; Biookaghazadeh, S., Ravi, P.K., Zhao, M., Toward multi-fpga acceleration of the neural networks (2021) ACM J. Emerg. Technol. Comput. Syst., 17 (2), pp. 1-23; Blott, M., Preußer, T.B., Fraser, N.J., Gambardella, G., O'brien, K., Umuroglu, Y., Leeser, M., Vissers, K., Finn-r: an end-to-end deep-learning framework for fast exploration of quantized neural networks (2018) ACM Trans. Reconfigurable Technol. Syst., 11 (3), pp. 1-23; Chen, Y., He, J., Zhang, X., Hao, C., Chen, D., Cloud-dnn: an open framework for mapping dnn models to cloud fpgas (2019) Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 73-82; Chen, Y., Xie, Y., Song, L., Chen, F., Tang, T., A survey of accelerator architectures for deep neural networks (2020) Engineering, 6 (3), pp. 264-274; Fowers, J., Brown, G., Cooke, P., Stitt, G., A performance and energy comparison of fpgas, gpus, and multicores for sliding-window applications (2012) Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays, pp. 47-56; Haghi, P., Geng, T., Guo, A., Wang, T., Herbordt, M., Fp-amg: fpga-based acceleration framework for algebraic multigrid solvers (2020) 2020 IEEE 28th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), pp. 148-156. , IEEE; Hussain, S., Javaheripi, M., Neekhara, P., Kastner, R., Koushanfar, F., Fastwave: accelerating autoregressive convolutional neural networks on fpga (2020), preprint; Hwang, W.-J., Jhang, Y.-J., Tai, T.-M., An efficient fpga-based architecture for convolutional neural networks (2017) 2017 40th International Conference on Telecommunications and Signal Processing (TSP), pp. 582-588. , IEEE; Intel, Intel arria 10 product table (2018), https://www.intel.com/content/dam/www/programmable/us/en/pdfs/literature/pt/arria-10-product-table.pdf; IP, D.I.S.U., (2021), Vivado design suite user guide, UG892 (v2020.2); Jiang, W., Sha, E.H.-M., Zhang, X., Yang, L., Zhuge, Q., Shi, Y., Hu, J., Achieving super-linear speedup across multi-fpga for real-time dnn inference (2019) ACM Trans. Embed. Comput. Syst., 18 (5s), pp. 1-23; Kung, H., McDanel, B., Zhang, S.Q., Dong, X., Chen, C.C., Maestro: a memory-on-logic architecture for coordinated parallel use of many systolic arrays (2019) 2019 IEEE 30th International Conference on Application-Specific Systems, Architectures and Processors (ASAP), 2160, pp. 42-50. , IEEE; Kwadjo, D.T., Mbongue, J.M., Bobda, C., Performance exploration on pre-implemented cnn hardware accelerator on fpga (2020) 2020 International Conference on Field-Programmable Technology (ICFPT), pp. 298-299. , IEEE; Kwadjo, D.T., Mbongue, J.M., Bobda, C., Exploring a layer-based pre-implemented flow for mapping cnn on fpga (2021) 2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW), pp. 116-123. , IEEE; Lavin, C., Kaviani, A., Rapidwright: enabling custom crafted implementations for fpgas (2018) 2018 IEEE 26th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), pp. 133-140. , IEEE; Lavin, C., Padilla, M., Ghosh, S., Nelson, B., Hutchings, B., Wirthlin, M., Using hard macros to reduce fpga compilation time (2010) 2010 International Conference on Field Programmable Logic and Applications, pp. 438-441. , IEEE; Lavin, C., Padilla, M., Lamprecht, J., Lundrigan, P., Nelson, B., Hutchings, B., Hmflow: accelerating fpga compilation with hard macros for rapid prototyping (2011) 2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines, pp. 117-124. , IEEE; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Ma, S., Aklah, Z., Andrews, D., Just in time assembly of accelerators (2016) Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 173-178; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., An automatic rtl compiler for high-throughput fpga implementation of diverse deep convolutional neural networks (2017) 2017 27th International Conference on Field Programmable Logic and Applications (FPL), pp. 1-8. , IEEE; Maidee, P., Neely, C., Kaviani, A., Lavin, C., An open-source lightweight timing model for rapidwright (2019) 2019 International Conference on Field-Programmable Technology (ICFPT), pp. 171-178. , IEEE; Mbongue, J.M., Kwadjo, D.T., Bobda, C., Automatic generation of application-specific fpga overlays with rapidwright (2019) 2019 International Conference on Field-Programmable Technology (ICFPT), pp. 303-306. , IEEE; McDanel, B., Zhang, S.Q., Kung, H., Dong, X., Full-stack optimization for accelerating cnns using powers-of-two weights with fpga validation (2020) Proceedings of the ACM International Conference on Supercomputing, pp. 449-460; Microsoft, Project catapult (2018), https://www.microsoft.com/en-us/research/project/project-catapult/; Miranda, G., Luna, H.P.L., Mateus, G.R., Ferreira, R.P.M., A performance guarantee heuristic for electronic components placement problems including thermal effects (2005) Comput. Oper. Res., 32 (11), pp. 2937-2957; Mittal, S., A survey of fpga-based accelerators for convolutional neural networks (2020) Neural Comput. Appl., pp. 1-31; Nguyen, D.T., Kim, H., Lee, H.-J., Layer-specific optimization for mixed data flow with mixed precision in fpga design for cnn-based object detectors (2020) IEEE Trans. Circuits Syst. Video Technol.; Pang, W., Wu, C., Lu, S., An energy-efficient implementation of group pruned cnns on fpga (2020) IEEE Access, 8, pp. 217033-217044; Pantho, M.J.H., Bhowmik, P., Bobda, C., Towards an efficient cnn inference architecture enabling in-sensor processing (2021) Sensors, 21 (6), p. 1955; Petrica, L., Alonso, T., Kroes, M., Fraser, N., Cotofana, S., Blott, M., Memory-efficient dataflow inference for deep cnns on fpga (2020) 2020 International Conference on Field-Programmable Technology (ICFPT), pp. 48-55. , IEEE; Sharma, H., Park, J., Mahajan, D., Amaro, E., Kim, J.K., Shao, C., Mishra, A., Esmaeilzadeh, H., From high-level deep neural models to fpgas (2016) The 49th Annual IEEE/ACM International Symposium on Microarchitecture, p. 17. , IEEE Press; Shen, Y., Ferdman, M., Milder, P., Maximizing cnn accelerator efficiency through resource partitioning (2017) 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA), pp. 535-547. , IEEE; Sohrabizadeh, A., Wang, J., Cong, J., End-to-end optimization of deep learning applications (2020) Proceedings of the 2020 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 133-139; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Venieris, S.I., Bouganis, C.-S., fpgaConvNet: a framework for mapping convolutional neural networks on FPGAs (2016) 2016 IEEE 24th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), pp. 40-47; Venieris, S.I., Bouganis, C.-S., Latency-driven design for fpga-based convolutional neural networks (2017) 2017 27th International Conference on Field Programmable Logic and Applications (FPL), pp. 1-8. , IEEE; Venieris, S.I., Bouganis, C.S., fpgaConvNet: mapping regular and irregular convolutional neural networks on FPGAs (2018) IEEE Trans. Neural Netw. Learn. Syst., pp. 1-17; Wang, J., Lou, Q., Zhang, X., Zhu, C., Lin, Y., Chen, D., Design flow of accelerating hybrid extremely low bit-width neural network in embedded fpga (2018) 2018 28th International Conference on Field Programmable Logic and Applications (FPL), pp. 163-1636. , IEEE; Wei, X., Yu, C.H., Zhang, P., Chen, Y., Wang, Y., Hu, H., Liang, Y., Cong, J., Automated systolic array architecture synthesis for high throughput cnn inference on fpgas (2017) Proceedings of the 54th Annual Design Automation Conference 2017, p. 29. , ACM; Wei, X., Liang, Y., Cong, J., Overcoming data transfer bottlenecks in fpga-based dnn accelerators via layer conscious memory management (2019) 2019 56th ACM/IEEE Design Automation Conference (DAC), pp. 1-6. , IEEE; Wold, A., Koch, D., Torresen, J., Component based design using constraint programming for module placement on fpgas (2013) 2013 8th International Workshop on Reconfigurable and Communication-Centric Systems-on-Chip (ReCoSoC), pp. 1-8. , IEEE; Xiao, Y., Park, D., Butt, A., Giesen, H., Han, Z., Ding, R., Magnezi, N., DeHon, A., Reducing fpga compile time with separate compilation for fpga building blocks (2019) 2019 International Conference on Field-Programmable Technology (ICFPT), pp. 153-161. , IEEE; Xilinx, Hierarchical design (2017), https://www.xilinx.com/support/documentation/sw_manuals/xilinx2017_1/ug905-vivado-hierarchical-design.pdf; Xilinx, Alveo u250 data center accelerator card (2019), https://www.xilinx.com/u250; Xilinx, Ultrascale architecture configurable logic block (2018), https://www.xilinx.com/support/documentation/user_guides/ug574-ultrascale-clb.pdf; Xing, Y., Liang, S., Sui, L., Jia, X., Qiu, J., Liu, X., Wang, Y., Wang, Y., Dnnvm: end-to-end compiler leveraging heterogeneous optimizations on fpga-based cnn accelerators (2019) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst.; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing fpga-based accelerator design for deep convolutional neural networks (2015) Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 161-170; Zhang, C., Sun, G., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: towards uniformed representation and acceleration for deep convolutional neural networks (2018) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst.; Zhu, C., Huang, K., Yang, S., Zhu, Z., Zhang, H., Shen, H., An efficient hardware accelerator for structured sparse convolutional neural networks on fpgas (2020) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 28 (9), pp. 1953-1965","Tchuinkou Kwadjo, D.; Electrical and Computer Engineering Department, United States; email: dtchuinkoukwadjo@ufl.edu",,,"Academic Press Inc.",,,,,07437315,,JPDCE,,"English","J. Parallel Distrib. Comput.",Article,"Final","",Scopus,2-s2.0-85130093750
"Choong B.C.M., Luo T., Liu C., He B., Zhang W., Zhou J.T.","57700971000;57205249350;57191676782;7402047189;55323850100;56335714100;","Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems",2022,"Journal of Systems Architecture","128",,"102507","","",,,"10.1016/j.sysarc.2022.102507","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130409295&doi=10.1016%2fj.sysarc.2022.102507&partnerID=40&md5=81f5f42ac1286c9a72dc4e1d0d2fb080","Department of Electrical and Computer Engineering, National University of Singapore, 4 Engineering Drive 3, Singapore, 117583, Singapore; Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR), 1 Fusionopolis Way, #16-16 Connexis, Singapore, 138632, Singapore; Institute of Computing Technology, Chinese Academy of Sciences, 6 Kexueyuan South Road, Zhongguancun, Haidian District, Beijing, 100190, China; School of Computing, National University of Singapore, COM1, 13, Computing Dr, Singapore, 117417, Singapore; Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; A*STAR Centre for Frontier AI Research (CFAR), 1 Fusionopolis Way, #16-16 Connexis, Singapore, 138632, Singapore","Choong, B.C.M., Department of Electrical and Computer Engineering, National University of Singapore, 4 Engineering Drive 3, Singapore, 117583, Singapore; Luo, T., Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR), 1 Fusionopolis Way, #16-16 Connexis, Singapore, 138632, Singapore; Liu, C., Institute of Computing Technology, Chinese Academy of Sciences, 6 Kexueyuan South Road, Zhongguancun, Haidian District, Beijing, 100190, China; He, B., School of Computing, National University of Singapore, COM1, 13, Computing Dr, Singapore, 117417, Singapore; Zhang, W., Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; Zhou, J.T., A*STAR Centre for Frontier AI Research (CFAR), 1 Fusionopolis Way, #16-16 Connexis, Singapore, 138632, Singapore","Deep neural networks generate and process large volumes of data, posing challenges for low-resource embedded systems. In-memory computing has been demonstrated as an efficient computing infrastructure and shows promise for embedded AI applications. Among newly-researched memory technologies, racetrack memory is a non-volatile technology that allows high data density fabrication, making it a good fit for in-memory computing. However, integrating in-memory arithmetic circuits with memory cells affects both the memory density and power efficiency. It remains challenging to build efficient in-memory arithmetic circuits on racetrack memory within area and energy constraints. To this end, we present an efficient in-memory convolutional neural network (CNN) accelerator optimized for use with racetrack memory. We design a series of fundamental arithmetic circuits as in-memory computing cells suited for multiply-and-accumulate operations. Moreover, we explore the design space of racetrack memory based systems and CNN model architectures, employing co-design to improve the efficiency and performance of performing CNN inference in racetrack memory while maintaining model accuracy. Our designed circuits and model-system co-optimization strategies achieve a small memory bank area with significant improvements in energy and performance for racetrack memory based embedded systems. © 2022 The Author(s)","Artificial intelligence; Deep learning; Embedded systems; Emerging memory; Hardware-software co-design","Convolutional neural networks; Deep neural networks; Hardware-software codesign; Memory architecture; Software design; Arithmetic circuit; Computing infrastructures; Convolutional neural network; Deep learning; Embedded-system; Emerging memory; Hardware/software; Hardware/software codesign; Large volumes; Network inference; Embedded systems",,,,,"A18A1b0045","This work is partially support by Joey Tianyi Zhou's SERC Central Research Fund (Use-inspired Basic Research) and the Singapore Government's Research, Innovation and Enterprise 2020 Plan (Advanced Manufacturing and Engineering domain) under Grant A18A1b0045.","This work is partially support by Joey Tianyi Zhou’s SERC Central Research Fund (Use-inspired Basic Research) and the Singapore Government’s Research, Innovation and Enterprise 2020 Plan (Advanced Manufacturing and Engineering domain) under Grant A18A1b0045 .",,,,,,,,,"Chen, Y.-H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2017) IEEE J. Solid-State Circuits, 52 (1), pp. 127-138; Kang, H.-J., Accelerator-aware pruning for convolutional neural networks (2020) IEEE Trans. Circuits Syst. Video Technol., 30 (7), pp. 2093-2103; Yang, T.-J., Chen, Y.-H., Sze, V., Designing energy-efficient convolutional neural networks using energy-aware pruning (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6071-6079; Hegde, K., Yu, J., Agrawal, R., Yan, M., Pellauer, M., Fletcher, C., UCNN: Exploiting computational reuse in deep neural networks via weight repetition (2018) 2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA), pp. 674-687; Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., Kalenichenko, D., Quantization and training of neural networks for efficient integer-arithmetic-only inference (2018) 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2704-2713; Lee, E.H., Miyashita, D., Chai, E., Murmann, B., Wong, S.S., LogNet: Energy-efficient neural networks using logarithmic computation (2017) 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5900-5904; Kim, N., Shin, D., Choi, W., Kim, G., Park, J., Exploiting retraining-based mixed-precision quantization for low-cost DNN accelerator design (2020) IEEE Trans. Neural Netw. Learn. Syst., 32 (7), pp. 2925-2938; Moons, B., Verhelst, M., An energy-efficient precision-scalable ConvNet processor in 40-nm CMOS (2016) IEEE J. Solid-State Circuits, 52 (4), pp. 903-914; Sharma, H., Park, J., Suda, N., Lai, L., Chau, B., Chandra, V., Esmaeilzadeh, H., Bit fusion: Bit-level dynamically composable architecture for accelerating deep neural network (2018) 2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA), pp. 764-775. , IEEE; Hsu, L.-C., Chiu, C.-T., Lin, K.-T., Chou, H.-H., Pu, Y.-Y., ESSA: An energy-aware bit-serial streaming deep convolutional neural network accelerator (2020) J. Syst. Archit., 111. , https://www.sciencedirect.com/science/article/pii/S1383762120301235, URL:; Kwon, H., Lai, L., Pellauer, M., Krishna, T., Chen, Y.-H., Chandra, V., Heterogeneous dataflow accelerators for multi-DNN workloads (2021) 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA), pp. 71-83. , IEEE; Aimar, A., Mostafa, H., Calabrese, E., Rios-Navarro, A., Tapiador-Morales, R., Lungu, I.-A., Milde, M.B., Liu, S.-C., Nullhop: A flexible convolutional neural network accelerator based on sparse representations of feature maps (2018) IEEE Trans. Neural Netw. Learn. Syst., 30 (3), pp. 644-656; Zhu, C., Huang, K., Yang, S., Zhu, Z., Zhang, H., Shen, H., An efficient hardware accelerator for structured sparse convolutional neural networks on FPGAs (2020) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 28 (9), pp. 1953-1965; Chen, C., Li, K., Ouyang, A., Zeng, Z., Li, K., GFlink: An in-memory computing architecture on heterogeneous CPU-GPU clusters for big data (2018) IEEE Trans. Parallel Distrib. Syst., 29 (6), pp. 1275-1288; Chen, C., Li, K., Ouyang, A., Li, K., Flinkcl: An opencl-based in-memory computing architecture on heterogeneous cpu-gpu clusters for big data (2018) IEEE Trans. Comput., 67 (12), pp. 1765-1779; Chen, C., Li, K., Ouyang, A., Tang, Z., Li, K., Gpu-accelerated parallel hierarchical extreme learning machine on flink for big data (2017) IEEE Trans. Syst. Man Cybern.: Syst., 47 (10), pp. 2740-2753; Parkin, S.S.P., Hayashi, M., Thomas, L., Magnetic domain-wall racetrack memory (2008) Science, 320 (5873), pp. 190-194. , https://science.sciencemag.org/content/320/5873/190, URL:; Lin, C., Kang, S., Wang, Y., Lee, K., Zhu, X., Chen, W., Li, X., Tran, L., 45Nm low power CMOS logic compatible embedded STT MRAM utilizing a reverse-connection 1T/1MTJ cell (2009) 2009 IEEE International Electron Devices Meeting (IEDM), pp. 1-4; Wang, J., Liu, J., Wang, D., An, J., Fan, X., An automatic-addressing architecture with fully serialized access in racetrack memory for energy-efficient CNNs (2020) IEEE Trans. Comput.; Zhang, C., Sun, G., Zhang, W., Mi, F., Li, H., Zhao, W., Quantitative modeling of racetrack memory, a tradeoff among area, performance, and power (2015) The 20th Asia and South Pacific Design Automation Conference, pp. 100-105; Chen, Z., Deng, Q., Xiao, N., Pruhs, K., Zhang, Y., DWMAcc: Accelerating shift-based CNNs with domain wall memories (2019) ACM Trans. Embed. Comput. Syst., 18 (5s). , URL:, https://doi-org.libproxy1.nus.edu.sg/10.1145/3358199; Hu, Q., Sun, G., Shu, J., Zhang, C., Exploring main memory design based on racetrack memory technology (2016) 2016 International Great Lakes Symposium on VLSI (GLSVLSI), pp. 397-402; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2016); Ding, R., Liu, Z., Blanton, R.D.S., Marculescu, D., Quantized deep neural networks for energy efficient hardware-based inference (2018) 2018 23rd Asia and South Pacific Design Automation Conference (ASP-DAC), pp. 1-8; Zhou, A., Yao, A., Guo, Y., Xu, L., Chen, Y., Incremental network quantization: Towards lossless CNNs with low-precision weights (2017), CoRR. URL:; Luo, T., Zhang, W., He, B., Liu, C., Maskell, D., Energy efficient in-memory integer multiplication based on racetrack memory (2020) 2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS), pp. 1409-1414. , IEEE; Luo, T., Zhang, W., He, B., Maskell, D., A racetrack memory based in-memory booth multiplier for cryptography application (2016) 2016 21st Asia and South Pacific Design Automation Conference (ASP-DAC), pp. 286-291. , IEEE; Trinh, H.-P., Zhao, W., Klein, J.-O., Zhang, Y., Ravelsona, D., Chappert, C., Magnetic adder based on racetrack memory (2013) IEEE Trans. Circuits Syst. I. Regul. Pap., 60 (6), pp. 1469-1477; Booth, A.D., A signed binary multiplication technique (1951) Quart. J. Mech. Appl. Math., 4 (2), pp. 236-240; Dong, X., Xu, C., Xie, Y., Jouppi, N.P., NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory (2012) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst., 31 (7), pp. 994-1007; Eckert, C., Wang, X., Wang, J., Subramaniyan, A., Iyer, R., Sylvester, D., Blaaauw, D., Das, R., Neural cache: Bit-serial in-cache acceleration of deep neural networks (2018) 2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA), pp. 383-396; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., MobileNets: Efficient convolutional neural networks for mobile vision applications (2017), CoRR. URL:; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015), CoRR. URL:; 45Nm FreePDK library (2016), https://si2.org/open-cell-library/, URL:; Zhang, Y., Zhao, W., Ravelosona, D., Klein, J.-O., Kim, J., Chappert, C., Perpendicular-magnetic-anisotropy CoFeB racetrack memory (2012) J. Appl. Phys., 111 (9); Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, , Bengio Y. LeCun Y. URL:; Deng, L., The mnist database of handwritten digit images for machine learning research (2012) IEEE Signal Process. Mag., 29 (6), pp. 141-142; Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Chintala, S., PyTorch: An imperative style, high-performance deep learning library (2019) Advances in Neural Information Processing Systems 32, pp. 8024-8035. , Curran Associates, Inc; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis. (IJCV), 115 (3), pp. 211-252; Malladi, K.T., Nothaft, F.A., Periyathambi, K., Lee, B.C., Kozyrakis, C., Horowitz, M., Towards energy-proportional datacenter memory with mobile DRAM (2012) 2012 39th Annual International Symposium on Computer Architecture (ISCA), pp. 37-48; Kang, W., Zheng, C., Huang, Y., Zhang, X., Lv, W., Zhou, Y., Zhao, W., Compact modeling and evaluation of magnetic skyrmion-based racetrack memory (2017) IEEE Trans. Electron Devices, 64 (3), pp. 1060-1068; Luo, T., He, B., Zhang, W., Maskell, D.L., A novel two-stage modular multiplier based on racetrack memory for asymmetric cryptography (2017) 2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pp. 276-282. , IEEE; Song, L., Wang, Y., Han, Y., Li, H., Cheng, Y., Li, X., STT-RAM buffer design for precision-tunable general-purpose neural network accelerator (2017) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 25 (4), pp. 1285-1296; Wang, G., Zhang, Y., Zhang, B., Wu, B., Nan, J., Zhang, X., Zhang, Z., Wang, Z., Ultra-dense ring-shaped racetrack memory cache design (2018) IEEE Trans. Circuits Syst. I. Regul. Pap., (99), pp. 1-11; Luo, T., Wang, X., Qu, C., Lee, M.K.F., Tang, W.T., Wong, W.-F., Goh, R.S.M., An fpga-based hardware emulator for neuromorphic chip with rram (2018) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst., 39 (2), pp. 438-450; Sun, Z., Wu, W., Li, H., Cross-layer racetrack memory design for ultra high density and low power consumption (2013) Design Automation Conference (DAC), 2013 50th ACM/EDAC/IEEE, pp. 1-6; Wang, Y., Yu, H., Sylvester, D., Kong, P., Energy efficient in-memory aes encryption based on nonvolatile domain-wall nanowire (2014) Design, Automation and Test in Europe Conference and Exhibition (DATE), 2014, pp. 1-4. , IEEE; Xu, H., Li, Y., Melhem, R., Jones, A.K., Multilane Racetrack caches: Improving efficiency through compression and independent shifting (2015) Design Automation Conference (ASP-DAC), 2015 20th Asia and South Pacific, pp. 417-422. , IEEE; Zand, R., Roohi, A., Fan, D., DeMara, R.F., Energy-efficient nonvolatile reconfigurable logic using spin hall effect-based lookup tables (2017) IEEE Trans. Nanotechnol., 16 (1), pp. 32-43; Mao, M., Wen, W., Zhang, Y., Chen, Y., Li, H., Exploration of GPGPU register file architecture using domain-wall-shift-write based racetrack memory (2014) Design Automation Conference (DAC), 2014 51st ACM/EDAC/IEEE, pp. 1-6; Mao, M., Wen, W., Zhang, Y., Chen, Y., Li, H., An energy-efficient GPGPU register file architecture using racetrack memory (2017) IEEE Trans. Comput., 66 (9), pp. 1478-1490; Venkatesan, R., Ramasubramanian, S.G., Venkataramani, S., Roy, K., Raghunathan, A., Stag: Spintronic-tape architecture for gpgpu cache hierarchies (2014) Computer Architecture (ISCA), 2014 ACM/IEEE 41st International Symposium on, pp. 253-264; Wang, Y., Ni, L., Chang, C.-H., Yu, H., Dw-aes: A domain-wall nanowire-based aes for high throughput and energy-efficient data encryption in non-volatile memory (2016) IEEE Trans. Inf. Forensics Secur., 11 (11), pp. 2426-2440; Zhao, W., Romdhane, N.B., Zhang, Y., Klein, J.-O., Ravelosona, D., Racetrack memory based reconfigurable computing (2013) Faible Tension Faible Consommation (FTFC), 2013 IEEE, pp. 1-4. , IEEE; Venkatesan, R., Sharad, M., Roy, K., Raghunathan, A., DWM-TAPESTRI-An energy efficient all-spin cache using domain wall shift based writes (2013) Proceedings of the Conference on Design, Automation and Test in Europe, pp. 1825-1830. , EDA Consortium; Matsunaga, S., Hayakawa, J., Ikeda, S., Miura, K., Hasegawa, H., Endoh, T., Ohno, H., Hanyu, T., Fabrication of a nonvolatile full adder based on logic-in-memory architecture using magnetic tunnel junctions (2008) Appl. Phys. Express, 1 (9); Meng, H., Wang, J., Wang, J.-P., A spintronics full adder for magnetic CPU (2005) Electron Device Lett. IEEE, 26 (6), pp. 360-362; Riente, F., Turvani, G., Vacca, M., Graziano, M., Parallel computation in the racetrack memory (2021) IEEE Trans. Emerg. Top. Comput.; Kang, W., Chen, X., Zhu, D., Zhang, X., Zhou, Y., Qiu, K., Zhang, Y., Zhao, W., A comparative study on racetrack memories: Domain wall vs. skyrmion (2018) 2018 IEEE 7th Non-Volatile Memory Systems and Applications Symposium (NVMSA), pp. 7-12. , IEEE; Luo, S., You, L., Skyrmion devices for memory and logic applications (2021) APL Mater., 9 (5); Zhang, X., Ezawa, M., Zhou, Y., Magnetic skyrmion logic gates: conversion, duplication and merging of skyrmions (2015) Sci. Rep., 5 (1), pp. 1-8; Liu, B., Gu, S., Chen, M., Kang, W., Hu, J., Zhuge, Q., Sha, E.H.-M., An efficient racetrack memory-based processing-in-memory architecture for convolutional neural networks (2017) 2017 IEEE International Symposium on Parallel and Distributed Processing with Applications and 2017 IEEE International Conference on Ubiquitous Computing and Communications (ISPA/IUCC), pp. 383-390; Chauwin, M., Hu, X., Garcia-Sanchez, F., Betrabet, N., Paler, A., Moutafis, C., Friedman, J.S., Skyrmion logic system for large-scale reversible computation (2019) Phys. Rev. A, 12 (6); Mei, L., Houshmand, P., Jain, V., Giraldo, S., Verhelst, M., ZigZag: Enlarging joint architecture-mapping design space exploration for DNN accelerators (2021) IEEE Trans. Comput., 70 (8), pp. 1160-1174; Zhang, J., Wang, Z., Verma, N., In-memory computation of a machine-learning classifier in a standard 6T SRAM array (2017) IEEE J. Solid-State Circuits, 52 (4), pp. 915-924; Yu, H., Wang, Y., Chen, S., Fei, W., Weng, C., Zhao, J., Wei, Z., Energy efficient in-memory machine learning for data intensive image-processing by non-volatile domain-wall memory (2014) 2014 19th Asia and South Pacific Design Automation Conference (ASP-DAC), pp. 191-196","Luo, T.; Institute of High Performance Computing (IHPC), 1 Fusionopolis Way, #16-16 Connexis, Singapore; email: leto.luo@gmail.com",,,"Elsevier B.V.",,,,,13837621,,JSARF,,"English","J Syst Archit",Article,"Final","",Scopus,2-s2.0-85130409295
"Cho H., Lee J., Lee J.","57202361479;57219269911;7601484232;","FARNN: FPGA-GPU Hybrid Acceleration Platform for Recurrent Neural Networks",2022,"IEEE Transactions on Parallel and Distributed Systems","33","7",,"1725","1738",,1,"10.1109/TPDS.2021.3124125","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118639502&doi=10.1109%2fTPDS.2021.3124125&partnerID=40&md5=166d1ddce202d159eef0c03869fe583f","Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea","Cho, H., Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Lee, J., Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea; Lee, J., Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea","GPU-based platforms provide high computation throughput for large mini-batch deep neural network computations. However, a large batch size may not be ideal for some situations, such as aiming at low latency, training on edge/mobile devices, partial retraining for personalization, and having irregular input sequence lengths. GPU performance suffers from low utilization especially for small-batch recurrent neural network (RNN) applications where sequential computations are required. In this article, we propose a hybrid architecture, called FARNN, which combines a GPU and an FPGA to accelerate RNN computation for small batch sizes. After separating RNN computations into GPU-efficient and GPU-inefficient tasks, we design special FPGA computation units that accelerate the GPU-inefficient RNN tasks. FARNN off-loads the GPU-inefficient tasks to the FPGA. We evaluate FARNN with synthetic RNN layers of various configurations on the Xilinx UltraScale+ FPGA and the NVIDIA P100 GPU in addition to evaluating it with real RNN applications. The evaluation result indicates that FARNN outperforms the P100 GPU platform for RNN training by up to 4.2$\times {}$× with small batch sizes, long input sequences, and many RNN cells per layer. © 1990-2012 IEEE.","FPGA; GPU; hybrid platform; RNN","Deep neural networks; Graphics processing unit; Recurrent neural networks; Batch sizes; Hybrid platform; Input sequence; Low latency; Network computations; Neural network application; Performance; Personalizations; Sequence lengths; Sequential computations; Field programmable gate arrays (FPGA)",,,,,"Seoul National University, SNU; Ministry of Science, ICT and Future Planning, MSIP; National Research Foundation of Korea, NRF: NRF-2016M3C4A7952587, NRF-2019M3E4A1080386, NRF-2019R1F1A1062335; Institute for Information and Communications Technology Promotion, IITP: 2018-0-00581","This work was supported in part by the National Research Foundation of Korea (NRF) under Grants NRF-2016M3C4A7952587, NRF-2019M3E4A1080386, and NRF-2019R1F1A1062335 and by the Institute for Information communications Technology Promotion (IITP) under Grant 2018-0-00581, CUDA Programming Environment for FPGA Clusters, all funded by the Ministry of Science and ICT (MSIT) of Korea. The ICT at Seoul National University provided research facilities for this study.",,,,,,,,,,"Donahue, J., Long-term recurrent convolutional networks for visual recognition and description (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (4), pp. 677-691. , Apr; Amodei, D., Deep speech 2: End-to-end speech recognition in english and Mandarin (2016) Proc. 33rd Int. Conf. Mach. Learn., pp. 173-182; Hannun, A.Y., (2014) Deep Speech: Scaling up End-to-end Speech Recognition; Sak, H., Senior, A.W., Beaufays, F., Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition (2014) Proc. Annu. Conf. Int. Speech Commun. Assoc.; He, Y., Streaming end-to-end speech recognition for mobile devices (2019) Proc. IEEE Int. Conf. Acoust. Speech Signal Process., pp. 6381-6385; Zhao, Z., Chen, W., Wu, X., Chen, P.C.Y., Liu, J., LSTM network: A deep learning approach for short-term traffic forecast (2017) Iet Intell. Transport Syst., 11, pp. 68-75. , Mar; Chen, C., Gated residual recurrent graph neural networks for traffic prediction (2019) Proc. Aaai Conf. Artif. Intell., pp. 485-492; Greff, K., Srivastava, R.K., Koutnik, J., Steunebrink, B.R., Schmidhuber, J., LSTM: A search space Odyssey (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (10), pp. 2222-2232. , Oct; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9, pp. 1735-1780. , Dec; Cho, K., Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014) Proc. Conf. Empir. Methods Natural Lang. Process., pp. 1724-1734; Gers, F., Schraudolph, N., Schmidhuber, J., Learning precise timing with LSTM recurrent networks (2002) J. Mach. Learn. Res., 3, pp. 115-143. , Jan; Shi, X., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., Woo, W.-C., Convolutional LSTM network: A machine learning approach for precipitation nowcasting (2015) Proc. 28th Int. Conf. Neural Inf. Process. Syst., pp. 802-810; Vaswani, A., Attention is all you need (2017) Proc. 17th Int. Conf. Neural Inf. Process. Syst., pp. 6000-6010; Devlin, J., Chang, M., Lee, K., Toutanova, K., (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding; Mnih, V., Badia, A.P., Asynchronous methods for deep reinforcement learning (2016) Proc. 33rd Int. Conf. Mach. Learn., pp. 1928-1937; Zheng, B., Vijaykumar, N., Pekhimenko, G., Echo: Compilerbased GPU memory footprint reduction for LSTM RNN training (2020) Proc. ACM/IEEE 47th Annu. Int. Symp. Comput. Archit., pp. 1089-1102; Huang, Z., Xu, P., Liang, D., Mishra, A., Xiang, B., (2020) TRANSBLSTM: Transformer with Bidirectional Lstm for Language Understanding; Narayanan, D., Efficient large-scale language model training on GPU clusters using megatron-LM (2021) Proc. Int. Conf. High Perform. Comput., Netw., Storage Anal. (SC '21). Assoc. Comput. Mach., pp. 1-15; Konecny, J., McMahan, H.B., Yu, F.X., Richtarik, P., Suresh, A.T., Bacon, D., Federated learning: Strategies for improving communication efficiency (2016) Proc. Nips Workshop Private Multi-Party Mach. Learn.; McMahan, H.B., Moore, E., Ramage, D., Hampson, S., Arcas, B.A.Y., Communication-efficient learning of deep networks from decentralized data (2017) Proc. 20th Int. Conf. Artif. Intell. Statist., pp. 1273-1282; Yoon, S., Yun, H., Kim, Y., Tae Park, G., Jung, K., Efficient transfer learning schemes for personalized language modeling using recurrent neural network (2017) Proc. Aaai Workshop Crowdsourcing Deep Learn. Artif. Intell. Agents, pp. 457-463; Le, D., Keren, G., Chan, J., Mahadeokar, J., Fuegen, C., Seltzer, M.L., (2020) Deep Shallow Fusion for RNN-T Personalization; Volos, S., Vaswani, K., Bruno, R., Graviton: Trusted execution environments on GPUs (2018) Proc. 13th Usenix Conf. Oper. Syst. Des. Implementation, pp. 681-696; Oh, H., Nam, K., Jeon, S., Cho, Y., Paek, Y., MeetGo: A trusted execution environment for remote applications on FPGA (2021) IEEE Access, 9, pp. 51313-51324; https://developer.nvidia.com/cudnn, NVIDIA cuDNN GPU accelerated deep learning, 2019; Aydonat, U., O'Connell, S., Capalija, D., Ling, A.C., Chiu, G.R., An OpenCL deep learning accelerator on Arria 10 (2017) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 55-64; Chen, Y., DaDianNao: A machine-learning supercomputer (2014) Proc. 47th Annu. IEEE/ACM Int. Symp. Microarchit., pp. 609-622; Chen, Y.-H., Emer, J., Sze, V., Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks (2016) Proc. 43rd Int. Symp. Comput. Archit., pp. 367-379; Cho, H., Oh, P., Park, J., Jung, W., Lee, J., FA3C: FPGA-accelerated deep reinforcement learning (2019) Proc. 24th Int. Conf. Architect. Support Program. Lang. Oper. Syst., pp. 499-513; Guan, Y., FP-DNN: An automated framework for mapping deep neural networks onto FPGAS with RTL-HLS hybrid templates (2017) Proc. IEEE 25th Annu. Int. Symp. Field-Programmable Custom Comput. Mach., pp. 152-159; Ham, T.J., A3: Accelerating attention mechanisms in neural networks with approximation (2020) Proc. 26th IEEE Int. Symp. High-Perform. Comput. Archit., pp. 328-341; Kwon, H., Samajdar, A., Krishna, T., MAERI: Enabling flexible dataflow mapping over DNN accelerators via programmable interconnects (2018) Proc. 23rd Int. Conf. Archit. Support Program. Lang. Operation Syst., pp. 461-475; Mahajan, D., TABLA: A unified template-based framework for accelerating statistical machine learning (2016) Proc. IEEE Int. Symp. High Perform. Comput. Archit., pp. 14-26; Qiu, J., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 26-35; Shao, Y.S., Simba: Scaling deep-learning inference with multi-chip-module-based architecture (2019) Proc. 52nd Annu. IEEE/ Acm Int. Symp. Microarchit., pp. 14-27; Sharma, H., Fromhigh-level deep neuralmodels to FPGAS (2016) Proc. 49th Annu. IEEE/ACMInt. Symp.Microarchit., pp. 1-12; Sharma, H., Bit fusion: Bit-level dynamically composable architecture for accelerating deep neural network (2018) Proc. ACM/ IEEE 45th Annu. Int. Symp. Comput. Archit., pp. 764-775; Zhang, C., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: Towards uniformed representation and acceleration for deep convolutional neural networks (2016) Proc. 35th Int. Conf. Comput.-Aided Des., pp. 1-8; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 161-170; Zhang, J., Li, J., Improving the performance of OpenCL-based FPGA accelerator for convolutional neural network (2017) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 25-34; Fowers, J., A configurable cloud-scale DNN processor for real-time AI (2018) Proc. 45th Annu. Int. Symp. Comput. Archit., pp. 1-14; Gao, C., Neil, D., Ceolini, E., Liu, S.-C., Delbruck, T., DeltaRNN: A power-efficient recurrent neural network accelerator (2018) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 21-30; Guan, Y., Yuan, Z., Sun, G., Cong, J., FPGA-based accelerator for long short-term memory recurrent neural networks (2017) Proc. 22nd Asia South Pacific Des. Autom. Conf., pp. 629-634; Han, S., ESE: Efficient speech recognition engine with sparse LSTM on FPGA (2017) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 75-84; Li, Z., E-RNN: Design optimization for efficient recurrent neural networks in FPGAS (2019) Proc. 25th IEEE Int. Symp. High Perform. Comput. Archit., pp. 69-80; Lu, L., Xie, J., Huang, R., Zhang, J., Lin, W., Liang, Y., An efficient hardware accelerator for sparse convolutional neural networks on FPGAS (2019) Proc. IEEE 27th Annu. Int. Symp. Field-Programmable Custom Comput. Mach., pp. 17-25; Park, J., Kung, J., Yi, W., Kim, J.-J., Maximizing system performance by balancing computation loads in LSTM accelerators (2018) Proc. Des. Autom. Test Eur. Conf. Exhib., pp. 7-12; Wang, S., C-LSTM: Enabling efficient LSTM using structured compression techniques on FPGAS (2018) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 11-20; Hosseinabady, M., Zainol, M.A.B., Nunez-Yanez, J., (2019) Heterogeneous FPGA+GPU Embedded Systems: Challenges and Opportunities; Liu, X., Ounifi, H.-A., Gherbi, A., Li, W., Cheriet, M., A hybrid GPU-FPGA based design methodology for enhancing machine learning applications performance (2020) J. Ambient Intell. Humanized Comput., 11, pp. 2309-2323; Tu, Y., Sadiq, S., Tao, Y., Shyu, M.-L., Chen, S.-C., A power efficient neural network implementation on heterogeneous FPGA and GPU devices (2019) Proc. IEEE 20th Int. Conf. Inf. Reuse Integr. Data Sci., pp. 193-199; Carballo-Hernandez, W., Pelcat, M., Berry, F., (2021) Why Is Fpgagpu Heterogeneity the Best Option for Embedded Deep Neural Networks?; Chen, C., Li, K., Ouyang, A., Zeng, Z., Li, K., GFlink: An inmemory computing architecture on heterogeneous CPU-GPU clusters for big data (2018) IEEE Trans. Parallel Distrib. Syst., 29 (6), pp. 1275-1288. , Jun; Fei, X., Li, K., Yang, W., Li, K., Analysis of energy efficiency of a parallel AES algorithm for CPU-GPU heterogeneous platforms (2020) Parallel Comput., 94-95; Kim, H., Cho, H., Pyo, C., GPU-based acceleration of the linear complexity test for random number generator testing (2019) J. Parallel Distrib. Comput., 128, pp. 115-125; Zhu, Z., Xu, S., Tang, J., Qu, M., GraphVite: A high-performance CPU-GPU hybrid system for node embedding (2019) Proc. World Wide Web Conf., pp. 2494-2504; Yan, M., HyGCN: A GCN accelerator with hybrid architecture (2020) Proc. IEEE Int. Symp. High Perform. Comput. Archit., pp. 15-29; Wang, S., Liang, Y., Zhang, W., Poly: Efficient heterogeneous system and application management for interactive applications (2019) Proc. IEEE Int. Symp. High Perform. Comput. Archit., pp. 199-210; Yuan, G., (2020) DPUv3E for Alveo Accelerator Card with Hbm, , https://developer.xilinx.com/en/articles/dpuv3e-for-alveo-accelerator-card-with-hbm.html; Bittner, R., Ruf, E., Direct GPU/FPGA communication via PCI Express (2012) Proc. 41st Int. Conf. Parallel Process., pp. 135-139; https://developer.nvidia.com/gpudirect, GPUDirect 2019; https://www.xilinx.com/support/documentation/ip_documentation/xdma/v4_1/pg195-pcie-dma.pdf, DMA/Bridge subsystem for PCI Express v4.1 2021; Panayotov, V., Chen, G., Povey, D., Khudanpur, S., Librispeech: An ASR corpus based on public domain audio books (2015) Proc. IEEE Int. Conf. Acoust. Speech Signal Process., pp. 5206-5210; https://www.xilinx.com/support/documentation/data_sheets/ds950-versal-overview.pdf, Versal architecture and product data sheet: Overview 2021; Liu, X., Ounifi, H.A., Gherbi, A., Lemieux, Y., Li, W., A hybrid GPU-FPGA-based computing platform for machine learning (2018) Procedia Comput. Sci., 141, pp. 104-111; He, X., Enabling energy-efficient DNN training on hybrid GPU-FPGA accelerators (2021) Proc. Acm Int. Conf. Supercomput., pp. 227-241","Lee, J.; Department of Computer Science and Engineering, South Korea; email: jaejin@snu.ac.kr",,,"IEEE Computer Society",,,,,10459219,,ITDSE,,"English","IEEE Trans Parallel Distrib Syst",Article,"Final","",Scopus,2-s2.0-85118639502
"Mazumder A.N., Ren H., Rashid H.-A., Hosseini M., Chandrareddy V., Homayoun H., Mohsenin T.","57216314395;57219316619;57221320382;57195399478;57223428305;57203078254;23668732400;","Automatic Detection of Respiratory Symptoms Using a Low-Power Multi-Input CNN Processor",2022,"IEEE Design and Test","39","3",,"82","90",,4,"10.1109/MDAT.2021.3079318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105859667&doi=10.1109%2fMDAT.2021.3079318&partnerID=40&md5=236febb97308fa8aa6d9e8a4ddf41f0b","University of Maryland, Baltimore, MD  21250, United States; University of California at Davis, Davis, CA  95616, United States","Mazumder, A.N., University of Maryland, Baltimore, MD  21250, United States; Ren, H., University of Maryland, Baltimore, MD  21250, United States; Rashid, H.-A., University of Maryland, Baltimore, MD  21250, United States; Hosseini, M., University of Maryland, Baltimore, MD  21250, United States; Chandrareddy, V., University of Maryland, Baltimore, MD  21250, United States; Homayoun, H., University of California at Davis, Davis, CA  95616, United States; Mohsenin, T., University of Maryland, Baltimore, MD  21250, United States","Respiratory diseases are a leading cause of death in the world. This article proposes a deep convolutional neural network (DCNN) that can detect respiratory symptoms in a user using audio input, and with the assistance of additional physiological or demographic information. © 2013 IEEE.","Audio processing; CNN; FPGA; low power hardware implementation; respiratory symptoms detection","Convolutional neural networks; Deep learning; Deep neural networks; Demography; Diagnosis; Energy efficiency; Field programmable gate arrays (FPGA); Population dynamics; Population statistics; Automatic Detection; Demographic information; Detection accuracy; Disease detection; Learning frameworks; Processing engine; Respiratory symptoms; Scalable hardware; Audio signal processing",,,,,,,,,,,,,,,,"Belkacem, A.N., (2020) End-to-end AI-based pointof-care diagnosis system for classifying respiratory illnesses and early detection of COVID-19, , https://arxiv.org/abs/2006.15469, arXiv:2006.15469; Tokozume, Y., Harada, T., Learning environmental sounds with end-to-end convolutional neural network (2017) Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), pp. 2721-2725. , Mar; Fonseca, E., (2018) General-purpose tagging of freesound audio with AudioSet labels: Task description, dataset, and baseline, , https://arxiv.org/abs/1807.09902, arXiv:1807.09902; Piczak, K.J., ESC: Dataset for environmental sound classification (2015) Proc. 23rd Annu. ACM Conf. Multimedia, pp. 1015-1018. , http://dl.acm.org/citation.cfm?doid=2733373.2806390; Piczak, K.J., Environmental sound classification with convolutional neural networks (2015) Proc. IEEE 25th Int. Workshop Mach. Learn. Signal Process. (MLSP), pp. 1-6. , Sep; Abadi, M., (2015) TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, , http://tensorflow.org/; McFee, B., librosa: Audio and music signal analysis in Python (2015) Proc. 14th Python Sci. Conf., 8, pp. 18-25; Coelho, C.N., Jr., (2020) Automatic deep heterogeneous quantization of deep neural networks for ultra low-area, low-latency inference on the edge at particle colliders, , https://arxiv.org/abs/2006.10159, arXiv:2006.10159; Rocha, B.M., An open access database for the evaluation of respiratory sound classification algorithms (2019) Physiol. Meas., 40 (3); Hosseini, M., Neural networks for pulmonary disease diagnosis using auditory and demographic information (2020) Proc. 3rd epiDAMIK ACM SIGKDD Int. Workshop Epidemiol. Meets Data Mining Knowl. Discovery (epiDAMIK), pp. 1-5; Tariq, Z., Shah, S.K., Lee, Y., Lung disease classification using deep convolutional neural network (2019) Proc. IEEE Int. Conf. Bioinf. Biomed. (BIBM), pp. 732-735. , Nov; Jafari, A., SensorNet: A scalable and low-power deep convolutional neural network for multimodal data classification (2019) IEEE Trans. Circuits Syst. I, Reg. Papers, 66 (1), pp. 274-287. , Jan","Mazumder, A.N.; University of MarylandUnited States; email: arnabm1@umbc.edu",,,"IEEE Computer Society",,,,,21682356,,,,"English","IEEE Des. Test",Article,"Final","",Scopus,2-s2.0-85105859667
"Tsoukas V., Gkogkidis A., Kampa A., Spathoulas G., Kakarountas A.","57212274209;57200045628;57501093300;34168416400;8732123200;","Enhancing Food Supply Chain Security through the Use of Blockchain and TinyML",2022,"Information (Switzerland)","13","5","213","","",,,"10.3390/info13050213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129393349&doi=10.3390%2finfo13050213&partnerID=40&md5=dc10c8646c400ab88ad07f2a0df80a83","Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35100, Greece; Intelligent Systems Laboratory, Lamia, 35131, Greece","Tsoukas, V., Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35100, Greece, Intelligent Systems Laboratory, Lamia, 35131, Greece; Gkogkidis, A., Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35100, Greece, Intelligent Systems Laboratory, Lamia, 35131, Greece; Kampa, A., Intelligent Systems Laboratory, Lamia, 35131, Greece; Spathoulas, G., Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35100, Greece, Intelligent Systems Laboratory, Lamia, 35131, Greece; Kakarountas, A., Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35100, Greece, Intelligent Systems Laboratory, Lamia, 35131, Greece","Food safety is a fundamental right in modern societies. One of the most pressing problems nowadays is the provenance of food and food-related products that citizens consume, mainly due to several food scares and the globalization of food markets, which has resulted in food supply chains that extend beyond nations or even continent boundaries. Food supply networks are characterized by high complexity and a lack of openness. There is a critical requirement for applying novel techniques to verify and authenticate the origin, quality parameters, and transfer/storage details associated with food. This study portrays an end-to-end approach to enhance the security of the food supply chain and thus increase the trustfulness of the food industry. The system aims at increasing the transparency of food supply chain monitoring systems through securing all components that those consist of. A universal information monitoring scheme based on blockchain technology ensures the integrity of collected data, a self-sovereign identity approach for all supply chain actors ensures the minimization of single points of failure, and finally, a security mechanism, that is based on the use of TinyML’s nascent technology, is embedded in monitoring devices to mitigate a significant portion of malicious behavior from actors in the supply chain. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","blockchain; food supply chain; hardware; integrity; internet of things; machine learning; security; smart contracts; TinyML; traceability; transparency","Food supply; Internet of things; Machine learning; Supply chains; Transparency; Block-chain; Food supply chain; Food-safety; Hardware; Integrity; Pressung; Security; Supply chain security; Tinyml; Traceability; Smart contract",,,,,"European Commission, EC; European Regional Development Fund, ERDF","This work has received funding by the project ?ParICT_CENG: Enhancing ICT research infrastructure in Central Greece to enable processing of Big data from sensor stream, multimedia content, and complex mathematical modeling and simulations? (MIS 5047244) which is implemented under the Action ?Reinforcement of the Research and Innovation Infrastructure?, funded by the Operational Programme ?Competitiveness, Entrepreneurship and Innovation? (NSRF 2014?2020) and co-financed by Greece and the European Union (European Regional Development Fund).",,,,,,,,,,"Scallan, E., Hoekstra, R.M., Angulo, F.J., Tauxe, R.V., Widdowson, M.-A., Roy, S.L., Jones, J.L., Griffin, P.M., Foodborne Illness Acquired in the United States—Major Pathogens (2011) Emerg. Infect. Dis, 17, pp. 7-15. , https://doi.org/10.3201/eid1701.P11101; Scharff, R.L., State Estimates for the Annual Cost of Foodborne Illness (2015) J. Food Prot, 78, pp. 1064-1071. , https://doi.org/10.4315/0362-028X.JFP-14-505; Boyacı, İ.H., Temiz, H.T., Uysal, R.S., Velioğlu, H.M., Yadegari, R.J., Rishkan, M.M., A Novel Method for Discrimination of Beef and Horsemeat Using Raman Spectroscopy (2014) Food Chem, 148, pp. 37-41. , https://doi.org/10.1016/j.foodchem.2013.10.006; Gourama, H., Foodborne pathogens (2020) Food Safety Engineering, pp. 25-49. , https://doi.org/10.1007/978-3-030-42660-6\_2, Demirci, A., Feng, H., Krishnamurthy, K., Eds.; Food Engineering Series; Springer International Publishing: Cham, Switzerland; Gaul, L.K., Farag, N.H., Shim, T., Kingsley, M.A., Silk, B.J., Hyytia-Trees, E., Hospital-Acquired Listeriosis Outbreak Caused by Contaminated Diced Celery–Texas, 2010 (2013) Clin. Infect. Dis, 56, pp. 20-26. , https://doi.org/10.1093/cid/cis817; Buchholz, U., Bernard, H., Werber, D., Böhmer, M.M., Remschmidt, C., Wilking, H., Deleré, Y., Dreesman, J., German Outbreak of Escherichia Coli O104:H4 Associated with Sprouts (2011) N. Engl. J. Med, 365, pp. 1763-1770. , https://doi.org/10.1056/NEJMoa1106482; Multistate Outbreak of Listeriosis Linked to Whole Cantaloupes from Jensen Farms, Colorado | Listeria | CDC, , https://www.cdc.gov/listeria/outbreaks/cantaloupes-jensen-farms/index.html, (accessed on 29 March 2022); Sprouts and Investigation of Human Listeriosis Cases, , https://www.cdc.gov/listeria/outbreaks/bean-sprouts-11-14/index.html, (accessed on 29 March 2022); Davis, K.R., Dunn, A.C., Burnett, C., McCullough, L., Dimond, M., Wagner, J., Smith, L., Nakashima, A.K., Campylobacter Jejuni Infections Associated with Raw Milk Consumption—Utah, 2014 (2016) Morb. Mortal. Wkly. Rep, 65, pp. 301-305; Enteritidis Infections Linked to Bean Sprouts | November 2014 | Salmonella | CDC, , https://www.cdc.gov/salmonella/enteritidis-11-14/index.html, (accessed on 29 March 2022); Outbreak of Salmonella Infections Linked to Pre-Cut Melons | Outbreak of Salmonella Infections Linked to Pre-Cut Melon | April 2019 | Salmonella | CDC, , https://www.cdc.gov/salmonella/carrau-04-19/index.html, (accessed on 29 March 2022); Tseng, M.-L., Ha, H.M., Tran, T.P.T., Bui, T.-D., Lim, M.K., Lin, C.-W., Helmi Ali, M., Data-Driven on Sustainable Food Supply Chain: A Comparison on Halal and Non-Halal Food System (2022) J. Ind. Prod. Eng, pp. 1-28. , https://doi.org/10.1080/21681015.2022.2040622; Fung, F., Wang, H.-S., Menon, S., Food Safety in the 21st Century (2018) Biomed. J, 41, pp. 88-95. , https://doi.org/10.1016/j.bj.2018.03.003; Nayak, R., Waterson, P., Global Food Safety as a Complex Adaptive System: Key Concepts and Future Prospects (2019) Trends Food Sci. Technol, 91, pp. 409-425; Kaur, H., Modelling Internet of Things Driven Sustainable Food Security System (2019) Benchmarking, 28, pp. 1740-1760. , https://doi.org/10.1108/BIJ-12-2018-0431; Thyberg, K.L., Tonjes, D.J., Drivers of Food Waste and Their Implications for Sustainable Policy Development (2016) Resour. Conserv. Recycl, 106, pp. 110-123. , https://doi.org/10.1016/j.resconrec.2015.11.016; Théolier, J., Barrere, V., Charlebois, S., Benrejeb Godefroy, S., Risk Analysis Approach Applied to Consumers’ Behaviour toward Fraud in Food Products (2021) Trends Food Sci. Technol, 107, pp. 480-490. , https://doi.org/10.1016/j.tifs.2020.11.017; Liu, W., Shao, X.-F., Wu, C.-H., Qiao, P., A Systematic Literature Review on Applications of Information and Communication Technologies and Blockchain Technologies for Precision Agriculture Development (2021) J. Clean. Prod, 298, p. 126763. , https://doi.org/10.1016/j.jclepro.2021.126763; Dixon, B.R., Fayer, R., Santín, M., Hill, D.E., Dubey, J.P., Protozoan parasites: Cryptosporidium, Giardia, Cyclospora, and Toxoplasma (2011) Rapid Detect. Identif. Quantif. Foodborne Pathog, pp. 349-370. , https://doi.org/10.1128/9781555817121.ch24; Kelly, S., New approaches to determining the origin of food (2011) Food Chain Integrity, , Woodhead Publishing: Sawston, UK; Andersson, A., Ronner, U., Granum, P.E., What Problems Does the Food Industry Have with the Spore-Forming Pathogens Bacillus Cereus and Clostridium Perfringens? (1995) Int. J. Food Microbiol, 28, pp. 145-155. , https://doi.org/10.1016/0168-1605(95)00053-4; https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32005R2073&from=EN, (accessed on 3 April 2022); Schaffner, D.W., Brown, L.G., Ripley, D., Reimann, D., Koktavy, N., Blade, H., Nicholas, D., Quantitative Data Analysis to Determine Best Food Cooling Practices in U.S. Restaurants (2015) J. Food Prot, 78, pp. 778-783. , https://doi.org/10.4315/0362-028X.JFP-14-252; Taormina, P.J., Dorsa, W.J., Growth Potential of Clostridium Perfringens during Cooling of Cooked Meats (2004) J. Food Prot, 67, pp. 1537-1547. , https://doi.org/10.4315/0362-028X-67.7.1537; Rolfe, C., Daryaei, H., Intrinsic and extrinsic factors affecting microbial growth in food systems (2020) Food Safety Engineering, pp. 3-24. , https://doi.org/10.1007/978-3-030-42660-6_1, Demirci, A., Feng, H., Krishnamurthy, K., Eds.; Food Engineering Series; Springer International Publishing: Cham, Switzreland; Bucknavage, M., Campbell, J.A., Good manufacturing practices and other programs in support of the food safety system (2020) Food Safety Engineering, pp. 159-173. , https://doi.org/10.1007/978-3-030-42660-6_6, Demirci, A., Feng, H., Krishnamurthy, K., Eds.; Food Engineering Series; Springer International Publishing: Cham, Switzerland; Ho, K.-L.G., Sandoval, A., Sanitation Standard Operating Procedures (SSOPs) (2020) Food Safety Engineering, pp. 175-190. , https://doi.org/10.1007/978-3-030-42660-6_7, Demirci, A., Feng, H., Krishnamurthy, K., Eds.; Springer International Publishing: Cham, Switzerland; LaBorde, L.F., The hazard analysis risk-based preventive controls (2020) Food Safety Engineering, pp. 205-226. , https://doi.org/10.1007/978-3-030-42660-6_9, Demirci, A., Feng, H., Krishnamurthy, K., Eds.; Food Engineering Series; Springer: Cham, Switzerland; Kennedy, A., Stitzinger, J., Burke, T., Food traceability (2020) Food Safety Engineering, pp. 227-245. , https://doi.org/10.1007/978-3-030-42660-6_10, Demirci, A., Feng, H., Krishnamurthy, K., Eds.; Food Engineering Series; Springer International Publishing: Cham, Switzerland; Martino, K., Stone, W., Ozadali, F., Product recalls as part of the last line of food safety defense (2020) Food Safety Engineering, pp. 247-263. , https://doi.org/10.1007/978-3-030-42660-6_11, Demirci, A., Feng, H., Krishnamurthy, K., Eds.; Food Engineering Series; Springer International Publishing: Cham, Switzerland; Lin, J., Shen, Z., Zhang, A., Chai, Y., Blockchain and IoT based food traceability for smart agriculture (2018) Proceedings of the ICCSE’18 3rd International Conference on Crowd Science and Engineering, pp. 1-6. , https://doi.org/10.1145/3265689.3265692, Singapore, Singapore, 28–31 July; Astill, J., Dara, R.A., Campbell, M., Farber, J.M., Fraser, E.D.G., Sharif, S., Yada, R.Y., Transparency in Food Supply Chains: A Review of Enabling Technology Solutions (2019) Trends Food Sci. Technol, 91, pp. 240-247. , https://doi.org/10.1016/j.tifs.2019.07.024; Ahmed, S., ten Broek, N., Blockchain Could Boost Food Security (2017) Nature, 550, p. 43. , https://doi.org/10.1038/550043e; Ray, P., Harsh, H.O., Daniel, A., Ray, A., Incorporating Block Chain Technology in Food Supply Chain (2019) Int. J. Manag. Stud, 6, p. 115. , https://doi.org/10.18843/ijms/v6i1(5)/13; Tian, F., An agri-food supply chain traceability system for china based on RFID & blockchain technology (2016) Proceedings of the 2016 13th International Conference on Service Systems and Service Management (ICSSSM), pp. 1-6. , https://doi.org/10.1109/ICSSSM.2016.7538424, Kunming, China, 24–26 June; Shahid, A., Almogren, A., Javaid, N., Al-Zahrani, F.A., Zuair, M., Alam, M., Blockchain-Based Agri-Food Supply Chain: A Complete Solution (2020) IEEE Access, 8, pp. 69230-69243. , https://doi.org/10.1109/ACCESS.2020.2986257; Patel, N., Shukla, A., Tanwar, S., Singh, D., KRanTi: Blockchain-Based Farmer’s Credit Scheme for Agriculture-Food Supply Chain (2021) Trans. Emerg. Telecommun. Technol, p. e4286. , https://doi.org/10.1002/ett.4286; Tian, F., A supply chain traceability system for food safety based on HACCP, blockchain & Internet of Things (2017) Proceedings of the 2017 International Conference on Service Systems and Service Management, pp. 1-6. , https://doi.org/10.1109/ICSSSM.2017.7996119, Dalian, China, 16–18 June; Mondal, S., Wijewardena, K.P., Karuppuswami, S., Kriti, N., Kumar, D., Chahal, P., Blockchain Inspired RFID-Based Information Architecture for Food Supply Chain (2019) IEEE Internet Things J, 6, pp. 5803-5813. , https://doi.org/10.1109/JIOT.2019.2907658; Blockchain: Transforming Seafood Supply Chain Traceability, , https://www.wwf.org.nz/?15961/Blockchain-Transforming-Seafood-Supply-Chain-Traceability, (accessed on 12 March 2022); From Shore to Plate: Tracking Tuna on the Blockchain, , https://www.provenance.org/tracking-tuna-on-the-blockchain, (accessed on 12 March 2022); Marchese, A., Tomarchio, O., An agri-food supply chain traceability management system based on hyperledger fabric blockchain (2021) Proceedings of the 23rd International Conference on Enterprise Information Systems (ICEIS2021), pp. 648-658. , Prague, Czech Republic, 26–28 April; Huynh, T.S., Nguyen, L.A., Developing Blockchain-Based System for Tracking the Origin of Chicken Products (2019) Int. J. Innov. Technol. Explor. Eng, 8, pp. 90-96; Dey, S., Saha, S., Singh, A.K., McDonald-Maier, K., FoodSQRBlock: Digitizing Food Production and the Supply Chain with Blockchain and QR Code in the Cloud (2021) Sustainability, 13, p. 3486. , https://doi.org/10.3390/su13063486; Tsoukas, V., Gkogkidis, A., Kampa, A., Spathoulas, G., Kakarountas, A., Blockchain technology in food supply chain: A state of the art (2021) Proceedings of the 2021 6th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference (SEEDA-CECNSM), pp. 1-8. , https://doi.org/10.1109/SEEDA-CECNSM53056.2021.9566256, Preveza, Greece, 24–26 September; Creydt, M., Fischer, M., Blockchain and More—Algorithm Driven Food Traceability (2019) Food Control, 105, pp. 45-51. , https://doi.org/10.1016/j.foodcont.2019.05.019; http://www.fao.org/waicent/faoinfo/food-safety-quality/cd_hygiene/cnt/cnt_en/sec_3/docs_3.6/Traceability.pdf, (accessed on 12 March 2022); Aung, M.M., Chang, Y., Traceability in a Food Supply Chain: Safety and Quality Perspectives (2014) Food Control, 39, pp. 172-184. , https://doi.org/10.1016/j.foodcont.2013.11.007; Salampasis, M., Tektonidis, D., Kalogianni, E.P., TraceALL: A Semantic Web Framework for Food Traceability Systems (2012) J. Syst. Inf. Technol, 14, pp. 302-317. , https://doi.org/10.1108/13287261211279053; Oliveira, J., Lima, J.E., da Silva, D., Kuprych, V., Faria, P.M., Teixeira, C., Ferreira Cruz, E., Rosado da Cruz, A.M., Trace-ability System for Quality Monitoring in the Fishery and Aquaculture Value Chain (2021) J. Agric. Food Res, 5, p. 100169. , https://doi.org/10.1016/j.jafr.2021.100169; Bevilacqua, M., Ciarapica, F.E., Giacchetta, G., Business Process Reengineering of a Supply Chain and a Traceability System: A Case Study (2009) J. Food Eng, 93, pp. 13-22. , https://doi.org/10.1016/j.jfoodeng.2008.12.020; Biswas, K., Muthukkumarasamy, V., Lum, W., Blockchain based wine supply chain traceability system (2017) Proceedings of the Future Technologies Conference (FTC), , Vancouver, BC, Canada, 29–30 November; Narrod, C., Roy, D., Okello, J., Avendaño, B., Rich, K., Thorat, A., Public–Private Partnerships and Collective Action in High Value Fruit and Vegetable Supply Chains (2009) Food Policy, 34, pp. 8-15. , https://doi.org/10.1016/j.foodpol.2008.10.005; Demestichas, K., Peppes, N., Alexakis, T., Adamopoulou, E., Blockchain in Agriculture Traceability Systems: A Review (2020) Appl. Sci, 10, p. 4113. , https://doi.org/10.3390/app10124113; Bosona, T., Gebresenbet, G., Food Traceability as an Integral Part of Logistics Management in Food and Agricultural Supply Chain (2013) Food Control, 33, pp. 32-48. , https://doi.org/10.1016/j.foodcont.2013.02.004; Dabbene, F., Gay, P., Tortia, C., Traceability Issues in Food Supply Chain Management: A Review (2014) Biosyst. Eng, 120, pp. 65-80. , https://doi.org/10.1016/j.biosystemseng.2013.09.006; Badia-Melis, R., Mishra, P., Ruiz-García, L., Food Traceability: New Trends and Recent Advances. A Review (2015) Food Control, 57, pp. 393-401. , https://doi.org/10.1016/j.foodcont.2015.05.005; Hofstede, G.J., Spaans, L., Schepers, H., Trienekens, J.H., Beulens, A.J.M., (2004) Hide or Confide: The Dilemma of Transparency, , Reed Business Information: New York, NY, USA; Wognum, P.M., Bremmers, H., Trienekens, J.H., van der Vorst, J.G.A.J., Bloemhof, J.M., Systems for Sustainability and Transparency of Food Supply Chains—Current Status and Challenges (2011) Adv. Eng. Informatics, 25, pp. 65-76. , https://doi.org/10.1016/j.aei.2010.06.001; Kraft, T., Zheng, Y., How Supply Chain Transparency Boosts Business Value (2021) MIT Sloan Manag. Rev, 63, pp. 34-40; Montecchi, M., Plangger, K., West, D.C., Supply Chain Transparency: A Bibliometric Review and Research Agenda (2021) Int. J. Prod. Econ, 238, p. 108152. , https://doi.org/10.1016/j.ijpe.2021.108152; Medina, G., Thomé, K., Transparency in Global Agribusiness: Transforming Brazil’s Soybean Supply Chain Based on Companies’ Accountability (2021) Logistics, 5, p. 58. , https://doi.org/10.3390/logistics5030058; Schäfer, N., Making Transparency Transparent: A Systematic Literature Review to Define and Frame Supply Chain Transparency in the Context of Sustainability (2022) Manag. Rev. Q, p. 1. , 26https://doi.org; https://openlink.com/en/insights/articles/blockchain-food-traceability-can-revolutionize-the-industry/, (accessed on 3 April 2022); Shafiee-Jood, M., Cai, X., Reducing Food Loss and Waste to Enhance Food Security and Environmental Sustainability (2016) Environ. Sci. Technol, 50, pp. 8432-8443. , https://doi.org/10.1021/acs.est.6b01993; Cavaliere, A., Ricci, E.C., Solesin, M., Banterle, A., Can Health and Environmental Concerns Meet in Food Choices? (2014) Sustainability, 6, pp. 9494-9509. , https://doi.org/10.3390/su6129494; European Commission Consumer Policy—Strengthening the Role of Consumers in the Green Transition, , https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12467-Empowering-the-consumer-for-the-green-transition, Available on-line: (accessed on 12 March 2022); Ivanov, D., Viable Supply Chain Model: Integrating Agility, Resilience and Sustainability Perspectives—Lessons from and Thinking beyond the COVID-19 Pandemic (2020) Ann. Oper. Res, pp. 1-21. , https://doi.org/10.1007/s10479-020-03640-6; Dolgui, A., Ivanov, D., Exploring Supply Chain Structural Dynamics: New Disruptive Technologies and Disruption Risks (2020) Int. J. Prod. Econ, 229, p. 107886. , https://doi.org/10.1016/j.ijpe.2020.107886; Nandi, S., Sarkis, J., Hervani, A.A., Helms, M.M., Redesigning Supply Chains Using Blockchain-Enabled Circular Economy and COVID-19 Experiences (2021) Sustain. Prod. Consum, 27, pp. 10-22. , https://doi.org/10.1016/j.spc.2020.10.019; Tseng, M.-L., Lim, M.K., Helmi Ali, M., Christianti, G., Juladacha, P., Assessing the Sustainable Food System in Thailand under Uncertainties: Governance, Distribution and Storage Drive Technological Innovation (2022) J. Ind. Prod. Eng, 39, pp. 1-18. , https://doi.org/10.1080/21681015.2021.1951858; Sustainability in the Food Industry: Progress and Next Steps, , https://insights.figlobal.com/sites/figlobal.com/files/uploads/2018/04/Whitepaper-Sustainability-in-the-food-industry-progress-and-next-steps-including-case-study-on-Symrise\protect\discretionary{\char\hyphenchar\font}{}{}Solvay\protect\discretionary{\char\hyphenchar\font}{}{}Diana-Food-and-ABC\FINAL-1.pdf, (accessed on 12 March 2022); Rana, R.L., Tricase, C., De Cesare, L., Blockchain Technology for a Sustainable Agri-Food Supply Chain (2021) Br. Food J, 123, pp. 3471-3485. , https://doi.org/10.1108/BFJ-09-2020-0832; Hervani, A.A., Nandi, S., Helms, M.M., Sarkis, J., A Performance Measurement Framework for Socially Sustainable and Resilient Supply Chains Using Environmental Goods Valuation Methods (2022) Sustain. Prod. Consum, 30, pp. 31-52. , https://doi.org/10.1016/j.spc.2021.11.026; Food Safety and Quality | Food and Agriculture Organization of the United Nations, , https://www.fao.org/food-safety/food-control-systems/supply-chains-and-consumers/ghp-and-haccp/en/, (accessed on 12 March 2022); Organic Area Accounted for 4% of the Total Utilised Agricultural Area in the EU25 in 2005, , https://ec.europa.eu/eurostat/web/products-euro-indicators/-5-12062007-bp, (accessed on 12 March 2022); https://ec.europa.eu/info/sites/default/files/food-farming-fisheries/farming/documents/market-brief-organic-farming-in-the-eu_mar2019_en.pdf, (accessed on 3 April 2022); Hoorfar, J., Jordan, K., Butler, F., Prugger, R., (2011) Food Chain Integrity: A Holistic Approach to Food Traceability, Safety, Quality, and Authenticity, , Woodhead Pub. Ltd: Oxford, UK; Philadelphia, PA, USA; Montet, D., Ray, R.C., (2017) Food Traceability and Authenticity: Analytical Techniques, , https://doi.org/10.1201/9781351228435, CRC Press: Boca Raton, FL, USA; (2020) The State of World Fisheries and Aquaculture, (SOFIA), , Technical Report, FAO: Rome, Italy, 2020; Oceana Oceana Canada Report Uncovers Widespread Seafood Fraud Across Country, , https://www.oceana.ca/en/press-center/press-releases/oceana-canada-report-uncovers-widespread-seafood-fraud-across-country, (accessed on 12 March 2022); Sotelo, C.G., Velasco, A., Perez-Martin, R.I., Kappel, K., Schröder, U., Verrez-Bagnis, V., Jérôme, M., Mariani, S., Tuna Labels Matter in Europe: Mislabelling Rates in Different Tuna Products (2018) PLoS ONE, 13, p. e0196641. , https://doi.org/10.1371/journal.pone.0196641; Regulation (EC) No 852/2004 of The European Parliament And Of The Council, , https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32004R0852&from=EN, (accessed on 3 April 2022); Regulation (EC) No 853/2004 of The European Parliament And Of The Council, , https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32004R0853&from=EN, (accessed on 14 March 2022); Panarello, A., Tapas, N., Merlino, G., Longo, F., Puliafito, A., Blockchain and IoT Integration: A Systematic Survey (2018) Sensors, 18, p. 2575. , https://doi.org/10.3390/s18082575; Perboli, G., Musso, S., Rosano, M., Blockchain in Logistics and Supply Chain: A Lean Approach for Designing Real-World Use Cases (2018) IEEE Access, 6, pp. 62018-62028. , https://doi.org/10.1109/ACCESS.2018.2875782; Banerjee, A., Chapter Three—Blockchain technology: Supply chain insights from ERP (2018) Advances in Computers, 111, pp. 69-98. , https://doi.org/10.1016/bs.adcom.2018.03.007, Raj, P., Deka, G.C., Eds.; Blockchain Technology: Platforms, Tools and Use Cases; Elsevier: Amsterdam, The Netherlands; Dos Santos, R.B., Torrisi, N.M., Yamada, E.R.K., Pantoni, R.P., IGR Token-Raw Material and Ingredient Certification of Recipe Based Foods Using Smart Contracts (2019) Informatics, 6, p. 11. , https://doi.org/10.3390/informatics6010011; Dettmers, T., (2016) 8-Bit Approximations for Parallelism in Deep Learning, , arXiv arXiv:1511.04561; Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M.W., Keutzer, K., (2021) A Survey of Quantization Methods for Efficient Neural Network Inference, , arXiv arXiv:2103.13630; Park, E., Yoo, S., Vajda, P., (2018) Value-Aware Quantization for Training and Inference of Neural Networks, , arXiv arXiv:1804.07802; Mozer, M.C., Smolensky, P., Skeletonization: A Technique for trimming the fat from a network via relevance assessment (1989) Advances in Neural Information Processing Systems 1, pp. 107-115. , Morgan Kaufmann Publishers Inc.: San Francisco, CA, USA; Hagiwara, M., Removal of hidden units and weights for back propagation networks (1993) Proceedings of the 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan), 1, pp. 351-354. , https://doi.org/10.1109/IJCNN.1993.713929, Nagoya, Japan, 25–29 October; David, R., Duke, J., Jain, A., Reddi, V.J., Jeffries, N., Li, J., Kreeger, N., Regev, S., TensorFlow Lite Micro: Embedded Machine Learning on TinyML Systems, , arXiv 2021, arXiv:2010.08678; https://www.edgeimpulse.com/, (accessed on 1 April 2022); Bian, S., Lukowicz, P., Capacitive sensing based on-board hand gesture recognition with TinyML (2021) Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing, pp. 4-5. , Virtual USA, 21–26 September; Fedorov, I., Stamenovic, M., Jensen, C., Yang, L.-C., Mandell, A., Gan, Y., Mattina, M., Whatmough, P.N., TinyLSTMs: Efficient Neural Speech Enhancement for Hearing Aids (2020) Interspeech, 2020, pp. 4054-4058. , https://doi.org/10.21437/Interspeech.2020-1864; T’Jonck, K., Kancharla, C.R., Vankeirsbilck, J., Hallez, H., Boydens, J., Pang, B., Real-time activity tracking using TinyML to support elderly care Proceedings of the 2021 XXX International Scientific Conference Electronics (ET), pp. 1-6. , https://doi.org/10.1109/ET52713.2021.9579991, Sozopol, Bulgaria, 15–17 September 2021; Roshan, A.N., Gokulapriyan, B., Siddarth, C., Kokil, P., Adaptive traffic control with TinyML (2021) Proceedings of the 2021 Sixth International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET), pp. 451-455. , https://doi.org/10.1109/WiSPNET51692.2021.9419472, Chennai, India, 11 May; Andrade, P., Silva, I., Signoretti, G., Silva, M., Dias, J., Marques, L., Costa, D.G., An unsupervised TinyML approach applied for pavement anomalies detection under the internet of intelligent vehicles Proceedings of the 2021 IEEE International Workshop on Metrology for Industry 4.0 IoT (MetroInd4.0 IoT), pp. 642-647. , https://doi.org/10.1109/MetroInd4.0IoT51437.2021.9488546, Rome, Italy, 7–9 June 2021; Lahade, S.V., Namuduri, S., Upadhyay, H., Bhansali, S., Alcohol Sensor Calibration on the Edge Using Tiny Machine Learning (Tiny-ML) Hardware (2020) Meet. Abstr, , https://doi.org/10.1149/MA2020-01261848mtgabs, MA2020-01, 1848; Alongi, F., Ghielmetti, N., Pau, D., Terraneo, F., Fornaciari, W., Tiny neural networks for environmental predictions: An integrated approach with Miosix (2020) Proceedings of the 2020 IEEE International Conference on Smart Computing (SMARTCOMP), pp. 350-355. , https://doi.org/10.1109/SMARTCOMP50058.2020.00076, Bologna, Italy, 14–17 September; Vuppalapati, C., Ilapakurti, A., Chillara, K., Kedari, S., Mamidi, V., Automating tiny ML intelligent sensors DevOPS using Microsoft Azure (2020) Proceedings of the 2020 IEEE International Conference on Big Data (Big Data), pp. 2375-2384. , https://doi.org/10.1109/BigData50022.2020.9377755, Atlanta, GA, USA, 10–13 December; Crossing the Artificial Intelligence (AI) Chasm, Albeit Using Constrained IoT Edges and Tiny ML, for Creating a Sustainable Food Future, , https://www.springerprofessional.de/en/crossing-the-artificial-intelligence-ai-chasm-albeit-using-const/18435296, (accessed on 1 April 2022); Lord, M., TinyML, Anomaly Detection, , https://scholarworks.calstate.edu/concern/theses/8336h7115?locale=en, (accessed on 1 April 2022); Dutta, A., Kant, S., Implementation of cyber threat intelligence platform on Internet of Things (IoT) using TinyML approach for deceiving cyber invasion (2021) Proceedings of the 2021 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME), pp. 1-6. , https://doi.org/10.1109/ICECCME52200.2021.9590959, Port Louis, Mauritius, 7–8 October; https://metamask.io/, (accessed on 12 March 2022); Lee, W.-M., Using the MetaMask chrome extension (2019) Beginning Ethereum Smart Contracts Programming: With Examples in Python, Solidity, and JavaScript, pp. 93-126. , https://doi.org/10.1007/978-1-4842-5086-0_5, Lee, W.-M., Ed.; Apress: Berkeley, CA, USA; Rewatkar, H.R., Agarwal, D., Khandelwal, A., Upadhyay, S., Decentralized voting application using blockchain (2021) Proceedings of the 2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT), pp. 735-739. , https://doi.org/10.1109/CSNT51715.2021.9509561, Bhopal, India, 18–19 June; Web3JS Etherreum JavaScript API, , https://web3js.readthedocs.io/en/v1.7.1/, (accessed on 12 March 2022); https://docs.arduino.cc/resources/datasheets/ABX00031-datasheet.pdf, (accessed on 12 March 2022)","Tsoukas, V.; Department of Computer Science and Biomedical Informatics, Greece; email: vtsoukas@uth.gr
Gkogkidis, A.; Department of Computer Science and Biomedical Informatics, Greece; email: agkogkidis@uth.gr
Spathoulas, G.; Department of Computer Science and Biomedical Informatics, Greece; email: gspathoulas@uth.gr",,,"MDPI",,,,,20782489,,,,"English","Information",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85129393349
"Ghanbari A., Modarressi M.","57211390663;13408135000;","Energy-efficient acceleration of convolutional neural networks using computation reuse",2022,"Journal of Systems Architecture","126",,"102490","","",,,"10.1016/j.sysarc.2022.102490","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128207364&doi=10.1016%2fj.sysarc.2022.102490&partnerID=40&md5=75742276eb9d43993dd2b9db14e23137","School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Iran","Ghanbari, A., School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Iran; Modarressi, M., School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Iran","The large and ever-increasing size of state-of-the-art convolutional neural networks (CNNs) poses both throughput and energy challenges to the underlying hardware, especially in embedded and mobile computing platforms. Weight quantization is a promising method to reduce the computational complexity of neural networks without losing significant accuracy. In this paper, we show that the value locality of quantized filter weights brings about a high amount of computation redundancy in CNNs. In order to leverage this computational redundancy to reduce neural network complexity, this paper proposes CORN–C, a computation reuse-aware accelerator for CNNs. CORN–C leverages two opportunities to eliminate repetitive computations: (1) the specific algorithmic structure of the convolutional neural networks in which each element of the input data (and intermediate feature maps) is multiplied by tens to thousands of CNN filter weights, and (2) the data value locality in the network filter weights when low-precision quantization is applied. Experimental results show that by eliminating the considerable amount of repetitive multiplication, computation reuse offers up to 10.5%–20.9% energy reduction and 13.4%–41.6% latency reduction over state-of-the-art accelerators across a set of widely-used CNN benchmarks. © 2022","Computation reuse; Convolutional neural networks; Energy-efficiency; Hardware acceleration; Quantization","Complex networks; Convolution; Convolutional neural networks; Parallel processing systems; Redundancy; Computation reuse; Convolutional neural network; Embedded computing; Energy; Energy efficient; Filter weights; Hardware acceleration; Quantisation; State of the art; Value locality; Energy efficiency",,,,,"Sharif University of Technology; University of Tehran, UT","The authors declare the following financial interests/personal relationships which may be considered as potential competing interests: University of Tehran: current employment of the second author Sharif University of Technology, Tehran, Iran: student from 2003 to 2009 (of the second author). IPM School of Computer Science, Tehran, Iran: Research position (the second author) from 2005 to now. MDH University, Sweden: Research position (the second author) from 2019 to now.",,,,,,,,,,"Sparsh Mittal and Shraiysh Vaishay. 2019. A survey of techniques for optimizing deep learning on GPUs. J. Syst. Archit. DOI:10.1016/j.sysarc.2019.101635; Osia, S.A., Shamsabadi, A.S., Sajadmanesh, S., Taheri, A., Katevas, K., Rabiee, H.R., Lane, N.D., Haddadi, H., A hybrid deep learning architecture for privacy-preserving mobile analytics (2020) IEEE Internet Things J, (2020); Daneshtalab, M., Modarressi, M., (2020) Hardware Architectures for Deep Learning, (2020); Hardik Sharma, Jongse Park, Naveen Suda, Liangzhen Lai, Benson Chau, Vikas Chandra, and Hadi Esmaeilzadeh. 2018. Bit fusion: bit-Level dynamically composable architecture for accelerating deep neural networks. In Proceedings - International Symposium on Computer Architecture. DOI:10.1109/ISCA.2018.00069; Yasoubi, A., Hojabr, R., Modarressi, M., Power-efficient accelerator design for neural networks using computation reuse (2017) IEEE Comput. Archit. Lett., (2017); Kartik Hegde, Jiyong Yu, Rohit Agrawal, Mengjia Yan, Michael Pellauer, and Christopher W. Fletcher. 2018. UCNN: exploiting computational reuse in deep neural networks via weight repetition. In Proceedings - International Symposium On Computer Architecture. DOI:10.1109/ISCA.2018.00062; Alvarez, C., Corbal, J., Valero, M., Fuzzy memoization for floating-point multimedia applications (2005) IEEE Trans. Comput., (2005); Suresh, A., Swamy, B.N., Rohou, E., Seznec, A., Intercepting functions for memoization: a case study using transcendental functions (2015) ACM Trans. Archit. Code Optim., (2015); Mehdi Modarressi, Ali Yasoubi, and Maryam Modarressi. 2016. Low-power online ECG analysis using neural networks. In Proceedings - 19th Euromicro Conference on Digital System Design, DSD 2016. DOI:10.1109/DSD.2016.104; Chen, Y.-H., Emer, J., Sze, V., Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks (2016) Annu. Int. Symp. Comput. Archit., pp. 367-379; Judd, P., Albericio, J., Moshovos, A., Stripes: bit-serial deep neural network computing (2017) IEEE Comput. Archit. Lett., (2017); Mahdiani, H., Khadem, A., Ghanbari, A., Modarressi, M., Fattahi, F., Daneshtalab, M., ΔNN: power-efficient neural network acceleration using differential weights (2019) IEEE Micro, (2019); Cesare Alippi, Simone Disabato, and Manuel Roveri. 2018. Moving convolutional neural networks to embedded systems: the AlexNet and VGG-16 case. In Proceedings - 17th ACM/IEEE International Conference On Information Processing in Sensor Networks, IPSN 2018. DOI:10.1109/IPSN.2018.00049; Zidong Du, Robert Fasthuber, Tianshi Chen, Paolo Ienne, Ling Li, Tao Luo, Xiaobing Feng, Yunji Chen, and Olivier Temam. 2015. ShiDianNao: shifting vision processing closer to the sensor. In Proceedings - International Symposium on Computer Architecture. DOI:10.1145/2749469.2750389; Johann Hauswald, Yiping Kang, Michael A. Laurenzano, Quan Chen, Cheng Li, Trevor Mudge, Ronald G. Dreslinski, Jason Mars, and Lingjia Tang. 2015. DjiNN and Tonic: DNN as a service and its implications for future warehouse scale computers. In Proceedings - International Symposium On Computer Architecture. DOI:10.1145/2749469.2749472; Zhuoran Song, Bangqi Fu, Feiyang Wu, Zhaoming Jiang, Li Jiang, Naifeng Jing, and Xiaoyao Liang. 2020. DRQ: dynamic region-based quantization for deep neural network acceleration. In Proceedings - International Symposium on Computer Architecture. DOI:10.1109/ISCA45697.2020.00086; Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 2016. XNOR-net: imagenet classification using binary convolutional neural networks. In Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). DOI:10.1007/978-3-319-46493-0_32; Salonik Resch, S.Karen Khatamifard, Zamshed Iqbal Chowdhury, Masoud Zabihi, Zhengyang Zhao, Jian Ping Wang, Sachin S. Sapatnekar, and Ulya R. Karpuzcu. 2018. PIMBALL: binary neural networks in spintronic memory. arXiv; Brandon Reagen, Paul Whatmough, Robert Adolf, Saketh Rama, Hyunkwang Lee, Sae Kyu Lee, Jose Miguel Hernandez-Lobato, Gu Yeon Wei, and David Brooks. 2016. Minerva: enabling low-power, highly-accurate deep neural network accelerators. In Proceedings - 2016 43rd International Symposium On Computer Architecture, ISCA 2016. DOI:10.1109/ISCA.2016.32; Ansari, M.S., Mrazek, V., Cockburn, B.F., Sekanina, L., Vasicek, Z., Han, J., Improving the accuracy and hardware efficiency of neural networks using approximate multipliers (2020) IEEE Trans. Very Large Scale Integr. Syst., (2020); Marc Riera, Jose Maria Arnau, and Antonio González. 2018. Computation reuse in DNNs by exploiting input similarity. In Proceedings - International Symposium On Computer Architecture. DOI:10.1109/ISCA.2018.00016; Mostafa Mahmoud, Kevin Siu, and Andreas Moshovos. 2018. Diffy: a déjà vu-free differential deep neural network accelerator. In Proceedings of the Annual International Symposium on Microarchitecture, MICRO. DOI:10.1109/MICRO.2018.00020; Lin Ning and Xipeng Shen. 2019. Deep reuse: streamline CNN inference on the fly via coarse-grained computation reuse. In Proceedings of the International Conference on Supercomputing. DOI:10.1145/3330345.3330384; (2020), Pramod Udupa, Gopinath Mahale, Kiran Kolar Chandrasekharan, and Sehwan Lee. 2020. IKW: inter-kernel weights for power efficient edge computing. IEEE Access. DOI:10.1109/ACCESS.2020.2993506; Jorge Albericio, Patrick Judd, Tayler Hetherington, Tor Aamodt, Natalie Enright Jerger, and Andreas Moshovos. 2016. Cnvlutin: ineffectual-neuron-free deep neural network computing. In Proceedings - 2016 43rd International Symposium on Computer Architecture, ISCA 2016. DOI:10.1109/ISCA.2016.11; Jorge Albericio, Alberto Delmás, Patrick Judd, Sayeh Sharify, Gerard O'Leary, Roman Genov, and Andreas Moshovos. 2017. Bit-pragmatic deep neural network computing. In Proceedings of the Annual International Symposium on Microarchitecture, MICRO. DOI:10.1145/3123939.3123982; Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark A. Horowitz, and William J. Dally. 2016. EIE: efficient inference engine on compressed deep neural network. In Proceedings - 2016 43rd International Symposium on Computer Architecture, ISCA 2016. DOI:10.1109/ISCA.2016.30; Sebastian Vogel, Jannik Springer, Andre Guntoro, and Gerd Ascheid. 2019. Self-supervised quantization of pre-trained neural networks for multiplierless acceleration. In Proceedings of the 2019 Design, Automation and Test in Europe Conference and Exhibition, DATE 2019. DOI:10.23919/DATE.2019.8714901; Angshuman Parashar, Minsoo Rhu, Anurag Mukkara, Antonio Puglielli, Rangharajan Venkatesan, Brucek Khailany, Joel Emer, Stephen W. Keckler, and William J. Dally. 2017. SCNN: an accelerator for compressed-sparse convolutional neural networks. In Proceedings - International Symposium on Computer Architecture. DOI:10.1145/3079856.3080254; (2015), http://www.nangate.com, NanGate 15nm Open Cell Library; Alberto Delmas Lascorz, et al. 2019. Bit-tactical: a software/hardware approach to exploiting value and bit sparsity in neural networks. In International Conference on Architectural Support For Programming Languages and Operating Systems - ASPLOS. DOI:10.1145/3297858.3304041; (2004), Fan, Angela, et al. 2020. Training with quantization noise for extreme fixed-point compression. In arXiv preprint arXiv07320; Lee, Jinmook, et al. 2018. UNPU: a 50.6 TOPS/W unified deep neural network accelerator with 1b-to-16b fully-variable weight bit-precision. In IEEE International Solid-State Circuits Conference-(ISSCC); Howard, Andrew et al. 2017. MobileNets: efficient convolutional neural networks for mobile vision applications. In arXiv preprint arXiv:1704.04861; (2021), https://paperswithcode.com/method/depthwise-separable-convolution, CNN model usage over time [online]","Modarressi, M.; School of Electrical and Computer Engineering, Iran; email: modarressi@ut.ac.ir",,,"Elsevier B.V.",,,,,13837621,,JSARF,,"English","J Syst Archit",Article,"Final","",Scopus,2-s2.0-85128207364
"Tiwari B., Yang M., Wang X., Jiang Y.","57208132199;57213789439;35110804100;7404833685;","Data streaming and traffic gathering in mesh-based NoC for deep neural network acceleration",2022,"Journal of Systems Architecture","126",,"102466","","",,,"10.1016/j.sysarc.2022.102466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127526041&doi=10.1016%2fj.sysarc.2022.102466&partnerID=40&md5=db20e68bdc3b29af8938b7e0b4a15ed3","Department of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV  89154, United States; Southern China Institute of Technology, China","Tiwari, B., Department of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV  89154, United States; Yang, M., Department of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV  89154, United States; Wang, X., Southern China Institute of Technology, China; Jiang, Y., Department of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV  89154, United States","The increasing popularity of deep neural network (DNN) applications demands high computing power and efficient hardware accelerator architecture. DNN accelerators use a large number of processing elements (PEs) and on-chip memory for storing weights and other parameters. As the communication backbone of a DNN accelerator, networks-on-chip (NoC) play an important role in supporting various dataflow patterns and enabling processing with communication parallelism in a DNN accelerator. However, the widely used mesh-based NoC architectures inherently cannot support the efficient one-to-many and many-to-one traffic largely existing in DNN workloads. In this paper, we propose a modified mesh architecture with a one-way/two-way streaming bus to speedup one-to-many (multicast) traffic, and the use of gather packets to support many-to-one (gather) traffic. The analysis of the runtime latency of a convolutional layer shows that the two-way streaming architecture achieves better improvement than the one-way streaming architecture for an Output Stationary (OS) dataflow architecture. The simulation results demonstrate that the gather packets can reduce the runtime latency up to 1.8 times and network power consumption up to 1.7 times, compared to the repetitive unicast method on modified mesh architectures supporting two-way streaming. Furthermore, the comparison with state-of-the-art mesh-based accelerator shows that the proposed gather supporting scheme has the advantages in both area efficiency and power efficiency. © 2022 Elsevier B.V.","Accelerators; Collective communication; DNN; Neural networks; NoC","Acceleration; Convolution; Data flow analysis; Data transfer; Efficiency; Mesh generation; MESH networking; Network architecture; Network-on-chip; Collective communications; Data streaming; Many-to-one; Mesh architecture; Mesh-based networks; Networks on chips; Neural-networks; Runtimes; Streaming architecture; Two ways; Deep neural networks",,,,,"National Science Foundation, NSF: 1949585","This work is supported in part by the National Science Foundation under grant no. 1949585 . The authors would like to thank the reviewers for providing suggestions to improve the quality of the paper.",,,,,,,,,,"LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Chen, C., Seff, A., Kornhauser, A., Xiao, J., DeepDriving: learning affordance for direct perception in autonomous driving (2015), pp. 2722-2730. , Proc. IEEE Int'l Conf. on Computer Vision (ICCV), Santiago; Esteva, A., Kuprel, B., Novoa, R., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542, pp. 115-118; Krizhevsky, A., One weird trick for parallelizing convolutional neural networks (2014), CoRR,. [Online]. Available:; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015), Proc. ICLR; Sze, V., Chen, Y., Emer, J., Suleiman, A., Zhang, Z., Hardware for machine learning: challenges and opportunities (2017), pp. 1-8. , Proc. IEEE Custom Integrated Circuits Conf. (CICC), Austin, TX; Dally, W.J., Towles, B., Route packets, not wires: on-chip interconnection networks (2001), pp. 684-689. , Proc. 38th DAC; (2018), pp. 461-475. , Hyoukjun Kwon, Ananda Samajdar, Tushar Krishna, MAERI: enabling flexible dataflow mapping over DNN accelerators via reconfigurable interconnects, in: Proc. ASPLOS; Carrillo, S., Scalable hierarchical network-on-chip architecture for spiking neural network hardware implementations (2013) IEEE Trans. Parallel Distrib. Syst., 24, pp. 2451-2461; Bohnenstiehl, B., KiloCore: a 32-nm 1000-processor computational array (2017) IEEE J. Solid-State Circuits, 52 (4), pp. 891-902; Touzene, A., On all-to-all broadcast in dense gaussian network-on-chip (2015) IEEE Trans. Parallel Distrib. Syst., 26 (4), pp. 1085-1095; Tiwari, B., Yang, M., Jiang, Y., Wang, X., Efficient on-chip multicast routing based on dynamic partition merging (2020), pp. 274-281. , Proc. 28th Euromicro Int'l Conf. on Parallel, Distributed and Network-Based Processing (PDP), Vasteras, Sweden; (2019), pp. 1-31. , Cerebras Systems, Wafer-scale deep learning, in: Proc. IEEE Hot Chips 31 Symp. (HCS), Cupertino, CA; Abts, D., (2020), pp. 145-158. , Think Fast: a Tensor Streaming Processor (TSP) for accelerating deep learning workloads, in: Proc. ACM/IEEE 47th Annual Int'l Symp. on Comp. Architecture (ISCA), Valencia, Spain; Karkar, A., Mak, T., Tong, K., Yakovlev, A., A survey of emerging interconnects for on-chip efficient multicast and broadcast in many-cores (2016) IEEE Circuits Syst. Mag., 16 (1), pp. 58-72; He, K., Zhang, X., (2016), Deep residual learning for image recognition, in: Proc. CVPR; Jouppi, N.P., (2017), In-datacenter performance analysis of a tensor processing unit, in: Proc. 44th Int. Symp. Comp. Architecture (ISCA); Chen, Y., Yang, T., Emer, J., Sze, V., Eyeriss v2: a flexible accelerator for emerging deep neural networks on mobile devices (2019) IEEE J. Emerg. Sel. Top. Circuits Syst., 9 (2), pp. 292-308; Du, Z., (2015), pp. 92-104. , ShiDianNao: shifting vision processing closer to the sensor, in: Proc. ACM/IEEE 42nd Annual Int'l Symp. on Comp. Architecture (ISCA), Portland, OR; Sharma, H., (2016), From high-level deep neural models to FPGAs, in: Proc. 49th Annual IEEE/ACM Int'l Symp. on Microarchitecture (MICRO), Taipei; Nurvitadhi, E., Sheffield, D., (2016), Jaewoong Sim, A. Mishra, G. Venkatesh, D. Marr, Accelerating binarized neural networks: comparison of FPGA, CPU, GPU, and ASIC, in: Proc. Int'l Conf. on Field-Programmable Technology (FPT), Xi'an; Chen, T., (2014), DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning, in: Proc. ASPLOS; Luo, T., DaDianNao: a neural network supercomputer (2017) IEEE Trans. Comput., 66 (1), pp. 73-88; Vainbrand, D., Ginosar, R., Network-on-chip architectures for neural networks (2010), pp. 135-144. , Proc. 4th Int'l Symp. Networks-on-Chip (NoCS), Grenoble; Painkras, E., SpiNNaker: a 1-W 18-core system-on-chip for massively-parallel neural network simulation (2013) IEEE J. Solid-State Circuits, 48 (8), pp. 1943-1953; Xiao, S., NeuronLink: an efficient chip-to-chip interconnect for large-scale neural network accelerators (2020) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 28 (9), pp. 1966-1978; Hojabr, R., Modarressi, M., Daneshtalab, M., Yasoubi, A., Khonsari, A., Customizing Clos network-on-chip for neural networks (2017) IEEE Trans. Comput., 66 (11), pp. 1865-1877; Tiwari, B., (2020), Improving the performance of a NoC-based CNN accelerator with gather support, in: Proc. IEEE 33rd Intl. System-on-Chip Conf. (SOCC); (2018), pp. 141-146. , X. Liu and, Neu-NoC: a high-efficient interconnection network for accelerated neuromorphic systems, in: Proc. 23rd ASP-DAC; Firuzan, A., Modarressi, M., Daneshtalab, M., Reshadi, M., Reconfigurable network-on-chip for 3D neural network accelerators (2018), pp. 1-8. , Proc. 12th Int'l Symp. Networks-on-Chip (NoCS); Kwon, H., Samajdar, A., Krishna, T., Rethinking NoCs for spatial neural network accelerators (2017), Proc. 11th Int'l Symp. Networks-on-Chip (NoCS); (2019), Seyedeh Mirmahaleh, Flow mapping and data distribution on mesh-based deep learning accelerator, in: Proc. 13th Int'l Symp. Networks-on-Chip (NoCS); (2020), pp. 1-7. , Ying Wang, A many-core accelerator design for on-chip deep reinforcement learning, in: Proc. 39th ICCAD; Jerger, N.E., Peh, L., Lipasti, M., Virtual circuit tree multicasting: a case for on-chip hardware multicast support (2008), pp. 229-240. , Proc. Int'l Symp. on Comp. Architecture (ISCA), Beijing; Dally, W., Towles, B., Principles and Practices of Interconnection Networks (2003), Morgan Kaufmann Publishers Inc. San Francisco, CA, USA; Moons, B., Verhelst, M., (2016), pp. 1-2. , A 0.3–2.6 TOPS/W precision-scalable processor for real-time large-scale ConvNets, in: Proc. Symp. VLSI; Esmaeilzadeh, H., Sampson, A., Ceze, L., Burger, D., Neural acceleration for general-purpose approximate programs (2012), pp. 449-460. , Proc. 45th Annual IEEE/ACM Int'l Symp. on Microarchitecture (MICRO), Vancouver, BC, Canada; Paszke, A., (2019), pp. 8024-8035. , PyTorch: An imperative style, high-performance deep learning library, in: 33rd Conf. on Neural Information Processing Systems (NeurIPS), Vancouver, Canada; Wang, X., Mak, T., Yang, M., Jiang, Y., (2013), pp. 1-8. , On self-tuning networks-on-chip for dynamic network-flow dominance adaptation, in: Proc. 7th Int'l Symp. Networks-on-Chip (NoCS); Kahng, A.B., Lin, B., Nath, S., ORION3.0: a comprehensive NoC router estimation tool (2015) IEEE Embedded Syst. Lett., 7 (2), pp. 41-45; Sun, C., (2012), pp. 201-210. , DSENT - a tool connecting emerging photonics with electronics for opto-electronic networks-on-chip modeling, in: Proc. 6th Int'l Symp. Networks-on-Chip (NoCS); Stillmaker, A., Baas, B., Scaling equations for the accurate prediction of CMOS device performance from 180 nm to 7 nm (2017) Integr. VLSI J., 58, pp. 74-81","Yang, M.; Department of Electrical and Computer Engineering, United States; email: mei.yang@unlv.edu",,,"Elsevier B.V.",,,,,13837621,,JSARF,,"English","J Syst Archit",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85127526041
"Elangovan R., Jain S., Raghunathan A.","57221280605;57209870103;7005407504;","Ax-BxP: Approximate Blocked Computation for Precision-reconfigurable Deep Neural Network Acceleration",2022,"ACM Transactions on Design Automation of Electronic Systems","27","3","28","","",,,"10.1145/3492733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127430727&doi=10.1145%2f3492733&partnerID=40&md5=2ab5ddd0fdac33f0470748bf3d1fb134","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States; IBM T.J. Watson Research Center, Yorktown Heights, NY, United States","Elangovan, R., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States; Jain, S., IBM T.J. Watson Research Center, Yorktown Heights, NY, United States; Raghunathan, A., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States","Precision scaling has emerged as a popular technique to optimize the compute and storage requirements of Deep Neural Networks (DNNs). Efforts toward creating ultra-low-precision (sub-8-bit) DNNs for efficient inference suggest that the minimum precision required to achieve a given network-level accuracy varies considerably across networks, and even across layers within a network. This translates to a need to support variable precision computation in DNN hardware. Previous proposals for precision-reconfigurable hardware, such as bit-serial architectures, incur high overheads, significantly diminishing the benefits of lower precision. We propose Ax-BxP, a method for approximate blocked computation wherein each multiply-accumulate operation is performed block-wise (a block is a group of bits), facilitating re-configurability at the granularity of blocks. Further, approximations are introduced by only performing a subset of the required block-wise computations to realize precision re-configurability with high efficiency. We design a DNN accelerator that embodies approximate blocked computation and propose a method to determine a suitable approximation configuration for any given DNN. For the AlexNet, ResNet50, and MobileNetV2 DNNs, Ax-BxP achieves improvement in system energy and performance, respectively, over an 8-bit fixed-point (FxP8) baseline, with minimal loss (<1% on average) in classification accuracy. Further, by varying the approximation configurations at a finer granularity across layers and data-structures within a DNN, we achieve improvement in system energy and performance, respectively. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Approximate computing; Precision-reconfigurable DNN acceleration","Digital storage; Network layers; Reconfigurable architectures; Reconfigurable hardware; Approximate computing; Configurability; Lower precision; Network level; Precision-reconfigurable deep neural network acceleration; Reconfigurable; Scalings; Storage requirements; System energy; Systems performance; Deep neural networks",,,,,"Semiconductor Research Corporation, SRC; Defense Advanced Research Projects Agency, DARPA","This work was supported by C-BRIC, one of six centers in JUMP, a Semiconductor Research Corporation (SRC) program, sponsored by DARPA. Authors’ addresses: R. Elangovan and A. Raghunathan, School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; emails: {elangovr, raghunathan}@purdue.edu; S. Jain, IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; email: shubham.jain35@ibm.com.",,,,,,,,,,"Chen, J.X., The evolution of computing: AlphaGo (2016) Comput. Sci. Eng., 18 (4), pp. 4-7. , 2016; Amodei, D., Brown, T., (2020) Language Models Are Few-shot Learners; Tan, M., Le, Q., EfficientNet: Rethinking model scaling for convolutional neural networks (2019) Proceedings of the 36th International Conference on Machine Learning., pp. 6105-6114; Venkataramani, S., Roy, K., Raghunathan, A., Efficient embedded learning for IoT devices (2016) Proceedings of the Asia and South Pacific Design Automation Conference (ASP-DAC)., pp. 308-311; Sze, V., Chen, Y., Yang, T., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. IEEE, 105 (12), pp. 2295-2329. , Dec. 2017; Hyun, D., Jouppi, N.P., In-datacenter performance analysis of a tensor processing unit (2017) SIGARCH Comput. Archit. News, 45 (2). , https://doi.org/10.1145/3140659.3080246, 2017; Wang, K., Liu, Z., Lin, Y., Lin, J., Han, S., HAQ: Hardware-Aware automated quantization with mixed precision (2019) Proceedings of the Conference on Computer Vision and Pattern Recognition; Mishra, A., Nurvitadhi, E., Cook, J.J., Marr, D., (2017) WRPN: Wide Reduced-precision Networks; Zhou, S., Wang, Y., Wen, H., He, Q., Zou, Y., Balanced quantization: An effective and efficient approach to quantized neural networks (2017) J. Comput. Sci. Technol., 32 (4). , 2017; Choi, J., Wang, Z., Venkataramani, S., Pierce Chuang, I.-J., Srinivasan, V., Gopalakrishnan, K., (2018) Pact: Parameterized Clipping Activation for Quantized Neural Networks; Jain, S., Venkataramani, S., Srinivasan, V., Choi, J., Gopalakrishnan, K., Chang, L., BiScaled-DNN: Quantizing long-tailed datastructures with two scale factors for deep neural networks (2019) Proceedings of the 56th ACM/IEEE Design Automation Conference (DAC)., pp. 1-6; Judd, P., Albericio, J., Hetherington, T., Aamodt, T.M., Enright Jerger, N., Moshovos, A., Proteus: Exploiting numerical precision variability in deep neural networks (2016) Proceedings of the International Conference on Supercomputing; Hashemi, S., Anthony, N., Tann, H., Iris Bahar, R., Reda, S., Understanding the impact of precision quantization on the accuracy and energy of neural networks (2017) Proceedings of the Design, Automation, and Test in Europe Conference; Umuroglu, Y., Rasnayake, L., Sjalander, M., Bismo: A scalable bit-serial matrix multiplication overlay for reconfigurable computing (2018) Proceedings of the 28th International Conference on Field Programmable Logic and Applications (FPL)., pp. 3007-3077; Judd, P., Albericio, J., Hetherington, T., Aamodt, T.M., Moshovos, A., Stripes: Bit-serial deep neural network computing (2016) Proceedings of the IEEE/ACM International Symposium on Microarchitecture. IEEE; Sharify, S., Delmas Lascorz, A., Siu, K., Judd, P., Moshovos, A., Loom: Exploiting weight and activation precisions to accelerate convolutional neural networks (2018) Proceedings of the Design Automation Conference. ACM; Sharma, H., Park, J., Suda, N., Lai, L., Chau, B., Kyung Kim, J., Chandra, V., Esmaeilzadeh, H., Bit fusion: Bit-level dynamically composable architecture for accelerating deep neural networks (2018) Proceedings of the Annual International Symposium on Computer Architecture; Camus, V., Mei, L., Enz, C., Verhelst, M., Reviewand benchmarking of precision-scalable multiply-accumulate unit architectures for embedded neural-network processing (2019) IEEE J. Emerg. Select. Topics Circ. Syst., 9 (4), pp. 697-711. , http://dx.doi.org/10.1109/JETCAS.2019.2950386, 2019; Venkataramani, S., Ranjan, A., Roy, K., Raghunathan, A., AxNN: Energy-efficient neuromorphic systems using approximate computing (2014) Proceedings of the International Symposium on Low Power Electronics and Design, p. 2732; Chippa, V.K., Venkataramani, S., Chakradhar, S.T., Roy, K., Raghunathan, A., Approximate computing: An integrated hardware approach (2013) Proceedings of the Asilomar Conference on Signals, Systems and Computers., pp. 111-117. , http://dx.doi.org/10.1109/ACSSC.2013.6810241; Hartley, R.I., Parhi, K.K., (1995) Digit-serial Computation, , https://doi.org/10.1007/978-1-4615-2327-7, Springer, Boston, MA; Zhou, S., (2016) DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients; Samajdar, A., Zhu, Y., Whatmough, P., Mattina, M., Krishna, T., (2019) SCALE-Sim: Systolic CNN Accelerator; Muralimanohar, N., Balasubramonian, R., Jouppi, N.P., (2009) CACTI 6. 0: A Tool to Model Large Caches, , Technical Report. HP Laboratories; Wang, K., Liu, Z., Lin, Y., Lin, J., Han, S., (2019), https://github.com/mit-han-lab/haq; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Quantized neural networks: Training neural networks with low precision weights and activations (2017) J. Mach. Learn. Res., 18 (1). , 2017; Li, F., Zhang, B., Liu, B., (2016) Ternary Weight Networks; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., (2016) BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to+1 or-1; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., XNOR-Net: ImageNet classification using binary convolutional neural networks (2016) Computer Vision-ECCV, , Springer; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding (2016) Proceedings of the 4th International Conference on Learning Representations (ICLR), , http://arxiv.org/abs/1510.00149; Jain, S., Venkataramani, S., Srinivasan, V., Choi, J., Chuang, P., Chang, L., Compensated-DNN: Energy efficient low-precision deep neural networks by compensating quantization errors (2018) Proceedings of the 55th ACM/ESDA/IEEE Design Automation Conference (DAC)., pp. 1-6. , http://dx.doi.org/10.1109/DAC.2018.8465893; Liu, Y., Zhang, T., Parhi, K.K., Computation error analysis in digital signal processing systems with overscaled supply voltage (2010) IEEE Trans. Very Large Scale Integ. (VLSI) Syst., 18 (4), pp. 517-526. , 2010; Venkataramani, S., Sabne, A., Kozhikkottu, V., Roy, K., Raghunathan, A., SALSA: Systematic logic synthesis of approximate circuits (2012) Proceedings of the Design Automation Conference 2012., pp. 796-801; Vasicek, Z., Sekanina, L., Evolutionary approach to approximate digital circuits design (2015) IEEE Trans. Evolut. Comput., 19 (3), pp. 432-444. , 2015; Venkatesan, R., Agarwal, A., Roy, K., Raghunathan, A., MACACO: Modeling and analysis of circuits for approximate computing (2011) Proceedings of the IEEE/ACMInternational Conference on Computer-aided Design (ICCAD)., pp. 667-673; Verma, A.K., Brisk, P., Ienne, P., Variable latency speculative addition: A new paradigm for arithmetic circuit design (2008) Proceedings of the Conference on Design, Automation and Test in Europe, p. 12501255; Zhu, N., Ling Goh, W., Zhang, W., Seng Yeo, K., Hui Kong, Z., Design of low-power high-speed truncation-error-tolerant adder and its application in digital signal processing (2010) IEEE Trans. Very Large Scale Integ. (VLSI) Syst., 18 (8). , 2010; Gupta, V., Mohapatra, D., Park, S.P., Raghunathan, A., Roy, K., IMPACT: IMPrecise adders for low-power approximate computing (2011) Proceedings of the IEEE/ACM International Symposium on Low Power Electronics and Design., pp. 409-414; Qiqieh, I., Shafik, R., Tarawneh, G., Sokolov, D., Yakovlev, A., Energy-efficient approximate multiplier design using bit significance-driven logic compression (2017) Proceedings of the Design, Automation Test in Europe Conference Exhibition (DATE)., pp. 7-12; Kulkarni, P., Gupta, P., Ercegovac, M., Trading accuracy for power with an underdesigned multiplier architecture (2011) Proceedings of the 24th Internatioal Conference on VLSI Design., pp. 346-351; Lin, C., Lin, I., High accuracy approximate multiplier with error correction (2013) Proceedings of the IEEE 31st International Conference on Computer Design (ICCD)., pp. 33-38; Bulic Uroš Lotric, P., Applicability of approximate multipliers in hardware neural networks (2012) Neurocomputing, 96, pp. 57-65. , 2012; Shakib Sarwar, S., Venkataramani, S., Ankit, A., Raghunathan, A., Roy, K., Energyefficient neural computing with approximate multipliers (2018) Journal on Emerging Technologies in Computing Systems, , https://doi.org/10.1145/3097264; Park, J., Choo, H., Muhammad, K., Choi, S., Im, Y., Roy, K., Non-adaptive and adaptive filter implementation based on sharing multiplication (2000) Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing; Yin Kyaw, K., Ling Goh, W., Seng Yeo, K., Low-power high-speed multiplier for error-tolerant application (2010) Proceedings of the IEEE International Conference of Electron Devices and Solid-State Circuits (EDSSC)., pp. 1-4; Schulte, M.J., Swartzlander, E.E., Truncated multiplication with correction constant [for DSP] (1993) Proceedings of the IEEE Workshop on VLSI Signal Processing., pp. 388-396; Kidambi, S.S., El-Guibaly, F., Antoniou, A., Area-efficient multipliers for digital signal processing applications (1996) IEEE Trans. Circ. Syst. II: Analog Dig. Sig. Process., 43 (2), pp. 90-95. , 1996; Min Jou, J., Rong Kuang, S., Der Chen, R., Design of low-error fixed-width multipliers for DSP applications (1999) IEEE Trans. Circ. Syst. II: Analog Dig. Sig. Process., 46 (6), pp. 836-842. , 1999; Narayanamoorthy, S., Moghaddam, H.A., Liu, Z., Park, T., Kim, N.S., Energy-efficient approximate multiplication for digital signal processing and classification applications (2015) IEEE Trans. Very Large Scale Integ. (VLSI) Syst., 23 (6), pp. 1180-1184. , 2015; Hashemi, S., Bahar, R.I., Reda, S., DRUM: A dynamic range unbiased multiplier for approximate applications (2015) Proceedings of the IEEE/ACM International Conference on Computer-aided Design (ICCAD)., pp. 418-425; Zervakis, G., Tsoumanis, K., Xydis, S., Soudris, D., Pekmestzi, K., Design-efficient approximate multiplication circuits through partial product perforation (2016) IEEE Trans. Very Large Scale Integ. (VLSI) Syst., 24 (10), pp. 3105-3117. , 2016; Tong, J.Y.F., Nagle, D., Rutenbar, R.A., Reducing power by optimizing the necessary precision/range of floating-point arithmetic (2000) IEEE Trans. Very Large Scale Integ. (VLSI) Syst., 8 (3), pp. 273-286. , 2000",,,,"Association for Computing Machinery",,,,,10844309,,,,"English","ACM Trans. Design Autom. Electron. Syst.",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85127430727
"Krishnan G., Mandal S.K., Chakrabarti C., Seo J.-S., Ogras U.Y., Cao Y.","57220522325;57204963201;35554384700;7401783933;9038580800;57221839449;","Impact of On-chip Interconnect on In-memory Acceleration of Deep Neural Networks",2022,"ACM Journal on Emerging Technologies in Computing Systems","18","2","34","","",,,"10.1145/3460233","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129769451&doi=10.1145%2f3460233&partnerID=40&md5=14eabc66dc7a46a282b324930ee3c10b","Arizona State University, School of Electrical Computer and Energy Engineering, Tempe, AZ  85287, United States; University of Wisconsin-Madison, Department of Electrical and Computer Engineering, Madison, WI  53706, United States","Krishnan, G., Arizona State University, School of Electrical Computer and Energy Engineering, Tempe, AZ  85287, United States; Mandal, S.K., University of Wisconsin-Madison, Department of Electrical and Computer Engineering, Madison, WI  53706, United States; Chakrabarti, C., Arizona State University, School of Electrical Computer and Energy Engineering, Tempe, AZ  85287, United States; Seo, J.-S., Arizona State University, School of Electrical Computer and Energy Engineering, Tempe, AZ  85287, United States; Ogras, U.Y., University of Wisconsin-Madison, Department of Electrical and Computer Engineering, Madison, WI  53706, United States; Cao, Y., Arizona State University, School of Electrical Computer and Energy Engineering, Tempe, AZ  85287, United States","With the widespread use of Deep Neural Networks (DNNs), machine learning algorithms have evolved in two diverse directions - one with ever-increasing connection density for better accuracy and the other with more compact sizing for energy efficiency. The increase in connection density increases on-chip data movement, which makes efficient on-chip communication a critical function of the DNN accelerator. The contribution of this work is threefold. First, we illustrate that the point-to-point (P2P)-based interconnect is incapable of handling a high volume of on-chip data movement for DNNs. Second, we evaluate P2P and network-on-chip (NoC) interconnect (with a regular topology such as a mesh) for SRAM- and ReRAM-based in-memory computing (IMC) architectures for a range of DNNs. This analysis shows the necessity for the optimal interconnect choice for an IMC DNN accelerator. Finally, we perform an experimental evaluation for different DNNs to empirically obtain the performance of the IMC architecture with both NoC-tree and NoC-mesh. We conclude that, at the tile level, NoC-tree is appropriate for compact DNNs employed at the edge, and NoC-mesh is necessary to accelerate DNNs with high connection density. Furthermore, we propose a technique to determine the optimal choice of interconnect for any given DNN. In this technique, we use analytical models of NoC to evaluate end-to-end communication latency of any given DNN. We demonstrate that the interconnect optimization in the IMC architecture results in up to 6 × improvement in energy-delay-area product for VGG-19 inference compared to the state-of-the-art ReRAM-based IMC architectures. © 2021 Association for Computing Machinery.","connection density; deep neural networks; DNN acceleration; In-memory computing; machine learning; network-on-chip; RRAM","Energy efficiency; Forestry; Learning algorithms; Memory architecture; Mesh generation; Network architecture; Network-on-chip; Peer to peer networks; RRAM; Servers; Static random access storage; Connection density; Critical functions; Data movements; Deep neural network acceleration; In-memory computing; Machine learning algorithms; On chip communication; On-chip interconnects; On-chip-data; P2P-based; Deep neural networks",,,,,"Semiconductor Research Corporation, SRC; Defense Advanced Research Projects Agency, DARPA","Gokul Krishnan and Sumit K. Mandal have equal contributions. This work was supported by C-BRIC, one of six centers in JUMP, a Semiconductor Research Corporation (SRC) program sponsored by DARPA, and SRC GRC Task 3012.001. Authors’ addresses: G. Krishnan, C. Chakrabarti, J.-S. Seo, and Y. Cao, Arizona State University, School of Electrical, Computer, and Energy Engineering, Tempe, AZ, 85287; emails: {gkrish19, chaitali, jseo28, Yu.Cao}@asu.edu; S. K. Mandal and U. Y. Ogras, University of Wisconsin-Madison, Department of Electrical and Computer Engineering, Madison, WI, 53706; emails: {skmandal, uogras}@wisc.edu. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2021 Association for Computing Machinery. 1550-4832/2021/12-ART34 $15.00 https://doi.org/10.1145/3460233",,,,,,,,,,"Agarwal, N., Krishna, T., Peh, L., Jha, N.K., GARNET: A detailed on-chip network model inside a full-system simulator (2009) Ieee International Symposium on Performance Analysis of Systems and Software (ISPASS)., pp. 33-42; Bhat, G., Deb, R., Vardhan Chaurasia, V., Shill, H., Ogras, U.Y., Online human activity recognition using low-power wearable devices (2018) IEEE/ACM International Conference on Computer-Aided Design (ICCAD)., pp. 1-8; Chen, P., Peng, X., Yu, S., NeuroSim: A circuit-level macromodel for benchmarking neuroinspired architectures in online learning (2018) Ieee Trans. Comput.-Aid. Des. Integ. Circ. Syst., 37 (12), pp. 3067-3080. , 2018; Chen, Y., Yang, T., Emer, J., Sze, V., Eyeriss v2: A flexible accelerator for emerging deep neural networks on mobile devices (2019) Ieee J. Emerg. Select. Topics Circ. Syst., 9 (2), pp. 292-308. , 2019; Deng, L., Hinton, G., Kingsbury, B., New types of deep neural network learning for speech recognition and related applications: An overview (2013) Ieee International Conference on Acoustics, Speech and Signal Processing., pp. 8599-8603; Dong, X., Xu, C., Xie, Y., Jouppi, N.P., NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory (2012) Ieee Trans. Comput.-Aid. Des. Integ. Circ. Syst., 31 (7), pp. 994-1007. , 2012; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Ieee Conference on Computer Vision and Pattern Recognition., pp. 770-778; Horowitz, M., Computing's energy problem (and what we can do about it) (2014) Ieee International Solid-State Circuits Conference Digest of Technical Papers (ISSCC)., pp. 10-14; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Ieee Conference on Computer Vision and Pattern Recognition., pp. 4700-4708; Jeffers, J., Reinders, J., Sodani, A., (2016) Intel Xeon Phi Processor High Performance Programming: Knights Landing Edition., , Morgan Kaufmann; Jiang, N., Becker, D.U., Michelogiannakis, G., Balfour, J., Towles, B., Shaw, D.E., Kim, J., Dally, W.J., A detailed and flexible cycle-Accurate network-on-chip simulator (2013) Ieee International Symposium on Performance Analysis of Systems and Software (ISPASS)., pp. 86-96; Jiang, Z., Yin, S., Seo, J., Seok, M., C3SRAM: An in-memory-computing SRAM macro based on robust capacitive coupling computing mechanism (2020) Ieee J. Solid-State Circ., 55 (7), pp. 1888-1897. , 2020; Khwa, W., Chen, J., Li, J., Si, X., Yang, E., Sun, X., Liu, R., Chang, M., A 65 nm 4 Kb algorithm-dependent computing-in-memory SRAM unit-macro with 2.3 ns and 55.8 TOPS/W fully parallel product-sum operation for binary DNN edge processors (2018) Ieee International Solid-State Circuits Conference (ISSCC)., pp. 496-498; Eslami Kiasari, A., Lu, Z., Jantsch, A., An analytical latency model for networks-on-chip (2012) Ieee Trans. Very Large Scale Integ. Syst., 21 (1), pp. 113-123. , 2012; Krishnan, G., Mandal, S.K., Chakrabarti, C., Seo, J., Ogras, U.Y., Cao, Y., Interconnectaware area and energy optimization for in-memory acceleration of DNNs (2020) Ieee Des. Test, 37 (6), pp. 79-87. , 2020; Krizhevsky, A., Sutskever, I., Geoffrey, E.Hinton, Imagenet classificationwith deep convolutional neural networks (2012) Conference on Advances in Neural Information Processing Systems., pp. 1097-1105; Kwon, H., Samajdar, A., Krishna, T., MAERI: Enabling flexible dataflow mapping over DNN accelerators via reconfigurable interconnects (2018) Acm Sigplan Notices, 53, pp. 461-475; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. Ieee, 86 (11), pp. 2278-2324. , 1998; Lin, M., Chen, Q., Yan, S., (2013) Network in Network., , 2013; Litjens, G., Kooi, T., Ehteshami Bejnordi, B., Arindra Adiyoso, A., Ghafoorian, M., Van Der Laak, J.A., Van Ginneken, B., Sánchez, C.I., A survey on deep learning in medical image analysis (2017) Med. Image Anal., 42, pp. 60-88. , 2017; Mandal, S.K., Ayoub, R., Kishinevsky, M., Islam, M.M., Ogras, U.Y., Analytical performance modeling of NoCs under priority arbitration and bursty traffic (2021) Ieee Embed. Syst. Lett., 13 (3), pp. 98-101. , 2021; Mandal, S.K., Ayoub, R., Kishinevsky, M., Ogras, U.Y., Analytical performance models for NoCs with multiple priority traffic classes (2019) Acm Trans. Embed. Comput. Syst., 18 (5 S), pp. 1-21. , 2019; Mandal, S.K., Krishnan, G., Chakrabarti, C., Seo, J., Cao, Y., Ogras, U.Y., A latencyoptimized reconfigurable NoC for in-memory acceleration of DNNs (2020) Ieee J. Emerg. Select. Topics Circ. Syst., 10 (3), pp. 362-375. , 2020; Mao, M., Peng, X., Liu, R., Li, J., Yu, S., Chakrabarti, C., MAX2: An ReRAMbased neural network accelerator that maximizes data reuse and area utilization (2019) Ieee J. Emerg. Select. Topics Circ. Syst., 9 (2), pp. 398-410. , 2019; Mirza-Aghatabar, M., Koohi, S., Hessabi, S., Pedram, M., An empirical investigation of mesh and torus NoC topologies under different routing algorithms and traffic models (2007) 10th Euromicro Conference on Digital System Design Architectures, Methods and Tools (DSD'07)., pp. 19-26; Morteza Nabavinejad, S., Baharloo, M., Chen, K., Palesi, M., Kogel, T., Ebrahimi, M., An overview of efficient interconnection networks for deep neural network accelerators (2020) Ieee J. Emerg. Select. Topics Circ. Syst., 10 (3), pp. 268-282. , 2020; Ogras, U.Y., Bogdan, P., Marculescu, R., An analytical approach for network-on-chip performance analysis (2010) Ieee Trans. Comput.-Aid. Des. Integ. Circ. Syst., 29 (12), pp. 2001-2013. , 2010; Peng, X., Kim, M., Sun, X., Yin, S., Rakshit, T., Hatcher, R.M., Kittl, J.A., Yu, S., Inference engine benchmarking across technological platforms from CMOS to RRAM (2019) International Symposium on Memory Systems., pp. 471-479; Qian, Z., Juan, D., Bogdan, P., Tsui, C., Marculescu, D., Marculescu, R., A support vector regression (SVR)-based latency model for network-on-chip (NoC) architectures (2015) Ieee Trans. Comput.-Aid. Des. Integ. Circ. Syst., 35 (3), pp. 471-484. , 2015; Qiao, X., Cao, X., Yang, H., Song, L., Li, H., AtomLayer: A universal ReRAM-based CNN accelerator with atomic layer computation (2018) IEEE/ACM Design Automation Conference; Shafiee, A., Nag, A., Muralimanohar, N., Balasubramonian, R., Paul Strachan, J., Hu, M., StanleyWilliams, R., Srikumar, V., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) 43rd International Symposium on Computer Architecture; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition., , 2014; Song, L., Qian, X., Li, H., Chen, Y., PipeLayer: A pipelined ReRAM-based accelerator for deep learning (2017) Ieee International Symposium on High Performance Computer Architecture (HPCA)., pp. 541-552; Venkataramani, S., Ranjan, A., Banerjee, S., Das, D., Avancha, S., Jagannathan, A., Durg, A., Raghunathan, A., ScaleDeep: A scalable compute architecture for learning and evaluating deep networks (2017) Acm Sigarch Comput. Archit. News, 45, p. 2. , 2017; Xie, S., Kirillov, A., Girshick, R., He, K., Exploring randomly wired neural networks for image recognition (2019) Ieee International Conference on Computer Vision., pp. 1284-1293; Yin, S., Jiang, Z., Kim, M., Gupta, T., Seok, M., Seo, J., Vesti: Energy-efficient in-memory computing accelerator for deep neural networks (2019) Ieee Trans. Very Large Scale Integ. Syst., 28 (1), pp. 48-61. , 2019; Zhu, Z., Sun, H., Qiu, K., Xia, L., Krishnan, G., Dai, G., Niu, D., Yang, H., MNSIM 2.0: A behavior-level modeling tool for memristor-based neuromorphic computing systems (2020) Great Lakes Symposium on VLSI., pp. 83-88; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., Learning transferable architectures for scalable image recognition (2018) Ieee Conference on Computer Vision and Pattern Recognition., pp. 8697-8710",,,,"Association for Computing Machinery",,,,,15504832,,,,"English","ACM J. Emerg. Technologies Comput. Syst.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85129769451
"Albanese A., Nardello M., Brunelli D.","57216363022;57197767089;22233293600;","Low-power deep learning edge computing platform for resource constrained lightweight compact UAVs",2022,"Sustainable Computing: Informatics and Systems","34",,"100725","","",,,"10.1016/j.suscom.2022.100725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126677037&doi=10.1016%2fj.suscom.2022.100725&partnerID=40&md5=4e7f2ec9e53734c48ffadc219e2595e6","Department of Industrial Engineering, University of Trento, Via Sommarive 9, Trento, 38123, Italy","Albanese, A., Department of Industrial Engineering, University of Trento, Via Sommarive 9, Trento, 38123, Italy; Nardello, M., Department of Industrial Engineering, University of Trento, Via Sommarive 9, Trento, 38123, Italy; Brunelli, D., Department of Industrial Engineering, University of Trento, Via Sommarive 9, Trento, 38123, Italy","Unmanned Aerial Vehicles (UAVs), which can operate autonomously in dynamic and complex environments, are becoming increasingly common. Deep learning techniques for motion control have recently taken a major qualitative step since vision-based inference tasks can be executed directly on edge. The goal is to fully integrate the machine learning (ML) element into small UAVs. However, given the limited payload capacity and energy available on small UAVs, integrating computing resources sufficient to host ML and vehicle control functions is still challenging. This paper presents a modular and generic system that can control the UAV by evaluating vision-based ML tasks directly inside the resource-constrained UAV. Two different vision-based navigation configurations were tested and demonstrated. The first configuration implements an autonomous landing site detection system, tested with two models based on LeNet-5 and MobileNetV2, respectively. This allows the UAV to change its planned path accordingly and approach the target to land. Moreover, a model for people detection based on a custom MobileNetV2 network was evaluated in the second configuration. Finally, the execution time and power consumption were measured and compared with a cloud computing approach. The results show the ability of the developed system to dynamically react to the environment to provide the necessary maneuver after detecting the target exploiting only the constrained computational resources of the UAV controller. Furthermore, we demonstrated that moving to the edge, instead of using cloud computing inference, decreases the energy requirement of the system without reducing the quality of service. © 2022 Elsevier Inc.","Deep Neural Networks; Edge inference; Sustainable computing; UAV; Visual navigation","Aircraft control; Aircraft detection; Antennas; Control system synthesis; Deep neural networks; Edge computing; Low power electronics; Quality of service; Cloud-computing; Computing platform; Dynamic environments; Edge computing; Edge inference; Low Power; Small unmanned aerial vehicles; Sustainable computing; Vision based; Visual Navigation; Unmanned aerial vehicles (UAV)",,,,,"2018-2022","All authors approved the version of the manuscript to be published. This work was supported by the Italian Ministry for University and Research (MUR) under the program “Dipartimenti di Eccellenza (2018-2022)”.",,,,,,,,,,"Bejiga, M.B., Zeggada, A., Nouffidj, A., Melgani, F., A convolutional neural network approach for assisting avalanche search and rescue operations with UAV imagery (2017) Remote Sens., 9 (2). , https://www.mdpi.com/2072-4292/9/2/100, URL; Lygouras, E., Santavas, N., Taitzoglou, A., Tarchanidis, K., Mitropoulos, A., Gasteratos, A., Unsupervised human detection with an embedded vision system on a fully autonomous UAV for search and rescue operations (2019) Sensors, 19 (16). , https://www.mdpi.com/1424-8220/19/16/3542, URL; Leduc, M.-B., Knudby, A.J., Mapping wild leek through the forest canopy using a UAV (2018) Remote Sens., 10 (1). , https://www.mdpi.com/2072-4292/10/1/70, URL; Zhang, Y., Zhang, Y., Yu, Z., A solution for searching and monitoring forest fires based on multiple UAVs (2019) 2019 International Conference on Unmanned Aircraft Systems (ICUAS), pp. 661-666; Angel, Y., Morton, M., Malbeteau, Y., Negrão, S.S.C., Fiene, G.M., Mousa, M.A.A., Tester, M., McCabe, M., Multitemporal monitoring of phenotypic traits in wild tomato species (s. pimpinellifolium) using UAV-based hyperspectral imagery (2019) AGU Fall Meeting Abstracts, Vol. 2019, pp. B31K-2415; Vanegas, F., Bratanov, D., Powell, K., Weiss, J., Gonzalez, F., A novel methodology for improving plant pest surveillance in vineyards and crops using UAV-based hyperspectral and spatial data (2018) Sensors, 18 (1). , https://www.mdpi.com/1424-8220/18/1/260, URL; Kaivosoja, J., Hautsalo, J., Heikkinen, J., Hiltunen, L., Ruuttunen, P., Näsi, R., Niemeläinen, O., Salonen, J., Reference measurements in developing UAV systems for detecting pests, weeds, and diseases (2021) Remote Sens., 13 (7). , https://www.mdpi.com/2072-4292/13/7/1238, URL; Tetila, E.C., Machado, B.B., Astolfi, G., de Souza Belete, N.A., Amorim, W.P., Roel, A.R., Pistori, H., Detection and classification of soybean pests using deep learning with UAV images (2020) Comput. Electron. Agric., 179. , https://www.sciencedirect.com/science/article/pii/S016816991831055X, URL; Qi, F., Zhu, X., Mang, G., Kadoch, M., Li, W., UAV network and IoT in the sky for future smart cities (2019) IEEE Netw., 33 (2), pp. 96-101; Tiurlikova, A., Stepanov, N., Mikhaylov, K., Improving the energy efficiency of a LoRaWAN by a UAV-based gateway (2019) 2019 11th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT), pp. 1-6; Nazib, R.A., Moh, S., Energy-efficient and fast data collection in UAV-aided wireless sensor networks for hilly terrains (2021) IEEE Access, 9, pp. 23168-23190; Vijayanandh, R., Darshan Kumar, J., Senthil Kumar, M., Ahilla Bharathy, L., Raj Kumar, G., Design and fabrication of solar powered unmanned aerial vehicle for border surveillance (2019) Proceedings of International Conference on Remote Sensing for Disaster Management, pp. 61-71. , Rao P.J. Rao K.N. Kubo S. Springer International Publishing Cham; Laouira, M.L., Abdelli, A., Othman, J.B., Kim, H., An efficient WSN based solution for border surveillance (2021) IEEE Trans. Sustain. Comput., 6 (1), pp. 54-65; Granelli, F., Sacchi, C., Bassoli, R., Cohen, R., Ashkenazi, I., A dynamic and flexible architecture based on UAVS for border security and safety (2020) Advanced Technologies for Security Applications, pp. 295-306. , Palestini C. Springer Netherlands Dordrecht; Kalatzis, N., Avgeris, M., Dechouniotis, D., Papadakis-Vlachopapadopoulos, K., Roussaki, I., Papavassiliou, S., Edge computing in IoT ecosystems for UAV-enabled early fire detection (2018) 2018 IEEE International Conference on Smart Computing (SMARTCOMP), pp. 106-114; Boursianis, A.D., Papadopoulou, M.S., Diamantoulakis, P., Liopa-Tsakalidi, A., Barouchas, P., Salahas, G., Karagiannidis, G., Goudos, S.K., Internet of things (IoT) and agricultural unmanned aerial vehicles (UAVs) in smart farming: A comprehensive review (2020) Internet Things, , https://www.sciencedirect.com/science/article/pii/S2542660520300238, URL; Zhao, N., Lu, W., Sheng, M., Chen, Y., Tang, J., Yu, F.R., Wong, K.-K., UAV-assisted emergency networks in disasters (2019) IEEE Wirel. Commun., 26 (1), pp. 45-51; Radoglou-Grammatikis, P., Sarigiannidis, P., Lagkas, T., Moscholios, I., A compilation of UAV applications for precision agriculture (2020) Comput. Netw., 172. , https://www.sciencedirect.com/science/article/pii/S138912862030116X, URL; Ayyappaa, N., Raj, A.Y., Adithya, A., Murali, R., Vinodh, A., Autonomous drone for efficacious blood conveyance (2019) 2019 4th International Conference on Robotics and Automation Engineering (ICRAE), pp. 99-103; Song, B.D., Park, K., Kim, J., Persistent UAV delivery logistics: MILP formulation and efficient heuristic (2018) Comput. Ind. Eng., 120, pp. 418-428. , https://www.sciencedirect.com/science/article/pii/S0360835218302146, URL; Falanga, D., Zanchettin, A., Simovic, A., Delmerico, J., Scaramuzza, D., Vision-based autonomous quadrotor landing on a moving platform (2017) 2017 IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR), pp. 200-207; Sadeghi, F., Levine, S., CAD2Rl: Real single-image flight without a single real image (2017); Kim, D.K., Chen, T., Deep neural network for real-time autonomous indoor navigation (2015); Santana, P., Correia, L., Mendonça, R., Alves, N., Barata, J., Tracking natural trails with swarm-based visual saliency (2013) J. Field Robot., 30 (1), pp. 64-86; Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. IEEE, 105 (12), pp. 2295-2329; Carrio, A., Sampedro, C., Rodriguez-Ramos, A., Campoy, P., A review of deep learning methods and applications for unmanned aerial vehicles (2017) J. Sensors, , 2017; Zhu, P., Wen, L., Bian, X., Ling, H., Hu, Q., Vision meets drones: A challenge (2018); Bonomi, F., Milito, R., Zhu, J., Addepalli, S., Fog computing and its role in the internet of things (2012) Proceedings of the First Edition of the MCC Workshop on Mobile Cloud Computing, MCC ’12, pp. 13-16. , Association for Computing Machinery New York, NY, USA; Mohamed, N., Al-Jaroodi, J., Jawhar, I., Noura, H., Mahmoud, S., UAVFog: A UAV-based fog computing for internet of things (2017) 2017 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computed, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI), pp. 1-8; Chen, M., Hao, Y., Li, Y., Lai, C.-F., Wu, D., On the computation offloading at ad hoc cloudlet: architecture and service modes (2015) IEEE Commun. Mag., 53 (6), pp. 18-24; Mohanarajah, G., Hunziker, D., D'Andrea, R., Waibel, M., Rapyuta: A cloud robotics platform (2015) IEEE Trans. Autom. Sci. Eng., 12 (2), pp. 481-493; Chen, W., Liu, B., Huang, H., Guo, S., Zheng, Z., When UAV swarm meets edge-cloud computing: The QoS perspective (2019) IEEE Netw., 33 (2), pp. 36-43; Mukherjee, M., Kumar, V., Lat, A., Guo, M., Matam, R., Lv, Y., Distributed deep learning-based task offloading for UAV-enabled mobile edge computing (2020) IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS), pp. 1208-1212; Callegaro, D., Levorato, M., Optimal edge computing for infrastructure-assisted UAV systems (2021) IEEE Trans. Veh. Technol., 70 (2), pp. 1782-1792; Mahmoud, S., Mohamed, N., Broker architecture for collaborative UAVs cloud computing (2015) 2015 International Conference on Collaboration Technologies and Systems (CTS), pp. 212-219; Satyanarayanan, M., The emergence of edge computing (2017) Computer, 50 (1), pp. 30-39; Petritoli, E., Leccese, F., Leccisi, M., Inertial navigation systems for UAV: Uncertainty and error measurements (2019) 2019 IEEE 5th International Workshop on Metrology for AeroSpace (MetroAeroSpace), pp. 1-5; Woodman, O.J., An Introduction to Inertial Navigation: Tech. Rep. UCAM-CL-TR-696 (2007), https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-696.pdf, University of Cambridge, Computer Laboratory URL; Parkinson, B.W., Stansell, T., Beard, R., Gromov, K., A history of satellite navigation (1995) Navigation, 42 (1), pp. 109-164. , https://onlinelibrary.wiley.com/doi/abs/10.1002/j.2161-4296.1995.tb02333.x, URL; Fauadi, M.H.F.M., Akmal, S., Ali, M.M., Anuar, N.I., Ramlan, S., Noor, A.Z.M., Awang, N., Intelligent vision-based navigation system for mobile robot: A technological review (2018) Period. Eng. Nat. Sci., 6 (2), pp. 47-57; Courbon, J., Mezouar, Y., Guénard, N., Martinet, P., Vision-based navigation of unmanned aerial vehicles (2010) Control Eng. Pract., 18 (7), pp. 789-799. , https://www.sciencedirect.com/science/article/pii/S0967066110000808, Special Issue on Aerial Robotics. URL; Li, S., Ozo, M.M., De Wagter, C., de Croon, G.C., Autonomous drone race: A computationally efficient vision-based navigation and control strategy (2020) Robot. Auton. Syst., 133. , https://www.sciencedirect.com/science/article/pii/S0921889020304619, URL; Choi, S.Y., Cha, D., Unmanned aerial vehicles using machine learning for autonomous flight; state-of-the-art (2019) Adv. Robot., 33 (6), pp. 265-277; Paszkuta, M., Rosner, J., Peszor, D., Szender, M., Wojciechowska, M., Wojciechowski, K., Nowacki, J.P., UAV on-board emergency safe landing spot detection system combining classical and deep learning-based segmentation methods (2021) Asian Conference on Intelligent Information and Database Systems, pp. 467-478. , Springer; Mathur, P., Jangir, Y., Goveas, N., A generalized Kalman filter augmented deep-learning based approach for autonomous landing in MAVs (2021) 2021 International Symposium of Asian Control Association on Intelligent Robotics and Industrial Automation (IRIA), pp. 1-6. , IEEE; Alsalam, B.H.Y., Morton, K., Campbell, D., Gonzalez, F., Autonomous UAV with vision based on-board decision making for remote sensing and precision agriculture (2017) 2017 IEEE Aerospace Conference, pp. 1-12. , IEEE; Lee, J., Wang, J., Crandall, D., Šabanović, S., Fox, G., Real-time, cloud-based object detection for unmanned aerial vehicles (2017) 2017 First IEEE International Conference on Robotic Computing (IRC), pp. 36-43. , IEEE; Koubâa, A., Qureshi, B., Dronetrack: Cloud-based real-time object tracking using unmanned aerial vehicles over the internet (2018) IEEE Access, 6, pp. 13810-13824; Segalla, A., Fiacco, G., Tramarin, L., Nardello, M., Brunelli, D., Neural networks for pest detection in precision agriculture (2020) 2020 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor), pp. 7-12. , IEEE; Albanese, A., Nardello, M., Brunelli, D., Automated pest detection with DNN on the edge for precision agriculture (2021) IEEE J. Emerg. Sel. Top. Circuits Syst., 11 (3), pp. 458-467; Liu, S., Deng, W., Very deep convolutional neural network based image classification using small training sample size (2015) 2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR), pp. 730-734. , IEEE; Jung, S., Hwang, S., Shin, H., Shim, D.H., Perception, guidance, and navigation for indoor autonomous drone racing using deep learning (2018) IEEE Robot. Autom. Lett., 3 (3), pp. 2539-2544; Xie, X., Han, X., Liao, Q., Shi, G., Visualization and pruning of SSD with the base network VGG16 (2017), pp. 90-94. , Proceedings of the 2017 International Conference on Deep Learning Technologies; Lee, S.-H., Yeh, C.-H., Hou, T.-W., Yang, C.-S., A lightweight neural network based on AlexNet-SSD model for garbage detection (2019), pp. 274-278. , Proceedings of the 2019 3rd High Performance Computing and Cluster Technologies Conference; Gu, S., Ding, L., Yang, Y., Chen, X., A new deep learning method based on AlexNet model and SSD model for tennis ball recognition (2017) 2017 IEEE 10th International Workshop on Computational Intelligence and Applications (IWCIA), pp. 159-164. , IEEE; Tijtgat, N., (2017), pp. 2110-2118. , W. Van Ranst, T. Goedeme, B. Volckaert, F. De Turck, Embedded real-time object detection for a UAV warning system, in: Proceedings of the IEEE International Conference on Computer Vision Workshops; Redmon, J., Farhadi, A., YOLO9000: better, faster, stronger (2017), pp. 7263-7271. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Khokhlov, I., Davydenko, E., Osokin, I., Ryakin, I., Babaev, A., Litvinenko, V., Gorbachev, R., Tiny-YOLO object detection supplemented with geometrical data (2020) 2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring), pp. 1-5. , IEEE; Deng, L., Li, G., Han, S., Shi, L., Xie, Y., Model compression and hardware acceleration for neural networks: A comprehensive survey (2020) Proc. IEEE, 108 (4), pp. 485-532; Mishra, R., Gupta, H.P., Dutta, T., A survey on deep neural network compression: Challenges, overview, and solutions (2020), arXiv preprint; Ye, S., Feng, X., Zhang, T., Ma, X., Lin, S., Li, Z., Xu, K., Tang, J., Progressive dnn compression: A key to achieve ultra-high weight pruning and quantization rates using admm (2019), arXiv preprint; Yang, E.-H., Amer, H., Jiang, Y., Compression helps deep learning in image classification (2021) Entropy, 23 (7), p. 881; Hu, Z., Zou, X., Xia, W., Jin, S., Tao, D., Liu, Y., Zhang, W., Zhang, Z., Delta-DNN: Efficiently compressing deep neural networks via exploiting floats similarity (2020) 49th International Conference on Parallel Processing-ICPP, pp. 1-12; Nagel, M., Fournarakis, M., Amjad, R.A., Bondarenko, Y., van Baalen, M., Blankevoort, T., A white paper on neural network quantization (2021), arXiv preprint; Shafique, M., Theocharides, T., Reddy, V.J., Murmann, B., TinyML: Current progress, research challenges, and future roadmap (2021) 2021 58th ACM/IEEE Design Automation Conference (DAC), pp. 1303-1306. , IEEE; Puchtler, P., Peinl, R., Evaluation of deep learning accelerators for object detection at the edge (2020) KI 2020: Advances in Artificial Intelligence, pp. 320-326. , Schmid U. Klügl F. Wolter D. Springer International Publishing Cham; Hossain, S., Lee, D.-J., Deep learning-based real-time multiple-object detection and tracking from aerial imagery via a flying robot with GPU-based embedded devices (2019) Sensors, 19 (15). , https://www.mdpi.com/1424-8220/19/15/3371, URL; Joudat, B., Lighvan, M.Z., The role of machine learning in IIoT through FPGAs (2021) AI-Enabled Threat Detection and Security Analysis for Industrial IoT, pp. 121-137. , Karimipour H. Derakhshan F. Springer International Publishing Cham; Hao, C., Zhang, X., Li, Y., Huang, S., Xiong, J., Rupnow, K., Hwu, W.-M., Chen, D., FPGA/DNN co-design: An efficient design methodology for 1oT intelligence on the edge (2019) 2019 56th ACM/IEEE Design Automation Conference (DAC), pp. 1-6; Wu, R., Guo, X., Du, J., Li, J., Accelerating neural network inference on FPGA-based platforms—A survey (2021) Electronics, 10 (9), p. 1025; Murshed, M., Murphy, C., Hou, D., Khan, N., Ananthanarayanan, G., Hussain, F., Machine learning at the network edge: A survey (2019), arXiv preprint; Murshed, M.G.S., Murphy, C., Hou, D., Khan, N., Ananthanarayanan, G., Hussain, F., Machine learning at the network edge: A survey (2021) ACM Comput. Surv., 54 (8); Kyrkou, C., Plastiras, G., Theocharides, T., Venieris, S.I., Bouganis, C.-S., DroNet: Efficient convolutional neural network detector for real-time UAV applications (2018) 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 967-972. , IEEE; Plastiras, G., Kyrkou, C., Theocharides, T., Edgenet: Balancing accuracy and performance for edge-based convolutional neural network object detectors (2019), pp. 1-6. , Proceedings of the 13th International Conference on Distributed Smart Cameras; Bhardwaj, S., Mittal, A., A survey on various edge detector techniques (2012) Proc. Technol., 4, pp. 220-226. , https://www.sciencedirect.com/science/article/pii/S221201731200312X, URL 2nd International Conference on Computer, Communication, Control and Information Technology( C3IT-2012) on February 25 - 26, 2012; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Guo, T., Dong, J., Li, H., Gao, Y., Simple convolutional neural network on image classification (2017) 2017 IEEE 2nd International Conference on Big Data Analysis (ICBDA)(, pp. 721-724. , IEEE; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., Mobilenetv2: Inverted residuals and linear bottlenecks (2018), pp. 4510-4520. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., Mobilenets: Efficient convolutional neural networks for mobile vision applications (2017), arXiv preprint; Argenteri, F., Enhancing UAV capabilities with machine learning on board (2020), https://github.com/frank1789/MasterThesis, URL; Niu, S., Liu, Y., Wang, J., Song, H., A decade survey of transfer learning (2010–2020) (2020) IEEE Trans. Artif. Intell., 1 (2), pp. 151-166; Da Silva, F.L., Costa, A.H.R., A survey on transfer learning for multiagent reinforcement learning systems (2019) J. Artificial Intelligence Res., 64, pp. 645-703; Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H., He, Q., A comprehensive survey on transfer learning (2021) Proc. IEEE, 109 (1), pp. 43-76","Albanese, A.; Department of Industrial Engineering, Via Sommarive 9, Italy; email: andrea.albanese@unitn.it",,,"Elsevier Inc.",,,,,22105379,,,,"English","Sustainable Computing: Informatics and Systems",Article,"Final","",Scopus,2-s2.0-85126677037
"Nguyen D.-A., Tran X.-T., Dang K.N., Iacopi F.","57206720246;16308138900;57188649063;7004143793;","A low-power, high-accuracy with fully on-chip ternary weight hardware architecture for Deep Spiking Neural Networks",2022,"Microprocessors and Microsystems","90",,"104458","","",,,"10.1016/j.micpro.2022.104458","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124212101&doi=10.1016%2fj.micpro.2022.104458&partnerID=40&md5=2eb544a48da24a896e2a6472d7b352d1","VNU Information Technology Institute - Vietnam National University, Hanoi (VNU), Ha Noi, 123106, Viet Nam; JTIRC, VNU-UET, Viet Nam; VNU Key Laboratory for Smart Integrated Systems (SISLAB), VNU-UET, Vietnam National University, Hanoi (VNU), Ha Noi, 123106, Viet Nam; The University of Technology Sydney, 15 Broadway, Ultimo, NSW 2007, Australia","Nguyen, D.-A., VNU Information Technology Institute - Vietnam National University, Hanoi (VNU), Ha Noi, 123106, Viet Nam, JTIRC, VNU-UET, Viet Nam; Tran, X.-T., VNU Information Technology Institute - Vietnam National University, Hanoi (VNU), Ha Noi, 123106, Viet Nam; Dang, K.N., VNU Key Laboratory for Smart Integrated Systems (SISLAB), VNU-UET, Vietnam National University, Hanoi (VNU), Ha Noi, 123106, Viet Nam; Iacopi, F., The University of Technology Sydney, 15 Broadway, Ultimo, NSW 2007, Australia","Recently, Deep Spiking Neural Network (DSNN) has emerged as a promising neuromorphic approach for various AI-based applications, such as image classification, speech recognition, robotic control etc. on edge computing platforms. However, the state-of-the-art offline training algorithms for DSNNs are facing two major challenges. Firstly, many timesteps are required to reach comparable accuracy with traditional frame-based DNNs algorithms. Secondly, extensive memory requirements for weight storage make it impossible to store all the weights on-chip for DSNNs with many layers. Thus the inference process requires continue access to expensive off-chip memory, ultimately leading to performance degradation in terms of throughput and power consumption. In this work, we propose a hardware-friendly training approach for DSNN that allows the weights to be constrained to ternary format, hence reducing the memory footprints and the energy consumption. Software simulations on MNIST and CIFAR10 datasets have shown that our training approach could reach an accuracy of 97% for MNIST (3-layer fully connected networks) and 89.71% for CIFAR10 (VGG16). To demonstrate the energy efficiency of our approach, we have proposed a neural processing module to implement our trained DSNN. When implemented as a fixed, 3-layers fully-connected system, the system has reached at energy efficiency of 74nJ/image with a classification accuracy of 97% for MNIST dataset. We have also considered a scalable design to support more complex network topologies when we integrate the neural processing module with a 3D Network-on-Chip. © 2022 Elsevier B.V.","Deep Spiking Neural Network; Hardware implementation; Neuromorphic; Ternary-weight quantization","Classification (of information); Complex networks; Deep neural networks; Energy utilization; Low power electronics; Network-on-chip; Speech recognition; Deep spiking neural network; Hardware implementations; Low Power; Neural-networks; Neural-processing; Neuromorphic; On chips; Processing modules; Quantisation; Ternary-weight quantization; Energy efficiency",,,,,"Đại học Quốc gia Hà Nội, ĐHQGHN","This work is partly supported by Vietnam National University, Hanoi (VNU) through research project “Investigate and develop a secure IoT platform” (Secu-IoT).",,,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012), 1, pp. 1097-1105. , Proceedings Of The 25th International Conference On Neural Information Processing Systems, NIPS’12; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015), International Conference On Learning Representations; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016), pp. 770-778. , Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016), pp. 779-788. , Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., Berg, A.C., Ssd: Single shot multibox detector (2016) European Conference On Computer Vision, pp. 21-37. , Springer; Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., Dyer, C., Neural architectures for named entity recognition (2016), arXiv preprint; Hermann, K.M., Kocisky, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman, M., Blunsom, P., Teaching machines to read and comprehend (2015) Advances In Neural Information Processing Systems, pp. 1693-1701; Zhou, B., Lapedriza, A., Xiao, J., Torralba, A., Oliva, A., Learning deep features for scene recognition using places database (2014) Advances In Neural Information Processing Systems, pp. 487-495; Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Yoon, D.H., In-datacenter performance analysis of a tensor processing unit (2017) Proceedings Of The 44th Annual International Symposium On Computer Architecture, ISCA ’17, pp. 1-12. , ACM New York, NY, USA; Chen, Y.H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2017) IEEE J. Solid-State Circ., 52 (1), pp. 127-138; Luo, T., Liu, S., Li, L., Wang, Y., Zhang, S., Chen, T., Xu, Z., Chen, Y., Dadiannao: A neural network supercomputer (2017) IEEE Trans. Comput., 66 (1), pp. 73-88; Ma, Y., Cao, Y., Vrudhula, S., Seo, J., Optimizing the convolution operation to accelerate deep neural networks on FPGA (2018) IEEE Trans. Very Large Scale Integrat. (VLSI) Syst., 26 (7), pp. 1354-1367; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., MobileNets: EFficient convolutional neural networks for mobile vision applications (2017); Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: Efficient inference engine on compressed deep neural network (2016), pp. 243-254. , 2016 ACM/IEEE 43rd Annual International Symposium On Computer Architecture (ISCA); Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Quantized neural networks: Training neural networks with low precision weights and activations (2017) J. Mach. Learn. Res., 18 (1), pp. 6869-6898; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., Xnor-net: ImageNet classification using binary convolutional neural networks (2016) ECCV; Miyashita, D., Lee, E.H., Murmann, B., Convolutional neural networks using logarithmic data representation (2016); Ding, C., Liao, S., Wang, Y., Li, Z., Liu, N., Zhuo, Y., Wang, C., Yuan, B., Circnn: Accelerating and compressing deep neural networks using block-CirculantWeight matrices (2017); Ardakani, A., Leduc-Primeau, F., Onizawa, N., Hanyu, T., Gross, W.J., VLSI implementation of deep neural network using integral stochastic computing (2017) IEEE Trans. Very Large Scale Integrat. (VLSI) Syst., 25 (10), pp. 2688-2699; Gerstner, W., Kistler, W., Spiking Neuron Models: An Introduction (2002), Cambridge University Press New York, NY, USA; Akopyan, F., Sawada, J., Cassidy, A., Alvarez-Icaza, R., Arthur, J., Merolla, P., Imam, N., Modha, D.S., TrueNorth: Design and tool flow of a 65 mW 1 million neuron programmable neurosynaptic chip (2015) IEEE Trans. Comput.-Aided Des. Integrat. Circ. Syst., 34 (10), pp. 1537-1557; Davies, M., Srinivasa, N., Lin, T., Chinya, G., Cao, Y., Choday, S.H., Dimou, G., Wang, H., Loihi: A neuromorphic manycore processor with on-chip learning (2018) IEEE Micro, 38 (1), pp. 82-99; Sengupta, A., Ye, Y., Wang, R., Liu, C., Roy, K., Going deeper in spiking neural networks: VGG and residual architectures (2019) Front. Neurosci., 13, p. 95; Rueckauer, B., Lungu, I.-A., Hu, Y., Pfeiffer, M., Liu, S.-C., Conversion of continuous-valued deep networks to efficient event-driven networks for image classification (2017) Front. Neurosci., 11, p. 682; Diehl, P., Cook, M., Unsupervised learning of digit recognition using spike-timing-dependent plasticity (2015) Front. Comput. Neurosci., 9, p. 99; Masquelier, T., Thorpe, S.J., Unsupervised learning of visual features through spike timing dependent plasticity (2007) PLoS Comput. Biol., 3 (2), pp. 1-11; Mozafari, M., Ganjtabesh, M., Nowzari-Dalini, A., Thorpe, S.J., Masquelier, T., Bio-inspired digit recognition using reward-modulated spike-timing-dependent plasticity in deep convolutional networks (2019) Pattern Recognit., 94, pp. 87-95; Cao, Y., Chen, Y., Khosla, D., Spiking deep convolutional neural networks for energy-efficient object recognition (2015) Int. J. Comput. Vis., 113 (1), pp. 54-66; Hu, Y., Tang, H., Wang, Y., Pan, G., Spiking deep residual network (2018), arXiv preprint; Lee, J.H., Delbruck, T., Pfeiffer, M., Training deep spiking neural networks using backpropagation (2016) Front. Neurosci., 10, p. 508; Diehl, P.U., Neil, D., Binas, J., Cook, M., Liu, S., Pfeiffer, M., Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing (2015), pp. 1-8. , 2015 International Joint Conference On Neural Networks (IJCNN); Yin, S., Venkataramanaiah, S.K., Chen, G.K., Krishnamurthy, R., Cao, Y., Chakrabarti, C., Seo, J., Algorithm and hardware design of discrete-time spiking neural networks based on back propagation with binary activations (2017), pp. 1-5. , 2017 IEEE Biomedical Circuits And Systems Conference (BioCAS); Wu, Y., Deng, L., Li, G., Zhu, J., Shi, L., Spatio-temporal backpropagation for training high-performance spiking neural networks (2018) Front. Neurosci., 12, p. 331; Wu, Y., Deng, L., Li, G., Zhu, J., Xie, Y., Shi, L., Direct training for spiking neural networks: Faster, larger, better (2019), 33, pp. 1311-1318. , Proceedings Of The AAAI Conference On Artificial Intelligence; Park, S., Kim, S., Na, B., Yoon, S., T2FSNN: deep spiking neural networks with time-to-first-spike coding (2020) 2020 57th ACM/IEEE Design Automation Conference (DAC), pp. 1-6. , IEEE; Kim, S., Park, S., Na, B., Kim, J., Yoon, S., Towards fast and accurate object detection in bio-inspired spiking neural networks through Bayesian optimization (2020) IEEE Access, 9, pp. 2633-2643; Lee, J., Kim, C., Kang, S., Shin, D., Kim, S., Yoo, H., UNPU: An energy-efficient deep neural network accelerator with fully variable weight bit precision (2019) IEEE J. Solid-State Circ., 54 (1), pp. 173-185; Courbariaux, M., Bengio, Y., David, J.-P., Binaryconnect: Training deep neural networks with binary weights during propagations (2015) Advances In Neural Information Processing Systems, pp. 3123-3131; Li, F., Zhang, B., Liu, B., Ternary weight networks (2016), arXiv preprint; Zhu, C., Han, S., Mao, H., Dally, W.J., Trained ternary quantization (2016), arXiv preprint; Putra, R.V.W., Shafique, M., Fspinn: An optimization framework for memory-efficient and energy-efficient spiking neural networks (2020) IEEE Trans. Comput.-Aided Des. Integrat. Circ. Syst., 39 (11), pp. 3601-3613; Putra, R.V.W., Shafique, M., Q-spinn: A framework for quantizing spiking neural networks (2021) 2021 International Joint Conference On Neural Networks (IJCNN), pp. 1-8. , IEEE; Benjamin, B.V., Gao, P., McQuinn, E., Choudhary, S., Chandrasekaran, A.R., Bussat, J.-M., Alvarez-Icaza, R., Boahen, K., Neurogrid: A mixed-analog-digital multichip system for large-scale neural simulations (2014) Proc. IEEE, 102 (5), pp. 699-716; Furber, S.B., Galluppi, F., Temple, S., Plana, L.A., The spinnaker project (2014) Proc. IEEE, 102 (5), pp. 652-665; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification (2015) Proceedings Of The 2015 IEEE International Conference On Computer Vision (ICCV), ICCV ’15, pp. 1026-1034. , IEEE Computer Society USA; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., Binarized neural networks: Training deep neural networks with weights and activations constrained to +1 or -1 (2016); Bengio, Y., Léonard, N., Courville, A., Estimating or propagating gradients through stochastic neurons for conditional computation (2013), arXiv preprint; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015), pp. 1-9. , 2015 IEEE Conference On Computer Vision And Pattern Recognition (CVPR); Ben Abdallah, A., Dang, K.N., Toward robust cognitive 3D brain-inspired cross-paradigm system (2021) Front. Neurosci., 15, p. 795; Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Chintala, S., Pytorch: An imperative style, high-performance deep learning library (2019) Advances In Neural Information Processing Systems 32, pp. 8024-8035. , Curran Associates, Inc; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: a simple way to prevent neural networks from overfitting (2014) J. Mach. Learn. Res., 15 (1), pp. 1929-1958; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2015), International Conference On Learning Representations (ICLR); http://yann.lecun.com/exdb/mnist/, The MNIST database of handwritten digits, URL; Xiao, H., Rasul, K., Vollgraf, R., Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms (2017); Cohen, G., Afshar, S., Tapson, J., Van Schaik, A., EMNIST: Extending MNIST to handwritten letters (2017) 2017 International Joint Conference On Neural Networks (IJCNN), pp. 2921-2926. , IEEE; Hunsberger, E., Eliasmith, C., Spiking deep networks with LIF neurons (2015), arXiv preprint; Lee, C., Sarwar, S.S., Panda, P., Srinivasan, G., Roy, K., Enabling spike-based backpropagation for training deep neural network architectures (2020) Front. Neurosci., 14, p. 119; Park, S., Kim, S., Choe, H., Yoon, S., Fast and efficient information transmission with burst spikes in deep spiking neural networks (2019), 2019 56th ACM/IEEE Design Automation Conference (DAC); Stillmaker, A., Baas, B., Scaling equations for the accurate prediction of CMOS device performance from 180 nm to 7 nm (2017) Integrat. VLSI J., 58, pp. 74-81. , http://vcl.ece.ucdavis.edu/pubs/2017.02.VLSIintegration.TechScale/; Whatmough, P.N., Lee, S.K., Lee, H., Rama, S., Brooks, D., Wei, G.Y., (2017), pp. 242-243. , 14.3 A 28nm SoC with a 1.2 GHz 568 nJ/prediction sparse deep-neural-network engine with >0.1 timing error rate tolerance for IoT applications, in: 2017 IEEE International Solid-State Circuits Conference (ISSCC); Park, J., Lee, J., Jeon, D., (2019), pp. 140-142. , A 65nm 236.5nJ/classification neuromorphic processor with 7.5 overhead on-chip learning using direct spike-only feedback, in: 2019 IEEE International Solid- State Circuits Conference - (ISSCC); Chuang, P.-Y., Tan, P.-Y., Wu, C.-W., Lu, J.-M., A 90nm 103.14 tops/w binary-weight spiking neural network cmos asic for real-time object classification (2020) 2020 57th ACM/IEEE Design Automation Conference (DAC), pp. 1-6. , IEEE; Frenkel, C., Lefebvre, M., Legat, J., Bol, D., A 0.086-mm2 12.7-pj/SOP 64k-synapse 256-neuron online-learning digital spiking neuromorphic processor in 28-nm CMOS (2019) IEEE Trans. Biomed. Circ. Syst., 13 (1), pp. 145-158; Zheng, N., Mazumder, P., A low-power hardware architecture for on-line supervised learning in multi-layer spiking neural networks (2018), pp. 1-5. , 2018 IEEE International Symposium On Circuits And Systems (ISCAS); Nguyen, D.-A., Bui, D.-H., Iacopi, F., Tran, X.-T., An efficient event-driven neuromorphic architecture for deep spiking neural networks (2019) 2019 32nd IEEE International System-On-Chip Conference (SOCC), pp. 144-149. , IEEE; Muralimanohar, N., Balasubramonian, R., Jouppi, N.P., Cacti 6.0: A tool to model large caches (2009) HP Laborator., 27, p. 28; Agrawal, A., Ali, M., Koo, M., Rathi, N., Jaiswal, A., Roy, K., IMPULSE: A 65-nm digital compute-in-memory macro with fused weights and membrane potential for spike-based sequential learning tasks (2021) IEEE Solid-State Circ. Lett., 4, pp. 137-140; Agrawal, A., Ankit, A., Roy, K., SPARE: Spiking neural network acceleration using ROM-embedded RAMs as in-memory-computation primitives (2019) IEEE Trans. Comput., 68 (8), pp. 1190-1200","Tran, X.-T.; VNU Information Technology Institute - Vietnam National University, Viet Nam; email: tutx@vnu.edu.vn",,,"Elsevier B.V.",,,,,01419331,,MIMID,,"English","Microprocessors Microsyst",Article,"Final","",Scopus,2-s2.0-85124212101
"Saurav S., Saini A.K., Saini R., Singh S.","56340567500;26221927300;57206265011;55740404900;","Deep learning inspired intelligent embedded system for haptic rendering of facial emotions to the blind",2022,"Neural Computing and Applications","34","6",,"4595","4623",,,"10.1007/s00521-021-06613-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117830803&doi=10.1007%2fs00521-021-06613-3&partnerID=40&md5=ff31d4bd7bc4190b4483b813b2837a34","Academy of Scientific & Innovative Research, Uttar Pradesh, Ghaziabad, 201002, India; CSIR-Central Electronics Engineering Research Institute, Rajasthan, Pilani, 333031, India","Saurav, S., Academy of Scientific & Innovative Research, Uttar Pradesh, Ghaziabad, 201002, India, CSIR-Central Electronics Engineering Research Institute, Rajasthan, Pilani, 333031, India; Saini, A.K., CSIR-Central Electronics Engineering Research Institute, Rajasthan, Pilani, 333031, India; Saini, R., Academy of Scientific & Innovative Research, Uttar Pradesh, Ghaziabad, 201002, India, CSIR-Central Electronics Engineering Research Institute, Rajasthan, Pilani, 333031, India; Singh, S., Academy of Scientific & Innovative Research, Uttar Pradesh, Ghaziabad, 201002, India, CSIR-Central Electronics Engineering Research Institute, Rajasthan, Pilani, 333031, India","In our day-to-day social interactions, non-verbal cues such as facial emotions play a vital role. These cues assist people in understanding and inferring the hidden emotional state of the individuals. However, blind and visually impaired persons (VIPs) sadly lack access to such cues, which results in impaired interpersonal communication. To alleviate the issue, in this research, we present a proof-of-concept (POC) implementation of a deep learning-inspired vision-based low-cost intelligent embedded system for the haptic rendering of facial emotions to the VIPs. To this end, a novel lightweight shallow convolutional neural network (CNN) has been designed, optimized, and implemented on a resource-constrained embedded platform for the real-time analysis of facial emotions in static images. We evaluated the model on five benchmark FER datasets, namely CK+, RaFD, SFEW, FER2013, and RAF. Also, for real-time performance, the trained CNN is optimized using TensorRT SDK and deployed on the Nvidia Jetson TX2 embedded platform. Comparative analysis results with state-of-the-art FER techniques confirm the efficacy of the designed CNN that achieves competitive recognition accuracy and runs in real-time at a frame processing speed of 40 fps on the Jetson TX2 embedded device. Finally, the embedded FER platform is integrated with a low-cost and user-friendly haptic device to render emotions to the VIPs in the form of vibration cues. A working demo of the developed FER system is available at https://youtu.be/c73Ledn27dQ. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Convolutional neural networks; Deep learning architectures; Embedded implementation; Facial emotion recognition; Haptic device; Model optimization; Real-time performance","Constrained optimization; Convolution; Convolutional neural networks; Deep neural networks; Embedded systems; Face recognition; Convolutional neural network; Deep learning architecture; Embedded implementation; Emotion recognition; Facial emotion recognition; Facial emotions; Haptic devices; Learning architectures; Model optimization; Real time performance; Costs",,,,,"Central Electronics Engineering Research Institute, CEERI","The authors would like to thank the director, CSIR-CEERI, Pilani, for supporting and encouraging research activities at CSIR-CEERI, Pilani. Constant motivation by the group head, cognitive computing group, CSIR-CEERI is also acknowledged.",,,,,,,,,,"Li, T.H.S., Kuo, P.H., Tsai, T.N., Luan, P.C., Cnn and lstm based facial expression analysis model for a humanoid robot (2019) IEEE Access, 7, pp. 93998-94011; Cao, N.T., Ton-That, A.H., Choi, H.I., An effective facial expression recognition approach for intelligent game systems (2016) Int J Comput Vis Robot, 6 (3), pp. 223-234; Jeong, M., Ko, B.C., Driver’s facial expression recognition in real-time for safe driving (2018) Sensors, 18 (12), p. 4270; Lee, K.W., Yoon, H.S., Song, J.M., Park, K.R., Convolutional neural network-based classification of driver’s emotion during aggressive and smooth driving using multi-modal camera sensors (2018) Sensors, 18 (4), p. 957; Lozano-Monasor, E., López, M.T., Vigo-Bustos, F., Fernández-Caballero, A., Facial expression recognition in ageing adults: from lab to ambient assisted living (2017) J Ambient Intell Hum Comput, 8 (4), pp. 567-578; Zheng, K., Yang, D., Liu, J., Cui, J., Recognition of teachers’ facial expression intensity based on convolutional neural network and attention mechanism (2020) IEEE Access, 8, pp. 226437-226444; Bahreini, K., van der Vegt, W., Westera, W., A fuzzy logic approach to reliable real-time recognition of facial emotions (2019) Multimed Tools Appl, 78 (14), pp. 18943-18966; Bu, Y., Jia, J., Tang, Y., Zang, X., Gao, T., Lookine: Let the blind hear a smile (2018) Thirty-Second AAAI Conference on Artificial Intelligence; Fei, Z., Yang, E., Li, D.D.U., Butler, S., Ijomah, W., Li, X., Zhou, H., Deep convolution network based emotion analysis towards mental health care (2020) Neurocomputing, 388, pp. 212-227; Sivasangari, A., Ajitha, P., Rajkumar, I., Poonguzhali, S., Emotion recognition system for autism disordered people (2019) J Ambient Intell Hum Comput; Vergura, D.T., Luceri, B., Product packaging and consumers’ emotional response. Does spatial representation influence product evaluation and choice? (2018) J Consum Market, 35 (2), p. 10; Bartkiene, E., Steibliene, V., Adomaitiene, V., Juodeikiene, G., Cernauskas, D., Lele, V., Klupsaite, D., Guiné, R.P., Factors affecting consumer food preferences: food taste and depression-based evoked emotional expressions with the use of face reading technology (2019) BioMed Res Int; Meshach, W.T., Hemajothi, S., Anita, E.M., Real-time facial expression recognition for affect identification using multi-dimensional svm (2020) J Ambient Intell Hum Comput, 12 (6), pp. 6355-6365; Shan, C., Gong, S., McOwan, P.W., Facial expression recognition based on local binary patterns: a comprehensive study (2009) Image Vis Comput, 27 (6), pp. 803-816; Saurav, S., Singh, S., Saini, R., Yadav, M., Facial expression recognition using improved adaptive local ternary pattern (2020) Proceedings of 3Rd International Conference on Computer Vision and Image Processing, pp. 39-52. , Springer; Ashir, A.M., Eleyan, A., Akdemir, B., Facial expression recognition with dynamic cascaded classifier (2020) Neural Comput Appl, 32 (10), pp. 6295-6309; Caroppo, A., Leone, A., Siciliano, P., Comparison between deep learning models and traditional machine learning approaches for facial expression recognition in ageing adults (2020) J Comput Sci Technol, 35 (5), pp. 1127-1146; Happy, S., Dantcheva, A., Bremond, F., Expression recognition with deep features extracted from holistic and part-based models (2021) Image Vis Comput, 105, p. 104038; Valente, D., Theurel, A., Gentaz, E., The role of visual experience in the production of emotional facial expressions by blind people: a review (2018) Psychon Bull Rev, 25 (2), pp. 483-497; Saeed, A., Al-Hamadi, A., Niese, R., Elzobi, M., Frame-based facial expression recognition using geometrical features (2014) Adv Hum-Comput Interact; Ahmed, F., Hossain, E., Automated facial expression recognition using gradient-based ternary texture patterns (2013) Chin J Eng; Holder, R.P., Tapamo, J.R., Improved gradient local ternary patterns for facial expression recognition (2017) EURASIP J Image Video Process, 1, p. 42; Carcagnì, P., Del Coco, M., Leo, M., Distante, C., Facial expression recognition and histograms of oriented gradients: a comprehensive study (2015) SpringerPlus, 4 (1), p. 645; Lekdioui, K., Messoussi, R., Ruichek, Y., Chaabi, Y., Touahni, R., Facial decomposition for expression recognition using texture/shape descriptors and svm classifier (2017) Signal Process Image Commun, 58, pp. 300-312; Liu, M., Li, S., Shan, S., Chen, X., Au-inspired deep networks for facial expression feature learning (2015) Neurocomputing, 159, pp. 126-136; Zhao, X., Shi, X., Zhang, S., Facial expression recognition via deep learning (2015) IETE Tech Rev, 32 (5), pp. 347-355; Sun, B., Li, L., Zhou, G., He, J., Facial expression recognition in the wild based on multimodal texture features (2016) J Electron Imaging, 25 (6), p. 061407; Majumder, A., Behera, L., Subramanian, V.K., Automatic facial expression recognition system using deep network-based data fusion (2016) IEEE Trans Cybern, 48 (1), pp. 103-114; Yang, B., Cao, J., Ni, R., Zhang, Y., Facial expression recognition using weighted mixture deep neural network based on double-channel facial images (2017) IEEE Access, 6, pp. 4630-4640; Lopes, A.T., de Aguiar, E., De Souza, A.F., Oliveira-Santos, T., Facial expression recognition with convolutional neural networks: coping with few data and the training sample order (2017) Pattern Recognit, 61, pp. 610-628; Sun, N., Li, Q., Huan, R., Liu, J., Han, G., Deep spatial-temporal feature fusion for facial expression recognition in static images (2019) Pattern Recognit Lett, 119, pp. 49-61; Kong, F., Facial expression recognition method based on deep convolutional neural network combined with improved lbp features (2019) Pers Ubiquitous Comput, 23 (3-4), pp. 531-539; Aghamaleki, J.A., Chenarlogh, V.A., Multi-stream cnn for facial expression recognition in limited training data (2019) Multimed Tools Appl, 78 (16), pp. 22861-22882; Li, Y., Zeng, J., Shan, S., Chen, X., Occlusion aware facial expression recognition using cnn with attention mechanism (2018) IEEE Trans Image Process, 28 (5), pp. 2439-2450; Sun, W., Zhao, H., Jin, Z., A visual attention based roi detection method for facial expression recognition (2018) Neurocomputing, 296, pp. 12-22; Xie, S., Hu, H., Facial expression recognition using hierarchical features with deep comprehensive multipatches aggregation convolutional neural networks (2018) IEEE Trans Multimed, 21 (1), pp. 211-220; Wu, B.F., Lin, C.H., Adaptive feature mapping for customizing deep learning based facial expression recognition model (2018) IEEE Access, 6, pp. 12451-12461; Chen, J., Xu, R., Liu, L., Deep peak-neutral difference feature for facial expression recognition (2018) Multimed Tools Appl, 77 (22), pp. 29871-29887; Li, M., Xu, H., Huang, X., Song, Z., Liu, X., Li, X., Facial expression recognition with identity and emotion joint learning (2018) IEEE Trans Affect Comput, 12 (2), pp. 544-550; Shao, J., Qian, Y., Three convolutional neural network models for facial expression recognition in the wild (2019) Neurocomputing, 355, pp. 82-92; Li, K., Jin, Y., Akram, M.W., Han, R., Chen, J., Facial expression recognition with convolutional neural networks via a new face cropping and rotation strategy (2020) Vis Comput, 36 (2), pp. 391-404; González-Lozoya, S.M., de la Calleja, J., Pellegrin, L., Escalante, H.J., Medina, M.A., Benitez-Ruiz, A., Recognition of facial expressions based on cnn features (2020) Multimed Tools Appl, 79 (19), pp. 13987-14007; Liu, X., Zhou, F., Improved curriculum learning using ssm for facial expression recognition (2019) Vis Comput, 36 (8), pp. 1635-1649; Wu, M., Su, W., Chen, L., Liu, Z., Cao, W., Hirota, K., Weight-adapted convolution neural network for facial expression recognition in human-robot interaction (2019) IEEE Trans Syst Man Cybern Syst, 51 (3), pp. 1473-1484; Kim, J.H., Kim, B.G., Roy, P.P., Jeong, D.M., Efficient facial expression recognition algorithm based on hierarchical deep neural network structure (2019) IEEE Access, 7, pp. 41273-41285; Xie, S., Hu, H., Wu, Y., Deep multi-path convolutional neural network joint with salient region attention for facial expression recognition (2019) Pattern Recognit, 92, pp. 177-191; Riaz, M.N., Shen, Y., Sohail, M., Guo, M., Exnet: an efficient approach for emotion recognition in the wild (2020) Sensors, 20 (4), p. 1087; Agrawal, A., Mittal, N., Using cnn for facial expression recognition: a study of the effects of kernel size and number of filters on accuracy (2020) Vis Comput, 36 (2), pp. 405-412; Zhao, G., Yang, H., Yu, M., Expression recognition method based on a lightweight convolutional neural network (2020) IEEE Access, 8, pp. 38528-38537; Sikkandar, H., Thiyagarajan, R., Deep learning based facial expression recognition using improved cat swarm optimization (2020) J Ambient Intell Hum Comput, 12 (2), pp. 3037-3053; Gogić, I., Manhart, M., Pandžić, I.S., Ahlberg, J., Fast facial expression recognition using local binary features and shallow neural networks (2020) Vis Comput, 36 (1), pp. 97-112; Miao, S., Xu, H., Han, Z., Zhu, Y., Recognizing facial expressions using a shallow convolutional neural network (2019) IEEE Access, 7, pp. 78000-78011; Huang, J., Rathod, V., Sun, C., Zhu, M., Korattikara, A., Fathi, A., Fischer, I., Guadarrama, S., Speed/accuracy trade-offs for modern convolutional object detectors (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7310-7311; King, D.E., Dlib-ml: a machine learning toolkit (2009) J Mach Learn Res, 10, pp. 1755-1758; Carrier, P.L., Courville, A., Goodfellow, I.J., Mirza, M., Bengio, Y., (2013) Fer-2013 Face Database; Li, S., Deng, W., Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expression recognition (2018) IEEE Trans Image Process, 28 (1), pp. 356-370; Langner, O., Dotsch, R., Bijlstra, G., Wigboldus, D.H., Hawk, S.T., Van Knippenberg, A., Presentation and validation of the radboud faces database (2010) Cognit Emot, 24 (8), pp. 1377-1388; Dhall, A., Goecke, R., Lucey, S., Gedeon, T., Static facial expression analysis in tough conditions: Data, evaluation protocol and benchmark (2011) 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), IEEE, pp. 2106-2112; Wen, G., Chang, T., Li, H., Jiang, L., Dynamic objectives learning for facial expression recognition (2020) IEEE Trans Multimed, 22 (11), pp. 2914-2925; Hasani, B., Negi, P.S., Mahoor, M., Breg-next: facial affect computing using adaptive residual networks with bounded gradient (2020) IEEE Trans Affect Comput; Jiang, P., Liu, G., Wang, Q., Wu, J., Accurate and reliable facial expression recognition using advanced softmax loss with fixed weights (2020) IEEE Signal Process Lett, 27, pp. 725-729; Jiang, P., Wan, B., Wang, Q., Wu, J., Fast and efficient facial expression recognition using a gabor convolutional network (2020) IEEE Signal Process Lett, 27, pp. 1954-1958; Wang, K., Peng, X., Yang, J., Meng, D., Qiao, Y., Region attention networks for pose and occlusion robust facial expression recognition (2020) IEEE Trans Image Process, 29, pp. 4057-4069; Li, H., Wen, G., Sample awareness-based personalized facial expression recognition (2019) Appl Intell, 49 (8), pp. 2956-2969; Wang, Z., Zeng, F., Liu, S., Zeng, B., Oaenet: oriented attention ensemble for accurate facial expression recognition (2021) Pattern Recognit, 112, p. 107694; Vo, T.H., Lee, G.S., Yang, H.J., Kim, S.H., Pyramid with super resolution for in-the-wild facial expression recognition (2020) IEEE Access, 8, pp. 131988-132001; Li, Y., Lu, G., Li, J., Zhang, Z., Zhang, D., Facial expression recognition in the wild using multi-level features and attention mechanisms (2020) IEEE Trans Affect Comput; Jain, D.K., Shamsolmoali, P., Sehdev, P., Extended deep neural network for facial emotion recognition (2019) Pattern Recognit Lett, 120, pp. 69-74; Yu, Z., Zhang, C., Image based static facial expression recognition with multiple deep network learning (2015) Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, pp. 435-442; Dinelli, G., Meoni, G., Rapuano, E., Benelli, G., Fanucci, L., An fpga-based hardware accelerator for cnns using on-chip memories only: Design and benchmarking with intel movidius neural compute stick (2019) Int J Reconfig Comput; Choudhary, T., Mishra, V., Goswami, A., Sarangapani, J., A comprehensive survey on model compression and acceleration (2020) Artif Intell Rev, 57 (3), pp. 5113-5155; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) Arxiv Preprint Arxiv:150302531; Migacz, S., (2017)","Saurav, S.; CSIR-Central Electronics Engineering Research Institute, Rajasthan, India; email: sumeet@ceeri.res.in",,,"Springer Science and Business Media Deutschland GmbH",,,,,09410643,,,,"English","Neural Comput. Appl.",Article,"Final","",Scopus,2-s2.0-85117830803
"Liu G., Dai X., Liu X., Chen M., Huang Z., Xing T.","57217175483;57218098736;57217176650;57254492200;57254260900;54685377600;","An efficient and low power deep learning framework for image recognition on mobile devices",2022,"CCF Transactions on Pervasive Computing and Interaction","4","1",,"","",,,"10.1007/s42486-021-00076-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114676000&doi=10.1007%2fs42486-021-00076-0&partnerID=40&md5=476c77e8f796ca3b27ea7644c63a6ff0","School of Information Science and Technology, Northwest University, Xi’an, China; Shaanxi International Joint Research Centre for the Internet of Things, Northwest University, Xi’an, China","Liu, G., School of Information Science and Technology, Northwest University, Xi’an, China; Dai, X., School of Information Science and Technology, Northwest University, Xi’an, China; Liu, X., School of Information Science and Technology, Northwest University, Xi’an, China; Chen, M., School of Information Science and Technology, Northwest University, Xi’an, China; Huang, Z., School of Information Science and Technology, Northwest University, Xi’an, China; Xing, T., School of Information Science and Technology, Northwest University, Xi’an, China, Shaanxi International Joint Research Centre for the Internet of Things, Northwest University, Xi’an, China","Image classification on mobile devices can provide convenient and secure services for users when using various social software. The traditional classification method mainly relies on the user’s manual marking, but the accuracy of automatic classification has some defects. With the development of convolutional neural network(CNN), the design of lightweight neural network has become a hot topic. However, the state-of-the-art studies always sacrifice classification accuracy for network lightweight, which greatly frustrates usability. In this paper, a new neural network framework, named MobVi, is proposed to enhance the precision of lightweight neural network by solution space division. MobVi is including image solution space division and judgment class. The former uses clustering method based on deep learning to distinguish which small solution space the image belongs to, while the latter uses lightweight neural network customized for the solution space to judge the class. In order to reduce the amount of model parameters and calculations, we designed a customized CNN module. Finally, we propose an energy prediction model to measure whether the model can be successfully implemented on mobile devices. A series of experiments have proved that MobVi has better performance than most existing models for mobile devices. Our model achieves 83.5% accuracy on CIFAR-10 data set, and the parameter quantity is only 2.0 M. © 2021, China Computer Federation (CCF).","Convolutional neural network; Image classification; Mobile devices; Solution space division",,,,,,"2020KW-004; China Postdoctoral Science Foundation: 2017M613187; Shaanxi Key Science and Technology Innovation Team Project: 2018TD-026; Key Research and Development Projects of Shaanxi Province: 2018SF-369","This work was supported in part by International Cooperation Project of Shaanxi Province (No. 2020KW-004), the China Postdoctoral Science Foundation (No. 2017M613187), the Key Research and Development Project of Shaanxi Province (No. 2018SF-369), and the Shaanxi Science and Technology Innovation Team Support Project under grant agreement (No. 2018TD-026).",,,,,,,,,,"Alaziz, M., Jia, Z., Howard, R.E., Lin, X., Zhang, Y., In-bed body motion detection and classification system (2020) ACM Trans. Sens. Netw., 16 (2), pp. 13:1-13:26; Bay, H., Tuytelaars, T., Gool, L.V., Surf: Speeded up robust features (2006) European Conference on Computer Vision(Eccv), pp. 404-417; Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2007) Advances in Neural Information Processing Systems, 19, pp. 153-160; Bhandari, R., Nambi, A.U., Padmanabhan, V.N., Raman, B., Driving lane detection on smartphones using deep neural networks (2020) ACM Trans. Sens. Netw, 16 (1), pp. 2:1-2:22; Bhardwaj, S., Srinivasan, M., Khapra, M.M., Efficient video classification using fewer frames (2019) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 354-363; Caron, M., Bojanowski, P., Joulin, A., Douze, M., Deep clustering for unsupervised learning of visual features (2018) European Conference on Computer Vision(Eccv), pp. 139-156; Chang, J., Wang, L., Meng, G., Xiang, S., Pan, C., Deep adaptive image clustering (2017) IEEE International Conference on Computer Vision (ICCV), pp. 5880-5888; Chen, Y., Tu, L., Density-based clustering for real-time stream data (2007) International Conference on Knowledge Discovery and Data Mining, p. 133142; Deng, J., Dong, W., Socher, R., Li, L., Li, K., Li, F., Imagenet: A large-scale hierarchical image database (2009) IEEE Conference on Computer Vision and Pattern Recognition(Cvpr), pp. 248-255; Franti, P., Virmajoki, O., Hautamaki, V., Fast agglomerative clustering using a k-nearest neighbor graph (2006) IEEE Trans. Pattern Anal. Mach. Intell., 28 (11), pp. 1875-1881; Gowda, K., Krishna, G., Agglomerative clustering using the concept of mutual nearest neighbourhood (1978) Pattern Recog., 10 (2), pp. 105-112; Han, S., Mao, H., Dally, W.J., (2016) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding.; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., Mobilenets: Efficient convolutional neural networks for mobile visionapplications Corr (2017).; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., Squeezenet: Alexnet-level accuracy with 50x fewer parameters and< 0.5 mb model size Corr (2016).; Jaderberg, M., Vedaldi, A., Zisserman, A., Speeding up convolutional neural networks with low rank expansions (2014) British Machine Vision Conference(Bmvc); Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009) Handb. Syst. Autoim. Dis., , 1; Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet:Classification with deep convolutional neural networks (2012) International Conference on Neural Information Processing Systems(Nips); Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning filters for efficient convnets (2016) International Conference on Learning Representations(Iclr; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vis., 60 (2), pp. 91-110; Norouzi, M., Fleet, D.J., Cartesian k-means (2013) IEEE Conference on Computer Vision and Pattern Recognition(Cvpr), pp. 3017-3024; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4510-4520; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) International Conference on Learning Representations(Iclr; Sindhwani, V., Sainath, T., Kumar, S., Structured transforms for small-footprint deep learning (2015) International Conference on Neural Information Processing Systems(Nips), pp. 3088-3096; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1-9; Wang, J., Wang, J., Song, J., Xu, X., Shen, H., Li, S., Optimized cartesian k-means (2015) IEEE Trans. Knowl. Data Eng., 27 (1), pp. 180-192; Yang, Y., Xu, D., Nie, F., Yan, S., Zhuang, Y., Image clustering using local discriminant models and global integration (2010) IEEE Trans. Image Process., 19 (10), pp. 2761-2773; Zhang, X., Zhou, X., Lin, M., Sun, J., Shufflenet: An extremely efficient convolutional neural network for mobile devices (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6848-6856","Xing, T.; Shaanxi International Joint Research Centre for the Internet of Things, China; email: xtz@nwu.edu.cn",,,"Springer",,,,,2524521X,,,,"English","CCF. Trans. Pervasive. Comp. Interact.",Article,"Final","",Scopus,2-s2.0-85114676000
"Chen Y., Wen X., Zhang Y., He Q.","56645034500;57219265491;38863602600;55217854300;","FPC: Filter pruning via the contribution of output feature map for deep convolutional neural networks acceleration",2022,"Knowledge-Based Systems","238",,"107876","","",,,"10.1016/j.knosys.2021.107876","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121585377&doi=10.1016%2fj.knosys.2021.107876&partnerID=40&md5=1405d6fc58d5705f41bc66cd2637b27f","School of Compute Science and Technology, Anhui University, Hefei, China; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia","Chen, Y., School of Compute Science and Technology, Anhui University, Hefei, China; Wen, X., School of Compute Science and Technology, Anhui University, Hefei, China; Zhang, Y., School of Compute Science and Technology, Anhui University, Hefei, China; He, Q., School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia","Pruning is a very effective solution to alleviate the difficulty of deploying neural networks on resource-constrained devices. However, most of the existing methods focus on the inherent parameters of the network itself, but rarely consider the contribution of the output feature map. In this paper, we propose the FPC, a novel filter pruning method based on the contribution of the output feature map, which considers the diverse information carried by different output feature maps. According to the above characteristic, FPC can evaluate the contribution of output feature maps and then effectively delete low contribution part without reducing the performance of the model. In this paper, we firstly use Singular Value Decomposition (SVD) to decompose the output feature map. Then we analyze the contribution of the output feature map to the model performance. Finally, we delete the filters with lower contribution output feature maps. Extensive experimental results show that our proposed FPC can produce excellent compression results. For example, with VGG-16, we can reduce the FLOPs by 65.62% and increase the accuracy by 0.25% on CIFAR-10. With ResNet-110, we can reduce FLOPs by 50.66% and increase the accuracy by 0.09% on CIFAR-100. © 2021 Elsevier B.V.","Filter pruning; Model compression; Neural network; Singular Value Decomposition (SVD)","Convolution; Convolutional neural networks; Deep neural networks; Effective solution; Feature map; Filter pruning; Model compression; Modeling performance; Neural-networks; Performance; Pruning methods; Resourceconstrained devices; Singular value decomposition; Singular value decomposition",,,,,"National Natural Science Foundation of China, NSFC: 61802001, 62041212; Natural Science Foundation of Shanxi Province: 2020JM-548","This work is supported in part by the National Natural Science Foundation of China under Grand ( 61802001 , 62041212 ), Natural Science Foundation of Shanxi Province, China ( 2020JM-548 ).",,,,,,,,,,"(2012), pp. 1106-1114. , Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, ImageNet Classification with Deep Convolutional Neural Networks, in: NIPS; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR, pp. 770-778. , IEEE Computer Society; (2015), Karen Simonyan, Andrew Zisserman, Very Deep Convolutional Networks for Large-Scale Image Recognition, in: ICLR; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.E., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) CVPR, pp. 1-9. , IEEE Computer Society; Wang, S., Xiang, J., Zhong, Y., Zhou, Y., Convolutional neural network-based hidden Markov models for rolling element bearing fault identification (2018) Knowl. Based Syst., 144, pp. 65-76; (2016), pp. 379-387. , Jifeng Dai, Yi Li, Kaiming He, Jian Sun, R-FCN: Object Detection via Region-based Fully Convolutional Networks, in: NIPS; (2015), pp. 91-99. , Shaoqing Ren, Kaiming He, Ross B. Girshick, Jian Sun, Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, in: NIPS; Girshick, R.B., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) CVPR, pp. 580-587. , IEEE Computer Society; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) CVPR, pp. 3431-3440. , IEEE Computer Society; (2015), Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L. Yuille, Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs, in: ICLR, Poster; Dong, Z., Li, J., Fang, T., Shao, X., Lightweight boundary refinement module based on point supervision for semantic segmentation (2021) Image Vis. Comput., 110; Zhang, Y., Pan, J., Qi, L., He, Q., Privacy-preserving quality prediction for edge-based IoT services (2021) Future Gener. Comput. Syst., 114, pp. 336-348; Liu, L., Lu, S., Zhong, R., Wu, B., Yao, Y., Zhang, Q., Shi, W., Computing systems for autonomous driving: State of the art and challenges (2021) IEEE Internet Things J., 8 (8), pp. 6469-6486; Zhang, Q., Zhong, H., Shi, W., Liu, L., A trusted and collaborative framework for deep learning in IoT (2021) Comput. Netw., 193; Emily, L., Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, Rob Fergus, Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation (2014), pp. 1269-1277. , NIPS; Jaderberg, M., Vedaldi, A., Zisserman, A., Speeding up convolutional neural networks with low rank expansions (2014) BMVC, , BMVA Press; Zhang, X., Zou, J., Ming, X., He, K., Sun, J., Efficient and accurate approximations of nonlinear convolutional networks (2015) CVPR, pp. 1984-1992. , IEEE Computer Society; Chen, W., Wilson, J.T., Tyree, S., Weinberger, K.Q., Chen, Y., Compressing neural networks with the hashing trick (2015) ICML, JMLR Workshop and Conference Proceedings, 37, pp. 2285-2294. , JMLR.org; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., Xnor-net: ImageNet classification using binary convolutional neural networks (2016) ECCV (4), Lecture Notes in Computer Science, 9908, pp. 525-542. , Springer; (2016), pp. 4107-4115. , Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, Yoshua Bengio, Binarized Neural Networks, in: NIPSpp; Wu, J., Leng, C., Wang, Y., Hu, Q., Cheng, J., Quantized convolutional neural networks for mobile devices (2016) CVPR, pp. 4820-4828. , IEEE Computer Society; Hinton, G.E., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015), CoRR, abs/1503.02531; Yim, J., Joo, D., Bae, J.-H., Kim, J., A gift from knowledge distillation: Fast optimization, network minimization and transfer learning (2017) CVPR, pp. 7130-7138. , IEEE Computer Society; (2015), Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, Yoshua Bengio, FitNets: Hints for Thin Deep Nets, in: ICLR, Poster; He, Y., Zhang, X., Sun, J., Channel pruning for accelerating very deep neural networks (2017) ICCV, pp. 1398-1406. , IEEE Computer Society; (2015), pp. 1135-1143. , Song Han, Jeff Pool, John Tran, William J. Dally, Learning both Weights and Connections for Efficient Neural Network, in: NIPS; Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J., Pruning convolutional neural networks for resource efficient inference (2017) ICLR (Poster), , OpenReview.net; He, Y., Kang, G., Dong, X., Fu, Y., Yang, Y., Soft filter pruning for accelerating deep convolutional neural networks (2018) IJCAI, pp. 2234-2240. , ijcai.org; Lemaire, C., Achkar, A., Jodoin, P.-M., Structured pruning of neural networks with budget-aware regularization (2019) CVPR, pp. 9108-9116. , Computer Vision Foundation / IEEE; Molchanov, P., Mallya, A., Tyree, S., Frosio, I., Kautz, J., Importance estimation for neural network pruning (2019) CVPR, pp. 11264-11272. , Computer Vision Foundation / IEEE; Á.Carreira-Perpiñán, M., Idelbayev, Y., ”Learning-compression” algorithms for neural net pruning (2018) CVPR, pp. 8532-8541. , IEEE Computer Society; Chen, Y., Wen, X., Zhang, Y., Shi, W., CCPrune: Collaborative channel pruning for learning compact convolutional networks (2021) Neurocomputing, 451, pp. 35-45; Chen, Y., Li, C., Gong, L., Wen, X., Zhang, Y., Shi, W., A deep neural network compression algorithm based on knowledge transfer for edge devices (2020) Comput. Commun., 163, pp. 186-194; Qin, H., Gong, R., Liu, X., Shen, M., Wei, Z., Yu, F., Song, J., Forward and backward information retention for accurate binary neural networks (2020) CVPR, pp. 2247-2256. , IEEE; (2015), Vadim Lebedev, Yaroslav Ganin, Maksim Rakhuba, Ivan V. Oseledets, Victor S. Lempitsky, Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition, in: ICLR, Poster; Luo, J.-H., Wu, J., Lin, W., Thinet: A filter level pruning method for deep neural network compression (2017) ICCV, pp. 5068-5076. , IEEE Computer Society; Lin, M., Ji, R., Wang, Y., Zhang, Y., Zhang, B., Tian, Y., Shao, L., Hrank: Filter pruning using high-rank feature map (2020) CVPR, pp. 1526-1535. , IEEE; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) ICML, JMLR Workshop and Conference Proceedings, 37, pp. 448-456. , JMLR.org; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning filters for efficient ConvNets (2017) ICLR, Poster, , OpenReview.net; Yu, R., Li, A., Chen, C.-F., Lai, J.-H., Morariu, V.I., Han, X., Gao, M., Davis, L.S., NISP: pruning networks using neuron importance score propagation (2018) CVPR, pp. 9194-9203. , IEEE Computer Society; He, Y., Liu, P., Wang, Z., Hu, Z., Yang, Y., Filter pruning via geometric median for deep convolutional neural networks acceleration (2019) CVPR, pp. 4340-4349. , Computer Vision Foundation / IEEE; Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C., Learning efficient convolutional networks through network slimming (2017) ICCV, pp. 2755-2763. , IEEE Computer Society; Zhao, C., Ni, B., Zhang, J., Zhao, Q., Zhang, W., Tian, Q., Variational convolutional neural network pruning (2019) CVPR, pp. 2780-2789. , Computer Vision Foundation / IEEE; Huang, Z., Wang, N., Data-driven sparse structure selection for deep neural networks (2018) ECCV (16), Lecture Notes in Computer Science, 11220, pp. 317-334. , Springer; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009), Citeseer; Darlow, L.N., Crowley, E.J., Antoniou, A., Storkey, A.J., CINIC-10 is not ImageNet or CIFAR-10 (2018), CoRR, abs/1810.03505; Huang, G., Liu, Z., van der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) CVPR, pp. 2261-2269. , IEEE Computer Society; Sutskever, I., Martens, J., Dahl, G.E., Hinton, G.E., On the importance of initialization and momentum in deep learning (2013) ICML (3), JMLR Workshop and Conference Proceedings, 28, pp. 1139-1147. , JMLR.org; Lin, S., Ji, R., Yan, C., Zhang, B., Cao, L., Ye, Q., Huang, F., Doermann, D.S., Towards optimal structured CNN pruning via generative adversarial learning (2019) CVPR, pp. 2790-2799. , Computer Vision Foundation / IEEE; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Li, F.-F., ImageNet large scale visual recognition challenge (2014), CoRR, abs/1409.0575","Zhang, Y.; School of Compute Science and Technology, China; email: zhangyiwen@ahu.edu.cn",,,"Elsevier B.V.",,,,,09507051,,KNSYE,,"English","Knowl Based Syst",Article,"Final","",Scopus,2-s2.0-85121585377
"Hong J.-S., Hermann I., Zöllner F.G., Schad L.R., Wang S.-J., Lee W.-K., Chen Y.-L., Chang Y., Wu Y.-T.","57191473280;57210440592;6603625932;7005125073;7410337053;57216035530;57446764600;57446764700;7406890264;","Acceleration of Magnetic Resonance Fingerprinting Reconstruction Using Denoising and Self-Attention Pyramidal Convolutional Neural Network",2022,"Sensors","22","3","1260","","",,,"10.3390/s22031260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124335622&doi=10.3390%2fs22031260&partnerID=40&md5=f7a9ed5518ff297ca781c83429053b51","Department of Biomedical Imaging and Radiological Sciences, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; Computer Assisted Clinical Medicine, Mannheim Institute for Intelligent Systems in Medicine, Medical Faculty Mannheim Heidelberg University, Mannheim, 68167, Germany; Department of Neurology, Neurological Institute, Taipei Veterans General Hospital, Taipei, 112, Taiwan; Faculty of Medicine, National Yang-Ming University School of Medicine, Taipei, 112, Taiwan; Brain Research Center, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; Institute of Biophotonics, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan","Hong, J.-S., Department of Biomedical Imaging and Radiological Sciences, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; Hermann, I., Computer Assisted Clinical Medicine, Mannheim Institute for Intelligent Systems in Medicine, Medical Faculty Mannheim Heidelberg University, Mannheim, 68167, Germany; Zöllner, F.G., Computer Assisted Clinical Medicine, Mannheim Institute for Intelligent Systems in Medicine, Medical Faculty Mannheim Heidelberg University, Mannheim, 68167, Germany; Schad, L.R., Computer Assisted Clinical Medicine, Mannheim Institute for Intelligent Systems in Medicine, Medical Faculty Mannheim Heidelberg University, Mannheim, 68167, Germany; Wang, S.-J., Department of Neurology, Neurological Institute, Taipei Veterans General Hospital, Taipei, 112, Taiwan, Faculty of Medicine, National Yang-Ming University School of Medicine, Taipei, 112, Taiwan, Brain Research Center, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; Lee, W.-K., Department of Biomedical Imaging and Radiological Sciences, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; Chen, Y.-L., Institute of Biophotonics, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; Chang, Y., Institute of Biophotonics, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; Wu, Y.-T., Brain Research Center, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan, Institute of Biophotonics, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan","Magnetic resonance fingerprinting (MRF) based on echo-planar imaging (EPI) enables whole-brain imaging to rapidly obtain T1 and T2* relaxation time maps. Reconstructing parametric maps from the MRF scanned baselines by the inner-product method is computationally expensive. We aimed to accelerate the reconstruction of parametric maps for MRF-EPI by using a deep learning model. The proposed approach uses a two-stage model that first eliminates noise and then regresses the parametric maps. Parametric maps obtained by dictionary matching were used as a reference and compared with the prediction results of the two-stage model. MRF-EPI scans were collected from 32 subjects. The signal-to-noise ratio increased significantly after the noise removal by the denoising model. For prediction with scans in the testing dataset, the mean absolute percentage errors between the standard and the final two-stage model were 3.1%, 3.2%, and 1.9% for T1, and 2.6%, 2.3%, and 2.8% for T2* in gray matter, white matter, and lesion locations, respectively. Our proposed two-stage deep learning model can effectively remove noise and accurately reconstruct MRF-EPI parametric maps, increasing the speed of reconstruction and reducing the storage space required by dictionaries. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Denoising convolutional neural network; Echo-planar imaging; Feature pyramid network; Magnetic resonance fingerprinting; Self-attention","Brain mapping; Convolution; Convolutional neural networks; Deep learning; Magnetic resonance imaging; Magnetism; Magnetorheological fluids; Signal to noise ratio; Statistical tests; Convolutional neural network; De-noising; Denoising convolutional neural network; Echo planar imaging; Feature pyramid; Feature pyramid network; Magnetic resonance fingerprinting; Pyramid network; Self-attention; Two stage model; Magnetic resonance; acceleration; attention; brain; diagnostic imaging; human; image processing; imaging phantom; nuclear magnetic resonance imaging; nuclear magnetic resonance spectroscopy; Acceleration; Attention; Brain; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Magnetic Resonance Spectroscopy; Neural Networks, Computer; Phantoms, Imaging",,,,,"Ministry of Science and Technology, Taiwan, MOST: MOST-110-2221-E-A49A-504-MY3, MOST-110-2321-B-010-005","Funding: This research and APC was funded by Taiwan’s Ministry of Science and Technology, grant number MOST-110-2321-B-010-005 and MOST-110-2221-E-A49A-504-MY3.",,,,,,,,,,"Cheng, H.L., Stikov, N., Ghugre, N.R., Wright, G.A., Practical Medical Applications of Quantitative MR Relaxometry (2012) J. Magn. Reson. Imaging, 36, pp. 805-824. , https://doi.org/10.1002/jmri.23718; Feng, L., Ma, D., Liu, F., Rapid MR Relaxometry Using Deep Learning: An Overview of Current Techniques and Emerging Trends (2020) NMR Biomed, p. e4416. , https://doi.org/10.1002/nbm.4416; Ji, S., Yang, D., Lee, J., Choi, S.H., Kim, H., Kang, K.M., Synthetic MRI: Technologies and Applications in Neuroradiology (2020) J. Magn. Reson. Imaging, , https://doi.org/10.1002/jmri.27440; Ma, D., Gulani, V., Seiberlich, N., Liu, K., Sunshine, J.L., Duerk, J.L., Griswold, M.A., Magnetic Resonance Fingerprinting (2013) Nature, 495, pp. 187-192. , https://doi.org/10.1038/nature11971; McGivney, D.F., Boyacıoğlu, R., Jiang, Y., Poorman, M.E., Seiberlich, N., Gulani, V., Keenan, K.E., Ma, D., Magnetic Resonance Fingerprinting Review Part 2: Technique and Directions (2020) J. Magn. Reson. Imaging, 51, pp. 993-1007. , https://doi.org/10.1002/jmri.26877; McGivney, D.F., Pierre, E., Ma, D., Jiang, Y., Saybasili, H., Gulani, V., Griswold, M.A., SVD Compression for Magnetic Resonance Fingerprinting in the Time Domain (2014) IEEE Trans Med. Imaging, 33, pp. 2311-2322. , https://doi.org/10.1109/TMI.2014.2337321; Yang, M., Ma, D., Jiang, Y., Hamilton, J., Seiberlich, N., Griswold, M.A., McGivney, D., Low Rank Approximation Methods for MR Fingerprinting with Large Scale Dictionaries (2018) Magn. Reson. Med, 79, pp. 2392-2400. , https://doi.org/10.1002/mrm.26867; Cohen, O., Zhu, B., Rosen, M.S., MR Fingerprinting Deep RecOnstruction NEtwork (DRONE) (2018) Magn. Reson. Med, 80, pp. 885-894. , https://doi.org/10.1002/mrm.27198; Hoppe, E., Thamm, F., Korzdorfer, G., Syben, C., Schirrmacher, F., Nittka, M., Pfeuffer, J., Maier, A., Magnetic Resonance Fingerprinting Reconstruction Using Recurrent Neural Networks (2019) Stud. Health Technol, 267, pp. 126-133. , https://doi.org/10.3233/Shti190816; Hoppe, E., Körzdörfer, G., Würfl, T., Wetzl, J., Lugauer, F., Pfeuffer, J., Maier, A., Deep Learning for Magnetic Resonance Fingerprinting: A New Approach for Predicting Quantitative Parameter Values from Time Series (2017) Ger. Med. Data Sci. Vis. Bridges, 243, pp. 202-206. , https://doi.org/10.3233/978-1-61499-808-2-202; Balsiger, F., Jungo, A., Scheidegger, O., Carlier, P.G., Reyes, M., Marty, B., Spatially Regularized Parametric Map Reconstruction for Fast Magnetic Resonance Fingerprinting (2020) Med. Image Anal, 64, p. 101741. , https://doi.org/10.1016/j.media.2020.101741; Fang, Z., Chen, Y., Liu, M., Xiang, L., Zhang, Q., Wang, Q., Lin, W., Shen, D., Deep Learning for Fast and Spatially Constrained Tissue Quantification From Highly Accelerated Data in Magnetic Resonance Fingerprinting (2019) IEEE Trans. Med. Imaging, 38, pp. 2364-2374. , https://doi.org/10.1109/TMI.2019.2899328; Hermann, I., Martinez-Heras, E., Rieger, B., Schmidt, R., Golla, A.K., Hong, J.S., Lee, W.K., Solana, E., Accelerated White Matter Lesion Analysis Based on Simultaneous T1 and T2* Quantification Using Magnetic Resonance Fingerprinting and Deep Learning (2021) Magn. Reson. Med, 86, pp. 471-486. , https://doi.org/10.1002/mrm.28688; Yang, M., Jiang, Y., Ma, D., Mehta, B.B., Griswold, M.A., (2020) Game of Learning Bloch Equation Simulations for MR Fingerprinting, , arXiv arXiv:2004.02270; Chen, D., Golbabaee, M., Gomez, P.A., Menzel, M.I., Davies, M.E., (2019) A Fully Convolutional Network for MR Fingerprinting, , arXiv arXiv:1911.09846; Li, G., Zrimec, J., Ji, B., Geng, J., Larsbrink, J., Zelezniak, A., Nielsen, J., Engqvist, M.K., Performance of Regression Models as a Function of Experiment Noise (2021) Bioinform. Biol. Insights, 15, pp. 1-10. , https://doi.org/10.1177/11779322211020315; Zhang, K., Zuo, W., Chen, Y., Meng, D., Zhang, L., Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising (2017) IEEE Trans Image Process, 26, pp. 3142-3155. , https://doi.org/10.1109/TIP.2017.2662206; Bloch, F., Nuclear Induction (1946) Phys. Rev, 70, p. 460; Lin, T.-Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie, S., Feature Pyramid Networks for Object Detection (2017) Proceedings of the IEEE Computer Society, pp. 936-944. , London, UK, 1 July; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł., Polosukhin, I., Attention Is All You Need (2017) Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 6000-6010. , Long Beach, CA, USA, 4-9 December Curran Associates Inc.: Red Hook, NY, USA, 2017; Wang, X., Girshick, R., Gupta, A., He, K., Non-Local Neural Networks (2018) Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7794-7803. , Salt Lake City, UT, USA, 18-23 June; Rieger, B., Zimmer, F., Zapp, J., Weingartner, S., Schad, L.R., Magnetic Resonance Fingerprinting Using Echo-Planar Imaging: Joint Quantification of T1 and T2* Relaxation Times (2017) Magn. Reson. Med, 78, pp. 1724-1733. , https://doi.org/10.1002/mrm.26561; Rieger, B., Akcakaya, M., Pariente, J.C., Llufriu, S., Martinez-Heras, E., Weingartner, S., Schad, L.R., Time Efficient Whole-Brain Coverage with MR Fingerprinting Using Slice-Interleaved Echo-Planar-Imaging (2018) Sci. Rep, 8, p. 6667. , https://doi.org/10.1038/s41598-018-24920-z; Hermann, I., Chacon-Caldera, J., Brumer, I., Rieger, B., Weingartner, S., Schad, L.R., Zollner, F.G., Magnetic Resonance Fingerprinting for Simultaneous Renal T1 and T2* Mapping in a Single Breath-Hold (2020) Magn. Reson. Med, 83, pp. 1940-1948. , https://doi.org/10.1002/mrm.28160; Ashburner, J., Barnes, G., Chen, C.-C., Daunizeau, J., Flandin, G., Friston, K., Kiebel, S., Moran, R., (2014) SPM12 Manual, 2464. , Wellcome Trust Centre for Neuroimaging: London, UK; Zhang, H., Goodfellow, I., Metaxas, D., Odena, A., (2019) Self-Attention Generative Adversarial Networks, , arXiv arXiv:1805.08318; Mohan, J., Krishnaveni, V., Guo, Y., A Survey on the Magnetic Resonance Image Denoising Methods (2014) Biomed. Signal Processing Control, 9, pp. 56-69. , https://doi.org/10.1016/j.bspc.2013.10.007; Larsson, E.-M., Nilsson, H., Holtås, S., Ståhlberg, F., Coil Selection for Magnetic Resonance Imaging of the Cervical and Thoracic Spine Using a Vertical Magnetic Field (1989) Acta Radiol, 30, pp. 141-146. , https://doi.org/10.1177/028418518903000205; Reiss-Zimmermann, M., Gutberlet, M., Köstler, H., Fritzsch, D., Hoffmann, K.-T., Improvement of SNR and Acquisition Acceleration Using a 32-Channel Head Coil Compared to a 12-Channel Head Coil at 3T (2013) Acta Radiol, 54, pp. 702-708. , https://doi.org/10.1177/0284185113479051; Gudbjartsson, H., Patz, S., The Rician Distribution of Noisy MRI Data (1995) Magn. Reson. Med, 34, pp. 910-914. , https://doi.org/10.1002/mrm.1910340618; Nowak, R.D., Wavelet-Based Rician Noise Removal for Magnetic Resonance Imaging (1999) IEEE Trans. Image Processing, 8, pp. 1408-1419. , https://doi.org/10.1109/83.791966; Soviany, P., Ionescu, R.T., Optimizing the Trade-Off between Single-Stage and Two-Stage Deep Object Detectors Using Image Difficulty Prediction (2018) Proceedings of the 2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC), pp. 209-214. , Timisoara, Romania, 20-23 September; Blystad, I., Håkansson, I., Tisell, A., Ernerudh, J., Smedby, Ö., Lundberg, P., Larsson, E.-M., Quantitative MRI for Analysis of Active Multiple Sclerosis Lesions without Gadolinium-Based Contrast Agent (2016) Am. J. Neuroradiol, 37, pp. 94-100. , https://doi.org/10.3174/ajnr.A4501; Krüger, G., Glover, G.H., Physiological Noise in Oxygenation-Sensitive Magnetic Resonance Imaging (2001) Magn. Reson. Med, 46, pp. 631-637. , https://doi.org/10.1002/mrm.1240; Péran, P., Hagberg, G., Luccichenti, G., Cherubini, A., Brainovich, V., Celsis, P., Caltagirone, C., Sabatini, U., Voxel-Based Analysis of R2* Maps in the Healthy Human Brain (2007) J. Magn. Reson. Imaging, 26, pp. 1413-1420. , https://doi.org/10.1002/jmri.21204; Wansapura, J.P., Holland, S.K., Dunn, R.S., Ball, W.S., NMR Relaxation Times in the Human Brain at 3.0 Tesla (1999) J. Magn. Reson. Imaging, 9, pp. 531-538. , https://doi.org/10.1002/(sici)1522-2586(199904)9:4<531::aid-jmri4>3.0.co;2-l; Jiang, Y., Ma, D., Keenan, K.E., Stupic, K.F., Gulani, V., Griswold, M.A., Repeatability of Magnetic Resonance Fingerprinting T1 and T2 Estimates Assessed Using the ISMRM/NIST MRI System Phantom (2017) Magn. Reson. Med, 78, pp. 1452-1457. , https://doi.org/10.1002/mrm.26509; Körzdörfer, G., Kirsch, R., Liu, K., Pfeuffer, J., Hensel, B., Jiang, Y., Ma, D., Bogner, W., Reproducibility and Repeatability of MR Fingerprinting Relaxometry in the Human Brain (2019) Radiology, 292, pp. 429-437. , https://doi.org/10.1148/radiol.2019182360; Andica, C., Hagiwara, A., Hori, M., Nakazawa, M., Goto, M., Koshino, S., Kamagata, K., Aoki, S., Automated Brain Tissue and Myelin Volumetry Based on Quantitative MR Imaging with Various In-Plane Resolutions (2018) J. Neuroradiol, 45, pp. 164-168. , https://doi.org/10.1016/j.neurad.2017.10.002; Lee, W.-H., Ozger, M., Challita, U., Sung, K.W., Noise Learning Based Denoising Autoencoder (2021) IEEE Commun. Lett, 25, pp. 2983-2987. , https://doi.org/10.1109/LCOMM.2021.3091800; Wang, S., Peterson, D.J., Gatenby, J.C., Li, W., Grabowski, T.J., Madhyastha, T.M., Evaluation of Field Map and Nonlinear Registration Methods for Correction of Susceptibility Artifacts in Diffusion MRI (2017) Front. Neuroinformatics, 11, p. 17. , https://doi.org/10.3389/fninf.2017.00017; Giorgio, A., De Stefano, N., Clinical Use of Brain Volumetry (2013) J. Magn. Reson. Imaging, 37, pp. 1-14. , https://doi.org/10.1002/jmri.23671; Balakrishnan, G., Zhao, A., Sabuncu, M.R., Guttag, J., Dalca, A.V., VoxelMorph: A Learning Framework for Deformable Medical Image Registration (2019) IEEE Trans. Med. Imaging, 38, pp. 1788-1800. , https://doi.org/10.1109/TMI.2019.2897538; Ronneberger, O., Fischer, P., Brox, T., (2015) U-Net: Convolutional Networks for Biomedical Image Segmentation, , arXiv arXiv:1505.04597","Wu, Y.-T.; Brain Research Center, Taiwan; email: ytwu@ym.edu.tw",,,"MDPI",,,,,14248220,,,"35162007","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85124335622
"Cuperman R., Jansen K.M.B., Ciszewski M.G.","57445722500;35324197100;57222272558;","An End-to-End Deep Learning Pipeline for Football Activity Recognition Based on Wearable Acceleration Sensors",2022,"Sensors","22","4","1347","","",,,"10.3390/s22041347","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124291672&doi=10.3390%2fs22041347&partnerID=40&md5=e2956bf3a60f5ba72c52b817da9cf067","Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology (TU Delft), Mekelweg 4, Delft, 2628 CD, Netherlands; Faculty of Industrial Design Engineering, Delft University of Technology (TU Delft), Landbergstraat 15, Delft, 2628 CE, Netherlands","Cuperman, R., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology (TU Delft), Mekelweg 4, Delft, 2628 CD, Netherlands; Jansen, K.M.B., Faculty of Industrial Design Engineering, Delft University of Technology (TU Delft), Landbergstraat 15, Delft, 2628 CE, Netherlands; Ciszewski, M.G., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology (TU Delft), Mekelweg 4, Delft, 2628 CD, Netherlands","Action statistics in sports, such as the number of sprints and jumps, along with the details of the corresponding locomotor actions, are of high interest to coaches and players, as well as medical staff. Current video-based systems have the disadvantage that they are costly and not easily transportable to new locations. In this study, we investigated the possibility to extract these statistics from acceleration sensor data generated by a previously developed sensor garment. We used deep learning-based models to recognize five football-related activities (jogging, sprinting, passing, shooting and jumping) in an accurate, robust, and fast manner. A combination of convolutional (CNN) layers followed by recurrent (bidirectional) LSTM layers achieved up to 98.3% of accuracy. Our results showed that deep learning models performed better in evaluation time and prediction accuracy than traditional machine learning algorithms. In addition to an increase in accuracy, the proposed deep learning architecture showed to be 2.7 to 3.4 times faster in evaluation time than traditional machine learning methods. This demonstrated that deep learning models are accurate as well as time-efficient and are thus highly suitable for cost-effective, fast, and accurate human activity recognition tasks. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial neural networks; Convolutional neural networks; Deep learning; Football; HAR; Human activity recognition; IMU; LSTM; Machine learning; Soccer","Convolution; Convolutional neural networks; Cost effectiveness; Deep neural networks; Learning algorithms; Long short-term memory; Pattern recognition; Wearable sensors; Acceleration sensors; Activity recognition; Convolutional neural network; Deep learning; End to end; HAR; Human activity recognition; IMU; Learning models; LSTM; Sports; acceleration; electronic device; football; human; Acceleration; Deep Learning; Football; Humans; Neural Networks, Computer; Wearable Electronic Devices",,,,,"Nederlandse Organisatie voor Wetenschappelijk Onderzoek, NWO: P16-28","Funding: This research was funded by NWO Perspective P16-28, project Citius Altius Sanius.",,,,,,,,,,"Abd, M.A., Paul, R., Aravelli, A., Bai, O., Lagos, L., Lin, M., Engeberg, E.D., Hierarchical Tactile Sensation Integration from Prosthetic Fingertips Enables Multi-Texture Surface Recognition (2021) Sensors, 21, p. 4324. , [CrossRef] [PubMed]; Slim, S., Atia, A., Elfattah, M., Mostafa, M.S.M., Survey on human activity recognition based on acceleration data (2019) Intl. J. Adv. Comput. Sci. Appl, 10, pp. 84-98. , [CrossRef]; Wang, L., Liu, R., Human activity recognition based on wearable sensor using hierarchical deep LSTM networks (2020) Circuits Syst. Signal Process, 39, pp. 837-856. , [CrossRef]; Adaskevicius, R., Method for recognition of the physical activity of human being using a wearable accelerometer (2014) Elektron. Elektrotechnika, 20, pp. 127-131. , [CrossRef]; Mannini, A., Sabatini, A.M., Machine learning methods for classifying human physical activity from on-body accelerometers (2010) Sensors, 10, pp. 1154-1175. , [CrossRef] [PubMed]; De Vries, S.I., Engels, M., Garre, F.G., Identification of children’s activity type with accelerometer-based neural networks (2011) Med. Sci. Sport. Exerc, 43, pp. 1994-1999. , [CrossRef] [PubMed]; Ignatov, A., Real-time human activity recognition from accelerometer data using Convolutional Neural Networks (2018) Appl. Soft Comput, 62, pp. 915-922. , [CrossRef]; Ha, S., Yun, J.M., Choi, S., Multi-modal convolutional neural networks for activity recognition (2015) Proceedings of the 2015 IEEE International Conference on Systems, Man, and Cybernetics, pp. 3017-3022. , Hong Kong, China, 9–12 October; Zebin, T., Scully, P.J., Ozanyan, K.B., Evaluation of supervised classification algorithms for human activity recognition with inertial sensors (2017) Proceedings of the 2017 IEEE SENSORS, pp. 1-3. , Glasgow, UK, 29 October–1 November; Blank, P., Hoßbach, J., Schuldhaus, D., Eskofier, B.M., Sensor-based stroke detection and stroke type classification in table tennis (2015) Proceedings of the 2015 ACM International Symposium on Wearable Computers, pp. 93-100. , Osaka, Japan, 7–11 September; Connaghan, D., Kelly, P., O’Connor, N.E., Gaffney, M., Walsh, M., O’Mathuna, C., Multi-sensor classification of tennis strokes Proceedings of the SENSORS, 2011 IEEE, pp. 1437-1440. , Limerick, Ireland, 28–31 October 2011; Groh, B.H., Kautz, T., Schuldhaus, D., Eskofier, B.M., IMU-based trick classification in skateboarding (2015) Proceedings of the KDD Workshop on Large-Scale Sports Analytics, 17. , Sydney, Australia, 10–13 August; Kautz, T., Groh, B.H., Hannink, J., Jensen, U., Strubberg, H., Eskofier, B.M., Activity recognition in beach volleyball using a Deep Convolutional Neural Network (2017) Data Min. Knowl. Discov, 31, pp. 1678-1705. , [CrossRef]; Schuldhaus, D., Zwick, C., Körger, H., Dorschky, E., Kirk, R., Eskofier, B.M., Inertial sensor-based approach for shot/pass classification during a soccer match (2015) Proceedings of the KDD Workshop on Large-Scale Sports Analytics, pp. 1-4. , Sydney, Australia, 10–13 August; Liu, X., (2020) Tennis Stroke Recognition: Stroke Classification Using Inertial Measuring Unit and Machine Learning Algorithm in Tennis, , Master’s Thesis, Delft University of Technology, Delft, The Netherlands; Jiao, L., Bie, R., Wu, H., Wei, Y., Ma, J., Umek, A., Kos, A., Golf swing classification with multiple deep convolutional neural networks (2018) Int. J. Distrib. Sens. Netw, 14, p. 1550147718802186. , [CrossRef]; Schuldhaus, D., (2019) Human Activity Recognition in Daily Life and Sports Using Inertial Sensors, , FAU University Press: Boca Raton, FL, USA; Xu, C., Chai, D., He, J., Zhang, X., Duan, S., InnoHAR: A deep neural network for complex human activity recognition (2019) IEEE Access, 7, pp. 9893-9902. , [CrossRef]; Xia, K., Huang, J., Wang, H., LSTM-CNN architecture for human activity recognition (2020) IEEE Access, 8, pp. 56855-56866. , [CrossRef]; Lv, M., Xu, W., Chen, T., A hybrid deep convolutional and recurrent neural network for complex activity recognition using multimodal sensors (2019) Neurocomputing, 362, pp. 33-40. , [CrossRef]; Ordóñez, F.J., Roggen, D., Deep convolutional and lstm recurrent neural networks for multimodal wearable activity recognition (2016) Sensors, 16, p. 115. , [CrossRef] [PubMed]; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , MIT Press: Cambridge, MA, USA; Hubel, D.H., Wiesel, T.N., Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex (1962) J. Physiol, 160, pp. 106-154. , [CrossRef] [PubMed]; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9, pp. 1735-1780. , [CrossRef] [PubMed]; Pascanu, R., Mikolov, T., Bengio, Y., On the difficulty of training recurrent neural networks (2013) Proceedings of the International Conference on Machine Learning, pp. 1310-1318. , PMLR, Atlanta, GA, USA, 17–19 June; Wilmes, E., De Ruiter, C.J., Bastiaansen, B.J., Van Zon, J.F., Vegter, R.J., Brink, M.S., Goedhart, E.A., Savelsbergh, G.J., Inertial sensor-based motion tracking in football with movement intensity quantification (2020) Sensors, 20, p. 2527. , [CrossRef] [PubMed]; (2013) Nine-Axis (Gyro + Accelerometer + Compass) MEMS MotionTracking™ Device, , Revision 4.3; Invensense: San Jose, CA, USA; Wilmes, E., (2019) Measuring Changes in Hamstring Contractile Strength and Lower Body Sprinting Kinematics during a Simulated Soccer Match, , Master’s Thesis, Delft University of Technology, Delft, The Netherlands; Steijlen, A., Bastemeijer, J., Plaude, L., French, P., Bossche, A., Jansen, K., Development of Sensor Tights with Integrated Inertial Measurement Units for Injury Prevention in Football (2020) Proceedings of the 6th International Conference on Design4Health, 1, p. 3. , Amsterdam, The Netherlands, 1–3 July; Berrar, D., Cross-Validation (2019) Encyclopedia of Bioinformatics and Computational Biology, , Elsevier: Amsterdam, The Netherlands; Kingma, D.P., Ba, J., (2014) Adam: A method for stochastic optimization, , arXiv arXiv:1412.6980; LeCun, Y.A., Bottou, L., Orr, G.B., Müller, K.R., Efficient backprop (2012) Neural Networks: Tricks of the Trade, pp. 9-48. , Springer: Berlin/Heidelberg, Germany; Roggen, D., Calatroni, A., Rossi, M., Holleczek, T., Förster, K., Tröster, G., Lukowicz, P., Ferscha, A., Collecting complex activity datasets in highly rich networked sensor environments (2010) Proceedings of the 2010 Seventh International Conference on Networked Sensing Systems (INSS), pp. 233-240. , Kassel, Germany, 15–18 June; Kwapisz, J.R., Weiss, G.M., Moore, S.A., Activity recognition using cell phone accelerometers (2011) ACM SigKDD Explor. Newsl, 12, pp. 74-82. , [CrossRef]; Anguita, D., Ghio, A., Oneto, L., Parra, X., Reyes-Ortiz, J.L., A public domain dataset for human activity recognition using smartphones (2013) Proceedings of the 21th International European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, 3, p. 3. , Bruges, Belgium, 24–26 April","Cuperman, R.; Faculty of Electrical Engineering, Mekelweg 4, Netherlands; email: rafaelcuperman@gmail.com
Jansen, K.M.B.; Faculty of Industrial Design Engineering, Landbergstraat 15, Netherlands; email: K.M.B.Jansen@tudelft.nl",,,"MDPI",,,,,14248220,,,"35214245","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85124291672
"Xu M., Liu W., Xu J., Xia Y., Mao J., Xu C., Hu S., Huang D.","57217482096;57194266135;57216620477;57212089171;57437229500;55935438400;15839322400;55238640800;","Recurrent Neural Network Based Link Quality Prediction for Fluctuating Low Power Wireless Links",2022,"Sensors","22","3","1212","","",,1,"10.3390/s22031212","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123935409&doi=10.3390%2fs22031212&partnerID=40&md5=7ce0624c0f5990b3247da51ca8371d5e","College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China; School of Electrical and Electronic Engineering, Chongqing University of Technology, Chongqing, 400054, China","Xu, M., College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China; Liu, W., School of Electrical and Electronic Engineering, Chongqing University of Technology, Chongqing, 400054, China; Xu, J., School of Electrical and Electronic Engineering, Chongqing University of Technology, Chongqing, 400054, China; Xia, Y., College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China; Mao, J., School of Electrical and Electronic Engineering, Chongqing University of Technology, Chongqing, 400054, China; Xu, C., College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China; Hu, S., School of Electrical and Electronic Engineering, Chongqing University of Technology, Chongqing, 400054, China; Huang, D., College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China","One of the main methods for link quality prediction is to predict the physical layer parameters first, and then evaluate the link quality based on the mapping models between such parameters and packet reception ratio (PRR). However, existing methods often ignore the temporal correlations of physical layer parameter series and rarely consider the influence of link fluctuations, which lead to more errors under moderate and sudden changed links with larger fluctuations. In view of these problems, this paper proposes a more effective link quality prediction method RNNLQI, which adopts Recurrent Neural Network (RNN) to predict the Link Quality Indicator (LQI) series, and then evaluates the link quality according to the fitting model of LQI and PRR. This method accurately mines the inner relationship among LQI series with the help of short-term memory characteristics of RNN and effectively deals with link fluctuations by taking advantage of the higher resolution of LQI in the transitional region. Compared with similar methods, RNN-LQI proves to be better under different link qualities. Especially under moderate and sudden changed links with larger fluctuations, the prediction error reduces at least by 14.51% and 13.37%, respectively. Therefore, the proposed method is more suitable for low power wireless links with more fluctuations. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Link quality indicator; Link quality prediction; Low power wireless links; Recurrent neural network; Temporal correlation; Time series","Forecasting; Low power electronics; Network layers; Quality control; Layer parameters; Link quality; Link quality indicators; Link quality predictions; Low-power wireless links; Network-based; Packet reception ratios; Physical layers; Temporal correlations; Times series; Recurrent neural networks; article; prediction error; recurrent neural network; short term memory; time series analysis; Neural Networks, Computer",,,,,"National Natural Science Foundation of China, NSFC: 61601069, 62031017; Chongqing Municipal Education Commission, CQMEC: KJQN201901136, KJQN202001110; National Key Research and Development Program of China, NKRDPC: 2017YFC0822404","Funding: This work is supported in part by National Key R&D Program of China (Grant No. 2017YFC0822404), National Natural Science Foundation of China (Grant No. 62031017 and 61601069), and Scientific and Technological Research Program of Chongqing Municipal Education Commission (Grant No. KJQN202001110 and KJQN201901136).",,,,,,,,,,"Putra, S.A., Trilaksono, B.R., Riyansyah, M., Laila, D.S., Multiagent architecture for bridge capacity measurement system using wireless sensor network and weight in motion (2021) IEEE Trans. Instrum. Meas, 70, pp. 1-14; Chen, C., Wang, Z., Li, W., Chen, H., Mei, Z., Yuan, W., Tao, L., Mei, Y., Novel flexible material-based unobtrusive and wearable body sensor networks for vital sign monitoring (2019) IEEE Sens. J, 19, pp. 8502-8513; Baccour, N., Koubaa, A., Mottola, L., Youssef, H., Boano, C.A., Alves, M., Radio link quality estimation in wireless sensor networks: A survey (2012) ACM Trans. Sens. Netw, 8, pp. 1-33; Woo, A., Culler, D., Evaluation of efficient link reliability estimators for low-power wireless networks (2003) Technical Report UCB/CSD-03-1270, , EECS Department, University of California: Berkeley, CA, USA; Liu, W., Xia, Y., Luo, R., FaLQE: Fluctuation adaptive link quality estimator for wireless sensor networks (2019) Commun. Comput. Inf. Sci, 1101, pp. 48-60; Xu, J., Xia, Y., Xie, J., Liu, W., Luo, R., Hu, S., Huang, D., Faster or slower: Convergence of link quality metrics in wireless sensor networks (2020) Proceedings of the IEEE International Conference on Computer and Communications (ICCC), pp. 357-362. , Chengdu, China, 11–14 December; Srinivasan, K., Dutta, P., Tavakoli, A., Levis, P., An empirical study of low-power wireless (2010) ACM Trans. Sens. Netw, 6, pp. 1-49; Boano, C.A., Voigt, T., Dunkels, A., Osterlind, F., Tsiftes, N., Mottola, L., Suarez, P., Poster abstract: Exploiting the LQI variance for rapid channel quality assessment (2009) Proceedings of the International Conference on Information Processing in Sensor Networks, pp. 369-370. , San Francisco, CA, USA; 13–16 April; Boano, C.A., Zuniga, M.A., Voigt, T., Willig, A., Römer, K., The triangle metric: Fast link quality estimation for mobile wireless sensor networks (2010) Proceedings of the IEEE International Conference on Computer Communications and Networks (ICCCN), pp. 1-7. , Zurich, Switzerland, 2–5 August; Liu, W., Xia, Y., Luo, R., Hu, S., Lightweight multi-parameter fusion link quality estimation based on weighted Euclidean distance (2019) Proceedings of the Annual IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, pp. 1-6. , Istanbul, Turkey, 8–11 September; Ye, R., Boukerche, A., Wang, H., Zhou, X., Yan, B., RECODAN: An efficient redundancy coding-based data transmission scheme for wireless sensor networks (2016) Comput. Netw, 110, pp. 351-363; Senel, M., Chintalapudi, K., Lal, D., Keshavarzian, A., Coyle, E.J., A kalman filter based link quality estimation scheme for wireless sensor networks (2007) Proceedings of the IEEE Global Telecommunications Conference, pp. 875-880. , Washington, DC, USA, 26–30 November; Gomez, C., Boix, A., Paradells, J., Impact of LQI-Based routing metrics on the performance of a one-to-one routing protocol for IEEE 802.15.4 multihop networks (2010) EURASIP J. Wirel. Commun. Netw, 6, p. 205407; Liu, T., Cerpa, A.E., Data-driven link quality prediction using link features (2014) ACM Trans. Sens. Netw, 10, pp. 1-35; Liu, T., Cerpa, A.E., Temporal adaptive link quality prediction with online learning (2014) ACM Trans. Sens. Netw, 10, pp. 1-42; Xue, X., Sun, W., Wang, J., Li, Q., Luo, G., Yu, K., RVFL-LQP: RVFL-based link quality prediction of wireless sensor networks in smart grid (2020) IEEE Access, 8, pp. 7829-7841; Sun, W., Lu, W., Li, Q., Chen, L., Mu, D., Yuan, X., WNN-LQE: Wavelet-neural-network-based link quality estimation for smart grid WSNs (2017) IEEE Access, 5, pp. 12788-12797; Xu, M., Xu, J., Xia, Y., Xie, J., Liu, W., Hu, S., Huang, D., Recurrent neural network based link quality prediction for wireless sensor networks (2021) Proceedings of the IEEE 6th International Conference on Computer and Communication Systems (ICCCS), pp. 905-909. , Chengdu, China, 23–26 April; Liu, W., Xu, J., Xia, Y., Xu, M., Mao, J., Hu, S., Huang, D., Wavelet neural network based link quality prediction for fluctuating low power wireless links (2021) Proceedings of the IEEE 6th International Conference on Computer and Communication Systems (ICCCS), pp. 899-904. , Chengdu, China, 23–26 April; Fonseca, R., Gnawali, O., Jamieson, K., Levis, P., Four bit wireless link estimation (2007) ACM HotNets, pp. 1-6. , ACM: Atlanta, GA, USA; Baccour, N., Koubaa, A., Youssef, H., Jamaa, M.B., Rosario, D., Alves, M., Becker, L.B., F-LQE: A fuzzy link quality estimator for wireless sensor networks (2010) Proceedings of the European Conference on Wireless Sensor Networks, pp. 240-255. , Coimbra, Portugal, 17–19 February; Rekik, S., Baccour, N., Jmaiel, M., Drira, K., Low-power link quality estimation in smart grid environments (2015) Proceedings of the International Wireless Communications and Mobile Computing Conference, pp. 1211-1216. , Dubrovnik, Croatia, 24–28 August; Jayasri, T., Hemalatha, M., Link quality estimation for adaptive data streaming in WSN (2016) Wirel. Pers. Commun, 94, pp. 1543-1562; Sun, W., Yuan, X., Wang, J., Li, Q., Chen, L., Mu, D., End-to-end data delivery reliability model for estimating and optimizing the link quality of industrial WSNs (2018) IEEE Trans. Autom. Sci. Eng, 15, pp. 1127-1137; Chen, M., Challita, U., Saad, W., Yin, C., Debbah, M., Artificial neural networks-based machine learning for wireless networks: A tutorial (2019) IEEE Commun. Surv. Tutor, 21, pp. 3039-3071; Graves, A., (2012) Supervised Sequence Labelling with Recurrent Neural Networks, , Springer: Berlin/Heidelberg, Germany; Chang, X., Huang, J., Liu, S., Xing, G., Zhang, H., Wang, J., Huang, L., Zhuang, Y., Accuracy-aware interference modeling and measurement in wireless sensor networks (2016) IEEE Trans. Mob. Comput, 15, pp. 278-291","Liu, W.; School of Electrical and Electronic Engineering, China; email: liu-wei@cqut.edu.cn",,,"MDPI",,,,,14248220,,,"35161954","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85123935409
"Lin H.-W., Shivanna V.M., Chang H.C., Guo J.-I.","57212026858;56378983800;57713547200;36982518000;","Real-Time Multiple Pedestrian Tracking With Joint Detection and Embedding Deep Learning Model for Embedded Systems",2022,"IEEE Access","10",,,"51458","51471",,,"10.1109/ACCESS.2022.3173408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130848626&doi=10.1109%2fACCESS.2022.3173408&partnerID=40&md5=538a77776f70cd613185050fbf22896c","Institute Of Electronics, National Yang Ming Chiao Tung University, Department Of Electronics Engineering, Hsinchu, 30010, Taiwan; Chunghua Telecom Company Ltd., Taoyuan City, 32661, Taiwan; National Yang Ming Chiao Tung University, Pervasive Artificial Intelligence Research (PAIR) Laboratories, Hsinchu, 30010, Taiwan; National Yang Ming Chiao Tung University, Wistron-NCTU Embedded Artificial Intelligence Research Center, Hsinchu, 30010, Taiwan","Lin, H.-W., Institute Of Electronics, National Yang Ming Chiao Tung University, Department Of Electronics Engineering, Hsinchu, 30010, Taiwan; Shivanna, V.M., Institute Of Electronics, National Yang Ming Chiao Tung University, Department Of Electronics Engineering, Hsinchu, 30010, Taiwan; Chang, H.C., Chunghua Telecom Company Ltd., Taoyuan City, 32661, Taiwan; Guo, J.-I., Institute Of Electronics, National Yang Ming Chiao Tung University, Department Of Electronics Engineering, Hsinchu, 30010, Taiwan, National Yang Ming Chiao Tung University, Pervasive Artificial Intelligence Research (PAIR) Laboratories, Hsinchu, 30010, Taiwan, National Yang Ming Chiao Tung University, Wistron-NCTU Embedded Artificial Intelligence Research Center, Hsinchu, 30010, Taiwan","This paper proposes an improvement to the multi-object tracking system framework based on the image inputs. By analyzing the role and performance of each block in the original multi-objects tracking system, the blocks of the original system are reconstructed to enhance the efficiency and yield a faster processing speed suiting the real-time applications. In the proposed method, the first two parts of the multi-object tracking system are merged into a single neural network designed for object detection and feature extraction. A new object association judgment method and JDE inspired prediction head are included in order to achieve a better and an outstanding association effect resulting in the overall improvement of the original system by 45.2%. The enhanced method is aimed at the application of smart roadside units and uses fixed-viewpoint image input to achieve multi-object tracking on embedded platforms. The proposed method is implemented on the NVIDIA Jetson AGX Xavier embedded platform. The NVIDIA TensorRT software development kit is used to accelerate the neural network. The overall performance of the proposed system yields better efficiency compared to that of the original SDE design and the overall computing performance achieve up to 14-26 images per second, making it ideal for the real-time smart roadside unit applications. © 2013 IEEE.","Advanced driver assistance system (ADAS); Embedded system; Multiple object tracking; Smart transportation","Advanced driver assistance systems; Automobile drivers; Deep learning; Efficiency; Embedded systems; Extraction; Image enhancement; Object detection; Object recognition; Real time systems; Software design; Advanced driver assistance system; Computational modelling; Embedded-system; Features extraction; Multi-object tracking; Multiple object tracking; Object Tracking; Real - Time system; Smart transportation; Targets tracking; Feature extraction",,,,,,,,,,,,,,,,"Rodrigue, J.-P., Comtois, C., Slack, B., (2020) The Geography of Transport Systems, 5th ed, p. 456. , New York, NY, USA: Routledge; (2008) OECD/ECMT. Managing Urban Traffic Congestion (Summary), , https://doi.org/10.1787/9789282101506-sum-en, [Online]; (2008) Introduction to Intelligent Transportation System, Freeway Bureau, Ministry of Transportation and Communications, , https://bit.ly/3upUgTZ, Freeway Bureau Ministry of Transportation and Communications(MOTC) Taiwan Jul. 4, [Online]; (2021) Intelligent Transportation Systems\WSP, , https://www.wsp.com/en-CA/services/intelligent-transportation-systems-its, Accessed: Feb., [Online]; Lin, T.-Y., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., Perona, P., Doll, P., Microsoft COCO: Common objects in context (2014) Proc. Eur. Conf. Comput. Vis., pp. 740-755; Milan, A., Leal-Taixe, L., Reid, I., Roth, S., Schindler, K., (2016) MOT16: A Benchmark For Multi-Object Tracking; Bochkovskiy, A., Wang, C.-Y., Mark Liao, H.-Y., (2020) YOLOv4: Optimal Speed and Accuracy of Object Detection; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks For Large-Scale Image Recognition; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1-9. , Jun; Xie, S., Girshick, R., Dollar, P., Tu, Z., He, K., Aggregated residual transformations for deep neural networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1492-1500. , Jul; Hu, J., Shen, L., Sun, G., Squeeze-and-excitation networks (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit, pp. 7132-7141. , Jun; Tan, M., Le, Q.V., EfficientNet: Rethinking model scaling for convolutional neural networks (2019) Proc. Int. Conf. Mach. Learn., pp. 1-10; Wang, C.-Y., Liao, H.-Y.M., Wu, Y.-H., Chen, P.-Y., Hsieh, J.-W., Yeh, I.-H., CSPNet: A new backbone that can enhance learning capability of CNN (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 390-391. , Jun; Lin, T.-Y., Dollar, P., Girshick, R., He, K., Hariharan, B., Belongie, S., Feature pyramid networks for object detection (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2117-2125. , Jul; Redmon, J., Farhadi, A., (2018) YOLOv3: An Incremental Improvement; Liu, S., Qi, L., Qin, H., Shi, J., Jia, J., Path aggregation network for instance segmentation (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit, pp. 8759-8768. , Jun; Tan, M., Pang, R., Le, Q.V., EfficientDet: Scalable and efficient object detection (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 10781-10790. , Jun; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Proc. Adv. Neural Inf. Process. Syst, pp. 91-99; Lin, T.-Y., Goyal, P., Girshick, R., He, K., Dollar, P., Focal loss for dense object detection (2017) Proc. IEEEInt. Conf. Comput. Vis. (ICCV), pp. 2980-2988. , Oct; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., Berg, A.C., SSD: Single shot multiBox detector (2016) Proc. Eur. Conf. Comput. Vis., pp. 21-37; Zhou, X., Wang, D., Krahenbuhl, P., (2019) Objects As Points; Law, H., Deng, J., CornerNet: Detecting objects as paired keypoints (2018) Proc. Eur. Conf. Comput. Vis., pp. 734-750; Tian, Z., Shen, C., Chen, H., He, T., FCOS: Fully convolutional one-stage object detection (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 9627-9636. , Oct; Bewley, A., Ge, Z., Ott, L., Ramos, F., Upcroft, B., Simple online and realtime tracking (2016) Proc. IEEE Int. Conf. Image Process. (ICIP), pp. 3464-3468. , Sep; Kalman, R.E., A new approach to linear filtering and prediction problems (1960) Trans. ASME, D, J. Basic Eng., 82, p. 355. , Mar; Kuhn, H.W., The Hungarian method for the assignment problem (1995) Naval Res. Logist., 2 (1-2), pp. 83-97. , Mar; Wojke, N., Bewley, A., Paulus, D., Simple online and realtime tracking with a deep association metric (2017) Proc. IEEE Int. Conf. Image Process. (ICIP), pp. 3645-3649. , Sep; Hsu, Y.-H., Guo, J.-I., A real-time and online multiple-type object tracking method with deep features (2019) Proc. Asia-Pacific Signal Inf. Process. Assoc. Annu. Summit Conf. (APSIPA ASC), pp. 1922-1928. , Nov; Wang, Z., Zheng, L., Liu, Y., Wang, S., Towards real-time multi-object tracking (2020) Proc. Eur. Conf. Comput. Vis., pp. 107-122; He, K.M., Zhang, X.Y., Ren, S.Q., Sun, J., Spatial pyramid pooling in deep convolutional networks for visual recognition (2015) IEEE Trans. Pattern Anal. Mach. Intell., 37 (9), pp. 1904-1916. , Jun; Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y., Deformable convolutional networks (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 764-773. , Oct; Zhu, X., Hu, H., Lin, S., Dai, J., Deformable ConvNets v2: More deformable, better results (2019) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 9308-9316. , Jun; Zhang, W., Sun, H., Zhao, D., Xu, L., Liu, X., Ning, H., Zhou, J., Yang, S., A streaming cloud platform for real-time video processing on embedded devices (2021) IEEE Trans. Cloud Comput., 9 (3), pp. 868-880. , Jul; Pan, S., Zhao, D., Zhang, W., CNN-based multi-model birdcall identification on embedded devices (2021) Proc. Int. Conf. Smart Internet Things (SmartIoT), pp. 245-251. , Aug; Zhao, H., Zhang, W., Sun, H., Xue, B., Embedded deep learning for ship detection and recognition (2019) Future Internet, 11 (2), p. 53. , Feb; Lu, Z., Rathod, V., Votel, R., Huang, J., RetinaTrack: Online single stage joint detection and tracking (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 14668-14678. , Jun; Zheng, L., Bie, Z., Sun, Y., Wang, J., Su, C., Wang, S., Tian, Q., MARS: A video benchmark for large-scale (2016) Proc. Eur. Conf. Comput. Vis., pp. 868-884; Dollar, P., Wojek, C., Schiele, B., Perona, P., Pedestrian detection: A benchmark (2009) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 304-311. , Jun; Xiao, T., Li, S., Wang, B., Lin, L., Wang, X., Joint detection and identification feature learning for person search (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3415-3424. , Jul; Zheng, L., Zhang, H., Sun, S., Chandraker, M., Yang, Y., Tian, Q., Person re-identification in the wild (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1367-1376. , Jul; Zhang, S., Benenson, R., Schiele, B., CityPersons: A diverse dataset for pedestrian detection (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3213-3221. , Jul; Ess, A., Leibe, B., Schindler, K., Van Gool, L., A mobile vision system for robust multi-person tracking (2008) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 1-8. , Jun; Leal-Taixé, L., Milan, A., Reid, I., Roth, S., Schindler, K., (2015) MOTChal-Lenge 2015: Towards A Benchmark For Multi-Target Tracking; Bernardin, K., Stiefelhagen, R., Evaluating multiple object tracking performance: The CLEAR MOT metrics (2008) EURASIP J. Image Video Process., 2008, pp. 1-10. , Dec; Wang, Z., Zheng, L., Liu, Y., Wang, S., (2021) Towards-Realtime-MOT, , https://github.com/Zhongdao/Towards-Realtime-MOT, Accessed: Oct., [Online]; (2021) NVIDIA TensorRT: Programmable Inference Accelerator, , https://developer.nvidia.com/tensorrt, NVIDIA, Accessed: Dec., [Online]; (2021) NVIDIA Jetson AGX Xavier: The AI Platform for Autonomous Machines, , https://developer.nvidia.com/embedded/jetson-agx-xavier-developer-kit, NVIDIA, Accessed: Dec., [Online]; Zhou, X., Koltun, V., Krähenbühl, P., (2020) Tracking Objects As Points","Shivanna, V.M.; Institute Of Electronics, Taiwan; email: vinay.ms23@gmail.com",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85130848626
"Fan H., Ferianc M., Que Z., Liu S., Niu X., Rodrigues M., Luk W.","57194654551;57209643749;57205100375;56610973400;57685448000;57210526627;26029526200;","FPGA-based Acceleration for Bayesian Convolutional Neural Networks",2022,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",,,,"","",,,"10.1109/TCAD.2022.3160948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127531687&doi=10.1109%2fTCAD.2022.3160948&partnerID=40&md5=df85e759491f1efe90f0af0028feab24","Department of Computing, Imperial College London, London, SW7 2AZ, UK.; Department of Electronic and Electrical Engineering, University College London, London, WC1E 6BT, UK.; School of Physics and Electronics, Hunan Normal University, Changsha 410081, China.; Corerain Technologies Ltd., Shenzhen, China.","Fan, H., Department of Computing, Imperial College London, London, SW7 2AZ, UK.; Ferianc, M., Department of Electronic and Electrical Engineering, University College London, London, WC1E 6BT, UK.; Que, Z., Department of Computing, Imperial College London, London, SW7 2AZ, UK.; Liu, S., School of Physics and Electronics, Hunan Normal University, Changsha 410081, China.; Niu, X., Corerain Technologies Ltd., Shenzhen, China.; Rodrigues, M., Department of Electronic and Electrical Engineering, University College London, London, WC1E 6BT, UK.; Luk, W., Department of Computing, Imperial College London, London, SW7 2AZ, UK.","Neural networks (NNs) have demonstrated their potential in a variety of domains ranging from computer vision to natural language processing. Among various NNs, two-dimensional (2D) and three-dimensional (3D) convolutional neural networks (CNNs) have been widely adopted for a broad spectrum of applications such as image classification and video recognition, due to their excellent capabilities in extracting 2D and 3D features. However, standard 2D and 3D CNNs are not able to capture their model uncertainty which is crucial for many safety-critical applications including healthcare and autonomous driving. In contrast, Bayesian convolutional neural networks (BayesCNNs), as a variant of CNNs, have demonstrated their ability to express uncertainty in their prediction via a mathematical grounding. Nevertheless, BayesCNNs have not been widely used in industrial practice due to their compute requirements stemming from sampling and subsequent forward passes through the whole network multiple times. As a result, these requirements significantly increase the amount of computation and memory consumption in comparison to standard CNNs. This paper proposes a novel FPGA-based hardware architecture to accelerate both 2D and 3D BayesCNNs based on Monte Carlo Dropout. Compared with other state-of-the-art accelerators for BayesCNNs, the proposed design can achieve up to 4 times higher energy efficiency and 9 times better compute efficiency. An automatic framework capable of supporting partial Bayesian inference is proposed to explore the trade-off between algorithm and hardware performance. Extensive experiments are conducted to demonstrate that our framework can effectively find the optimal implementations in the design space. IEEE","Bayes methods; Bayesian convolutional neural network (BayesCNN); Convolutional neural networks; Deep learning.; Field-programmable gate array (FPGA); Hardware; Monte Carlo methods; Standards; Three-dimensional convolutional neural network (3D CNN); Three-dimensional displays; Uncertainty","Bayesian networks; Computer hardware; Convolution; Deep neural networks; Economic and social effects; Energy efficiency; Inference engines; Integrated circuit design; Monte Carlo methods; Safety engineering; Three dimensional computer graphics; Three dimensional displays; Uncertainty analysis; Bayes method; Bayesian; Bayesian convolutional neural network; Convolutional neural network; Deep learning.; Field-programmable gate array; Hardware; MonteCarlo methods; Three-dimensional convolutional neural network (3d convolutional neural network); Three-dimensional display; Uncertainty; Field programmable gate arrays (FPGA)",,,,,,,,,,,,,,,,,,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Article in Press","",Scopus,2-s2.0-85127531687
"Agarwal M., Gupta S.K., Biswas M., Garg D.","57198019454;57213337943;57195430754;57217740133;","Compression and acceleration of convolution neural network: a Genetic Algorithm based approach",2022,"Journal of Ambient Intelligence and Humanized Computing",,,,"","",,,"10.1007/s12652-022-03793-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127492986&doi=10.1007%2fs12652-022-03793-1&partnerID=40&md5=e5f8689a595b758b874e725849557068","Bennett University, Greater Noida, 201310, India; Vignan’s Foundation for Science, Technology and Research (Deemed to be University), Guntur, 522213, India","Agarwal, M., Bennett University, Greater Noida, 201310, India; Gupta, S.K., Bennett University, Greater Noida, 201310, India; Biswas, M., Vignan’s Foundation for Science, Technology and Research (Deemed to be University), Guntur, 522213, India; Garg, D., Bennett University, Greater Noida, 201310, India","Genetic Algorithm (GA) is a meta-heuristics search and optimization approach which we have utilized for fine-tuning the standard deep learning models for reducing the storage space with improvement in inference time. The pre-trained models have been widely acclaimed as the best choice of CNN for various image classification problems in different domains, but they require huge storage space and it causes a problem for deploying these models on mobile or edge devices. As these devices are constrained with limited memory and computational power. In this paper, a novel GA based method has been proposed which compresses and accelerates the CNN models so that these models can be easily deployed on edge devices. Extensive computer simulations have been conducted on widely used models such as AlexNet, VGG16, SqueezeNet, and ResNet50. We used benchmark datasets such as MNIST, CIFAR-10, and CIFAR-100 to determine the performance. Results reveal that storage space of the AlexNet model was reduced by 87.5%, 86.55% and 86.16% on MNIST, CIFAR-10 and CIFAR- 100 datasets respectively, while VGG16, ResNet50, and SqueezeNet have been compressed by nearly 91%, 78%, 38% respectively. From the results, it has been noticed that there is a significant improvement in inference time of around 35% in AlexNet, 9% in SqueezeNet, 73% in ResNet50, and 80% in VGG16. This improvement is noticed mainly because of the fine-tuning of the deep learning models using the GA. Overall, the proposed GA-based method showed outstanding performance and it motivates research and practitioners to explore it further. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Acceleration; Accuracy; Compression; Deep CNN; Genetic algorithm","Benchmarking; Deep learning; Heuristic algorithms; Inference engines; Accuracy; Compression; Convolution neural network; Deep CNN; Fine tuning; Learning models; Meta-heuristic search; Metaheuristic optimization; Performance; Storage spaces; Genetic algorithms",,,,,,,,,,,,,,,,"Agarwal, M., Gupta, S., Biswas, K., A new conv2d model with modified Relu activation function for identification of disease type and severity in cucumber plant (2020) Sustain Comput Inf Syst, 30, p. 100473; Agarwal, M., Gupta, S.K., Biswas, K., Development of efficient cnn model for tomato crop disease identification (2020) Sustain Comput Inf Syst, 28, p. 100407; Agarwal, M., Gupta, S.K., Biswas, K., A compressed and accelerated SegNet for plant leaf disease segmentation: A differential evolution based approach (2021) Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 272-284. , Springer; Agarwal, M., Gupta, S.K., Biswas, K., Plant leaf disease segmentation using compressed UNet architecture (2021) Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 9-14. , Springer; Anwar, S., Hwang, K., Sung, W., Structured pruning of deep convolutional neural networks (2017) ACM J Emerg Technol Comput Syst (JETC), 13 (3), pp. 1-18; Arkadan, A., Sareen, T., Subramaniam, S., Genetic algorithms for nondestructive testing in crack identification (1994) IEEE Trans Magn, 30 (6), pp. 4320-4322; Bac, F.Q., Perov, V., New evolutionary genetic algorithms for NP-complete combinatorial optimization problems (1993) Biol Cybern, 69 (3), pp. 229-234; Beale, H.D., Demuth, H.B., Hagan, M., (1996) Neural network design, , PWS, Boston; International Symposium on VLSI design, automation and test (VLSI-DAT), pp 1–3 (2018) IEEE; Cheng, Y., Wang, D., Zhou, P., Zhang, T., (2017) A Survey of Model Compression and Acceleration for Deep Neural Networks. Arxiv Preprint Arxiv, 1710, p. 09282; Cheng, Y., Wang, D., Zhou, P., Zhang, T., Model compression and acceleration for deep neural networks: The principles, progress, and challenges (2018) IEEE Signal Process Mag, 35 (1), pp. 126-136; Choudhary, T., Mishra, V., Goswami, A., Sarangapani, J., A comprehensive survey on model compression and acceleration (2020) Artif Intell Rev, 53, pp. 1-43; Devarakonda, A., Naumov, M., Garland, M., (2017) Adabatch: Adaptive Batch Sizes for Training Deep Neural Networks; Gong, Y., Liu, L., Yang, M., Bourdev, L., (2014) Compressing deep convolutional networks using vector quantization., , arXiv preprint arXiv:1412.6115; Gui, S., Wang, H.N., Yang, H., Yu, C., Wang, Z., Liu, J., Model compression with adversarial robustness: A unified optimization framework (2019) Adv Neural Inf Process Syst, 32, pp. 1285-1296; Han, S., Mao, H., Dally, W.J., (2015) Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding., , (a), arXiv preprint arXiv:1510.00149; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Advances in Neural Information Processing Systems, pp. 1135-1143; He, Y., Zhang, X., Sun, J., Channel pruning for accelerating very deep neural networks (2017) : Proceedings of the IEEE International Conference on Computer Vision, pp. 1389-1397; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) ) Mobilenets: Efficient convolutional neural networks for mobile vision applications., , arXiv preprint arXiv:1704.04861; Hughes, D., Salathé, M., (2015) An open access repository of images on plant health to enable the development of mobile disease diagnostics; Hu, Y., Sun, S., Li, J., Wang, X., Gu, Q., (2018) A novel channel pruning method for deep neural network compression., , arXiv preprint arXiv:1805.11394; Keesing, R., Stork, D.G., Evolution and learning in neural networks: The number and distribution of learning trials affect the rate of evolution (1991) Advances in Neural Information Processing Systems, pp. 804-810; Khan, S., Yairi, T., A review on the application of deep learning in system health management (2018) Mech Syst Signal Process, 107, pp. 241-265; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., (2016) Pruning filters for efficient convnets, , arXiv preprint; Li, H., Ota, K., Dong, M., Learning iot in edge: Deep learning for the internet of things with edge computing (2018) IEEE Netw, 32 (1), pp. 96-101; Li, T., Wu, B., Yang, Y., Fan, Y., Zhang, Y., Liu, W., Compressing convolutional neural networks via factorized convolutional filters (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3977-3986; Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C., Learning efficient convolutional networks through network slimming (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 2736-2744; Luo, J.H., Wu, J., Lin, W., Thinet: A filter level pruning method for deep neural network compression (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 5058-5066; Minarro-Giménez, J.A., Marin-Alonso, O., Samwald, M., Exploring the application of deep learning techniques on medical text corpora (2014) Stud Health Technol Inf, 205, pp. 584-588; Mohanty, S.P., Hughes, D.P., Salathé, M., Using deep learning for image-based plant disease detection (2016) Front Plant Sci, 7, p. 1419; Panchal, G., Panchal, D., Solving np hard problems using genetic algorithm (2015) Transportation, 106, pp. 2-6; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition., , arXiv preprint arXiv:1409.1556; Singh, P., Verma, V.K., Rai, P., Namboodiri, V., Leveraging filter correlations for deep model compression (2020) Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 835-844; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826; Ullah, I., Petrosino, A., About pyramid structure in convolutional neural networks (2016) 2016 International Joint Conference on Neural Networks (IJCNN), pp. 1318-1324. , IEEE; Wang, X., Han, Y., Wang, C., Zhao, Q., Chen, X., Chen, M., In-edge ai: Intelligentizing mobile edge computing, caching and communication by federated learning (2019) IEEE Netw, 33 (5), pp. 156-165; Wang, N., Zhou, W., Song, Y., Ma, C., Li, H., Real-time correlation tracking via joint model compression and transfer (2020) IEEE Trans Image Process, 29, pp. 6123-6135; Yu, R., Li, A., Chen, C.F., Lai, J.H., Morariu, V.I., Han, X., Gao, M., Davis, L.S., Nisp: Pruning networks using neuron importance score propagation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9194-9203; Zhang, Q., Zhang, M., Chen, T., Sun, Z., Ma, Y., Yu, B., Recent advances in convolutional neural network acceleration (2019) Neurocomputing, 323, pp. 37-51","Agarwal, M.; Bennett UniversityIndia; email: mohit.agarwal@bennett.edu.in",,,"Springer Science and Business Media Deutschland GmbH",,,,,18685137,,,,"English","J. Ambient Intell. Humanized Comput.",Article,"Article in Press","",Scopus,2-s2.0-85127492986
"Shamim M.Z.M.","57192683787;","Hardware Deployable Edge-AI Solution for Pre-screening of Oral Tongue Lesions using TinyML on Embedded Devices",2022,"IEEE Embedded Systems Letters",,,,"","",,,"10.1109/LES.2022.3160281","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126693797&doi=10.1109%2fLES.2022.3160281&partnerID=40&md5=24f79d1cdcae8dfc38df1bb06c0af2de","Dept. of Electrical Engineering, College of Engineering and the Centre for Artificial Intelligence at King Khalid University, Abha, Saudi Arabia.","Shamim, M.Z.M., Dept. of Electrical Engineering, College of Engineering and the Centre for Artificial Intelligence at King Khalid University, Abha, Saudi Arabia.","Diagnosing Oral Cavity Cancer (OCC) in its initial stages is an effective way to reduce patient mortality. However, current pre-screening solutions are manual and the resultant clinical treatment isn&#x201D;t cost-effective for the average individual, primarily in developing nations. In this paper, we present an automated and inexpensive pre-screening solution utilizing Artificial Intelligence (AI) deployed on embedded edge devices to detect benign and pre-malignant superficial oral tongue lesions. The proposed machine vision solution utilizes a clinically annotated photographic dataset of 9 types of superficial oral tongue lesions to retrain a MobileNetV2 neural network using transfer learning. In this approach we also utilized TensorFlow Lite for Microcontrollers to quantize a 32-bit floating point (float32) precision model into an 8-bit integer (int8) model for deployment on power and resource constrained OpenMV Cam H7 Plus embedded edge device. The quantized int8 model was able to detect the 9 tongue lesions with an accuracy of 98.69% on the test set. More than 60% reduction in on-device RAM and Flash memory usage was measured for the int8 model when compared to the equivalently performing float32 model for relatively the same inference speed (~1.1 msec) on the target edge device. IEEE","Artificial Intelligence; Cancer; Computational modeling; Embedded Edge Devices; Image edge detection; Lesions; Oral Cavity Cancer; Performance evaluation; Tiny Machine Learning; Tongue; Tongue Lesions.; Training","Artificial intelligence; Digital arithmetic; Diseases; Edge detection; Flash memory; Learning systems; Random access storage; Computational modelling; Embedded edge device; Image edge detection; Lesion; Machine-learning; Oral cavity; Oral cavity cancer; Performances evaluation; Tiny machine learning; Tongue; Tongue lesion.; Cost effectiveness",,,,,,,,,,,,,,,,,,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,19430663,,,,"English","IEEE Emded. Syst. Lett.",Article,"Article in Press","",Scopus,2-s2.0-85126693797
"Vieira J.C., Sartori A., Stefenon S.F., Perez F.L., De Jesus G.S., Leithardt V.R.Q.","57476778800;55533586500;57194147390;55813849500;57476388200;35303109600;","Low-Cost CNN for Automatic Violence Recognition on Embedded System",2022,"IEEE Access","10",,,"25190","25202",,,"10.1109/ACCESS.2022.3155123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125730767&doi=10.1109%2fACCESS.2022.3155123&partnerID=40&md5=c66a58e8fefd1e1093741b6d12406717","Department of Telecom. Electrical and Mechanical Engineering, Regional University of Blumenau (FURB), Rua São Paulo, Blumenau, 3250, Brazil; Department of Information Systems and Computing, Regional University of Blumenau (FURB)., Rua Antônio da Veiga 140, Blumenau, Brazil; Fondazione Bruno Kessler., Via Sommarive 18 Trento, Povo, Italy; Computer Science and Artificial Intalligence, Uninversity of Udine., Via delle Scienze 206, Udine, 33100, Italy; COPELABS, Lusófona University of Humanities and Technologies, Campo Grande 376, Lisboa, Portugal; VALORIZA, Research Center for Endogenous Resources Valorization, Instituto Politécnico de Portalegre, Portalegre, 7300-555, Portugal","Vieira, J.C., Department of Telecom. Electrical and Mechanical Engineering, Regional University of Blumenau (FURB), Rua São Paulo, Blumenau, 3250, Brazil; Sartori, A., Department of Telecom. Electrical and Mechanical Engineering, Regional University of Blumenau (FURB), Rua São Paulo, Blumenau, 3250, Brazil, Department of Information Systems and Computing, Regional University of Blumenau (FURB)., Rua Antônio da Veiga 140, Blumenau, Brazil; Stefenon, S.F., Fondazione Bruno Kessler., Via Sommarive 18 Trento, Povo, Italy, Computer Science and Artificial Intalligence, Uninversity of Udine., Via delle Scienze 206, Udine, 33100, Italy; Perez, F.L., Department of Telecom. Electrical and Mechanical Engineering, Regional University of Blumenau (FURB), Rua São Paulo, Blumenau, 3250, Brazil; De Jesus, G.S., Department of Information Systems and Computing, Regional University of Blumenau (FURB)., Rua Antônio da Veiga 140, Blumenau, Brazil; Leithardt, V.R.Q., COPELABS, Lusófona University of Humanities and Technologies, Campo Grande 376, Lisboa, Portugal, VALORIZA, Research Center for Endogenous Resources Valorization, Instituto Politécnico de Portalegre, Portalegre, 7300-555, Portugal","Due to the increasing number of violence cases, there is a high demand for efficient monitoring systems, however, these systems can be susceptible to failure. Therefore, this work proposes the analysis and application of low-cost Convolutional Neural Networks (CNNs) techniques to automatically recognize and classify suspicious events. Thus, it is possible to alert and assist the monitoring process with a reduced deployment cost. For this purpose, a dataset with violence and non-violence actions in scenes of crowded and non-crowded environments was assembled. The mobile CNNs architectures were adapted and obtained a classification accuracy of up to 92.05%, with a low number of parameters. To demonstrate the models' validity, a prototype was developed by using an embedded Raspberry Pi platform, able to execute a model in real-time with 4 frames-per-second of speed. In addition, a warning system was developed to recognize pre-fight behavior and anticipate violent acts, alerting security to potential situations. © 2013 IEEE.","artificial neural networks; image classification; image processing; Neural networks","Convolution; Cost benefit analysis; Costs; Embedded systems; Feature extraction; Adaptation models; Convolutional neural network; Efficient monitoring; Embedded-system; Features extraction; High demand; Legged locomotion; Low-costs; Monitoring system; Neural-networks; Neural networks",,,,,"COFAC/ILIND/COPELABS/3/2020; UIDB/04111/2020, UIDB/05064/2020; Fundação para a Ciência e a Tecnologia, FCT","This work was supported by the National Funds through the Funda??o para a Ci?ncia e a Tecnologia, I.P. (Portuguese Foundation for Science and Technology) by the Project ``VALORIZA-Research Centre for Endogenous Resource Valorization'' under Grant UIDB/05064/2020 and Grant UIDB/04111/2020, and in part by the Instituto Lus?fono de Investiga??o e Desenvolvimento (ILIND) under Project COFAC/ILIND/COPELABS/3/2020.",,,,,,,,,,"Zhou, P., Ding, Q., Luo, H., Hou, X., Violence detection in surveillance video using low-level features (2018) PLoS ONE, 13 (10); Nievas, E.B., Suarez, O.D., Garciá, G.B., Sukthankar, R., Violence detection in video using computer vision techniques (2011) Computer Anal-ysis of Images and Patterns, 6855, pp. 332-339. , Berlin, Germany: Springer; Mabrouk, A.B., Zagrouba, E., Abnormal behavior recognition for intelligent video surveillance systems: A review (2018) Expert Syst. Appl., 91, pp. 480-491. , Jan; Vishwakarma, S., Agrawal, A., A survey on activity recognition and behavior understanding in video surveillance (2013) Vis. Comput., 29 (10), pp. 983-1009. , Oct; Popoola, O.P., Wang, K., Video-based abnormal human behavior recognition_A review (2012) IEEE Trans. Syst., Man, Cybern. C, Appl. Rev., 42 (6), pp. 865-878. , Nov; Rusci, M., Rossi, D., Farella, E., Benini, L., A sub-mW IoT-endnode for always-on visual monitoring and smart triggering (2017) IEEE Internet Things J., 4 (5), pp. 1284-1295. , Oct; Stefenon, S.F., Kasburg, C., Freire, R.Z., Ferreira, F.C.S., Bertol, D.W., Nied, A., Photovoltaic power forecasting using wavelet neuro-fuzzy for active solar trackers (2021) J. Intell. Fuzzy Syst., 40 (1), pp. 1083-1096. , Jan; Cerutti, G., Prasad, R., Brutti, A., Farella, E., Compact recurrent neural networks for acoustic event detection on low-energy low-complexity platforms (2020) IEEE J. Sel. Topics Signal Process., 14 (4), pp. 654-664. , May; Cimatti, A., Tonetta, S., Contracts-refinement proof system for component-based embedded systems (2015) Sci. Comput. Program., 97, pp. 333-348. , Jan; Cimatti, A., Mover, S., Tonetta, S., Quantifier-free encoding of invariants for hybrid systems (2014) Formal Methods Syst. Des., 45 (2), pp. 165-188. , Oct; Montagna, F., Buiatti, M., Benatti, S., Rossi, D., Farella, E., Benini, L., A machine learning approach for automated wide-range frequency tagging analysis in embedded neuromonitoring systems (2017) Methods, 129, pp. 96-107. , Oct; Stefenon, S.F., Kasburg, C., Nied, A., Klaar, A.C.R., Ferreira, F.C.S., Branco, N.W., Hybrid deep learning for power generation forecasting in active solar trackers (2020) IET Gener., Transmiss. Distrib., 14 (23), pp. 5667-5674. , Dec; Rusci, M., Rossi, D., Lecca, M., Gottardi, M., Farella, E., Benini, L., An event-driven ultra-low-power smart visual sensor (2016) IEEE Sensors J., 16 (13), pp. 5344-5353. , Jul; Neto, N.F.S., Stefenon, S.F., Meyer, L.H., Bruns, R., Nied, A., Seman, L.O., Gonzalez, G.V., Yow, K.-C., A study of multilayer perceptron networks applied to classification of ceramic insulators using ultrasound (2021) Appl. Sci., 11 (4), p. 1592. , Feb; Stefenon, S.F., Corso, M.P., Nied, A., Perez, F.L., Yow, K., Gonzalez, G.V., Leithardt, V.R.Q., Classification of insulators using neural network based on computer vision (2021) IET Gener., Transmiss. Distrib., pp. 1-12. , Dec; Liu, D., Zhang, H., Zhou, P., Video-based facial expression recognition using graph convolutional networks (2021) Proc. 25th Int. Conf. Pattern Recognit. (ICPR), Milan, Italy, 25, pp. 607-614. , Jan; Varshney, N., Bakariya, B., Deep convolutional neural model for human activities recognition in a sequence of video by combining multiple CNN streams (2021) Multimedia Tools Appl., pp. 1-13. , Aug; Dos Santos, G.H., Seman, L.O., Bezerra, E.A., Leithardt, V.R.Q., Mendes, A.S., Stefenon, S.F., Static attitude determination using convolutional neural networks (2021) Sensors, 21 (19), p. 6419. , Sep; Corso, M.P., Perez, F.L., Stefenon, S.F., Yow, K.-C., Ovejero, R.G., Leithardt, V.R.Q., Classification of contaminated insulators using knearest neighbors based on computer vision (2021) Computers, 10 (9), p. 112. , Sep; Li, J., Jiang, X., Sun, T., Xu, K., Efficient violence detection using 3D convolutional neural networks (2019) Proc. 16th IEEE Int. Conf. Adv. Video Signal Based Surveill. (AVSS), pp. 1-8. , Taipei, Taiwan, Sep; Dai, Q., Zhao, R.-W., Wu, Z., Wang, X., Gu, Z., Wu, W., Jiang, Y.-G., Fudan-Huawei at MediaEval 2015: Detecting violent scenes and affective impact in movies with deep learning (2015) Proc. Multimedia Benchmark Workshop, pp. 1-3. , Wurzen, Germany; Stefenon, S.F., Freire, R.Z., Meyer, L.H., Corso, M.P., Sartori, A., Nied, A., Klaar, A.C.R., Yow, K.-C., Fault detection in insulators based on ultrasonic signal processing using a hybrid deep learning technique (2020) IET Sci., Meas. Technol., 14 (10), pp. 953-961. , Dec; Fernandes, F., Stefenon, S.F., Seman, L.O., Nied, A., Ferreira, F.C.S., Subtil, M.C.M., Klaar, A.C.R., Leithardt, V.R.Q., Long short-term memory stacking model to predict the number of cases and deaths caused by COVID-19 (2021) J. Intell. Fuzzy Syst., pp. 1-14. , Dec; Ding, C., Fan, S., Zhu, M., Feng, W., Jia, B., Violence detection in video by using 3D convolutional neural networks (2014) Advances in Visual Computing, 8888, pp. 551-558. , Cham, Germany: Springer; Wang, P., Wang, P., Fan, E., Violence detection and face recognition based on deep learning (2021) Pattern Recognit. Lett., 142, pp. 20-24. , Feb; Sabokrou, M., Fayyaz, M., Fathy, M., Moayed, Z., Klette, R., Deepanomaly: Fully convolutional neural network for fast anomaly detection in crowded scenes (2018) Comput. Vis. Image Understand., 172, pp. 88-97. , Jul; Gauswami, M.H., Trivedi, K.R., Implementation of machine learning for gender detection usingCNNon raspberry Pi platform (2018) Proc. 2nd Int. Conf. Inventive Syst. Control (ICISC), Coimbatore, India, 2, pp. 608-613. , Jan; Suchitra, S.P., Tripathi, S., Real-time emotion recognition from facial images using raspberry Pi II (2016) Proc. 3rd Int. Conf. Sig-nal Process. Integr. Netw. (SPIN), Noida, India, 3, pp. 666-670. , Feb; Medeiros, A., Sartori, A., Stefenon, S.F., Meyer, L.H., Nied, A., Comparison of artificial intelligence techniques to failure prediction in contaminated insulators based on leakage current (2021) J. Intell. Fuzzy Syst., pp. 1-14. , Dec; Mazzia, V., Khaliq, A., Salvetti, F., Chiaberge, M., Real-time apple detection system using embedded systems with hardware accelerators: An edge AI application (2020) IEEE Access, 8, pp. 9102-9114; Leithardt, V., Santos, D., Silva, L., Viel, F., Zeferino, C., Silva, J., A solution for dynamic management of user profiles in IoT environments (2020) IEEE Latin Amer. Trans., 18 (7), pp. 1193-1199. , Jul; Dua, M., Singla, R., Raj, S., Jangra, A., Deep CNN models-based ensemble approach to driver drowsiness detection (2021) Neural Comput. Appl., 33, pp. 3155-3168. , Apr; Hassner, T., Itcher, Y., Kliper-Gross, O., Violent flows: Real-time detection of violent crowd behavior (2012) Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Workshops, 1, pp. 1-6. , Jun, Providence, RI, USA; Soomro, K., Roshan Zamir, A., Shah, M., (2012) UCF101: A Dataset of 101 Human Actions Classes from Videos in the Wild; Kuehne, H., Jhuang, H., Garrote, E., Poggio, T., Serre, T., HMDB: A large video database for human motion recognition (2011) Proc. Int. Conf. Comput. Vis., pp. 2556-2563. , Barcelona, Spain, Nov; Monfort, M., Vondrick, C., Oliva, A., Andonian, A., Zhou, B., Ramakrishnan, K., Bargal, S.A., Gutfreund, D., Moments in time dataset: One million videos for event understanding (2020) IEEE Trans. Pattern Anal. Mach. Intell., 42 (2), pp. 502-508. , Feb; Yoo, H.-J., Deep convolution neural networks in computer vision: A review (2015) IEIE Trans. Smart Process. Comput., 4 (1), pp. 35-43. , Feb; De Souza, P.R.R., Matteussi, K.J., Veith, A.D.S., Zanchetta, B.F., Leithardt, V.R.Q., Murciego, A.L., De Freitas, E.P., Geyer, C.F.R., Boosting big data streaming applications in clouds with BurstFlow (2020) IEEE Access, 8, pp. 219124-219136; Wong, S.C., Gatt, A., Stamatescu, V., McDonnell, M.D., Understanding data augmentation for classification: When to warp? (2016) Proc. Int. Conf. Digit. Image Comput., Techn. Appl. (DICTA), 1, pp. 1-6. , Nov, Gold Coast, QLD, Australia; Stefenon, S.F., Seman, L.O., Neto, N.F.S., Meyer, L.H., Nied, A., Yow, K.-C., Echo state network applied for classification of medium voltage insulators (2022) Int. J. Electr. Power Energy Syst., 134. , Jan; Stefenon, S.F., Ribeiro, M.H.D.M., Nied, A., Yow, K.-C., Mariani, V.C., Coelho, L.D.S., Seman, L.O., Time series forecasting using ensemble learning methods for emergency prevention in hydroelectric power plants with dam (2022) Electr. Power Syst. Res., 202. , Jan; Rajkumar, D., Image classification using network inception-architecture & appications (2021) Int. J. Innov. Res. Sci. Eng. Technol., 10 (1), pp. 329-333; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1-9. , Boston, MA, USA, Jun; Lin, C., Zhao, G., Yang, Z., Yin, A., Wang, X., Guo, L., Chen, H., Chen, Q., CIRNet: Automatic classification of human chromosome based on inception-ResNet architecture (2020) IEEE/ACM Trans. Comput. Biol. Bioinf., , early access, Jun. 18; Dionson, M.G.D., Bibangco, E.J.P., Inception-V3 architecture in dermatoglyphics-based temperament classification (2020) Philippine Social Sci. J., 3 (2), pp. 173-174. , Nov; Ucar, F., Korkmaz, D., COVIDiagnosis-Net: Deep Bayes-SqueezeNet based diagnosis of the coronavirus disease 2019 (COVID-19) from X-ray images (2020) Med. Hypotheses, 140. , Jul; Krizhevsky, A., Sulskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Informa-tion Processing Systems, 25, pp. 1-9. , Red Hook, NY, USA: Curran Associates; Xu, Y., Yang, G., Luo, J., He, J., An electronic component recognition algorithm based on deep learning with a faster SqueezeNet (2020) Math. Prob-lems Eng., 2020, pp. 1-11. , Oct; Stefenon, S.F., Seman, L.O., Neto, C.S.F., Nied, A., Seganfredo, D.M., Luz, F.G.D., Sabino, P.H., Leithardt, V.R.Q., Electric field evaluation using the finite element method and proxy models for the design of stator slots in a permanent magnet synchronous motor (2020) Electronics, 9 (11), p. 1975; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016) SqueezeNet: AlexNet-level Accuracy with 50x Fewer Parameters and <0.5 MB Model Size; Srinivasu, P.N., Sivasai, J.G., Ijaz, M.F., Bhoi, A.K., Kim, W., Kang, J.J., Classification of skin disease using deep learning neural networks with MobileNet V2 and LSTM (2021) Sensors, 21 (8), p. 2852; Phiphiphatphaisit, S., Surinta, O., Food image classification with improved MobileNet architecture and data augmentation (2020) Proc. 3rd Int. Conf. Inf. Sci. Syst., Cambridge, U.K., 3, pp. 51-56. , Mar; Kulkarni, U., Meena, M.S., Gurlahosur, S.V., Bhogar, G., Quantization friendly MobileNet (QF-MobileNet) architecture for vision based applications on embedded platforms (2021) Neural Netw., 136, pp. 28-39. , Apr; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Las Vegas, NV, USA, Jun; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., MobileNetV2: Inverted residuals and linear bottlenecks (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 4510-4520. , Salt Lake City, UT, USA, Jun; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., Learning transferable architectures for scalable image recognition (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 8697-8710. , Salt Lake City, UT, USA, Jun","Sartori, A.; Department of Information Systems and Computing, Rua Antônio da Veiga 140, Brazil; email: asartori@furb.br",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85125730767
"Fayaz J., Galasso C.","57208585437;26537243900;","A deep neural network framework for real-time on-site estimation of acceleration response spectra of seismic ground motions",2022,"Computer-Aided Civil and Infrastructure Engineering",,,,"","",,,"10.1111/mice.12830","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125542854&doi=10.1111%2fmice.12830&partnerID=40&md5=45c2f9dd1d79117d72c040ae3eb40a7d","Department of Civil, Environmental, and Geomatic Engineering, University College London, London, United Kingdom; Scuola Universitaria Superiore (IUSS) Pavia, Pavia, Italy","Fayaz, J., Department of Civil, Environmental, and Geomatic Engineering, University College London, London, United Kingdom; Galasso, C., Department of Civil, Environmental, and Geomatic Engineering, University College London, London, United Kingdom, Scuola Universitaria Superiore (IUSS) Pavia, Pavia, Italy","Various earthquake early warning (EEW) methodologies have been proposed globally for speedily estimating information (i.e., location, magnitude, ground-shaking intensities, and/or potential consequences) about ongoing seismic events for real-time/near real-time earthquake risk management. Conventional EEW algorithms have often been based on the inferred physics of a fault rupture combined with simplified empirical models to estimate the source parameters and intensity measures of interest. Given the recent boost in computational resources, data-driven methods/models are now widely accepted as effective alternatives for EEW. This study introduces a highly accurate deep-learning-based computational framework named ROSERS (i.e., Real-time On-Site Estimation of Response Spectra) to estimate the acceleration response spectrum (Sa(T)) of the expected on-site ground-motion waveforms using early non-damage-causing early p-waves and site characteristics. The framework is trained using a carefully selected extensive database of recorded ground motions. Due to the well-known correlation of Sa(T) with structures’ seismic response and resulting damage/losses, rapid and accurate knowledge of expected on-site Sa(T) values is highly beneficial to various end-users to make well-informed real-time and near-real-time decisions. The framework is thoroughly assessed and investigated through multiple statistical tests under three historical earthquake events. These analyses demonstrate that the overall framework leads to excellent prediction power and, on average, has an accuracy above 85% for hazard-consistent early-warning trigger classification. © 2022 The Authors.",,"Earthquakes; Risk management; Risk perception; Seismic response; Seismic waves; Acceleration response spectrums; Earthquake early warning; Earthquake risk; Ground shaking intensity; Ground-motion; Near-real time; Network frameworks; Real- time; Seismic event; Seismic ground motions; Deep neural networks",,,,,"Horizon 2020: 821046","This research is funded by the European Union's Horizon 2020 research and innovation program, specifically Grant Agreement Number 821046: TURNkey “Towards more Earthquake‐resilient Urban Societies through a Multi‐sensor‐based Information System enabling Earthquake Forecasting, Early Warning and Rapid Response actions.”",,,,,,,,,,"Akazawa, T., A technique for automatic detection of onset time of P- and S-phases in strong motion records (2004) 13th World Conference on Earthquake Engineering, , Vancouver, British Columbia, Canada; Ancheta, T.D., Darragh, R.B., Stewart, J.P., Seyhan, E., Silva, W.J., Chiou, B.S.J., Wooddell, K.E., Donahue, J.L., PEER NGA-West2 database (2014) Earthquake Spectra, 30 (3), pp. 989-1005; (2011) IEEE standard for transitions, pulses, and related waveforms. Waveform Generation, Measurement, and Analysis Committee IEEE Instrumentation and Measurement Society, , https://doi.org/10.1109/IEEESTD.2011.6016198; Bazzurro, P., Cornell, C.A., Shome, N., Carballo, J.E., Three proposals for characterizing MDOF nonlinear seismic response (1998) Journal of Structural Engineering, 124 (11), pp. 1281-1289. , https://doi.org/10.1061/(asce)0733-9445(1998)124:11(1281; Bhardwaj, R., Sharma, M.L., Kumar, A., Multi-parameter algorithm for earthquake early warning (2016) Geomatics, Natural Hazards and Risk, 7 (4), pp. 1242-1264. , https://doi.org/10.1080/19475705.2015.1069409; Blei, D.M., Kucukelbir, A., McAuliffe, J.D., Variational inference: A review for statisticians (2017) Journal of the American Statistical Association, 112 (518), pp. 859-877. , https://doi.org/10.1080/01621459.2017.1285773; Boore, D.M., Bommer, J.J., Processing of strong-motion accelerograms: Needs, options and consequences (2005) Soil Dynamics and Earthquake Engineering, 25 (2), pp. 93-115. , https://doi.org/10.1016/j.soildyn.2004.10.007; Borodinov, N., Neumayer, S., Kalinin, S.V., Ovchinnikova, O.S., Vasudevan, R.K., Jesse, S., Deep neural networks for understanding noisy data applied to physical property extraction in scanning probe microscopy (2019) npj Computational Materials, 5 (1), pp. 1-8. , https://doi.org/10.1038/s41524-019-0148-5; Brondi, P., Picozzi, M., Emolo, A., Zollo, A., Mucciarelli, M., Predicting the macroseismic intensity from early radiated P wave energy for on-site earthquake early warning in Italy (2015) Journal of Geophysical Research: Solid Earth, 120 (10), pp. 7174-7189. , https://doi.org/10.1002/2015JB012367; Brown, C.D., Davis, H.T., Receiver operating characteristics curves and related decision measures: A tutorial (2006) Chemometrics and Intelligent Laboratory Systems, 80 (1), pp. 24-38. , https://doi.org/10.1016/j.chemolab.2005.05.004; Caruso, A., Colombelli, S., Elia, L., Picozzi, M., Zollo, A., An on-site alert level early warning system for Italy (2017) Journal of Geophysical Research: Solid Earth, 122 (3), pp. 2106-2118. , https://doi.org/10.1002/2016JB013403; Chen, T., Guestrin, C., XGBoost (2016), Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,San Francisco, CA; Chollet, F., Deep learning with Python (2018) Manning Publications; Colombelli, S., Zollo, A., Fast determination of earthquake magnitude and fault extent from real-time P -wave recordings (2015) Geophysical Journal International, 202 (2). , https://doi.org/10.1093/gji/ggv217, 1158–1163; Cortes, C., Vapnik, V., Saitta, L., (1995) Support-vector networks editor, 20. , Kluwer Academic Publishers; Cremen, G., Galasso, C., Earthquake early warning: Recent advances and perspectives (2020) Earth-Science Reviews, 205; Cremen, G., Galasso, C., A decision-making methodology for risk-informed earthquake early warning (2021) Computer-Aided Civil and Infrastructure Engineering, 36 (6), pp. 747-761. , https://doi.org/10.1111/mice.12670; Demidenko, E., (2004) Mixed models, , John Wiley & Sons, Inc; Fayaz, J., Medalla, M., Zareian, Sensitivity of the response of box-girder seat-type bridges to the duration of ground motions arising from crustal and subduction earthquakes (2020) Engineering Structures, 219. , https://doi.org/10.1016/j.engstruct.2020.110845; Fayaz, J., Xiang, Y., Zareian, F., Generalized ground motion prediction model using hybrid recurrent neural network (2021) Earthquake Engineering and Structural Dynamics, 50 (6), pp. 1539-1561. , https://doi.org/10.1002/eqe.3410; Field, E.H., Arrowsmith, R.J., Biasi, G.P., Bird, P., Dawson, T.E., Felzer, K.R., Jackson, D.D., Zeng, Y., Uniform california earthquake rupture forecast, Version 3 (UCERF3)–The time-independent model (2014) Bulletin of the Seismological Society of America, 104 (3), p. 1122. , https://doi.org/10.1785/0120130164; Field, E.H., Dawson, T.E., Felzer, K.R., Frankel, A.D., Gupta, V., Jordan, T.H., Parsons, T., Wills, C.J., Uniform California earthquake rupture forecast, Version 2 (UCERF 2) (2009) Bulletin of the Seismological Society of America, 99 (4), pp. 2053-2107. , https://doi.org/10.1785/0120080049; Freedman, D.A., (2009) Statistical models, , Cambridge University Press; Gorijala, M., Dukkipati, A., Image generation and editing with variational info generative Adversarial Networks (2017) arXiv preprint arXiv:1701.04568; Gustafson, S.C., Little, G.R., Simon, G.M., Neural network for interpolation and extrapolation (1990) Applications of artificial neural networks, 1294, pp. 389-395. , Rogers, S. K., (Ed.),, SPIE; Hoshiba, M., Aoki, S., Numerical shake prediction for earthquake early warning: data assimilation, real-time shake mapping, and simulation of wave propagation (2015) Bulletin of the Seismological Society of America, 105 (3), pp. 1324-1338. , https://doi.org/10.1785/0120140280; Hsu, T.Y., Wu, R.T., Chang, K.C., Two novel approaches to reduce false alarm due to non-earthquake events for on-site earthquake early warning system (2016) Computer-Aided Civil and Infrastructure Engineering, 31 (7), pp. 535-549; Hsu, T.Y., Huang, S.K., Chang, Y.W., Kuo, C.H., Lin, C.M., Chang, T.M., Wen, K.L., Loh, C.H., Rapid on-site peak ground acceleration estimation based on support vector regression and P-wave features in Taiwan (2013) Soil Dynamics and Earthquake Engineering, 49, pp. 210-217. , https://doi.org/10.1016/j.soildyn.2013.03.001; Iaccarino, A.G., Picozzi, M., Bindi, D., Spallarossa, D., On-site earthquake early warning: Predictive models for acceleration response spectra considering site effects (2020) Bulletin of the Seismological Society of America, 110, pp. 1289-1304; Iervolino, I., Giorgio, M., Galasso, C., Manfredi, G., Uncertainty in early warning predictions of engineering ground motion parameters: What really matters? (2009) Geophysical Research Letters, 36 (5). , https://doi.org/10.1029/2008GL036644; Jozinović, D., Lomax, A., Štajduhar, I., Michelini, A., Rapid prediction of earthquake ground shaking intensity using raw waveform data and a convolutional neural network (2020) Geophysical Journal International, 222, pp. 1379-1389; Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., Tunyasuvunakool, K., Hassabis, D., Highly accurate protein structure prediction with AlphaFold (2021) Nature, 596 (7873), pp. 583-589. , https://doi.org/10.1038/s41586-021-03819-2; Kalkan, E., An automatic p-phase arrival-time picker (2016) Bulletin of the Seismological Society of America, 106 (3), pp. 971-986. , https://doi.org/10.1785/0120150111; Kingma, D.P., Ba, J., (2014) Adam: A method for stochastic optimization, , 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA; Kingma, D.P., Welling, M., An introduction to variational autoencoders (2019) Foundations and Trends in Machine Learning, 12 (4), pp. 307-392; (1995) Geotechnical earthquake engineering (1st ed.)., , Pearson; Kullback, S., Leibler, R.A., On information and sufficiency (1951) The Annals of Mathematical Statistics, 22 (1), pp. 79-86. , https://doi.org/10.1214/aoms/1177729694; LemaˆıtreLemaˆıtre, G., Nogueira, F., Aridas Char, C.K., Imbalanced-learn: A Python toolbox to tackle the curse of imbalanced datasets in machine learning (2017) Journal of Machine Learning Research, 18, pp. 1-5; Li, H., Yi, W.J., Yuan, X.X., Fuzzy-valued intensity measures for near fault pulse-like ground motions (2013) Computer Aided Civil and Infrastructure Engineering, 28 (10), pp. 780-795; Meier, M.A., How ‘Good’ are real-time ground motion predictions from earthquake early warning systems? (2017) Journal of Geophysical Research: Solid Earth, 122 (7), pp. 5561-5577. , https://doi.org/10.1002/2017JB014025; Minson, S.E., Baltay, A.S., Cochran, E.S., Hanks, T.C., Page, M.T., McBride, S.K., Milner, K.R., Meier, M.A., The limits of earthquake early warning accuracy and best alerting strategy (2019) Scientific Reports, 9 (1), pp. 1-13. , https://doi.org/10.1038/s41598-019-39384-y; Mu, H.Q., Yuen, K.V., Ground motion prediction equation development by heterogeneous Bayesian learning (2016) Computer-Aided Civil and Infrastructure Engineering, 31, pp. 761-776; Münchmeyer, J., Bindi, D., Leser, U., Tilmann, F., The transformer earthquake alerting model: A new versatile approach to earthquake early warning (2020) Geophysical Journal International, 225 (1), pp. 646-656. , https://doi.org/10.1093/gji/ggaa609; Panakkat, A., Adeli, H., Recent efforts in earthquake prediction (1990–2007) (2008) Natural Hazards Review, 9 (2), pp. 70-80; Panakkat, A., Adeli, H., Recurrent neural network for approximate earthquake time and location prediction using multiple seismicity indicators (2009) Computer-Aided Civil and Infrastructure Engineering, 24 (4), pp. 280-292; Petersen, M.D., Shumway, A.M., Powers, P.M., Mueller, C.S., Moschetti, M.P., Frankel, A.D., Rezaeian, S., Zeng, Y., The 2018 update of the U.S. National Seismic Hazard Model: Overview of model and implications (2020) Earthquake Spectra, 36 (1), pp. 5-41. , https://doi.org/10.1177/8755293019878199; Popov, P., Egor, T., Shuoh, Y., Chang, S.P., Design of steel MRF connections before and after 1994 Northridge earthquake (1998) Engineering Structures, 20 (12), pp. 1030-1038. , https://doi.org/10.1016/S0141-0296(97)00200-9; Rafiei, M., Adeli, H., NEEWS: A novel earthquake early warning model using neural dynamic classification and neural dynamic optimization (2017) Soil Dynamics and Earthquake Engineering, 100, pp. 417-427; Rosenblatt, F., The perceptron: A probabilistic model for information storage and organization in the brain (1958) Psychological Review, 65 (6), pp. 386-408. , https://doi.org/10.1037/h0042519; Sleeman, R., van Eck, T., Robust automatic P-Phase picking: An on-line implementation in the analysis of broadband seismogram recordings (1999) Physics of the Earth and Planetary Interiors, 113 (1-4). , https://doi.org/10.1016/S0031-9201(99)00007-2; Solomon, O.M., Larson, D.R., Paulter, N.G., Comparison of some algorithms to estimate the low and high state level of pulses (2001), pp. 96-101. , https://doi.org/10.1109/IMTC.2001.928794, IMTC 2001. Proceedings of the 18th IEEE Instrumentation and Measurement Technology Conference. Rediscovering Measurement in the Age of Informatics (Cat. No.01CH 37188),Budapest, Hungary (); (2019) Unified Hazard Tool (dynamic conterminous US 2014 edition), , https://earthquake.usgs.gov/hazards/interactive/index.php; Vamvatsikos, D., Cornell, C.A., Incremental dynamic analysis (2002) Earthquake Engineering and Structural Dynamics, 31 (3), pp. 491-514. , https://doi.org/10.1002/eqe.141; Velazquez, O., Pescaroli, G., Cremen, G., Galasso, C., A review of the technical and socio-organizational components of earthquake early warning systems (2020) Frontiers in Earth Science, 8 (October), pp. 1-19. , https://doi.org/10.3389/feart.2020.533498; Wald, D.J., Practical limitations of earthquake early warning (2020) Earthquake Spectra, 36 (3), pp. 1412-1447. , https://doi.org/10.1177/8755293020911388; Wu, S., Beck, J.L., Heaton, T.H., ePAD: Earthquake probability-based automated decision-making framework for earthquake early warning (2013) Computer-Aided Civil and Infrastructure Engineering, 28, pp. 737-752; Wu, Y.M., Kanamori, H., Development of an earthquake early warning system using real-time strong motion signals (2008) Sensors, 8 (1). , https://doi.org/10.3390/s8010001, 1–9; Xu, K., Zhang, M., Li, J., Du, S.S., Kawarabayashi, K.I., Jegelka, S., How neural networks extrapolate: From feedforward to graph neural networks (2021) International Conference on Learning Representations, , Vienna, Austria; Zarrin, M., Abyani, M., Asgarian, B., A statistical study on lognormal central tendency estimation in probabilistic seismic assessments (2020) Structure and Infrastructure Engineering, 16 (5), pp. 803-819. , https://doi.org/10.1080/15732479.2019.1668813","Fayaz, J.; Department of Civil, United Kingdom; email: j.fayaz@ucl.ac.uk",,,"John Wiley and Sons Inc",,,,,10939687,,CCIEF,,"English","Comput.-Aided Civ. Infrastruct. Eng.",Article,"Article in Press","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85125542854
"Bazan G.H., Goedtel A., Scalassara P.R., Endo W., Nunes E.A., Takase V.T.F., Guedes J.J., Gentil M.G.","56963583600;8066176400;15769802600;55662508300;57457754600;57457294700;57192695471;57222254274;","An Embedded System for Stator Short-Circuit Diagnosis in Three-Phase Induction Motors Using Information Theory and Artificial Neural Networks",2022,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",,,,"","",,,"10.1109/TSMC.2022.3149851","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124820405&doi=10.1109%2fTSMC.2022.3149851&partnerID=40&md5=7a129c057ad8bd12ac8d71b409fdc0f1","Department of Control and Industrial Process, Federal Institute of Paran&#x00E1;, Jacarezinho 86400-000, Brazil, and also with the Department of Electrical Engineering, Federal University of Technology--Paran&#x00E1;, Corn&#x00E9;lio Proc&#x00F3;pio 86300-000, Brazil; Department of Electrical Engineering, Federal University of Technology--Paran&#x00E1;, Corn&#x00E9;lio Proc&#x00F3;pio 86300-000, Brazil.; Department of Telecommunication and Control Engineering, University of S&#x00E3;o Paulo, S&#x00E3;o Paulo 05508-900, Brazil.","Bazan, G.H., Department of Control and Industrial Process, Federal Institute of Paran&#x00E1;, Jacarezinho 86400-000, Brazil, and also with the Department of Electrical Engineering, Federal University of Technology--Paran&#x00E1;, Corn&#x00E9;lio Proc&#x00F3;pio 86300-000, Brazil; Goedtel, A., Department of Electrical Engineering, Federal University of Technology--Paran&#x00E1;, Corn&#x00E9;lio Proc&#x00F3;pio 86300-000, Brazil.; Scalassara, P.R., Department of Electrical Engineering, Federal University of Technology--Paran&#x00E1;, Corn&#x00E9;lio Proc&#x00F3;pio 86300-000, Brazil.; Endo, W., Department of Electrical Engineering, Federal University of Technology--Paran&#x00E1;, Corn&#x00E9;lio Proc&#x00F3;pio 86300-000, Brazil.; Nunes, E.A., Department of Telecommunication and Control Engineering, University of S&#x00E3;o Paulo, S&#x00E3;o Paulo 05508-900, Brazil.; Takase, V.T.F., Department of Electrical Engineering, Federal University of Technology--Paran&#x00E1;, Corn&#x00E9;lio Proc&#x00F3;pio 86300-000, Brazil.; Guedes, J.J., Department of Electrical Engineering, Federal University of Technology--Paran&#x00E1;, Corn&#x00E9;lio Proc&#x00F3;pio 86300-000, Brazil.; Gentil, M.G., Department of Electrical Engineering, Federal University of Technology--Paran&#x00E1;, Corn&#x00E9;lio Proc&#x00F3;pio 86300-000, Brazil.","This study presents an embedded system in hardware based on mutual information measurements and artificial neural networks for the stator winding short-circuit diagnosis of three-phase induction motors (TIMs) with a line-connected sinusoidal power supply. The methodology employs an information theory measure to extract the most relevant characteristics of the current signals of TIM phases A and B. These data are presented to a multilayer perceptron neural network that performs the pattern classification. Experimental tests with different machine operating conditions validate the robustness and efficiency of the proposed methodology. IEEE","Artificial neural networks (ANNs); embedded system; induction motors; Induction motors; Monitoring; mutual information (MI); Power supplies; Rotors; stator short-circuit (SC) diagnosis; Stator windings; Torque; Vibrations","Classification (of information); Electric network analysis; Embedded systems; Induction motors; Information theory; Stators; Winding; Artificial neural network; Circuit diagnosis; Embedded-system; Inductions motors; Mutual information; Mutual informations; Power supply; Stator short-circuit diagnose; Stator winding; Vibration; Neural networks",,,,,,,,,,,,,,,,,,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21682216,,,,"English","IEEE Trans. Syst. Man Cybern. Syst.",Article,"Article in Press","",Scopus,2-s2.0-85124820405
"Oh S., Kwon D., Yeom G., Kang W.-M., Lee S., Woo S.Y., Kim J., Lee J.-H.","57204692443;57203288190;57219686810;57002141300;57201530665;57201527826;57226014340;57221622173;","Neuron Circuits for Low-Power Spiking Neural Networks Using Time-To-First-Spike Encoding",2022,"IEEE Access","10",,,"24444","24455",,,"10.1109/ACCESS.2022.3149577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124767173&doi=10.1109%2fACCESS.2022.3149577&partnerID=40&md5=696e9595a7db3d61054e331b42693157","Department of ECE and ISRC, Seoul National University, Seoul, 08826, South Korea","Oh, S., Department of ECE and ISRC, Seoul National University, Seoul, 08826, South Korea; Kwon, D., Department of ECE and ISRC, Seoul National University, Seoul, 08826, South Korea; Yeom, G., Department of ECE and ISRC, Seoul National University, Seoul, 08826, South Korea; Kang, W.-M., Department of ECE and ISRC, Seoul National University, Seoul, 08826, South Korea; Lee, S., Department of ECE and ISRC, Seoul National University, Seoul, 08826, South Korea; Woo, S.Y., Department of ECE and ISRC, Seoul National University, Seoul, 08826, South Korea; Kim, J., Department of ECE and ISRC, Seoul National University, Seoul, 08826, South Korea; Lee, J.-H., Department of ECE and ISRC, Seoul National University, Seoul, 08826, South Korea","Hardware-based Spiking Neural Networks (SNNs) are regarded as promising candidates for the cognitive computing system due to its low power consumption and highly parallel operation. In this paper, we train the SNN in which the firing time carries information using temporal backpropagation. The temporally encoded SNN with 512 hidden neurons achieved an accuracy of 96.90% for the MNIST test set. Furthermore, the effect of the device variation on the accuracy in temporally encoded SNN is investigated and compared with that of the rate-encoded network. In a hardware configuration of our SNN, NOR-type analog memory having an asymmetric floating gate is used as a synaptic device. In addition, we propose a neuron circuit including a refractory period generator for temporally encoded SNN. The performance of the 2-layer neural network composed of synapses and proposed neurons is evaluated through circuit simulation using SPICE based on the BSIM3v3 model with 0.35~μ m technology. The network with 128 hidden neurons achieved an accuracy of 94.9%, a 0.1% reduction compared to that of the system simulation of the MNIST dataset. Finally, each block's latency and power consumption constituting the temporal network is analyzed and compared with those of the rate-encoded network depending on the total time step. Assuming that the network has 256 total time steps, the temporal network consumes 15.12 times less power than the rate-encoded network and makes decisions 5.68 times faster. © 2013 IEEE.","hardware-based neural networks; Neuromorphic; neuron circuits; spiking neural networks (SNNs); temporal coding; time-to-first-spike (TTFS) coding","Electric power utilization; Encoding (symbols); Low power electronics; Network coding; Neural networks; SPICE; Timing circuits; Biological neural networks; Encodings; Firing; Hardware-based neural network; Neural-networks; Neuromorphic; Neuron circuits; Non-volatile memory; Nonvolatile memory; Performances evaluation; Spiking neural network; Synapse; Temporal coding; Time-to-first-spike coding; Neurons",,,,,"Ministry of Science, ICT and Future Planning, MSIP: 2021M3F3A2A02037889; National Research Foundation of Korea, NRF; National Key Research and Development Program of China, NKRDPC","This work was supported in part by the Brain Korea 21 Plus Project in 2022, and in part by the National Research and Development Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT under 2021M3F3A2A02037889.",,,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural. Inf. Process. Syst. (NIPS), pp. 1097-1105. , http://papers.nips.cc/paper/4824-imagenet-classification-withdeep-convolutional-neural-networks; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444. , May; Gokmen, T., Vlasov, Y., Acceleration of deep neural network training with resistive cross-point devices: Design considerations (2016) Frontiers Neurosci., 10, pp. 1-13. , Jul; Ambrogio, S., Narayana, P., Tsai, H., Shelby, R.M., Boybat, I., Nolfo, C., Sidler, S., Burr, G.W., Equivalent-accuracy accelerated neuralnetwork training using analogue memory (2018) Nature, 558, pp. 60-67. , Jun; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proc. 25th Int. Conf. Mach. Learn. (ICML), pp. 160-167; Jiang, F., Dong, L., Dai, Q., Designing a mixed multilayer wavelet neural network for solving ERI inversion problem with massive amounts of data: A hybrid STGWO-GD learning approach (2020) IEEE Trans. Cybern., , early access, May 20; Jiang, F., Dong, L., Wang, K., Yang, K., Pan, C., Distributed resource scheduling for large-scale MEC systems: A multi-agent ensemble deep reinforcement learning with imitation acceleration (2021) IEEE Internet Things J., , early access, Sep. 20; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323, pp. 533-536. , Oct; Ba, J., Caruana, R., Do deep nets really need to be deep? (2014) Proc. Adv. Neural. Inf. Process. Syst. (NIPS), pp. 2654-2662. , http://papers.nips.cc/paper/5484-do-deep-nets-reallyneed-to-be-deep; Taherkhani, A., Belatreche, A., Li, Y., Cosma, G., Maguire, L.P., McGinnity, T.M., A review of learning in biologically plausible spiking neural networks (2020) Neural Netw., 122, pp. 253-272. , Feb; Khalil, K., Eldash, O., Dey, B., Kumar, A., Bayoumi, M., Architecture of a novel low-cost hardware neural network (2020) Proc. IEEE 63rd Int. Midwest Symp. Circuits Syst. (MWSCAS), pp. 1060-1063. , Aug; Khalil, K., Eldash, O., Kumar, A., Bayoumi, M., An Efficient approach for neural network architecture (2018) Proc. 25th IEEE Int. Conf. Electron., Circuits Syst. (ICECS), pp. 745-748. , Dec; Rumelhart, D.E., McClelland, J.L., (1986) Parallel Distributed Processing: Explorations in the Microstructure of Cognition, 1. , Cambridge, MA, USA: MIT Press; Pfeiffer, M., Pfeil, T., Deep learning with spiking neurons: Opportunities and challenges (2018) Frontiers Neurosci., 12, p. 774. , Oct; Rueckauer, B., Lungu, I.-A., Hu, Y., Pfeiffer, M., Liu, S.-C., Conversion of continuous-valued deep networks to Efficient event-driven networks for image classification (2017) Frontiers Neurosci., 11, p. 682. , Dec; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper, Jun; Hunsberger, E., Eliasmith, C., (2016) Training Spiking Deep Networks for Neuromorphic Hardware; Maass, W., Natschläger, T., Emulation of Hopfield networks with spiking neurons in temporal coding (1998) Computational Neuroscience. Springer, pp. 221-226; Kayser, C., Montemurro, M.A., Logothetis, N.K., Panzeri, S., Spikephase coding boosts and stabilizes information carried by spatial and temporal spike patterns (2009) Neuron, 61 (4), pp. 597-608; Kim, J., Kim, H., Huh, S., Lee, J., Choi, K., Deep neural networks with weighted spikes (2018) Neurocomputing, 311, pp. 373-386. , Oct; Izhikevich, E.M., Desai, N.S., Walcott, E.C., Hoppensteadt, F.C., Bursts as a unit of neural information: Selective communication via resonance (2003) Trends Neurosci., 26 (3), pp. 161-167. , Mar; Park, S., Kim, S., Choe, H., Yoon, S., Fast and Efficient information transmission with burst spikes in deep spiking neural networks (2019) Proc. 56th Annu. Design Autom. Conf., pp. 1-6. , Jun; Park, S., Lee, D., Yoon, S., (2021) Noise-robust Deep Spiking Neural Networks with Temporal Information; Bohte, S.M., Kok, J.N., La Poutréerror, H., Error-backpropagation in temporally encoded networks of spiking neurons (2000) Neurocomput-ing, 48 (1-4), pp. 17-37; Yu, Q., Tang, H., Tan, K.C., Yu, H., A brain-inspired spiking neural network model with temporal encoding and learning (2014) Neurocomputing, 138, pp. 3-13. , Aug; Mostafa, H., Supervised learning based on temporal coding in spiking neural networks (2018) IEEE Trans. Neural Netw. Learn. Syst., 29 (7), pp. 3227-3235. , Jul; Comsa, I.M., Potempa, K., Versari, L., Fischbacher, T., Gesmundo, A., Alakuijala, J., Temporal coding in spiking neural networks with alpha synaptic function (2020) Proc. IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), pp. 8529-8533. , May; Rueckauer, B., Liu, S.-C., Conversion of analog to spiking neural networks using sparse temporal coding (2018) Proc. IEEE Int. Symp. Circuits Syst. (ISCAS), pp. 1-5. , May; Kheradpisheh, S.R., Masquelier, T., Temporal backpropagation for spiking neural networks with one spike per neuron (2020) Int. J. Neural Syst., 30 (6). , Jun; Vaila, R., Chiasson, J., Saxena, V., (2020) Adeep Unsupervised Feature Learning Spiking Neural Network with Binarized Classification Layers for EMNIST Classification Using SpykeFlow; Lee, C., Srinivasan, G., Panda, P., Roy, K., Deep spiking convolutional neural network trained with unsupervised spike-timing-dependent plasticity (2019) IEEE Trans. Cogn. Devel. Syst., 11 (3), pp. 384-394. , Sep; Kheradpisheha, S.R., Ganjtabesh, M., Thorpe, S.J., Masquelier, T., STDP-based spiking deep convolutional neural networks for object recognition (2018) Neural Netw., 99, pp. 56-67. , Mar; Oh, S., Kim, C.-H., Lee, S., Kim, J.S., Lee, J.-H., Unsupervised online learning of temporal information in spiking neural network using thin-film transistor-typeNORflash memory devices (2019) Nanotechnology, 30 (43). , Oct; Kim, C.H., Lee, S., Woo, S.Y., Kang, W.M., Lim, S., Bae, J.H., Kim, J., Lee, J.H., Demonstration of unsupervised learning with spike-timingdependent plasticity using a TFT-type NOR flash memory array (2018) IEEE Trans. Electron Devices, 65 (5), pp. 1774-1780. , May; Linn, E., Rosezin, R., Kügeler, C., Waser, R., Complementary resistive switches for passive nanocrossbar memories (2010) Nature Mater., 9, pp. 403-406. , Apr; Liang, J., Wong, H.-S.P., Cross-point memory array without cell selectors-device characteristics and data storage pattern dependencies (2010) IEEE Trans. Electron Devices, 57 (10), pp. 2531-2538. , Oct; Chiu, P.-F., Nikoli, B., A differential 2R crosspoint RRAM array with zero standby current (2015) IEEE Trans. Circuits Syst. II, Exp. Briefs, 62 (5), pp. 461-465. , May; Kim, S., Liu, X., Park, J., Jung, S., Lee, W., Woo, J., Shin, J., Hwang, H., Ultrathin (<10 nm) Nb2O5/NbO2 hybrid memory with both memory and selector characteristics for high density 3D vertically stackable RRAM applications (2012) Proc. Symp. VLSI Technol. (VLSIT), pp. 155-156. , Jun; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification (2015) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 1026-1034. , https://www.cv-foundation.org/openaccess/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper, Dec; Burr, G.W., Shelby, R.M., Sidler, S., Di Norfo, C., Jang, J., Irem, B., Shenoy, R.S., Hwang, H., Experimental demonstration and tolerancing of a large-scale neural network (165 000 synapses) using phase-change memory as the synaptic weight element (2015) IEEE Trans. Electron Devices, 62 (11), pp. 3498-3507. , Jul; Lim, S., Kwon, D., Eum, J.H., Lee, S.T., Bae, J.H., Kim, H., Kim, C.H., Lee, J.H., Highly reliable inference system of neural networks using gated Schottky diodes (2019) IEEE J. Electron Devices Soc., 7, pp. 522-528; Kwon, D., Lim, S., Bae, J.-H., Lee, S.-T., Kim, H., Kim, C.-H., Park, B.-G., Lee, J.-H., Adaptive weight quantization method for nonlinear synaptic devices (2019) IEEE Trans. Electron Device, 66 (1), pp. 395-401. , Jan; Neftci, E.O., Augustine, C., Paul, S., Detorakis, G., Event-driven random back-propagation: Enabling neuromorphic deep learning machines (2017) Frontiers Neurosci., 11, p. 324. , Jun; Yu, S., Gao, B., Fang, Z., Yu, H., Kang, J., Wong, H.-S.-P., A low energy oxide-based electronic synaptic device for neuromorphic visual systems with tolerance to device variation (2013) Adv. Mater., 25 (12), pp. 1774-1779. , Mar; Querlioz, D., Bichler, O., Dollfus, P., Gamrat, C., Immunity to device variations in a spiking neural network with memristive nanodevices (2013) IEEE Trans. Nanotechnol., 12 (3), pp. 288-295. , May; Sakemi, Y., Morino, K., Morie, T., Aihara, K., (2020) A Supervised Learning Algorithm for Multilayer Spiking Neural Networks Based on Temporal Coding Toward Energy-Efficient VLSI Processor Design; Li, Y., Wang, Z., Midya, R., Xia, Q., Yang, J.J., Review of memristor devices in neuromorphic computing: Materials sciences and device challenges (2018) J. Phys. D, Appl. Phys., 51 (50). , Dec; Kwon, D., Lim, S., Bae, J.-H., Lee, S.-T., Kim, H., Seo, Y.-T., Oh, S., Lee, J.-H., On-chip training spiking neural networks using approximated backpropagation with analog synaptic devices (2020) Frontiers Neurosci., 14, p. 423. , Jul; Truong, S.N., Single crossbar array of memristors with bipolar inputs for neuromorphic image recognition (2020) IEEE Access, 8, pp. 69327-69332; Chen, P.-Y., Lin, B., Wang, I.-T., Hou, T.-H., Ye, J., Vrudhula, S., Seo, J.-S., Yu, S., Mitigating effects of non-ideal synaptic device characteristics for on-chip learning (2015) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 194-199. , Nov; Alibart, F., Gao, L., Hoskins, B.D., Strukov, D.B., High precision tuning of state for memristive devices by adaptable variation-tolerant algorithm (2012) Nanotechnology, 23 (7). , Feb; Shari, M.J., Banadaki, Y.M., General SPICE models for memristor and application to circuit simulation of memristor-based synapses and memory cells (2010) J. Circuits, Syst. Comput., 19 (2), pp. 407-424. , Apr; Kim, H., Park, B.-G., Solving overlapping pattern issues in on-chip learning of bio-inspired neuromorphic system with synaptic transistors (2019) Electronics, 9 (1), p. 13. , Dec; Kang, W.-M., Kim, C.-H., Lee, S., Woo, S.Y., Bae, J.-H., Park, B.-G., Lee, J.-H., A spiking neural network with a global self-controller for unsupervised learning based on spike-timing-dependent plasticity using flash memory synaptic devices (2019) Proc. Int. Joint Conf. Neural Netw. (IJCNN), , Jul; Hwang, S., Kim, H., Park, J., Kwon, M.-W., Baek, M.-H., Lee, J.-J., Park, B.-G., System-level simulation of hardware spiking neural network based on synaptic transistors and I&F neuron circuits (2018) IEEE Electron Device Lett., 39 (9), pp. 1441-1444. , Sep","Lee, J.-H.; Department of ECE and ISRC, South Korea; email: jhl@snu.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85124767173
"Ansari A., Ogunfunmi T.","57203219753;7004919562;","Hardware Acceleration of a Generalized Fast 2-D Convolution Method for Deep Neural Networks",2022,"IEEE Access","10",,,"16843","16858",,,"10.1109/ACCESS.2022.3149505","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124708781&doi=10.1109%2fACCESS.2022.3149505&partnerID=40&md5=2a4eb522aaca9c9fec4770eab02b77c0","Department of Electrical and Computer Engineering, Santa Clara University, Santa Clara, CA, United States","Ansari, A., Department of Electrical and Computer Engineering, Santa Clara University, Santa Clara, CA, United States; Ogunfunmi, T., Department of Electrical and Computer Engineering, Santa Clara University, Santa Clara, CA, United States","The hardware acceleration of Deep Neural Networks (DNN) is a highly effective and viable solution for running them on mobile devices. The power of DNNs is now available at the edge in a compact and power-efficient form factor with the aid of hardware acceleration. In this paper, we introduce an architecture that uses a generalized method called Single Partial Product 2-Dimensional Convolution (SPP2D Convolution) which calculates a 2-D convolution in a fast and expedient manner. We demonstrate that the SPP2D architecture prevents the re-fetching of input weights for the calculation of partial products, and it can calculate the output of any input size and kernel with low latency and high throughput compared to other popular techniques. SPP2D based architecture can reduce the memory access and execution time related to input reuse by at least three times in comparison with the work done in Ardakani et al. (2018) and approximately nine times that of the standard sliding window approach. We have implemented the generalized SPP2D architecture on the Xilinx KC705 Kintex-7 evaluation board to illustrate that the new SPP2D algorithm is well-suited for the hardware acceleration of DNNs. We implemented LeNet-5 and VGGNet-16 using the SPP2D architecture. We demonstrate that the SPP2D based LeNet-5 has a high throughput of 5 GOP/s and 14.8 GOP/s/W and 42 GOP/s/W for the convolution operation using the SPP2D IP. Our LeNet-5 design achieves a similar throughput to Zhou and Jiang (2015) however using {3.3} fewer DSPs and an even smaller memory and lookup table (LUT) footprint. The SPP2D based VGGNet-16 network has a latency of 91.3 ms which is 79%,97%, 17% and 95% less than contemporary designs respectively, while running at a low power of 298 mW which is similar to the power level of these designs. The total processing time of our design with a parallelism factor of nine is 3.93 secs and it is 70% less than that in Ardakani et al. (2018) and 24% less than that in Panchbhaiyye and Ogunfunmi (2021). The SPP2D based LeNet-5 and VGGNet-16 accelerators provide a low-latency design with reduced memory access thus leading to a low-power design. As a result, SPP2D convolution is very well suited for hardware acceleration of DNNs. © 2013 IEEE.","convolution; convolutional neural networks (CNN); deep neural network (DNN); hardware accelerator; LeNet-5; processing engine; SPP2D; VGGNet-16","Acceleration; Computer hardware; Convolution; Deep neural networks; Memory architecture; Network architecture; Table lookup; Throughput; Convolutional neural network; Deep learning; Deep neural network; Hardware acceleration; Hardware accelerators; Kernel; Lenet-5; Processing engine; SPP2D; VGGNet-16; Field programmable gate arrays (FPGA)",,,,,,,,,,,,,,,,"Matan, O., Baird, H.S., Bromley, J., Burges, C.J.C., Denker, J.S., Jackel, L.D., Cun, Y.L., Thompson, T.J., Reading handwritten digits: A ZIP code recognition system (1992) Computer, 25 (7), pp. 59-63. , Jul; Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey Proc Ieee, 105 (12), pp. 2295-2329. , Dec. 2017; Chetlur, S., Woolley, C., Vandermersch, P., Cohen, J., Tran, J., Catanzaro, B., Shelhamer, E., (2014) CuDNN: Efficient Primitives for Deep Learning, , arXiv:1410 0759; Vanhoucke, V., Senior, A., Mao, M.Z., Improving the speed of neural networks on CPUs (2011) Proc. Deep Learn. Unsupervised Feature Learn. Nips Workshop, 1, p. 4; Li, Z., Eichel, J., Mishra, A., Achkar, A., Naik, K., A CPU-based algorithm for traffic optimization based on sparse convolutional neural networks (2017) Proc Ieee 30th Can. Conf. Electr. Comput. Eng. (CCECE), pp. 1-5. , Apr; Abuzaid, F., (2015) Optimizing Cpu Performance for Convolutional Neural Networks, , http://cs231n.stanford.edu/reports/2015/pdfs/fabuzaid-nalreport.pdf, Stanford Univ., Stanford, CA, USA, Tech. Rep; Chakradhar, S., Sankaradas, M., Jakkula, V., Cadambi, S., A dynamically configurable coprocessor for convolutional neural networks (2010) Acm Sigarch Comput. Archit. News, 38 (3), pp. 247-257; Han, S., EIE: Efficient inference engine on compressed deep neural network (2016) Proc. ACM/ Ieee 43rd Annu. Int. Symp. Comput. Archit. (ISCA, pp. 243-254; Alwani, M., Chen, H., Ferdman, M., Milder, P., Fused-layer CNN accelerators (2016) Proc. 49th Annu IEEE/ACMInt. Symp. Microarchitecture (MICRO), pp. 1-12. , Oct; Shen, Y., Ferdman, M., Milder, P., Maximizing CNN accelerator efficiency through resource partitioning Proc. 44th Annu. Int. Symp. Comput. Archit., 2017, pp. 535-547. , Jun; Gao, P., Huang, Z., Ye, H., Chen, G., IDLA: An instruction-based adaptive CNN accelerator (2020) Proc Ieee 15th Int. Conf. Solid-State Integr. Circuit Technol. (ICSICT), pp. 1-3. , Nov; Zeng, H., Zhang, C., Prasanna, V., Fast generation of high throughput customized deep learning accelerators on FPGAs (2017) Proc. Int. Conf. ReConFigurable Comput. FPGAs (ReConFig), pp. 1-8. , Dec; Tian, T., Jin, X., Zhao, L., Wang, X., Wang, J., Wu, W., Exploration of memory access optimization for FPGA-based 3D CNN accelerator (2020) Proc. Design, Automat. Test Eur. Conf. Exhib. (DATE), pp. 1650-1655. , Mar; Panchbhaiyye, V., Ogunfunmi, T., A FIFO based accelerator for convolutional neural networks Proc Ieee Int. Conf. Acoust. Speech Signal Process. (ICASSP), pp. 1758-1762. , May 2020; Panchbhaiyye, V., Ogunfunmi, T., An efficient FIFO based accelerator for convolutional neural networks J. Signal Process. Syst, 93 (10), pp. 1117-1129. , Oct. 2021; Ardakani, A., Condo, C., Ahmadi, M., Gross, W.J., An architecture to accelerate convolution in deep neural networks Ieee Trans. Circuits Syst. I, Reg. Papers, 65 (4), pp. 1349-1362. , Apr. 2018; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc ACM/SIGDA Int. Symp. Field-Program. Gate Arrays, pp. 161-170. , Feb; Chen, Y.-H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energyef ficient reconfigurable accelerator for deep convolutional neural networks (2016) Ieee J. Solid-State Circuits, 52 (1), pp. 127-138; Lin, K.-T., Chiu, C.-T., Chang, J.-Y., Hsiao, S.-C., High utilization energy-Aware real-Time inference deep convolutional neural network accelerator Proc Ieee Int. Symp. Circuits Syst. (ISCAS), May 2021, pp. 1-5; Lacey, G., Taylor, G.W., Areibi, S., (2016) Deep Learning on FPGAs: Past, Present, and Future, , arXiv:1602 04283; Fowers, J., Brown, G., Cooke, P., Stitt, G., A performance and energy comparison of FPGAs, GPUs, and multicores for sliding-window applications (2012) Proc ACM/SIGDA Int. Symp. Field Program. Gate Arrays (FPGA, pp. 47-56; Ansari, A., Gunnam, K., Ogunfunmi, T., An efficient reconfigurable hardware accelerator for convolutional neural networks (2017) Proc. 51st Asilomar Conf. Signals, Syst., Comput., pp. 1337-1341. , Oct; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., (2016) Pruning Filters for Efficient ConvNets, , arXiv:1608 08710; Wu, J., Leng, C., Wang, Y., Hu, Q., Cheng, J., Quantized convolutional neural networks for mobile devices (2016) Proc Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 4820-4828. , Jun; Jouppi, N.P., In-datacenter performance analysis of a tensor processing unit Proc. 44th Annu. Int. Symp. Comput. Archit, 2017, pp. 1-12; Han, S., (2017) Efficient Methods and Hardware for Deep Learning, , Ph.D. dissertation, Stanford Univ., Stanford, CA, USA; Ansari, A., Ogunfunmi, T., Empirical analysis of fixed point precision quantization of CNNs (2019) Proc Ieee 62nd Int. Midwest Symp. Circuits Syst. (MWSCAS), pp. 243-246. , Aug; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Infor-mation Processing Systems, pp. 1097-1105. , F. Pereira C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. Red Hook, NY, USA: Curran Associates; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv:1409 1556; Parashar, A., SCNN: An accelerator for compressed-sparse convolutional neural networks (2017) Proc. ACM/ Ieee 44th Annu. Int. Symp. Comput. Archit. (ISCA, pp. 27-40; Liu, X., Pool, J., Han, S., Dally, W.J., (2018) Efficient Sparse-winograd Convolutional Neural Networks, , arXiv 1802 06367; Mao, H., Han, S., Pool, J., Li, W., Liu, X., Wang, Y., Dally, W.J., (2017) Exploring the Regularity of Sparse Structure in Convolutional Neural Networks, , arXiv:1705 08922; Han, S., Pool, J., Narang, S., Mao, H., Tang, S., Elsen, E., Catanzaro, B., Dally, W.J., (2016) DSD: Regularizing Deep Neural Networks with Densesparse-dense Training Flow, , arXiv:1607 04381; Jiang, L., Kim, M., Wen, W., Wang, D., XNOR-POP: A processingin-memory architecture for binary convolutional neural networks in wide-IO2 DRAMs (2017) Proc IEEE/ACMInt. Symp. Low Power Electron. Design (ISLPED), pp. 1-6. , Jul; Tang, T., Xia, L., Li, B., Wang, Y., Yang, H., Binary convolutional neural network on RRAM (2017) Proc. 22nd Asia South Pacific Design Automat. Conf. (ASP-DAC), pp. 782-787. , Jan; Lin, D., Talathi, S., Annapureddy, S., Fixed point quantization of deep convolutional networks (2016) Proc. 33rd Int. Conf. Mach. Learn, 48, pp. 2849-2858. , https://proceedings.mlr.press/v48/linb16.html, Jun, New York, NY, USA; Doi, N., Horiyama, T., Nakanishi, M., Kimura, S., Minimization of fractional wordlength on fixed-point conversion for high-level synthesis (2004) Proc. Asia South Pacific Design Automat. Conf. ASP-DAC, pp. 80-85. , Jan; Gupta, S., Agrawal, A., Gopalakrishnan, K., Narayanan, P., Deep learning with limited numerical precision (2015) Proc. 32nd Int. Conf. Int. Conf. Mach. Learn, 37, pp. 1737-1746; Lee, S., Gerstlauer, A., Fine grain word length optimization for dynamic precision scaling in DSP systems (2013) Proc. IFIP/IEEE 21st Int. Conf. Very Large Scale Integr. (VLSI-SoC), pp. 266-271. , Oct; Gysel, P., Pimentel, J., Motamedi, M., Ghiasi, S., Ristretto: A framework for empirical study of resource-efficient inference in convolutional neural networks Ieee Trans. Neural Netw. Learn. Syst, 29 (11), pp. 5784-5789. , Nov. 2018; Kum, K., Sung, W., Word-length optimization for high-level synthesis of digital signal processing systems (1998) Proc. Ieee Workshop Signal Process. Syst. (SIPS), Design Implement, pp. 569-578. , Oct; Winograd, S., (1980) Arithmetic Complexity of Computations, 33. , Philadelphia, PA, USA SIAM; Kim, T.S., Bae, J., Sunwoo, M.H., Fast convolution algorithm for convolutional neural networks (2019) Proc Ieee Int. Conf. Artif. Intell. Circuits Syst. (AICAS, pp. 258-261; Cheng, C., Parhi, K.K., Fast 2D convolution algorithms for convolutional neural networks Ieee Trans. Circuits Syst. I, Reg. Papers, 67 (5), pp. 1678-1691. , May 2020; Ansari, A., Ogunfunmi, T., Selective data transfer from DRAMS for CNNs Proc Ieee Int. Workshop Signal Process. Syst. (SiPS), 2018, pp. 1-6. , Oct; Ansari, A., Ogunfunmi, T., A fast 2-D convolution technique for deep neural networks Proc Ieee Int. Symp. Circuits Syst. (ISCAS), 2020, pp. 1-5. , Oct; Zhou, Y., Jiang, J., An FPGA-based accelerator implementation for deep convolutional neural networks (2015) Proc. 4th Int. Conf. Comput. Sci. Netw. Technol. (ICCSNT, 1, pp. 829-832; Hailesellasie, M., Hasan, S.R., Khalid, F., Wad, F.A., Shafique, M., FPGA-based convolutional neural network architecture with reduced parameter requirements Proc Ieee Int. Symp. Circuits Syst. (ISCAS), May 2018, pp. 1-5; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc Ieee, 86 (11), pp. 2278-2324. , Nov","Ogunfunmi, T.; Department of Electrical and Computer Engineering, United States; email: togunfunmi@scu.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85124708781
"Qiu Q.","57437215900;","The application of neural network algorithm and embedded system in computer distance teach system",2022,"Journal of Intelligent Systems","31","1",,"148","158",,,"10.1515/jisys-2022-0004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123930084&doi=10.1515%2fjisys-2022-0004&partnerID=40&md5=5c409d7673086891c5f9782a53d74798","Dean's Office, Baotou Railway Vocational and Technical College, Inner Mongolia, Baotou, 014060, China","Qiu, Q., Dean's Office, Baotou Railway Vocational and Technical College, Inner Mongolia, Baotou, 014060, China","The computer distance teaching system teaches through the network, and there is no entrance threshold. Any student who is willing to study can log in to the network computer distance teaching system for study at any free time. Neural network has a strong self-learning ability and is an important part of artificial intelligence research. Based on this study, a neural network-embedded architecture based on shared memory and bus structure is proposed. By looking for an alternative method of exp function to improve the speed of radial basis function algorithm, and then by analyzing the judgment conditions in the main loop during the algorithm process, these judgment conditions are modified conditionally to reduce the calculation scale, which can double the speed of the algorithm. Finally, this article verifies the function, performance, and interface of the computer distance education system. © 2022 Qin Qiu, published by De Gruyter.","computer distance teaching system; embedded system; neural network algorithm","Distance education; Memory architecture; Artificial intelligence research; Computer distance teaching system; Condition; Distance teaching; Embedded-system; Network computers; Neural networks algorithms; Neural-networks; Self-learning ability; Teaching systems; Embedded systems",,,,,,,,,,,,,,,,"Granjo, J., Rasteiro, M.G., Labvirtual - A platform for the teaching of chemical engineering: The use of interactive videos (2018) Comput Appl Eng Educ, 26, pp. 1668-1676; Wang, X., Fan, C., A computer experiment teaching system based on omap embedded system (2018) Int J Emerg Technol Learn (IJET), 13, p. 188; Xu, Y., Computer-aided design of personalized recommendation in teaching system (2019) Comput des Appl, 17, pp. 44-56; Bogach, N., Boitsova, E., Chernonog, S., Lamtev, A., Blake, J., Speech processing for language learning: A practical approach to computer-assisted pronunciation teaching (2021) Electronics, 10, p. 235; Donelan, H., Smith, A., Wong, P., Virtualization for computer networking skills development in a distance learning environment (2018) Comput Appl Eng Educ, 26, pp. 872-883; Mateo Sanguino, T.D.J., Fernandez, D., Cortes Ancos, E., Espejo Fernandez, J., Exploring strengths and weaknesses: A case study after developing a remote network lab (2018) Comput Appl Eng Educ, 26, pp. 1422-1434; Saidi, R.M., Sharip, A.A., Rahim, N., Zulkifli, Z.A., Zain, S., Evaluating students' preferences of open and distance learning (odl) tools (2021) Proc Comput Sci, 179, pp. 955-961; Chen, C., Pan, Y., Li, D., Zhang, S., Hong, J., A virtual-physical collision detection interface for ar-based interactive teaching of robot (2020) Robot Comput-Integrated Manuf, 64, p. 101948; Zampirolli, F.A., Goya, D., Pimentel, E.P., Kobayashi, G., Evaluation process for an introductory programming course using blended learning in engineering education (2018) Comput Appl Eng Educ, 26, pp. 2210-2222; Farag, S.G., Computer laboratory teaching management system for improving teaching and learning (2018) Int J Online Eng (IJOE), 14, p. 182; Lee, J., Deshpande, N., Caldwell, D.G., Mattos, L.S., Microscale precision control of a computer-assisted transoral laser microsurgery system (2020) IEEE/ASME Trans Mechatron, 25, pp. 604-615; Wu, W., Berestova, A., Lobuteva, A., Stroiteleva, N., An intelligent computer system for assessing student performance (2021) Int J Emerg Technol Learn (IJET), 16, p. 31; Tian, G., Darcy, O., Study on the design of interactive distance multimedia teaching system based on vr technology (2021) Int J Continuing Eng Educ Life-Long Learn, 31, p. 1; Xie, Y., Wu, Z., Han, X., Wang, H., Chen, Z., Computer-aided system for the detection of multicategory pulmonary tuberculosis in radiographs (2020) J Healthc Eng, 2020, pp. 1-12; Jovanovic, N., Zakic, A., Network simulation tools and spectral graph theory in teaching computer network (2018) Comput Appl Eng Educ, 26, pp. 2084-2091; Lin, L., Lee, H.M., Lee, T.Y., The applications of processing message security in computer system (2018) ICIC Exp Lett, 12, pp. 255-262; Zhao, H., Guo, L., Design of intelligent computer aided network teaching system based on web (2021) Comput des Appl, 19, pp. 12-23; Li, H., Zhao, H., Improvement of intelligent computer aided Chinese teaching system (2020) Comput des Appl, 18, pp. 12-24; Yokobori, K., Miura, T., Computer-integrated manufacturing system for membrane structures (2019) MATEC Web Conf, 258, p. 02025; Pei, Z., Wang, Y., Analysis of computer aided teaching management system for music appreciation course based on network resources (2021) Comput des Appl, 19, pp. 1-11; Chou, J.S., Liu, C.H., Automated sensing system for real-time recognition of trucks in river dredging areas using computer vision and convolutional deep learning (2021) Sensors, 21, p. 555; Zhang, J., Computer assisted instruction system under artificial intelligence technology (2021) Int J Emerg Technol Learn (IJET), 16, p. 4; Wu, H., Multimedia interaction-based computer-aided translation technology in applied English teaching (2021) Mob Inf Syst, 2021, pp. 1-10","Qiu, Q.; Dean's Office, Inner Mongolia, China; email: qu45ur@126.com",,,"De Gruyter Open Ltd",,,,,03341860,,JISYE,,"English","J Intell Syst",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85123930084
"Trabelsi Ajili M., Hara-Azumi Y.","57442786900;36959583400;","Multimodal Neural Network Acceleration on a Hybrid CPU-FPGA Architecture: A Case Study",2022,"IEEE Access","10",,,"9603","9617",,,"10.1109/ACCESS.2022.3144977","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123703553&doi=10.1109%2fACCESS.2022.3144977&partnerID=40&md5=38893b538a70379fb08425c2c37286f1","Tokyo Institute of Technology, Department of Information and Communications, School of Engineering, Tokyo, 152-8550, Japan; Tokyo Institute of Technology, Department of Information and Communications, School of Engineering, Tokyo, 152-8550, Japan","Trabelsi Ajili, M., Tokyo Institute of Technology, Department of Information and Communications, School of Engineering, Tokyo, 152-8550, Japan; Hara-Azumi, Y., Tokyo Institute of Technology, Department of Information and Communications, School of Engineering, Tokyo, 152-8550, Japan","Internet of Things and deep learning (DL) are merging into one domain and enabling outstanding technologies for various classification tasks. Such technologies are based on complex networks that mainly target powerful platforms with rich computing resources, such as servers. Therefore, for resource-constrained embedded systems, new challenges of size, performance (i.e., latency, throughput, and accuracy), and power consumption-aware networks should be addressed, particularly when edge devices handle multimodal data (i.e., different types of real-time sensing data). In this case study, we focus on DeepSense, a time-series multimodal DL framework combining convolutional neural networks (NN) and recurrent NN to process accelerometer and gyroscope data for human activity recognition. We present a field-programmable gate array (FPGA)-based acceleration for DeepSense incorporated into a hardware/software co-design approach to achieve better latency and energy efficiency using the Xilinx Vitis AI framework. The architecture of DeepSense has drawbacks that cannot be easily alleviated by Vitis AI; therefore, we introduced a new methodology of adjusting the framework and its components (i.e., the deep learning processing unit (DPU)) to achieve a custom design suitable for such time-series multimodal NN. We implemented the accelerator on two FPGA boards and performed a quantitative evaluation by varying the DPU parameter settings to support our design approach. We demonstrated the effectiveness of our implementation against the original software implementation on mobile devices by achieving up to <inline-formula> <tex-math notation=""LaTeX"">$2.5\times $ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$5.2\times $ </tex-math></inline-formula> improvement in latency and energy consumption, respectively. Through this case study, we provide crucial insights into the FPGA-based accelerator design of multimodal NN and essential aspects to consider for further improvements and adaptation in other application domains. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Artificial intelligence; Artificial neural networks; Computer architecture; Feature extraction; Field programmable gate arrays; Sensors; Software","Complex networks; Computer architecture; Computer hardware; Embedded systems; Energy efficiency; Energy utilization; Integrated circuit design; Logic gates; Network architecture; Real time systems; Recurrent neural networks; Time series; Activity recognition; Array architecture; Case-studies; Deep learning; Features extraction; Multi-modal; Multi-modal neural networks; Processing units; Software; Times series; Field programmable gate arrays (FPGA)",,,,,,,,,,,,,,,,"Deng, B.L., Li, G., Han, S., Shi, L., Xie, Y., Model compression and hardware acceleration for neural networks: A comprehensive survey (2020) Proc. IEEE, 108 (4), pp. 485-532. , Apr; Ramachandram, D., Taylor, G.W., Deep multimodal learning: A survey on recent advances and trends (2017) IEEE Signal Process. Mag., 34 (6), pp. 96-108. , Nov; Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H., Ng, A.Y., Multimodal deep learning (2011) Proc. 28th Int. Conf. Mach. Learn., pp. 689-696; Srivastava, N., Salakhutdinov, R., Multimodal learning with deep Boltzmann machines (2012) Proc. 25th Int. Conf. Neural Inf. Process. Syst., 2, pp. 2222-2230; Zadeh, A., Zellers, R., Pincus, E., Morency, L.-P., Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages (2016) IEEE Intell. Syst., 31 (6), pp. 82-88. , Nov; Baltrušaitis, T., Ahuja, C., Morency, L.-P., Multimodal machine learning: A survey and taxonomy (2019) IEEE Trans. Pattern Anal. Mach. Intell., 41 (2), pp. 423-443. , Feb; Chen, Y., Xue, Y., A deep learning approach to human activity recognition based on single accelerometer (2015) Proc. IEEE Int. Conf. Syst., Man, Cybern., pp. 1488-1492. , Oct; Radu, V., Tong, C., Bhattacharya, S., Lane, N.D., Mascolo, C., Marina, M.K., Kawsar, F., Multimodal deep learning for activity and context recognition (2018) Proc. ACM Interact., Mobile, Wearable Ubiquitous Technol., 1 (4), pp. 1-27; Yao, S., Hu, S., Zhao, Y., Zhang, A., Abdelzaher, T., DeepSense: A unified deep learning framework for time-series mobile sensing data processing (2017) Proc. 26th Int. Conf. World Wide Web, pp. 351-360. , Apr; Tian, Y., Wang, X., Chen, L., Liu, Z., Wearable sensor-based human activity recognition via two-layer diversity-enhanced multiclassifier recognition method (2019) Sensors, 19 (9), p. 2039. , Apr; Guo, K., Zeng, S., Yu, J., Wang, Y., Yang, H., DL] A survey of FPGA-based neural network inference accelerators (2019) ACM Trans. Reconfigurable Technol. Syst., 12 (1), pp. 1-26; Olazabal, O., Gofman, M., Bai, Y., Choi, Y., Sandico, N., Mitra, S., Pham, K., Multimodal biometrics for enhanced IoT security (2019) Proc. IEEE 9th Annu. Comput. Commun. Workshop Conf. (CCWC), pp. 886-893. , Jan; Yang, C.-J., Fahier, N., He, C.-Y., Li, W.-C., Fang, W.-C., An AI-edge platform with multimodal wearable physiological signals monitoring sensors for affective computing applications (2020) Proc. IEEE Int. Symp. Circuits Syst. (ISCAS), pp. 1-5. , Oct; Attaran, N., Puranik, A., Brooks, J., Mohsenin, T., Embedded low-power processor for personalized stress detection (2018) IEEE Trans. Circuits Syst. II, Exp. Briefs, 65 (12), pp. 2032-2036. , Dec; Mazumder, A.N., Ren, H., Rashid, H.-A., Hosseini, M., Chandrareddy, V., Homayoun, H., Mohsenin, T., Automatic detection of respiratory symptoms using a low power multi-input CNN processor IEEE Des. Test, p. 2021. , early access, May 11; Jafari, A., Ganesan, A., Thalisetty, C.S.K., Sivasubramanian, V., Oates, T., Mohsenin, T., Sensornet: A scalable and low-power deep convolutional neural network for multimodal data classification (2019) IEEE Trans. Circuits Syst. I, Reg. Papers, 66 (1), pp. 274-287. , Jan; Mazumder, A.N., Rashid, H.-A., Mohsenin, T., An energy-efficient low power LSTM processor for human activity monitoring Proc. IEEE 33rd Int. Syst.-Chip Conf. (SOCC), pp. 54-59. , Sep. 2020; Basterretxea, K., Echanobe, J., Campo, I.D., A wearable human activity recognition system on a chip (2014) Proc. Conf. Design Archit. Signal Image Process., pp. 1-8. , Oct; Stisen, A., Blunck, H., Bhattacharya, S., Prentow, T.S., Kjærgaard, M.B., Dey, A., Sonne, T., Jensen, M.M., Smart devices are different: Assessing and MitigatingMobile sensing heterogeneities for activity recognition (2015) Proc. 13th ACM Conf. Embedded Networked Sensor Syst., pp. 127-140. , Nov; Bhattacharya, S., Lane, N.D., From smart to deep: Robust activity recognition on smartwatches using deep learning (2016) Proc. IEEE Int. Conf. Pervasive Comput. Commun. Workshops (PerCom Workshops), pp. 1-6. , Mar; Münzner, S., Schmidt, P., Reiss, A., Hanselmann, M., Stiefelhagen, R., Dürichen, R., CNN-based sensor fusion techniques for multimodal human activity recognition (2017) Proc. ACM Int. Symp. Wearable Comput., pp. 158-165. , Sep; Min, C., Song, J., Yoo, C., Hwang, I., Kang, S., Lee, Y., Lee, S., Choi, S., Sandra helps you learn: The more you walk, the more battery your phone drains (2015) Proc. ACM Int. Joint Conf. Pervasive Ubiquitous Comput. (UbiComp), pp. 421-432; Mariatos, E.P., Economopoulos, N.M., Lymberopoulos, D., Goutis, C.E., FPGA implementation of artificial neural networks: An application on medical expert systems (1994) Proc. 4th Int. Conf. Microelectron. Neural Netw. Fuzzy Syst., pp. 287-293; Shawahna, A., Sait, S.M., El-Maleh, A., FPGA-based accelerators of deep learning networks for learning and classification: A review (2019) IEEE Access, 7, pp. 7823-7859; Venieris, S.I., Kouris, A., Bouganis, C.-S., Toolflows for mapping convolutional neural networks on FPGAs: A survey and future directions (2018) ACM Comput. Surveys, 51 (3), pp. 56:1–56:39. , Jun; (2021) Zynq DPU V3.3 Product Guide (PG338), , https://www.xilinx.com/content/dam/xilinx/support/documentation/ip_docu%mentation/dpu/v3_3/pg338-dpu.pdf, Online; Zhu, J., Wang, L., Liu, H., Tian, S., Deng, Q., Li, J., An efficient task assignment framework to accelerate DPU-based convolutional neural network inference on FPGAs (2020) IEEE Access, 8, pp. 83224-83237; Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., Kalenichenko, D., Quantization and training of neural networks for efficient integer-arithmetic-only inference (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 2704-2713. , Jun; Mittal, S., Umesh, S., A survey on hardware accelerators and optimization techniques for RNNs J. Syst. Archit., 112 (2021). , Jan. Art; Nurvitadhi, E., Sim, J., Sheffield, D., Mishra, A., Krishnan, S., Marr, D., Accelerating recurrent neural networks in analytics servers: Comparison of FPGA, CPU, GPU, and ASIC (2016) Proc. 26th Int. Conf. Field Program. Log. Appl. (FPL), pp. 1-4. , Aug","Trabelsi Ajili, M.; Tokyo Institute of Technology, Japan; email: mehdi@cad.ict.e.titech.ac.jp",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85123703553
"Huynh T.V.","57428026000;","FPGA-based Acceleration for Convolutional Neural Networks on PYNQ-Z2",2022,"International Journal of Computing and Digital Systems","11","1",,"441","449",,,"10.12785/ijcds/110136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123525960&doi=10.12785%2fijcds%2f110136&partnerID=40&md5=91f4f8a4694eef83bd6286da26e09c5f","Faculty of Electronics and Telecommunication Engineering, University of Danang - University of Science and Technology, Danang, Viet Nam","Huynh, T.V., Faculty of Electronics and Telecommunication Engineering, University of Danang - University of Science and Technology, Danang, Viet Nam","Convolutional neural network is now widely used in computer vision and deep learning applications. The most compute-intensive layer in convolutional neural networks is the convolutional layer, which should be accelerated in hardware. This paper aims to develop an efficient hardware-software co-design framework for machine learning applications on the PYNQ-Z2 board. To achieve this goal, we develop hardware implementations of convolutional IP core and use them as Python overlays. Experiments show that the hardware implementations of the convolutional IP core outperform their software implementations by factors of up to 9 times. Furthermore, we make use of the designed convolutional IP core as hardware accelerator in the handwritten digit recognition application with MNIST dataset. Thanks to the use of the hardware accelerator for the convolutional layers, the execution performance of the convolutional neural network has been improved by a factor of 6.2 times. © 2022 University of Bahrain. All rights reserved.","Convolutional Neural Network; FPGA; Hardware Accelerator; PYNQ; Python",,,,,,"Đại học Đà Nẵng, UD: B2019-DN02-61","This research is funded by Funds for Science and Technology Development of the University of Danang under project number B2019-DN02-61.",,,,,,,,,,"Wei, Y., Xia, W., Lin, M., Huang, J., Ni, B., Dong, J., Zhao, Y., Yan, S., Hcp: A flexible cnn framework for multi-label image classification (2015) IEEE transactions on pattern analysis and machine intelligence, 38 (9), pp. 1901-1907; Krizhevsky, A., Sutskever, I., Hinton, G. E., Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, 25, pp. 1097-1105; Nassif, A. B., Shahin, I., Attili, I., Azzeh, M., Shaalan, K., Speech recognition using deep neural networks: A systematic review (2019) IEEE access, 7, pp. 19143-19165; Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L. D., Zhang, J., (2016) End to end learning for self-driving cars, , arXiv preprint arXiv:1604.07316; Strigl, D., Kofler, K., Podlipnig, S., Performance and scalability of gpu-based convolutional neural networks (2010) 2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing, pp. 317-324. , IEEE; Chen, Y.-H., Krishna, T., Emer, J. S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2016) IEEE journal of solid-state circuits, 52 (1), pp. 127-138; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing fpga-based accelerator design for deep convolutional neural networks (2015) Proceedings of the 2015 ACM/SIGDA international symposium on field-programmable gate arrays, pp. 161-170; Sit, M., Kazami, R., Amano, H., Fpga-based accelerator for losslessly quantized convolutional neural networks (2017) 2017 International Conference on Field Programmable Technology (ICFPT), pp. 295-298. , IEEE; PYNQ Homepage, , pynq.io/home.html, accessed: 2020-10-18. [Online]. Available; TUL PYNQ-Z2 board, , tul.com.tw/ProductsPYNQ-Z2.html, TUL Technology Unlimited, accessed: 2020-10-18. [Online]. Available; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; Cope, B., Implementation of 2d convolution on fpga, gpu and cpu (2006) Imperial College Report, pp. 2-5; Perri, S., Lanuzza, M., Corsonello, P., Cocorullo, G., A high-performance fully reconfigurable fpga-based 2d convolution processor (2005) Microprocessors and Microsystems, 29 (8-9), pp. 381-391; PYNQ Overlay Tutorials, , pynq.readthedocs.io/en/v2.5.1/pynqoverlays.html, accessed: 2020-10-18. [Online]. Available; Coleman, J. N., Chester, E., Softley, C. I., Kadlec, J., Arithmetic on the european logarithmic microprocessor (2000) IEEE Transactions on Computers, 49 (7), pp. 702-715; Albu, F., Kadlec, J., Coleman, N., Fagan, A., Pipelined implementations of the a priori error-feedback lsl algorithm using logarithmic arithmetic (2002) 2002 IEEE International Conference on Acoustics, Speech, and Signal Processing, 3, pp. III-2681. , IEEE; Huynh, T. V., Design space exploration for a single-fpga handwritten digit recognition system (2014) 2014 IEEE Fifth International Conference on Communications and Electronics (ICCE), pp. 291-296. , IEEE; Huynh, T. V., Evaluation of artificial neural network architectures for pattern recognition on fpga (2017) International Journal of Computing and Digital Systems, 6, pp. 133-138. , 03; Huynh, T. V., Deep neural network accelerator based on fpga (2017) 2017 4th NAFOSTED Conference on Information and Computer Science, pp. 254-257. , IEEE; Gupta, S., Agrawal, A., Gopalakrishnan, K., Narayanan, P., Deep learning with limited numerical precision (2015) International conference on machine learning. PMLR, pp. 1737-1746; Bishop, David W., (2011) VHDL-2008 support library, , github.com/FPHDL/fphdl, accessed: 2020-10-18. [Online]. Available; Vivado Design Suite Evaluation and WebPACK, , xilinx.com/products/design-tools/vivado/vivado-webpack.html, Xilinx, accessed: 2020-10-18. [Online]. Available; MNIST database, , yann.lecun.com/exdb/mnist/, accessed: 2020-10-18. [Online]. Available; Google Colaboratory (Colab) Introduction, , colab.research.google.com/notebooks/intro.ipynb, Google, accessed: 2020-10-18. [Online]. Available; Baldominos, A., Saez, Y., Isasi, P., A survey of handwritten character recognition with mnist and emnist (2019) Applied Sciences, 9 (15), p. 3169","Huynh, T.V.; Faculty of Electronics and Telecommunication Engineering, Danang, Viet Nam; email: thanghv@dut.udn.vn",,,"University of Bahrain",,,,,2210142X,,,,"English","Int. J. Comput. Digit. Syst.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85123525960
"Yang P., Yang C., Lanfranchi V., Ciravegna F.","57191521367;57223309014;8957737600;8957737400;","Activity Graph based Convolutional Neural Network for Physical Activity Recognition using Acceleration and Gyroscope Data",2022,"IEEE Transactions on Industrial Informatics",,,,"","",,,"10.1109/TII.2022.3142315","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123373521&doi=10.1109%2fTII.2022.3142315&partnerID=40&md5=c841e452a966b375b7ed310696e796c6","Department of Computer Science, The University of Sheffield, 7315 Sheffield, Sheffield, United Kingdom of Great Britain and Northern Ireland, S10 2TN (e-mail: poyangcn@gmail.com); Department of Computer Science, The University of Sheffield, 7315 Sheffield, Sheffield, United Kingdom of Great Britain and Northern Ireland, S10 2TN (e-mail: Danielyangcm@gmail.com); Department of Computer Science, The University of Sheffield, 7315 Sheffield, Sheffield, United Kingdom of Great Britain and Northern Ireland, S10 2TN (e-mail: v.lanfranchi@sheffield.ac.uk); Department of Computer Science, The University of Sheffield, 7315 Sheffield, Sheffield, United Kingdom of Great Britain and Northern Ireland, S10 2TN (e-mail: f.ciravegna@sheffield.ac.uk)","Yang, P., Department of Computer Science, The University of Sheffield, 7315 Sheffield, Sheffield, United Kingdom of Great Britain and Northern Ireland, S10 2TN (e-mail: poyangcn@gmail.com); Yang, C., Department of Computer Science, The University of Sheffield, 7315 Sheffield, Sheffield, United Kingdom of Great Britain and Northern Ireland, S10 2TN (e-mail: Danielyangcm@gmail.com); Lanfranchi, V., Department of Computer Science, The University of Sheffield, 7315 Sheffield, Sheffield, United Kingdom of Great Britain and Northern Ireland, S10 2TN (e-mail: v.lanfranchi@sheffield.ac.uk); Ciravegna, F., Department of Computer Science, The University of Sheffield, 7315 Sheffield, Sheffield, United Kingdom of Great Britain and Northern Ireland, S10 2TN (e-mail: f.ciravegna@sheffield.ac.uk)","Recent deep learning technique has shown a strong ability of performing automatic feature learning and outperformed models fitting on hand-crafted features in HAR, but their performance heavily replies on large amount of labelling data. In this paper, we proposed a novel deep learning approach with optimal activity graph generation model for accurate HAR with multiple subjects using only acceleration and gyroscope data. In the approach, we designed a three-step sensor signal input sorting mechanism for generating an optimal activity graph containing alignments of neighbored signals in both width and height. Then, we proposed a deep convolutional neural network to automatic extraction of distinguishable features for HAR. The experimental evaluation was carried out on three public HAR datasets in comparing other state-of-the-art approaches. Our method averagely improved recognition accuracy about 5% compared with other methods on these three datasets, particularly suitable to accurate HAR with multiple subjects using limited sensing data. IEEE","activity graph; Convolutional neural networks; Correlation; Deep learning; deep learning; Feature extraction; Gyroscopes; Human activity recognition; Sensors; Sorting","Convolution; Deep neural networks; Extraction; Feature extraction; Graphic methods; Gyroscopes; Activity graph; Convolutional neural network; Correlation; Deep learning; Features extraction; Graph-based; Human activity recognition; Optimal activity; Physical activity; Sorting",,,,,,,,,,,,,,,,,,,,"IEEE Computer Society",,,,,15513203,,,,"English","IEEE Trans. Ind. Inf.",Article,"Article in Press","",Scopus,2-s2.0-85123373521
"Rashid N., Demirel B.U., Faruque M.A.A.","57190584074;57222186593;57217848707;","AHAR: Adaptive CNN for Energy-efficient Human Activity Recognition in Low-power Edge Devices",2022,"IEEE Internet of Things Journal",,,,"","",,2,"10.1109/JIOT.2022.3140465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122588962&doi=10.1109%2fJIOT.2022.3140465&partnerID=40&md5=27b5c66da748183192d49eba1c653556","Department of Electrical Engineering and Computer Science, University of California, Irvine, CA 92697, USA. (e-mail: nafiulr@uci.edu); Department of Electrical Engineering and Computer Science, University of California, Irvine, CA 92697, USA.","Rashid, N., Department of Electrical Engineering and Computer Science, University of California, Irvine, CA 92697, USA. (e-mail: nafiulr@uci.edu); Demirel, B.U., Department of Electrical Engineering and Computer Science, University of California, Irvine, CA 92697, USA.; Faruque, M.A.A., Department of Electrical Engineering and Computer Science, University of California, Irvine, CA 92697, USA.","Human Activity Recognition (HAR) is one of the key applications of health monitoring that requires continuous use of wearable devices to track daily activities. This paper proposes an Adaptive CNN for energy-efficient HAR (AHAR) suitable for low-power edge devices. Unlike traditional adaptive (early-exit) architecture that makes the early-exit decision based on classification confidence, AHAR proposes a novel adaptive architecture that uses an output block predictor to select a portion of the baseline architecture to use during the inference phase. Experimental results show that traditional adaptive architectures suffer from performance loss whereas our adaptive architecture provides similar or better performance as the baseline one while being energy-efficient. We validate our methodology in classifying locomotion activities from two datasets-Opportunity and w-HAR. Compared to the fog/cloud computing approaches for the Opportunity dataset, our baseline and adaptive architecture shows a comparable weighted F1 score of 91.79%, and 91.57%, respectively. For the w-HAR dataset, our baseline and adaptive architecture outperforms the state-of-the-art works with a weighted F1 score of 97.55%, and 97.64%, respectively. Evaluation on real hardware shows that our baseline architecture is significantly energy-efficient (422.38x less) and memory-efficient (14.29x less) compared to the works on the Opportunity dataset. For the w-HAR dataset, our baseline architecture requires 2.04x less energy and 2.18x less memory compared to the state-of-the-art work. Moreover, experimental results show that our adaptive architecture is 12.32% (Opportunity) and 11.14% (w-HAR) energy-efficient than our baseline while providing similar (Opportunity) or better (w-HAR) performance with no significant memory overhead. IEEE","Adaptive CNN.; Cloud computing; Computer architecture; Convolution; Convolutional neural networks; Edge Computing; Feature extraction; Human Activity Recognition; Low-power; Performance evaluation; Wearable computers; Wearable Devices","Classification (of information); Convolution; Edge computing; Green computing; Low power electronics; Memory architecture; Network architecture; Neural networks; Pattern recognition; Wearable computers; Adaptive architecture; Adaptive CNN.; Cloud-computing; Convolutional neural network; Edge computing; Features extraction; Human activity recognition; Low Power; Performances evaluation; Wearable devices; Energy efficiency",,,,,,,,,,,,,,,,,,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,23274662,,,,"English","IEEE Internet Things J.",Article,"Article in Press","All Open Access, Green",Scopus,2-s2.0-85122588962
"Piątkowski D., Walkowiak K.","57395684300;8985785100;","TinyML-Based Concept System Used to Analyze Whether the Face Mask Is Worn Properly in Battery-Operated Conditions",2022,"Applied Sciences (Switzerland)","12","1","484","","",,,"10.3390/app12010484","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122178911&doi=10.3390%2fapp12010484&partnerID=40&md5=1f0ccd662953e51fdab23425aa68be91","Faculty of Information and Communication Technology, Wrocław University of Science and Technology, Wrocław, 50-370, Poland","Piątkowski, D., Faculty of Information and Communication Technology, Wrocław University of Science and Technology, Wrocław, 50-370, Poland; Walkowiak, K., Faculty of Information and Communication Technology, Wrocław University of Science and Technology, Wrocław, 50-370, Poland","As the COVID-19 pandemic emerged, everyone’s attention was brought to the topic of the health and safety of the entire human population. It has been proven that wearing a face mask can help limit the spread of the virus. Despite the enormous efforts of people around the world, there still exists a group of people that wear face masks incorrectly. In order to provide the best level of safety for everyone, face masks must be worn correctly, especially indoors, for example, in shops, cinemas and theaters. As security guards can only handle a limited area of the frequently visited objects, intelligent sensors can be used. In order to mount them on the shelves in the shops or near the cinema cash register queues, they need to be capable of battery operation. This restricts the sensor to be as energy-efficient as possible, in order to prolong the battery life of such devices. The cost is also a factor, as cheaper devices will result in higher accessibility. An interesting and quite novel approach that can answer all these challenges is a TinyML system, that can be defined as a combination of two concepts: Machine Learning (ML) and Internet of Things (IoT). The TinyML approach enables the usage of ML algorithms on boards equipped with low-cost, low-power microcontrollers without sacrificing the classifier quality. The main goal of this paper is to propose a battery-operated TinyML system that can be used for verification whether the face mask is worn properly. To this end, we carefully analyze several ML approaches to find the best method for the considered task. After detailed analysis of computation and memory complexity as well as after some preliminary experiments, we propose to apply the K-means algorithm with carefully designed filters and a sliding window technique, since this method provides high accuracy with the required energy-efficiency for the considered classification problem related to verification of using the face mask. The STM32F411 chip is selected as the best microcontroller for the considered task. Next, we perform wide experiments to verify the proposed ML framework implemented in the selected hardware platform. The obtained results show that the developed ML-system offers satisfactory performance in terms of high accuracy and lower power consumption. It should be underlined that the low-power aspect makes it possible to install the proposed system in places without the access to power, as well as reducing the carbon footprint of AI-focused industry which is not negligible. Our proposed TinyML system solution is able to deliver very high-quality metric values with accuracy, True Positive Ratio (TPR), True Negative Ratio (TNR), precision and recall being over 96% for masked face classification while being able to reach up to 145 days of uptime using a typical 18650 battery with capacity of 2500 mAh and nominal voltage of 3.7 V. The results are obtained using a STM32F411 microcontroller with 100 MHz ARM Cortex M4, which proves that execution of complex computer vision tasks is possible on such low-power devices. It should be noted that the STM32F411 microcontroller draws only 33 mW during operation. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Computer vision; COVID-19; Embedded systems; Face masks; Machine Learning; TinyML",,,,,,"Ministry of Education and Science of the Russian Federation, Minobrnauka: POWR.03.01.00-00-P015/18","Funding: This research was funded by Ministry of Education and Science, grant number POWR.03.01.00-00-P015/18.",,,,,,,,,,"Patterson, D., Gonzalez, J., Le, Q., Liang, C., Munguia, L.M., Rothchild, D., So, D., Dean, J., (2021) Carbon emissions and large neural network training, , arXiv arXiv:2104.10350; Ng, A., (2017) Machine Learning Course. Coursera, , https://www.coursera.org/learn/machine-learning, [Online]. (accessed on 29 August 2021); Sanchez-Iborra, R., Skarmeta, A.F., Tinyml-enabled frugal smart objects: Challenges and opportunities (2020) IEEE Circuits Syst. Mag, 20, pp. 4-18. , [CrossRef]; Banbury, C.R., Reddi, V.J., Lam, M., Fu, W., Fazel, A., Holleman, J., Huang, X., Lokhmotov, A., (2020) Benchmarking TinyML systems: Challenges and direction, , arXiv arXiv:2003.04821; Gowda, M., Gowda, J., Iyer, S., Pawar, M., Gaikwad, V., Power Consumption Optimization in IoT based Wireless Sensor Node Using ESP8266 (2020) ITM Web of Conferences, 32. , EDP Sciences: Ulis, France; Bertuletti, S., Cereatti, A., Comotti, D., Caldara, M., Della Croce, U., Static and dynamic accuracy of an innovative miniaturized wearable platform for short range distance measurements for human movement applications (2017) Sensors, 17, p. 1492. , [CrossRef]; Rapid expert consultation on the effectiveness of fabric masks for the COVID-19 Pandemic (8 April 2020) (2020) Rapid Expert Consultations on the COVID-19 Pandemic: 14 March–8 April 2020, , National Academies Press (US): Washington, DC, USA; Ueki, H., Furusawa, Y., Iwatsuki-Horimoto, K., Imai, M., Kabata, H., Nishimura, H., Kawaoka, Y., Effectiveness of face masks in preventing airborne transmission of SARS-CoV-2 (2020) MSphere, 5, pp. e00637-20. , [CrossRef] [PubMed]; Li, Y., Liang, M., Gao, L., Ahmed, M.A., Uy, J.P., Cheng, C., Zhou, Q., Sun, C., Face masks to prevent transmission of COVID-19: A systematic review and meta-analysis (2020) Am. J. Infect. Control, 49, pp. 900-906. , [CrossRef]; Verma, S., Dhanak, M., Frankenfield, J., Visualizing the effectiveness of face masks in obstructing respiratory jets (2020) Phys. Fluids, 32, p. 061708. , [CrossRef]; Swain, I.D., Why the mask? The effectiveness of face masks in preventing the spread of respiratory infections such as COVID-19–a home testing protocol (2020) J. Med. Eng. Technol, 44, pp. 334-337. , [CrossRef] [PubMed]; Eikenberry, S.E., Mancuso, M., Iboi, E., Phan, T., Eikenberry, K., Kuang, Y., Kostelich, E., Gumel, A.B., To mask or not to mask: Modeling the potential for face mask use by the general public to curtail the COVID-19 pandemic (2020) Infect. Dis. Model, 5, pp. 293-308. , [CrossRef]; de Prado, M., Rusci, M., Capotondi, A., Donze, R., Benini, L., Pazos, N., Robustifying the Deployment of tinyML Models for Autonomous mini-vehicles (2021) Sensors, 21, p. 1339. , [CrossRef]; Warden, P., Situnayake, D., (2019) Tinyml: Machine Learning with Tensorflow Lite on Arduino and Ultra-Low-Power Microcontrollers, , O’Reilly Media: Newton, MA, USA; Yang, W., Jiachun, Z., Real-time face detection based on YOLO (2018) Proceedings of the 2018 1st IEEE international conference on knowledge innovation and invention (ICKII), pp. 221-224. , Jeju Island, Korea, 23–27 July; Redmon, J., Farhadi, A., (2018) Yolov3: An incremental improvement, , arXiv arXiv:1804.02767; Wu, W., Yin, Y., Wang, X., Xu, D., Face detection with different scales based on faster R-CNN (2018) IEEE Trans. Cybern, 49, pp. 4017-4028. , [CrossRef]; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2015) Adv. Neural Inf. Process. Syst, 28, pp. 91-99. , [CrossRef] [PubMed]; Loey, M., Manogaran, G., Taha, M.H.N., Khalifa, N.E.M., Fighting against COVID-19: A novel deep learning model based on YOLO-v2 with ResNet-50 for medical face mask detection (2021) Sustain. Cities Soc, 65, p. 102600. , [CrossRef] [PubMed]; Redmon, J., Farhadi, A., YOLO9000: Better, faster, stronger (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7263-7271. , Honolulu, HI, USA, 21–26 July; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , Las Vegas, NV, USA, 27–30 June; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9. , Boston, MA, USA, 7–12 July; Jiang, M., Fan, X., Yan, H., (2020) Retinamask: A face mask detector, , arXiv arXiv:2005.03950; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) Mobilenets: Efficient convolutional neural networks for mobile vision applications, , arXiv arXiv:1704.04861; Mohan, P., Paul, A.J., Chirania, A., A tiny CNN architecture for medical face mask detection for resource-constrained endpoints (2021) Innovations in Electrical and Electronic Engineering, pp. 657-670. , Springer: Berlin, Germany; Lim, H., Ryoo, S., Jung, H., Face-Mask Detection with Micro processor (2021) J. Korea Inst. Inf. Commun. Eng, 25, pp. 490-493; Raza, W., Osman, A., Ferrini, F., Natale, F.D., Energy-Efficient Inference on the Edge Exploiting TinyML Capabilities for UAVs (2021) Drones, 5, p. 127. , [CrossRef]; Ng, A., Clustering with the k-means algorithm (2012) Mach. Learn, 36, pp. 451-461; Ng, A., Advice for applying machine learning (2011) Machine Learning, , https://see.stanford.edu/materials/aimlcs229/ml-advice.pdf, (accessed on 29 August 2021); Cabani, A., Hammoudi, K., Benhabiles, H., Melkemi, M., MaskedFace-Net—A Dataset of Correctly/Incorrectly Masked Face Images in the Context of COVID-19 (2020) Smart Health, 19, p. 100144. , [CrossRef]; Hammoudi, K., Cabani, A., Benhabiles, H., Melkemi, M., Validating the Correct Wearing of Protection Mask by Taking a Selfie: Design of a Mobile Application “CheckYourMask” to Limit the Spread of COVID-19 (2020) Comput. Model. Eng. Sci, 124, pp. 1049-1059. , [CrossRef]; Roy, P., Ghosh, S., Bhattacharya, S., Pal, U., (2018) Effects of Degradations on Deep Neural Network Architectures, , arXiv arXiv:1807.10108; Karras, T., Laine, S., Aila, T., A style-based generator architecture for generative adversarial networks (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4401-4410. , Long Beach, CA, USA, 15–20 June; Chen, R.C., Automatic License Plate Recognition via sliding-window darknet-YOLO deep learning (2019) Image Vis. Comput, 87, pp. 47-56","Walkowiak, K.; Faculty of Information and Communication Technology, Poland; email: krzysztof.walkowiak@pwr.edu.pl",,,"MDPI",,,,,20763417,,,,"English","Appl. Sci.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85122178911
"Lin Y.-C., Yu C., Hsu Y.-T., Fu S.-W., Tsao Y., Kuo T.-W.","57207857121;57213355374;57207854846;55943608500;13608047100;7401533801;","SEOFP-NET: Compression and Acceleration of Deep Neural Networks for Speech Enhancement Using Sign-Exponent-Only Floating-Points",2022,"IEEE/ACM Transactions on Audio Speech and Language Processing","30",,,"1016","1031",,,"10.1109/TASLP.2021.3133209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121785550&doi=10.1109%2fTASLP.2021.3133209&partnerID=40&md5=8919a8d473529d35fc30a82bc293bce0","Research Center for Information Technology Innovation, Academia Sinica, Taipei, 11529, Taiwan; Department of Computer Science, Johns Hopkins University, Baltimore, MD  21287, United States; Department of Computer Science and Information Engineering, National Taiwan University, Taipei, 10617, Taiwan; College of Engineering, City University of Hong Kong, Kowloon Tong, Hong Kong","Lin, Y.-C., Research Center for Information Technology Innovation, Academia Sinica, Taipei, 11529, Taiwan; Yu, C., Research Center for Information Technology Innovation, Academia Sinica, Taipei, 11529, Taiwan; Hsu, Y.-T., Department of Computer Science, Johns Hopkins University, Baltimore, MD  21287, United States; Fu, S.-W., Research Center for Information Technology Innovation, Academia Sinica, Taipei, 11529, Taiwan; Tsao, Y., Research Center for Information Technology Innovation, Academia Sinica, Taipei, 11529, Taiwan; Kuo, T.-W., Department of Computer Science and Information Engineering, National Taiwan University, Taipei, 10617, Taiwan, College of Engineering, City University of Hong Kong, Kowloon Tong, Hong Kong","Numerous compression and acceleration strategies have achieved outstanding results on classification tasks in various fields. Nevertheless, the same strategies may yield unsatisfactory performance on regression tasks because the nature between regression and classification tasks differs. In this paper, a novel sign-exponent-only floating-point network (SEOFP-NET) technique is proposed to compress the model size and accelerate the inference time for speech enhancement, a regression task of speech signal processing. The proposed method compressed the sizes of deep neural network (DNN)-based speech enhancement models by quantizing the fraction bits of single-precision floating-point parameters during training. Before inference implementation, all parameters in the trained SEOFP-NET model are adjusted to accelerate the inference time by replacing the floating-point multiplier with an integer-adder. The experimental results indicate that the size of SEOFP-NET models can be significantly compressed by up to 81.249% without noticeably downgrading their speech enhancement performance, and the inference time can be accelerated to 1.212x compared with the baseline models. The results also verify that SEOFP-NET can cooperate with other efficiency strategies to achieve a synergy effect for model compression. In addition, results of a just noticeable difference experiment show that the listeners cannot facilely differentiate between the enhanced speech signals processed by the baseline model and SEOFP-NET. To the best of our knowledge, this study is one of the first works that aims to compress the model size and reduce the inference time of speech enhancement while maintaining satisfactory performance. The promising results confirm the potential applicability of SEOFP-NET to lightweight embedded devices. © 2014 IEEE.","Deep neural network model compression; Floating-point integer arithmetic circuit; Inference acceleration; Speech dereverberation; Speech enhancement","Audio signal processing; Digital arithmetic; Inference engines; Speech communication; Speech enhancement; Timing circuits; Arithmetic circuit; Computational modelling; Deep neural network model compression; Floating points; Floating-point integer arithmetic circuit; Inference acceleration; Inference algorithm; Integer arithmetic; Model compression; Neural network model; Noise measurements; Signal processing algorithms; Speech dereverberation; Task analysis; Deep neural networks",,,,,"Academia Sinica: AS-CDA-106-M04","This work was supported by Academia Sinica Career Development Award AS-CDA-106-M04",,,,,,,,,,"Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. Int. Conf. Learn. Representations; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778; Luo, P., Tian, Y., Wang, X., Tang, X., Switchable deep network for pedestrian detection (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 899-906; Zeng, X., Ouyang, W., Wang, X., Multi-stage contextual deep learning for pedestrian detection (2013) Proc. Int. Conf. Comput. Vis.Workshop, pp. 121-128; Sermanet, P., Kavukcuoglu, K., Chintala, S., Lecun, Y., Pedestrian detection with unsupervised multi-stage feature learning (2013) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 3626-3633; Graves, A., Mohamed, A., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 6645-6649; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process. Mag., 29 (6), pp. 82-97. , Nov; Deng, L., Recent advances in deep learning for speech research at microsoft (2013) Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 8604-8608; Li, J., Deng, L., Haeb-Umbach, R., Gong, Y., (2015) Robust Automatic Speech Recognition: A Bridge to Practical Applications, , Elsevier, Orlando, FL, USA: Academic; Wang, Z.-Q., Wang, D., A joint training framework for robust automatic speech recognition (2016) IEEE/ACM Trans. Audio, Speech, Lang. Process., 24 (4), pp. 796-806. , Apr; Donahue, C., Li, B., Prabhavalkar, R., Exploring speech enhancement with generative adversarial networks for robust speech recognition (2018) Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 5024-5028; Ochiai, T., Watanabe, S., Hori, T., Hershey, J.R., Multichannel endto-end speech recognition (2017) Proc. 34th Int. Conf. Mach. Learn., pp. 2632-2641; Michelsanti, D., Tan, Z.-H., Conditional generative adversarial networks for speech enhancement and noise-robust speaker verification (2017) Proc. Interspeech, pp. 2008-2012; Shon, S., Tang, H., Glass, J., VoiceID loss: Speech enhancement for speaker verification (2019) Proc. Interspeech, pp. 2888-2892; Lan, Y., Hu, Z., Soh, Y.C., Huang, G.-B., An extreme learning machine approach for speaker recognition (2013) Neural Comput. Appl., 22 (3-4), pp. 417-425; Loizou, P.C., (2013) Speech Enhancement: Theory and Practice, 2nd Ed, , Boca Raton, FL, USA: CRC Press, Inc; Boll, S., Suppression of acoustic noise in speech using spectral subtraction (1979) IEEE Trans. Acoust., Speech, Signal Process., 27 (2), pp. 113-120. , Apr; Scalart, P., Filho, J.V., Speech enhancement based on a priori signal to noise estimation (1996) Proc. IEEE Int. Conf. Acoust., Speech, Signal Process. Conf. Proc., 2, pp. 629-632; Ephraim, Y., Malah, D., Speech enhancement using a minimummean square error short-time spectral amplitude estimator (1984) IEEE Trans. Acoust., Speech, Signal Process., 32 (6), pp. 1109-1121. , Dec; Hu, Y., Loizou, P.C., A subspace approach for enhancing speech corrupted by colored noise (2002) Proc. IEEE Int. Conf. Acoust., Speech, Signal Process., pp. I573-I576; Rezayee, A., Gazor, S., An adaptive klt approach for speech enhancement (2001) IEEE Speech Audio Process., 9 (2), pp. 87-95. , Feb; Huang, P., Chen, S.D., Smaragdis, P., Hasegawa-Johnson, M., Singingvoice separation from monaural recordings using robust principal component analysis (2012) Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 57-60; Zheng, N., Zhang, X.-L., Phase-aware speech enhancement based on deep neural networks (2019) IEEE/ACM Trans. Audio, Speech, Lang. Process., 27 (1), pp. 63-76. , Jan; Liu, D., Smaragdis, P., Kim, M., Experiments on deep learning for speech denoising (2014) Proc. Interspeech, pp. 2685-2689; Qi, J., Hu, H., Wang, Y., Yang, C.-H.H., Siniscalchi, S.M., Lee, C.-H., Exploring deep hybrid tensor-to-vector network architectures for regression based speech enhancement (2020) Proc. Interspeech, pp. 76-80; Qi, J., Hu, H., Wang, Y., Yang, C.-H.H., Siniscalchi, S.M., Lee, C.-H., Tensor-to-vector regression formulti-channel speech enhancement based on tensor-train network (2020) Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 7504-7508; Wang, D., Chen, J., Supervised speech separation based on deep learning: An overview (2018) IEEE/ACMTrans. Audio, Speech, Lang. Process., 26 (10), pp. 1702-1726. , Oct; Oh, K.-S., Jung, K., Gpu implementation of neural networks (2004) Pattern Recognit, 37 (6), pp. 1311-1314; Strigl, D., Kofler, K., Podlipnig, S., Performance and scalability of gpu-based convolutional neural networks (2010) Proc. 18th Euromicro Conf. Parallel, Distrib. Netw.-Based Process., pp. 317-324; Jang, H., Park, A., Jung, K., Neural network implementation using cuda and openmp (2008) Proc. Digit. Image Comput., Techn. Appl., pp. 155-161; Courbariaux, M., Bengio, Y., David, J.-P., Binaryconnect: Training deep neural networks with binary weights during propagations (2015) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 3105-3113; Gong, Y., Liu, L., Yang, M., Bourdev, L., Compressing deep convolutional networks using vector quantization (2015) Proc. Int. Conf. Learn. Representations; Zhou, A., Yao, A., Guo, Y., Xu, L., Chen, Y., Incremental network quantization:Towards losslessCNNswith low-precisionweights (2017) Proc. Int. Conf. Learn. Representations; Hung, P.H., Lee, C.H., Yang, S.W., Somayazulu, V.S., Chen, Y.K., Chien, S.Y., Bridge deep learning to the physical world: An efficientmethod to quantize network (2015) Proc. IEEE Workshop Signal Process. Syst., pp. 1-6; Tan, K., Wang, D., Towards model compression for deep learning based speech enhancement (2021) IEEE/ACM Trans. Audio, Speech, Lang. Process., 29, pp. 1785-1794. , May; Sun, X., Gao, Z.-F., Lu, Z.-Y., Li, J., Yan, Y., A model compression method with matrix product operators for speech enhancement (2020) IEEE/ACMTrans. Audio, Speech, Lang. Process., 28, pp. 2837-2847. , Oct; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE Proc. IRE, 86 (11), pp. 2278-2324; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , Citeseer; Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A., Reading digits in natural images with unsupervised feature learning (2011) NIPS Workshop Deep Learn. Unsupervised Feature Learn.; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. 25th Int. Conf. Neural Inf. Process. Syst., 1, pp. 1097-1105; Szegedy, C., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1-9; Hwang, K., Sung, W., Fixed-point feedforward deep neural network design using weights 1, 0, and 1 (2014) Proc. IEEE Workshop Signal Process. Syst., pp. 1-6; Seide, F., Fu, H., Droppo, J., Li, G., Yu, D., 1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns (2014) Proc. Interspeech, pp. 1058-1062; Prabhavalkar, R., Alsharif, O., Bruguier, A., McGraw, L., On the compression of recurrent neural networks with an application to LVCSR acoustic modeling for embedded speech recognition (2016) Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 5970-5974; Han, S., Ese: Efficient speech recognition engine with sparse LSTM on FPGA (2017) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 75-84; Lin, Y., Han, S., Mao, H., Wang, Y., Dally, W., Deep gradient compression: Reducing the communication bandwidth for distributed training (2018) Proc. Int. Conf. Learn. Representations; Wang, Y., Li, J., Gong, Y., Small-footprint high-performance deep neural network-based speech recognition using split-VQ (2015) Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 4984-4988; Ko, J.H., Fromm, J., Philipose, M., Tashev, I., Zarar, S., (2017) Precision Scaling of Neural Networks for Efficient Audio Processing; Sun, H., Li, S., An optimization method for speech enhancement based on deep neural network (2017) Proc. IOP Conf. Ser., Earth Environ. Sci., IOP Publishing; Erdogan, H., Hershey, J.R., Watanabe, S., Roux, J.L., Phase-sensitive and recognition-boosted speech separation using deep recurrent neural networks (2015) Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 708-712; Chen, Z., Watanabe, S., Erdogan, H., Hershey, J.R., Speech enhancement and recognition using multi-task learning of long short-termmemory recurrent neural networks (2015) Proc. Interspeech, pp. 1-5; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 3431-3440; Garofolo, J.S., Lamel, L., Fisher, W.M., Fiscus, J.G., Pallett, D.S., DARPA TIMIT acoustic-phonetic continous speech corpus CD-ROM. NIST speech disc 1-1.1 (1993) NASA STI/Recon, Tech. Rep. N, 93; Huang, M., (2005) Development of Taiwan Mandarin Hearing in Noise Test, , Department of speech language pathology and audiology, National Taipei University of Nursing and Health science; (2001) Perceptual Evaluation of Speech Quality (PESQ): An Objective Method for End-to-end Speech Quality Assessment of Narrowband Telephone Networks and Speech Codecs, , I.-T. Recommendation Rec. ITU-T P. 862, Jan; Taal, C.H., Hendriks, R.C., Heusdens, R., Jensen, J., An algorithm for intelligibility prediction of time-frequency weighted noisy speech (2011) IEEE Trans. Audio, Speech, Lang. Process., 19 (7), pp. 2125-2136. , Sep; McShefferty, D., Whitmer, W.M., Akeroyd, M.A., The justnoticeable difference in speech-to-noise ratio (2015) Trends Hear., 19; McShefferty, D., Whitmer, W., Akeroyd, M., The just-meaningful difference in speech-to-noise ratio (2016) Trends Hear., 20; Manocha, P., Finkelstein, A., Zhang, R., Bryan, N.J., Mysore, G.J., Jin, Z., A differentiable perceptual audio metric learned from just noticeable differences (2020) Proc. Interspeech, pp. 2852-2856; Lu, X., Tsao, Y., Matsuda, S., Hori, C., Speech enhancement based on deep denoising autoencoder (2013) Proc. Interspeech, pp. 436-440; Xu, Y., Du, J., Dai, L.R., Lee, C.H., A regression approach to speech enhancement based on deep neural networks (2015) IEEE/ACM Trans. Audio, Speech, Lang. Process., 23 (1), pp. 7-19. , Jan; Fu, S.-W., Tsao, Y., Lu, X., SNR-aware convolutional neural network modeling for speech enhancement (2016) Proc. Interspeech, pp. 3768-3772; Xia, B., Bao, C., Wiener filtering based speech enhancement with weighted denoising auto-encoder and noise classification (2014) Speech Commun., 60, pp. 13-29; Kolbk, M., Tan, Z.-H., Jensen, J., Kolbk, M., Tan, Z.-H., Jensen, J., Speech intelligibility potential of general and specialized deep neural network based speech enhancement systems (2017) IEEE/ACM Trans. Audio, Speech, Lang. Process., 25 (1), pp. 153-167. , Jan; Fu, S.-W., Hu, T.-Y., Tsao, Y., Lu, X., Complex spectrogram enhancement by convolutional neural network with multi-metrics learning (2017) Proc. IEEE 27th Int. Workshop Mach. Learn. Signal Process., pp. 1-6; Fu, S.-W., Tsao, Y., Lu, X., Kawai, H., Rawwaveform-based speech enhancement by fully convolutional networks (2017) Proc. Asia-Pacific Signal Inf. Process. Assoc. Annu. Summit Conf., pp. 006-012; Fu, S.-W., Wang, T.-W., Tsao, Y., Lu, X., Kawai, H., End-to-end waveform utterance enhancement for direct evaluation metrics optimization by fully convolutional neural networks (2018) IEEE/ACM Trans. Audio, Speech, Lang. Process., 26 (9), pp. 1570-1584. , Sep; Pascual, S., Bonafonte, A., Serra, J., Segan: Speech enhancement generative adversarial network (2017) Proc. Interspeech, pp. 3642-3646; Oord Den, A.Van, Wavenet: A generative model for raw audio (2016) Proc. 9th ISCA Workshop on Speech Synthesis Workshop, p. 125; Wang, K., He, B., Zhu, W.-P., Caunet: Context-aware u-net for speech enhancement in time domain (2021) Proc. IEEE Int. Symp. Circuits Syst., pp. 1-5; Lin, J., Niu, S., Van Wijngaarden, A.J., McClendon, J.L., Smith, M.C., Wang, K.-C., Improved speech enhancement using a time-domain GAN with mask learning (2020) Proc. Interspeech, pp. 3286-3290; Xiao, F., Guan, J., Kong, Q., Wang, W., (2021) Time-domain Speech Enhancement with Generative Adversarial Learning; Pandey, A., Wang, D., Dense CNN with self-attention for time-domain speech enhancement (2021) IEEE/ACM Trans. Audio, Speech Lang. Proc., pp. 1270-1279. , Jan; Miyoshi, M., Kaneda, Y., Inverse filtering of room acoustics (1988) IEEE Trans. Acoust., Speech, Signal Process., 36 (2), pp. 145-152. , Feb; Flanagan, J.L., Johnston, J.D., Zahn, R., Elko, A.W., Computer-steered microphone arrays for sound transduction in large rooms (1985) J. Acoustical Soc. Amer., 78 (5), pp. 1508-1518; Flanagan, J., Surendran, A., Jan, E., Spatially selective sound capture for speech and audio processing (1993) Speech Commun., 13 (1), pp. 207-222; Feng, X., Zhang, Y., Glass, J., Speech feature denoising and dereverberation via deep autoencoders for noisy reverberant speech recognition (2014) Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 1759-1763; Ishii, T., Komiyama, H., Shinozaki, T., Horiuchi, Y., Kuroiwa, S., Reverberant speech recognition based on denoising autoencoder (2013) Proc. Interspeech, pp. 3512-3516; IEEE Standard for Binary Floating-Point Arithmetic, I. of Electrical and E. Engineers, ANSI/IEEE Std 754-1985, 1985; Abadi, M., (2015) TensorFlow: Large-scale Machine Learning on Heterogeneous Systems; Liu, C.-T., Wu, Y.-H., Lin, Y.-S., Chien, S.-Y., Computationperformance optimization of convolutional neural networks with redundant kernel removal (2018) Proc. IEEEInt. Symp.Circuits Syst., pp. 1-5; Wu, J.-Y., Yu, C., Fu, S.-W., Liu, C.-T., Chien, S.-Y., Tsao, Y., Increasing compactness of deep learning based speech enhancement models with parameter pruning and quantization techniques (2019) IEEE Signal Process. Lett., 26 (12), pp. 1887-1891. , Dec","Tsao, Y.; Research Center for Information Technology Innovation, Taiwan; email: yu.tsao@citi.sinica.edu.tw",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,23299290,,,,"English","IEEE ACM Trans. Audio Speech Lang. Process.",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85121785550
"Bao Z., Fu G., Zhang W., Zhan K., Guo J.","56102179900;57386201400;56448358500;57223276473;57223287129;","LSFQ: A Low-Bit Full Integer Quantization for High-Performance FPGA-Based CNN Acceleration",2022,"IEEE Micro","42","2",,"8","15",,,"10.1109/MM.2021.3134968","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121767295&doi=10.1109%2fMM.2021.3134968&partnerID=40&md5=6a11fb44155c80b452be5572b0a0dcb3","Beijing University of Technology, Beijing, 100124, China","Bao, Z., Beijing University of Technology, Beijing, 100124, China; Fu, G., Beijing University of Technology, Beijing, 100124, China; Zhang, W., Beijing University of Technology, Beijing, 100124, China; Zhan, K., Beijing University of Technology, Beijing, 100124, China; Guo, J., Beijing University of Technology, Beijing, 100124, China","The effective implementation of quantization depends not only on the specific task but also on the hardware resources. This article presents a hardware-aware customized quantization method for convolutional neural networks. We propose a learnable parameter soft clipping full integer quantization (LSFQ), which includes weight and activation quantization with the learnable clipping parameters. Moreover, the LSFQ accelerator architecture is customized on the field-programmable gate array (FPGA) platform to verify the hardware awareness of our method, in which DSP48E2 is designed to realize the parallel computation of six low-bit integer multiplications. The results showed that the accuracy loss of LSFQ is less than 1% compared with the full-precision models including VGG7, mobile-net v2 in CIFAR10, and CIFAR100. An LSFQ accelerator was demonstrated at the 57th IEEE/ACM Design Automation Conference System Design Contest (DAC-SDC) and won the championship at the FPGA track. © 1981-2012 IEEE.",,"Computer aided design; Computer architecture; Computer hardware; Convolution; Field programmable gate arrays (FPGA); Network architecture; Quantization (signal); Accelerator architectures; Convolutional neural network; Hardware; Hardware resources; Integer quantization; Neural-networks; Performance; Quantisation; Quantization (signal); Specific tasks; Neural networks",,,,,,,,,,,,,,,,"Zhou, S., (2016) DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients, , arXiv 1606.06160; Bengio, Y., Leonard, N., Courville, A., (2013) Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation, , arXiv 1308.3432; Choi, J., (2018) PACT: Parameterized Clipping Activation for Quantized Neural Networks, , arXiv 1805 06085; Esser, S.K., Learned step size quantization (2020) Proc. Int. Conf. Learn. Representations, pp. 1-12; Blott, M., FINN-R: An end-To-end deep-learning framework for fast exploration of quantized neural networks (2018) ACMTrans. Reconfigurable Technol. Syst, 11 (16); Louizos, C., Relaxed quantization for discretized neural networks (2019) Proc. Int. Conf. Learn. Representations, pp. 1-15; Jiao, L., Luo, C., Cao, W., Zhou, X., Wang, L., Accelerating low bit-width convolutional neural networks with embedded FPGA (2017) Proc IEEE 27th Int. Conf. Field Programmable Logic Appl, pp. 1-4; Gysel, P., Ristretto: A framework for empirical study of resource-efficient inference in convolutional neural networks (2018) IEEE Trans. Neural Netw. Learn. Syst, 20 (11), pp. 5784-5789. , Nov; Rastegari, M., XNOR-Net: Imagenet classification using binary convolutional neural networks (2016) Proc. Eur. Conf. Comput. Vis, pp. 525-542; Wu, S., Training and inference with integers in deep neural networks (2018) Proc. Int. Conf. Learn. Representations, pp. 1-14; Shayer, O., Learning discrete weights using the local reparameterization trick (2018) Proc. Int. Conf. Learn. Representations, pp. 1-12; Gong, R., Differentiable soft quantization: Bridging full-precision and low-bit neural networks (2019) Proc IEEE Int. Conf. Comput. Vis, pp. 1-10",,,,"IEEE Computer Society",,,,,02721732,,IEMID,,"English","IEEE Micro",Article,"Final","",Scopus,2-s2.0-85121767295
"Zhang Y., Yu J., Chen Y., Yang W., Zhang W., He Y.","56909202300;57222962938;57196271504;57216210671;57222958569;36079131500;","Real-time strawberry detection using deep neural networks on embedded system (rtsd-net): An edge AI application",2022,"Computers and Electronics in Agriculture","192",,"106586","","",,1,"10.1016/j.compag.2021.106586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120805692&doi=10.1016%2fj.compag.2021.106586&partnerID=40&md5=97db3ea68b677044fc3e4375ccbe45b6","School of Machinery Engineering and Automation, Zhejiang Sci-Tech University, Hangzhou, Zhejiang Province  310018, China; College of Biosystem Engineering and Food Science, Zhejiang University, Hangzhou, Zhejiang Province  310058, China; Zhejiang Lab, Hangzhou, Zhejiang Province  310018, China","Zhang, Y., School of Machinery Engineering and Automation, Zhejiang Sci-Tech University, Hangzhou, Zhejiang Province  310018, China, College of Biosystem Engineering and Food Science, Zhejiang University, Hangzhou, Zhejiang Province  310058, China; Yu, J., School of Machinery Engineering and Automation, Zhejiang Sci-Tech University, Hangzhou, Zhejiang Province  310018, China; Chen, Y., College of Biosystem Engineering and Food Science, Zhejiang University, Hangzhou, Zhejiang Province  310058, China, Zhejiang Lab, Hangzhou, Zhejiang Province  310018, China; Yang, W., School of Machinery Engineering and Automation, Zhejiang Sci-Tech University, Hangzhou, Zhejiang Province  310018, China; Zhang, W., School of Machinery Engineering and Automation, Zhejiang Sci-Tech University, Hangzhou, Zhejiang Province  310018, China; He, Y., College of Biosystem Engineering and Food Science, Zhejiang University, Hangzhou, Zhejiang Province  310058, China","Computer vision is a key technique to make agricultural machinery smart. Deep neural network has achieved great success in computer vision. How to use it at a small size, low cost, low power consumption device with high accuracy and speed on strawberry harvesting machinery has drawn much research attention. Since the infield situation has reduced number of objects and that they are easier to be distinguished from the background compared to other computer vision datasets, the huge neural network structure can be simplified in order to speed up the detection inference without penalizing the detection accuracy. In this research, a new deep neural network called RTSD-Net is proposed based on stat-of-art light-weighted YOLOv4-tiny with reduced layers and modified structure for real-time strawberry detection under infield condition. The original CSPNet was replaced by 2 types of CSPNet designed with reduced parameters and a simplified structure and 4 new network structures are designed by combining these 2 types. The performances of the 4 networks were evaluated. It was observed that the number of parameters of these 4 networks and the detection speed of the model is negatively correlated. Simplified structure and reduced parameters can contribute to faster operational speed. The last one was selected and named as RTSD-Net. Comparing with YOLOv4 tiny, the accuracy of RTSD-Net is only reduced by 0.62% but the speed is increased by 25FPS, which is 25.93% higher than that of YOLOv4-tiny. Embedded system Jetson Nano was selected as the evaluation platform to evaluate the RTSD-Net's performance for edge computing. The original Open Neural Network Exchange (ONNX) model was loaded on Jetson Nano and the speed of RTSD-Net was 13.1FPS, which is 19.0% higher than that of YOLOv4-tiny. After speeded up by TensorRT method, the transformed model reached 25.20fps, which is twice as fast as the ONNX model, and 15% faster than the YOLOv4-tiny model. After speeding up, the efficiency of RTSD-Net is enough for computer vision based strawberry detection and harvesting. In summary, the proposed RTSD-Net has good potential in smart strawberry harvesting machinery and the idea of redesigning neural structure and reducing parameters to speed up the detection rate of deep neural network is expected to have good application in edge computing. © 2021 Elsevier B.V.","Deep learning; Edge computing; Object detection; YOLO","Computer vision; Deep neural networks; Edge computing; Embedded systems; Harvesting; Multilayer neural networks; Object detection; Object recognition; Speed; AI applications; Deep learning; Edge computing; Embedded-system; Exchange models; Neural-networks; Performance; Real- time; Speed up; YOLO; Fruits; artificial neural network; computer vision; detection method; machinery; real time; research work; Fragaria x ananassa",,,,,"National Natural Science Foundation of China, NSFC: 61905219","This research was funded by the National Natural Science Foundation of China (NSFC), grant number: 61905219.",,,,,,,,,,"Aguiar, A., Santos, F., Santos, L., Filipe, V., Sousa, A., Vineyard trunk detection using deep learning – An experimental device benchmark (2020) Comput. Electron. Agric., 175; Bochkovskiy, A., Wang, C.-Y., Liao, H., (2020), -Y. M. Yolov4: Optimal speed and accuracy of object detection. arXiv preprint arXiv:2004.10934; Cass, S., Nvidia makes it easy to embed AI: The Jetson nano packs a lot of machine-learning power into DIY projects-[Hands on] (2020) IEEE Spectr., 57 (7), pp. 14-16; Chen, M., Tang, Y., Zou, X., Huang, Z., Zhou, H., Chen, S., 3D global mapping of large-scale unstructured orchard integrating eye-in-hand stereo vision and SLAM (2021) Comput. Electron. Agric., 187, p. 106237; Chen, Y., Lee, W.S., Gan, H., Peres, N., Fraisse, C., Zhang, Y., He, Y., Strawberry Yield Prediction Based on a Deep Neural Network Using High-Resolution Aerial Orthoimages (2019) Remote Sens., 11 (13), p. 1584; DeVries, T., Taylor, G.W., (2017), Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552; Gao, J., French, A.P., Pound, M.P., He, Y., Pridmore, T.P., Pieters, J.G., Deep convolutional neural networks for image-based Convolvulus sepium detection in sugar beet fields (2020) Plant Methods, 16 (1); He, K., Zhang, X., Ren, S., Sun, J., Spatial pyramid pooling in deep convolutional networks for visual recognition (2015) IEEE Trans. Pattern Anal. Mach. Intell., 37 (9), pp. 1904-1916; Henderson, P., Ferrari, V., (2016) End-to-end training of object class detectors for mean average precision, pp. 198-213. , Springer; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017), MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications; Lin, G., Tang, Y., Zou, X., Cheng, J., Xiong, J., Fruit detection in natural environment using partial shape matching and probabilistic Hough transform (2019) Precis. Agric.; Liu, J., Wang, X., Early recognition of tomato gray leaf spot disease based on MobileNetv2-YOLOv3 model (2020) Plant Methods, 16 (1); Mazzia, V., Khaliq, A., Salvetti, F., Chiaberge, M., Real-Time Apple Detection System Using Embedded Systems With Hardware Accelerators: An Edge AI Application (2020) IEEE Access, 8, pp. 9102-9114; Müller, R., Kornblith, S., Hinton, G., (2019), When does label smoothing help? arXiv preprint arXiv:1906.02629; Pound, M.P., Atkinson, J.A., Townsend, A.J., Wilson, M.H., Marcus, G., Jackson, A.S., Adrian, B., Murchie, E.H., Deep Machine Learning provides state-of-the-art performance in image-based plant phenotyping (2018) Gigascience, 10, pp. 1-10; Proteggente, A.R., Pannala, A.S., Paganga, G., Buren, L.V., Wagner, E., Wiseman, S., Put, F.V.D., Rice-Evans, C.A., The antioxidant activity of regularly consumed fruit and vegetables reflects their phenolic and vitamin C composition (2002) Free Radical Res. Commun., 36 (2), pp. 217-233; Redmon, J., Farhadi, A., (2018), Yolov3: An incremental improvement. arXiv preprint arXiv:1804.02767; Sati, V., Sánchez, S.M., Shoeibi, N., Arora, A., Corchado, J.M., (2020) Face Detection and Recognition, Face Emotion Recognition Through NVIDIA Jetson Nano, pp. 177-185. , Springer; Vanholder, H., (2016), Efficient inference with tensorrt. In): ed; Vijitkunsawat, W., Chantngarm, P., (2020), pp. 201-204. , comparison of machine learning algorithm's on self-driving car navigation using Nvidia Jetson Nano. In: 2020 17th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), IEEE; Wang, C.-Y., Liao, H.-Y.-M., Wu, Y.-H., Chen, P.-Y., Hsieh, J.-W., Yeh, I.-H., CSPNet: A new backbone that can enhance learning capability of CNN (2020) In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops, pp. 390-391; Wang, W., Xie, E., Song, X., Zang, Y., Wang, W., Lu, T., Yu, G., Shen, C., Efficient and accurate arbitrary-shaped text detection with pixel aggregation network (2019) In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 8440-8449; Yun, S., Han, D., Oh, S.J., Chun, S., Choe, J., Yoo, Y., Cutmix: Regularization strategy to train strong classifiers with localizable features (2019) Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 6023-6032; Zhang, H., Cisse, M., Dauphin, Y.N., Lopez-Paz, D., (2017), mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412; , 34, pp. 12993-13000. , Distance-IoU loss: Faster and better learning for bounding box regression. In: Proceedings of the AAAI Conference on Artificial Intelligence","Zhang, Y.; School of Machinery Engineering and Automation, China; email: yczhang@zstu.edu.cn",,,"Elsevier B.V.",,,,,01681699,,CEAGE,,"English","Comput. Electron. Agric.",Article,"Final","",Scopus,2-s2.0-85120805692
"Sanchez-Iborra R., Bernal-Escobedo L., Santa J., Skarmeta A.","55933950900;57205447415;18038232200;7004419066;","Tinyml-based fall detection for connected personal mobility vehicles",2022,"Computers, Materials and Continua","71","2",,"3869","3885",,,"10.32604/cmc.2022.022610","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120800558&doi=10.32604%2fcmc.2022.022610&partnerID=40&md5=8dec6331f879be826a0866a471a86a08","University Center of Defense, General Air Force Academy, San Javier, 30720, Spain; University of Murcia, Murcia, 30100, Spain; Technical University of Cartagena, Cartagena, 30202, Spain","Sanchez-Iborra, R., University Center of Defense, General Air Force Academy, San Javier, 30720, Spain; Bernal-Escobedo, L., University of Murcia, Murcia, 30100, Spain; Santa, J., Technical University of Cartagena, Cartagena, 30202, Spain; Skarmeta, A., University of Murcia, Murcia, 30100, Spain","A new wave of electric vehicles for personal mobility is currently crowding public spaces. They offer a sustainable and efficient way of getting around in urban environments, however, these devices bring additional safety issues, including serious accidents for riders. Thereby, taking advantage of a connected personal mobility vehicle, we present a novel on-device Machine Learning (ML)-based fall detection system that analyzes data captured from a range of sensors integrated on an on-board unit (OBU) prototype. Given the typical processing limitations of these elements, we exploit the potential of the TinyML paradigm, which enables embedding powerfulML algorithms in constrained units. We have generated and publicly released a large dataset, including real riding measurements and realistically simulated falling events, which has been employed to produce different TinyML models. The attained results show the good operation of the system to detect falls efficiently using embedded OBUs. The considered algorithms have been successfully tested on mass-market low-power units, implying reduced energy consumption, flash footprints and running times, enabling new possibilities for this kind of vehicles. © 2022 Tech Science Press. All rights reserved.","C-ITS; IoT; Machine learning; On-board unit; Personal mobility","Energy utilization; Fall detection; Large dataset; Machine learning; Vehicles; C-ITS; Detection system; Fall detection; Machine-learning; On-board units; Personal mobility; Personal mobility vehicles; Public space; Safety issues; Urban environments; Internet of things",,,,,"PGE-MOVES-SING-2019-000104; Ministerio de Ciencia, Innovación y Universidades, MCIU: PID2020-112675RB, RED2018-102585-T, RYC-2017-23823; European Commission, EC: 825496","Funding Statement: This work has been supported by the Spanish Ministry of Science, Innovation and Universities, under the Ramon y Cajal Program (ref. RYC-2017-23823) and the projects ONOFRE 3 (ref. PID2020-112675RB) and Go2Edge (ref. RED2018-102585-T); by the European Commission, under the 5G-MOBIX (ref. 825496) project; and by the Spanish Ministry for the Ecological Transition and the Demographic Challenge, under the MECANO project (ref. PGE-MOVES-SING-2019-000104). Ramon Sanchez-Iborra would like to thank Prof. Sanchez-Muñoz for his patience and valuable comments during the preparation of this paper.",,,,,,,,,,"Santa, J., Bernal-Escobedo, L., Sanchez-Iborra, R., On-board unit to connect personalmobility vehicles to the IoT (2020) 17th Int. Conf. onMobile Systems and Pervasive Computing (MobiSPC), 175, pp. 173-180; (2019) New study looks at motorized scooter injuries, , Radiological Society of North America (RSNA), RSNA Press Release; Dockless electric scooter-related injuries study (2019) APH Epidemiology and Disease Surveillance Unit, , Austin Public Health (APH); Trivedi, T.K., Liu, C., Antonio, A. L., Wheaton, N., Kreger, V., Injuries associated with standing electric scooter use (2019) JAMA Network Open, 2 (1), p. e187381; Paudel, M., Yap, F. F., Bastola, A. K., Safety assessment of personal mobility devices with different wheel size based on their dynamic stability performance (2020) International Journal of Sustainable Design, 3 (4), p. 227; Kim, J. Y., Lee, S. C., Lee, S., Lee, C. A., Ahn, K. O., Characteristics of injuries according to types of personal mobility devices in a multicenter emergency department from 2011 to 2017 (2021) Medicine, 100 (6), p. e24642; Javed, M. A., Ben Hamida, E., On the interrelation of security, QoS, and safety in cooperative ITS (2017) IEEE Transactions on Intelligent Transportation Systems, 18 (7), pp. 1943-1957; Warden, P., Situnayake, D., (2020) Tinyml: Machine Learning with Tensorflow Lite on Arduino and Ultra-Low-Power Microcontrollers, , 1st ed. Sebastopol, USA: O'Reilly Media; Sanchez-Iborra, R., Cano, M. -D., State of the art in LP-wAN solutions for industrial IoT services (2016) Sensors, 16 (5), p. 708; Zigel, Y., Litvak, D., Gannot, I., A method for automatic fall detection of elderly people using floor vibrations and sound-proof of concept on human mimicking doll falls (2009) IEEE Transactions on Biomedical Engineering, 56 (12), pp. 2858-2867; Tri, T., Truong, H., Khanh, T., Automatic fall detection using smartphone acceleration sensor (2016) International Journal of Advanced Computer Science and Applications, 7 (12), pp. 123-129; Wan, S., Qi, L., Xu, X., Tong, C., Gu, Z., Deep learning models for real-time human activity recognition with smartphones (2020) Mobile Networks and Applications, 25 (2), pp. 743-755; Casilari, E., Oviedo-Jimenez, M. A., Automatic fall detection system based on the combined use of a smartphone and a smartwatch (2015) PLOS ONE, 10 (11), p. e0140929; Minh Dang, L., Min, K., Wang, H., Jalil Piran, M., Hee Lee, C., Sensor-based and vision-based human activity recognition: A comprehensive survey (2020) Pattern Recognition, 108, p. 107561; Ferrari, A., Micucci, D., Mobilio, M., Napoletano, P., On the personalization of classification models for human activity recognition (2020) IEEE Access, 8, pp. 32066-32079; Casilari, E., Santoyo-Ramon, J. A., Cano-Garcia, J. M., UMAFall: A multisensor dataset for the research on automatic fall detection (2017) Procedia Computer Science, 110, pp. 32-39; Sanchez-Iborra, R., Skarmeta, A. F., Tinyml-enabled frugal smart objects: Challenges and opportunities (2020) IEEE Circuits and Systems Magazine, 20 (3), pp. 4-18; Iorga, M., Feldman, L., Barton, R., Martin, M. J., Goren, N., (2018) Fog computing conceptual model, , Gaithersburg, MD; Aziz, O., Musngi, M., Park, E. J., Mori, G., Robinovitch, S.N., A comparison of accuracy of fall detection algorithms (threshold-based vs. machine learning) usingwaist-mounted tri-axial accelerometer signals from a comprehensive set of falls and non-fall trials (2017) Medical & Biological Engineering & Computing, 55 (1), pp. 45-55; Vallabh, P., Malekian, R., Ye, N., Bogatinoska, C., Fall detection using machine learning algorithms (2016) 24th Int. Conf. on Software, Telecommunications and Computer Networks (SoftCOM), pp. 1-9. , andD Split, Croatia; Kumar, N., Acharya, D., Lohani, D., An IoT-based vehicle accident detection and classification system using sensor fusion (2021) IEEE Internet of Things Journal, 8 (2), pp. 869-880; Moulik, S., Majumdar, S., Fallsense: An automatic fall detection and alarm generation system in IoTenabled environment (2019) IEEE Sensors Journal, 19 (19), pp. 8452-8459; Chelli, A., Patzold, M., A machine learning approach for fall detection and daily living activity recognition (2019) IEEE Access, 7, pp. 38670-38687; Putra, I., Brusey, J., Gaura, E., Vesilo, R., An event-triggered machine learning approach for accelerometer-based fall detection (2017) Sensors, 18 (2), p. 20; Ramachandran, A., Karuppiah, A., A survey on recent advances in wearable fall detection systems (2020) BioMed Research International, 2020, pp. 1-17; Bormann, C., Ersue, M., Keranen, A., Terminology for constrained-node networks (2014) IETF RFC 7228; Ren, L., Peng, Y., Research of fall detection and fall prevention technologies: A systematic review (2019) IEEE Access, 7, pp. 77702-77722; Choi, H. -R., Ryu, M. -H., Yang, Y. -S., Lee, N. -B., Jang, D. -J., Evaluation of algorithm for the fall and fall direction detection during bike riding (2013) International Journal of Control and Automation, 6 (6), pp. 209-218; Wirth, F., Wen, T., Fernandez-Lopez, C., Stiller, C., Model-based prediction of two-wheelers (2020) IEEE Intelligent Vehicles Symposium (IV), pp. 1669-1674. , Las Vegas, NV, USA; Santa, J., Fernandez, P. J., Seamless IPv6 connectivity for two-wheelers (2017) Pervasive and Mobile Computing, 42, pp. 526-541; Chen, S., Hu, J., Shi, Y., Peng, Y., Fang, J., Vehicle-to-everything (v2x) services supported by LTE-based systems and 5G (2017) IEEE Communications Standards Magazine, 1 (2), pp. 70-76; Al-Zeyadi, M., Andreu-Perez, J., Hagras, H., Royce, C., Smith, D., Deep learning towards intelligent vehicle fault diagnosis (2020) Int. Joint Conf. on Neural Networks (IJCNN), pp. 1-7. , Glasgow, UK","Santa, J.; Technical University of CartagenaSpain; email: jose.santa@upct.es",,,"Tech Science Press",,,,,15462218,,,,"English","Comput. Mater. Continua",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85120800558
"Kwon J., Kong J., Munir A.","57655864000;25927220400;24587067400;","Sparse convolutional neural network acceleration with lossless input feature map compression for resource-constrained systems",2022,"IET Computers and Digital Techniques","16","1",,"29","43",,,"10.1049/cdt2.12038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120050901&doi=10.1049%2fcdt2.12038&partnerID=40&md5=5c1f1cff34c79731551a8f20ef047004","School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, South Korea; Department of Computer Science, Kansas State University, Manhattan, KS, United States","Kwon, J., School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, South Korea; Kong, J., School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, South Korea; Munir, A., Department of Computer Science, Kansas State University, Manhattan, KS, United States","Many recent research efforts have exploited data sparsity for the acceleration of convolutional neural network (CNN) inferences. However, the effects of data transfer between main memory and the CNN accelerator have been largely overlooked. In this work, the authors propose a CNN acceleration technique that leverages hardware/software co-design and exploits the sparsity in input feature maps (IFMs). On the software side, the authors' technique employs a novel lossless compression scheme for IFMs, which are sent to the hardware accelerator via direct memory access. On the hardware side, the authors' technique uses a CNN inference accelerator that performs convolutional layer operations with their compressed data format. With several design optimization techniques, the authors have implemented their technique in a field-programmable gate array (FPGA) system-on-chip platform and evaluated their technique for six different convolutional layers in SqueezeNet. Results reveal that the authors' technique improves the performance by 1.1×–22.6× while reducing energy consumption by 47.7%–97.4% as compared to the CPU-based execution. Furthermore, results indicate that the IFM size and transfer latency are reduced by 34.0%–85.2% and 4.4%–75.7%, respectively, compared to the case without data compression. In addition, the authors' hardware accelerator shows better performance per hardware resource with less than or comparable power consumption to the state-of-the-art FPGA-based designs. © 2021 The Authors. IET Computers & Digital Techniques published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.","accelerator; compression; convolutional neural networks; field programmable gate array; input sparsity","Acceleration; Convolution; Convolutional neural networks; Data transfer; Energy utilization; Integrated circuit design; Logic gates; System-on-chip; Accelerator; Compression; Convolutional neural network; Feature map; Hardware accelerators; Input features; Input sparsity; Lossless; Network inference; Performance; Field programmable gate arrays (FPGA)",,,,,"National Research Foundation of Korea, NRF; Kementerian Pendidikan Malaysia, KPM: NRF‐2018R1D1A3B07045908, NRF‐2021R1I1A3A04037455","This research was supported by the Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF‐2018R1D1A3B07045908 and NRF‐2021R1I1A3A04037455).",,,,,,,,,,"Lee, K., Kong, J., Munir, A., Hw/sw co-design of cost-efficient cnn inference for cognitive iot (2020) Proc. of IEEE International Conference on Intelligent Computing in Data Sciences. ICDS; Sze, V., Efficient processing of deep neural networks: a tutorial and survey (2017) Proceedings of the IEEE; Han, S., Mao, H., Dally, W.J., (2015) Deep compression: compressing deep neural networks with pruning, trained quantization and Huffman coding, , arXiv preprint; Arm cortex-a53 mpcore processor. Techical Reference Manual; Aimar, A., A flexible convolutional neural network accelerator based on sparse representations of feature maps (2019) IEEE Trans. Neural Netw. Learn. Syst, 30 (3), pp. 644-656; Kala, S., High-performance cnn accelerator on FPGA using unified winograd-gemm architecture (2019) IEEE Trans. Very Large Scale Integrat. Syst, 27 (12), pp. 2816-2828; Liu, B., An FPGA-based cnn accelerator integrating depthwise separable convolution (2019) MDPI Electron, 8 (3), pp. 1-18; Shen, J., Towards a multi-array architecture for accelerating large-scale matrix multiplication on FPGAs (2018) 2018 IEEE International Symposium on Circuits and Systems (ISCAS), pp. 1-5; Zhang, C., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 161-170; Albericio, J., Cnvlutin: ineffectual-neuron-free deep neural network computing (2016) Proceedings of the 43rd International Symposium on Computer Architecture, pp. 1-13; Zhang, S., Cambricon-X: an accelerator for sparse neural networks (2016) 2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), pp. 1-12; Parashar, A., SCNN: an accelerator for compressed-sparse convolutional neural networks (2017) Proceedings of the 44th Annual International Symposium on Computer Architecture, pp. 27-40; Kim, D., Ahn, J., Yoo, S., A novel zero weight/activation-aware hardware architecture of convolutional neural network (2017) Proceedings of the Conference on Design, Automation & Test in Europe, pp. 1466-1471; Gondimalla, A., Sparten: a sparse tensor accelerator for convolutional neural networks (2019) Proceedings of the 52Nd Annual IEEE/ACM International Symposium on Microarchitecture, pp. 151-165; Chen, Y., Eyeriss: an energy-efficient reconfigurable accelerator for deep convolutional neural networks (2017) IEEE J. Solid-State Circ, 52 (1), pp. 127-138; Li, H., A high performance FPGA-based accelerator for large-scale convolutional neural networks (2016) 2016 26th International Conference on Field Programmable Logic and Applications (FPL), pp. 1-9; Rhu, M., Compressing dma engine: leveraging activation sparsity for training deep neural networks (2018) 2018 IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 78-91; Shen, Y., Escher: a cnn accelerator with flexible buffering to minimize off-chip transfer (2017) 2017 IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), pp. 93-100; Li, J., SmartShuttle: optimizing off-chip memory accesses for deep learning accelerators (2018) 2018 Design, Automation Test in Europe Conference Exhibition (DATE), pp. 343-348; Zhang, J.J., Compact: on-chip compression of activations for low power systolic array based cnn acceleration (2019) ACM Trans. Embed. Comput. Syst, 18 (5s), pp. 1-24; Yuan, T., High performance cnn accelerators based on hardware and algorithm co-optimization (2021) IEEE Trans. Circ. Syst. I Regul. Pap, 68 (1), pp. 250-263; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition, , arXiv preprint; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the 25th International Conference on Neural Information Processing Systems, 1, pp. 1097-1105; Han, S., Learning both weights and connections for efficient neural network (2015) Adv. Neural Inf. Process. Syst, 28, pp. 1135-1143; Gao, Z., Wang, L., Wu, G., Lip: local importance-based pooling (2019) 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 3354-3363; Xilinx zynq ultrascale+ mpsoc zcu106 evaluation kit; Redmon, J., (2013), http://pjreddie.com/darknet/, Darknet open source neural networks in c; https://www.raspberrypi.org/products/raspberry-pi-zero/, Raspberry Pi zero., Accessed 28 January 2021; Technical Reference Manual., , https://developer.arm.com/documentation/ddi0301/h/, Accessed 28 January 2021; Iandola, F.N., (2016) Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <0.5mb model size, , arXiv preprint; Zhong, G., Synergy: an hw/sw framework for high throughput cnns on embedded heterogeneous soc (2019) ACM Trans. Embed. Comput. Syst, 18 (2); Lee, K., Memory streaming acceleration for embedded systems with cpu-accelerator cooperative data processing (2019) Microprocess. Microsyst, 71; Altera: FPGA Architecture, , https://www.intel.com/content/dam/www/programmable/us/en/pdfs/literature/wp/wp-01003.pdf, Accessed 31 January 2021; Rabaey, J.M., Chandrakasan, A., Nikolic, B., (2003) Digital Integrated Circuits, , 2nd ed, Prentice Hall Press; Xilinx: Xilinx Power Estimator, , https://www.xilinx.com/products/technology/power/xpe.html; Wu, C.-J., Machine learning at facebook: understanding inference at the edge (2019) 2019 IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 331-344; Redmon, J., Farhadi, A., (2018) Yolov3: an incremental improvement, , arXiv preprint; Liu, W., Ssd: single shot multibox detector (2016) Lecture Notes in Computer Science, pp. 21-37; Ren, S., Faster R-CNN: towards real-time object detection with region proposal networks (2017) IEEE Trans. Pattern Anal. Mach, 39, pp. 1137-1149. , https://doi.org/10.1109/tpami.2016.2577031, 6","Kong, J.; School of Electronic and Electrical Engineering, South Korea; email: joonho.kong@knu.ac.kr",,,"John Wiley and Sons Inc",,,,,17518601,,,,"English","IET Comput. Digital Tech.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85120050901
"Mohajeri N., Ebrahimi B., Dousti M.","57224102344;24823899900;8366431900;","HPM: High-Precision Modeling of a Low-Power Inverter-Based Memristive Neural Network",2021,"Journal of Circuits, Systems and Computers","30","15","2150274","","",,,"10.1142/S0218126621502741","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107008349&doi=10.1142%2fS0218126621502741&partnerID=40&md5=29186a3e86d59edf161df5550c6e98fd","Department of Electrical and Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran","Mohajeri, N., Department of Electrical and Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran; Ebrahimi, B., Department of Electrical and Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran; Dousti, M., Department of Electrical and Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran","In this paper, we propose a high-precision memristive neural network with neurons implemented by complementary metal oxide semiconductor (CMOS) inverters. Regarding the process variations in the memristors and the sensitivity of the memristive crossbar structure to these fluctuations, the read operation with repetitive pulses and feedback-based write in the memristors are used to implement the neural networks trained by the ex-situ method. Moreover, accurate modeling of the neuron circuit (CMOS inverter) and decreasing the mismatch between trained weights and the limited memristances fill the gap between simulation and implementation. To employ physical constraints based on the memristor framework during the training phase, a linear function is utilized to map the trained weights to the acceptable range of memristances after the training phase. To solve the vanishing gradient problem due to the use of the tanh function as an activation function and for better learning of the network, some measures are taken. Moreover, fin field-effect transistor (FinFET) technology is used to prevent the reduction of the accuracy of the inverter-based memristive neural networks due to the process variations. Overall, our implementation improves the speed, area, power-delay product (PDP), and mean square error (MSE) of the training stage by 91.43%, 95.06%, 48.29% and 81.64%, respectively. © 2021 World Scientific Publishing Company.","ex-situ training; inverter-based neuron; Memristor; process variations","CMOS integrated circuits; Electric inverters; Low power electronics; Mean square error; Memristors; Metals; MOS devices; Oxide semiconductors; Sensitivity analysis; Activation functions; Complementary metal oxide semiconductors; Cross-bar structures; High-precision models; Low power inverter; Physical constraints; Power delay product; Vanishing gradient; Neural networks",,,,,,,,,,,,,,,,"Chen, B., Cai, F., Zhou, J., Ma, W., Sheridan, P., Lu, W. D., Ecient in-memory computing architecture based on crossbar arrays (2015) Technical Digest Int. Electron Devices Meeting IEDM 2015, , Washington, DC, USA, 17.5.1 17.5.4; Chi, P., Li, S., Xu, C., Zhang, T., Zhao, J., Liu, Y., PRIME: A novel processing-inmemory architecture for neural network computation in ReRAM-based main memory (2016) Proc. 2016 43rd Int. Symp. Computer Architecture ISCA, pp. 27-39. , Seoul, Korea; Ravichandran, V., Li, C., Banagozar, A., Yang, J. J., Xia, Q., Artificial neural networks based on memristive devices (2018) Sci. China Inf. Sci, 61, p. 114; Fausett, L., (2005) Fundamentals of Neural Networks: Architectures, Algorithms and Applications, p. 814. , (Pearson Education India); Kim, S., Ishii, M., Lewis, S., Perri, T., Brightsky, M., Kim, W., NVM neuromorphic core with 64k-cell (256-by-256) phase change memory synaptic array with on-chip neuron circuits for continuous in-situ learning (2015) Technical Digest Int. Electron Devices Meeting IEDM, , Washington, DC, USA, 17.1.1 17.1.4; Adam, G. C., Hoskins, B. D., Prezioso, M., Merrikh-Bayat, F., Chakrabartiand, B., Strukov, D. B., 3-D memristor crossbars for analog and neuromorphic computing applications (2017) IEEE Trans. Electron Devices, 64, pp. 312-318; Eryilmaz, S. B., Neftci, E., Joshi, S., Kim, S., Brightsky, M., Lung, H. L., Training a probabilistic graphical model with resistive switching electronic synapses (2016) IEEE Trans. Electron Devices, 63, p. 50045011; Zayer, F., Dghais, W., Benabdeladhim, M., Hamdi, B., Low power, ultrafast synaptic plasticity in 1R-ferroelectric tunnel memristive structure for spiking neural networks (2019) AEU Int. J. Electron. Commun, 100, pp. 56-65. , HPM: High-Precision Modeling of a Low-Power Inverter-Based Memristive Neural Network 2150274-17; Chua, L., Memristor. The missing circuit element (1971) IEEE Trans. Circuit Theory, 18, pp. 507-519; Williams, R. S., How we found the missing memristor (2008) IEEE Spectr, 45, pp. 28-35; Jo, S. H., Chang, T., Ebong, I., Bhadviya, B. B., Mazumder, P., Lu, W., Nanoscale memristor device as synapse in neuromorphic systems (2010) Nano Lett, 10, pp. 1297-1301; Such, O., Klimo, M., Kemp, N. T., Skvarek, O., Passive memristor synaptic circuits with multiple timing dependent plasticity mechanisms (2018) AEU Int. J. Electron. Commun, 96, pp. 252-259; Ho, Y., Huang, G. M., Li, P., Nonvolatile memristor memory: Device characteristics and design impications (2009) Int. Conf. Computer-Aided Design (ICCAD), pp. 485-490. , San Jose, CA, USA; Yakopcic, C., Hasan, R., Taha, T. M., McLean, M. R., Palmer, D., Ecacy of memristive crossbars for neuromorphic processors (2014) Proc. Int. Joint Conf. Neural Networks, pp. 15-20. , Beijing, China; Khalid, M., Alphanumeric pattern recognition by memristive crossbar circuit using perceptron learning rule (2020) J. Circuits Syst. Comput, 29, p. 118; Adhikari, S. P., Yang, C., Kim, H., Chua, L. O., Memristor bridge synapse-based neural network and its learning (2012) IEEE Trans. Neural Netw. Learn. Syst, 23, pp. 1426-1435; Sah, M. P., Yang, C., Kim, H., Chua, L. O., Memristor circuit for artificial synaptic weighting of pulse inputs (2012) Int. Symp. Circuits and Systems (ISCAS), pp. 1604-1607. , Seoul, Korea (South); Liu, C., Yan, B., Yang, C., Song, L., Li, Z., Liu, B., A spiking neuromorphic design with resistive crossbar (2015) Proc. Design Automation Conf, , San Francisco, CA, USA; Keerthy Rai, V., Sakthivel, R., Design of artificial neuron network with synapse utilizing hybrid CMOS transistors with memristor for low power applications (2020) J. Circuits Syst. Comput, 29, p. 120; Jo, S. H., Kumar, T., Narayanan, S., Lu, W. D., Nazarian, H., 3D-stackable crossbar resistive memory based on field assisted superlinear threshold (FAST) selector (2015) Technical Digest Int. Electron Devices Meeting IEDM, , San Francisco, CA, USA, 6.7.1 6.7.4; Manem, H., Rose, G. S., He, X., Wang, W., Design considerations for variation tolerant multilevel CMOS/Nano memristor memory (2010) Proc. ACM Great Lakes Symp. VLSI, GLSVLSI, Rhode Island, USA, pp. 287-292; Pellegrini, D., Ottavi, M., Martinelli, E., Natale, C., Complementary resistive switch sensing (2018) 2018 IEEE Int. Symp. Defect Fault Tolerance in VLSI Nanotechnol Systems, p. 15. , Chicago, IL, USA; Hasan, R., Yakopcic, C., Taha, T. M., Ex-situ training of large memristor crossbars for neural network applications (2019) Analog Integr. Circuits Signal Process, 99, p. 110; Joshua Yang, J., Zhang, M. X., Pickett, M. D., Miao, F., Paul Strachan, J., Li, W. D., Engineering nonlinearity into memristors for passive crossbar applications (2012) Appl. Phys. Lett, 100, pp. 98-102; Qureshi, M. S., Yi, W., Medeiros-Ribeiro, G., Williams, R. S., AC sense technique for memristor crossbar (2012) Electron. Lett, 48, pp. 757-758. , N. Mohajeri, B. Ebrahimi & M. Dousti; Hasan, R., Taha, T. M., Enabling back propagation training of memristor crossbar neuromorphic processors (2014) Proc. Int. Joint Conf. Neural Networks, pp. 21-28. , Beijing, China; Vahdat, S., Kamal, M., Afzali-Kusha, A., Pedram, M., O®line training improvement of inverter-based memristive neural networks using inverter voltage characteristic smoothing (2020) IEEE Trans. Circuits Syst. II Exp. Briefs, 7747, p. 11; Ansari, M., Fayyazi, A., BanaGozar, A., Maleki, M. A., Kamal, M., Afzali-Kusha, A., PHAX: Physical characteristics aware ex-situ training framework for inverter-based memristive neuromorphic circuits (2018) IEEE Trans. Comput. Des. Integr. Circuits Syst, 37, pp. 1602-1613; Rasamoelina, D., Adjailia, F., Sincak, P., A review of activation function for artificial neural network (2020) Proc. IEEE 18th World Symp. Applied Machine Intelligence Informatics, pp. 281-286. , Herl'any, Slovakia; Ansari, M., Fayyazi, A., Kamal, M., Afzali-Kusha, A., Pedram, M., OCTAN: An on-chip training algorithm for memristive neuromorphic circuits (2019) IEEE Trans. Circuits Syst, 66, pp. 4687-4698; Jihong, L., Deqin, L., A survey of FPGA-based hardware implementation of ANNs (2005) Int. Conf. Neural Networks and Brain (ICNNB), pp. 915-918. , Beijing, China; Hutchison, D., Mitchell, J. C., (1973) Neural Networks: Tricks of the Trade, , 2nd edn. (Springer); Alibart, F., Gao, L., High-precision tuning of state for memristive devices by adaptable variation (2012) Nanotechnology; Yakopcic, C., Taha, T. M., Mclean, M., Method for ex-situ training in memristorbased neuromorphic circuit using robust weight programming method (2015) Electron. Lett, 51, pp. 899-900; Dong, X., Xu, C., Xie, Y., Jouppi, N. P., NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory (2012) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst, 31, pp. 994-1007; Yakopcic, C., Taha, T. M., Memristor crossbar based implementation of a multilayer perceptron (2017) 2017 IEEE National Aerospace and Electronics Conf. (NAECON), pp. 38-43. , Dayton, OH, USA; Yazdanbakhsh, A., Esmaeilzadeh, H., Mahajan, D., AXBENCH: A multiplatform benchmark suite for approximate computing (2017) IEEE Design & Test, 34; Yakopcic, T. M., Subramanyam, G., Pino, R. E., Generalized memristive device SPICE model and its application in circuit design (2013) IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 32, pp. 1201-1214; Lu, W., Kim, K. H., Chang, T., Gaba, S., Two-Terminal resistive switches (memristors) for memory and logic applications (2011) Proc. Asia South Pacific Design Automation Conf. ASP-DAC, pp. 217-223. , Yokohama, Japan; Zhang, R., Liu, Z., Yang, K., Liu, T., Cai, W., Milor, L., Inverse design of finFET SRAMcells (2020) IEEE Int Reliability Physics Symp. Proc; Mahmoodi, E., Gholipour, M., Design space exploration of low-power °ip-°ops in FinFET technology (2020) Integration, 75, pp. 52-62; (2012), http://ptm.asu.edu/.HPM:High-PrecisionModelingofaLow-PowerInverter-BasedMemristiveNeuralNetwork2150274-19","Ebrahimi, B.; Department of Electrical and Computer Engineering, Iran; email: behzad.ebrahimi@srbiau.ac.ir",,,"World Scientific",,,,,02181266,,JCSME,,"English","J. Circuits Syst. Comput.",Article,"Final","",Scopus,2-s2.0-85107008349
"Hazarika A., Poddar S., Rahaman H.","57209273202;55321684000;57207594144;","High Performance Kernel Architecture for Convolutional Neural Network Acceleration",2021,"Journal of Circuits, Systems and Computers","30","15","2150266","","",,1,"10.1142/S0218126621502662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106906165&doi=10.1142%2fS0218126621502662&partnerID=40&md5=79deae78432adc482d2a7109119ddffe","Department of Electronics and Communications, Indian Institute of Information Technology Guwahati, Guwahati, Assam, 781015, India; Indian Institute of Engineering Science and Technology, Shibpur, West Bengal711103, India","Hazarika, A., Department of Electronics and Communications, Indian Institute of Information Technology Guwahati, Guwahati, Assam, 781015, India; Poddar, S., Department of Electronics and Communications, Indian Institute of Information Technology Guwahati, Guwahati, Assam, 781015, India; Rahaman, H., Indian Institute of Engineering Science and Technology, Shibpur, West Bengal711103, India","Convolutional neural networks (CNNs) have emerged as a prominent choice in artificial intelligence tasks. Recent advancements in CNN designs have greatly improved the performance and energy-efficiency of several computation-intensive applications. However, in real-time applications, greater accuracy of CNN is attained at the expense of very high computational cost and complexity. Further, the implementation of real-time CNN on embedded platforms is highly challenging due to resource and power constraints. This paper addresses the aforesaid computational complexity and presents an accelerator architecture accompanied by a novel kernel design to improve overall CNN performance. The proposed kernel design introduces a computing mechanism that reduces the data movement cost in terms of computational cycle count (latency) by parallelizing the convolution processing elements. This architecture takes advantage of the overlap of spatially adjacent data. The performance of the proposed architecture is also analyzed for multiple hyper-parameter configurations. The proposed accelerator achieves an average of 16× improvement in reduction of execution time than the conventional computing architecture. To analyze the proposed architecture's performance, we validate the architecture with AlexNet and VGG-16 CNN models. The proposed accelerator architecture achieves an average of 1.7× throughput improvement over state-of-the-art accelerators. © 2021 World Scientific Publishing Company.","CNN acceleration; Convolutional neural networks (CNNs); Field programmable gate array (FPGA); Hardware accelerator; Multiply-and-accumulate (MAC)","Acceleration; Complex networks; Convolution; Energy efficiency; Network architecture; Accelerator architectures; Computation intensives; Computational cycles; Computing architecture; Processing elements; Proposed architectures; Real-time application; Throughput improvement; Convolutional neural networks",,,,,,,,,,,,,,,,"LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444. , 1; Roska, T., Chua, L. O., The CNN universal machine: An analogic array computer (1993) IEEE Trans. Circuits Syst. II Analog Digit. Signal Process, 40, pp. 163-173. , 2; Venetianer, P. L., Werblin, F., Roska, T., Chua, L. O., Analogic CNN algorithms for some image compression and restoration tasks (1995) IEEE Trans. Circuits Syst. I Fundam. Theory Appl, 42, pp. 278-284. , 3; Müller, J., Wittig, R., Müller, J., Tetzlaff, R., An improved cellular nonlinear network architecture for binary and grayscale image processing (2016) IEEE Trans. Circuits Syst. II Exp. Brief, 65, pp. 1084-1088. , 4; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) IEEE Proc. Conf. Computer Vision and Pattern Recognition, pp. 770-778. , 5. in Las Vegas, NV, USA; Chen, Y.-H., Emer, J., Sze, V., Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks (2016) ACM SIGARCH Comput. Architect. News, 44, pp. 367-379. , 6; Krizhevsky, A., Sutskever, I., Geoffrey, H., Imagenet classification with deep convolu-tional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105. , 7. in (NeurIPS); Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Int. Conf. Learning Representations (ICLR), pp. 40-54. , 8. San Diego, CA, USA; Chen, T., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., Temam, O., DianNao: A small-footprint high-throughput accelerator for ubiquitous machine-learning (2014) ACM Sigplan Not, 49, pp. 269-284. , 9; Chen, Y., DaDianNao: A machine-learning supercomputer (2014) IEEE/ACM Proc. Int. Symp. Microarchitecture, pp. 609-622. , 10. in Cambridge, United Kingdom; Liu, D., Chen, T., Liu, S., Zhou, J., Zhou, S., Teman, O., Feng, X., Chen, Y., PuDianNao: A polyvalent machine learning accelerator (2015) ACM SIGARCH Comput. Architect. News, 43, pp. 369-381. , 11; Bojnordi, M. N., Ipek, E., Memristive boltzmann machine: A hardware accelerator for combinatorial optimization and deep learning (2016) IEEE Int. Symp. High Performance Computer Architecture (HPCA), pp. 1-13. , 12. (IEEE); Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) ACM Proc. Intl. Symp. Field-Programmable Gate Arrays, pp. 161-170. , 13. in Monterey, CA, USA, February; Samuel, W., Andrew, W., David, P., Roofline: An insightful visual performance model for multicore architectures (2009) Commun. ACM, 52, pp. 65-72. , 14; Hailesellasie, M. T., Hasan, S. R., MulNet: A flexible CNN processor with higher resource utilization efficiency for constrained devices (2019) IEEE Access, 7, pp. 47509-47524. , 15; Chen, Y.-H., Krishna, T., Emer, J. S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2016) IEEE J. Solid-State Circuits, 52, pp. 127-138. , 16; Chen, Y.-H., Yang, T.-J., Emer, J., Sze, V., Eyeriss v2: A flexible accelerator for emerging deep neural networks on mobile devices (2019) IEEE J. Emerg. Sel. Top. Circuits Syst, 9, pp. 292-308. , 17; Struharik, R., Vukobratovic, B., AIScale-A coarse grained reconfigurable CNN hardware accelerator (2017) IEEE East-West Design & Test Symp, pp. 1-9. , 18. Novi Sad, Serbia, November; Gokhale, V., Zaidy, A., Chang, A. X. M., Culurciello, E., Snowflake: An efficient hardware accelerator for convolutional neural networks (2017) IEEE Intl. Symp. Circuits and Systems, pp. 1-4. , 19. Baltimore, MD, USA, September; Cavigelli, L., Benini, L., Origami: A 803-gop/s/w convolutional network accelerator (2016) IEEE Trans. Circuits Syst. Video Technol, 27, pp. 2461-2475. , 20; Shen, Y., Ferdman, M., Milder, P., Maximizing CNN accelerator efficiency through resource partitioning (2017) ACM/IEEE Annu. Intl. Symp. Computer Architecture, pp. 535-547. , 21. Toronto, ON, Canada, December; Jo, J., Kim, S., Park, I.-C., Energy-efficient convolution architecture based on rescheduled dataflow (2018) IEEE Trans. Circuits and Syst. I Regular Papers, 65, pp. 4196-4207. , 22; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., Optimizing the convolution operation to accelerate deep neural networks on FPGA (2018) IEEE Trans. Very Large Scale Integr. (VLSI) Syst, 26, pp. 1354-1367. , 23; Lian, X., Liu, Z., Song, Z., Dai, J., Zhou, W., Ji, X., High-performance FPGA-based CNN accelerator with block-floating-point arithmetic (2019) IEEE Trans. Very Large Scale Integr. (VLSI) Syst, 27 (8), pp. 1874-1885. , 24. Early Access; Pourmeidani, H., Sheikhfaal, S., Zand, R., DeMara, R. F., Probabilistic interpolation recoder for energy-error-product efficient dbns with p-bit devices (2020) Trans. Emerg. Top. Comput, , https://ieeexplore.ieee.org/document/8954781, 25. Early Access; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You Only Look Once: Unified, realtime object detection (2016) Proc. Conf. Computer Vision and Pattern Recognition, pp. 779-788. , 26. in Las Vegas, NV, USA; Redmon, J., Farhadi, A., YOLO9000: better, faster, stronger (2017) Proc. Conf. Computer Vision and Pattern Recognition, pp. 7263-7271. , 27. in Honolulu, HI, USA; Remdon, J., Farhadi, A., (2018) YOLOv3: An incremental improvement, , 28. preprint arXiv:1804.02767; Xiao, D., Shan, F., Li, Z., Le, B. T., Liu, X., Li, X., A target detection model based on improved tiny-yolov3 under the environment of mining truck (2019) IEEE Access, 7, pp. 123757-123764. , 29; Ahmad, A., Pasha, M. A., FFConv: An fpga-based accelerator for fast convolution layers in convolutional neural networks (2020) Trans. Embed. Comput. Syst. (TECS), 19, pp. 1-24. , 30; Asgari, B., Hadidi, R., Krishna, T., Kim, H., Yalamanchili, S., ALRESCHA: A lightweight reconfigurable sparse-computation accelerator (2020) Int. Symp. High Performance Computer Architecture (HPCA), pp. 249-260. , 31. (IEEE); Qin, E., Samajdar, A., Kwon, H., Nadella, V., Srinivasan, S., Das, D., Kaul, B., Krishna, T., Sigma: A sparse and irregular gemm accelerator with flexible interconnects for dnn training (2020) Int. Symp. High Performance Computer Architecture (HPCA), pp. 58-70. , 32. (IEEE); Li, G., Wang, P., Liu, Z., Leng, C., Cheng, J., Hardware acceleration of CNN with one-hot quantization of weights and activations (2020) Design, Automation & Test in Europe Conf. & Exhibition (DATE), pp. 971-974. , 33. (IEEE); Liu, Z.-G., Whatmough, P. N., Mattina, M., Systolic tensor array: An efficient structured-sparse GEMM accelerator for mobile CNN inference (2020) Comput. Architect. Lett, 19, pp. 34-37. , 34; Lu, L., Xie, J., uang, R., Zhang, H. J., Lin, W., Liang, Y., An efficient hardware accelerator for sparse convolutional neural networks on FPGAs (2020) Int. Symp. Field-Programmable Custom Computing Machines (FCCM), pp. 17-25. , 35. (IEEE); Hazarika, A., Poddar, S., Rahaman, H., Hardware efficient convolution processing unit for deep neural networks (2019) 2019 2nd International Symposium on Devices, Circuits and Systems (ISDCS), pp. 1-4. , 36. (IEEE); Szegedy, C., Liu, W., Yangqing, J., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) IEEE Proc. Conf. Computer Vision and Pattern Recognition, pp. 1-9. , 37. in Boston, MA, USA; Iandola, F., Han, S., Moskewicz, M., Ashraf, K., Dally, W., Keutzer, K., (2016) SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and 0.5 MB model size, , 38. preprint arXiv:1602.07360; Gschwend, D., (2016) Zynqnet: An FPGA-Accelerated embedded convolutional neural network, , 39. Master's thesis (Swiss Federal Institute of Technology Zurich); BAIR, Caffe: Deep learning framework, , http://caffe.berkeleyvision.org/, 40; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86, pp. 2278-2324. , 41; Keras, , https://keras.io/, 42; Zhang, C., Sun, G., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: Toward uniformed representation and acceleration for deep convolutional neural networks (2018) Trans. Comput.-Aided Design Integrated Circuits Syst, 38, pp. 2072-2085. , 43","Poddar, S.; Department of Electronics and Communications, Assam, India; email: poddar18@gmail.com",,,"World Scientific",,,,,02181266,,JCSME,,"English","J. Circuits Syst. Comput.",Article,"Final","",Scopus,2-s2.0-85106906165
"Hong S., Cho H., Kim J.-S.","56072402300;55470966400;53870368900;","Citiussynapse: A deep learning framework for embedded systems",2021,"Applied Sciences (Switzerland)","11","23","11570","","",,,"10.3390/app112311570","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120817783&doi=10.3390%2fapp112311570&partnerID=40&md5=1a12f97b19a6eb42d19555c2a5f967a7","High Performance Embedded System SW Research Section, Artificial Intelligence Research Laboratory, Electronics and Telecommunications Research Institute (ETRI), Daejeon, 34129, South Korea","Hong, S., High Performance Embedded System SW Research Section, Artificial Intelligence Research Laboratory, Electronics and Telecommunications Research Institute (ETRI), Daejeon, 34129, South Korea; Cho, H., High Performance Embedded System SW Research Section, Artificial Intelligence Research Laboratory, Electronics and Telecommunications Research Institute (ETRI), Daejeon, 34129, South Korea; Kim, J.-S., High Performance Embedded System SW Research Section, Artificial Intelligence Research Laboratory, Electronics and Telecommunications Research Institute (ETRI), Daejeon, 34129, South Korea","As embedded systems, such as smartphones with limited resources, have become increas-ingly popular, active research has recently been conducted on performing on-device deep learning in such systems. Therefore, in this study, we propose a deep learning framework that is specialized for embedded systems with limited resources, the operation processing structure of which differs from that of standard PCs. The proposed framework supports an OpenCL-based accelerator engine for accelerator deep learning operations in various embedded systems. Moreover, the parallel processing performance of OpenCL is maximized through an OpenCL kernel that is optimized for embedded GPUs, and the structural characteristics of embedded systems, such as unified memory. Furthermore, an on-device optimizer for optimizing the performance in on-device environments, and model con-verters for compatibility with conventional frameworks, are provided. The results of a performance evaluation show that the proposed on-device framework outperformed conventional methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning framework; Embedded systems; On-device; OpenCL acceleration",,,,,,"Institute for Information and Communications Technology Promotion, IITP; Ministry of Science and ICT, South Korea, MSIT","Funding: This work was supported by the Institute for Information & communications Technology Planning & Evaluation(IITP) grant funded by the Korean government(MSIT) (No.2017-0-00142, Development of Acceleration SW Platform Technology for On-device Intelligent Information Processing in Smart Devices).",,,,,,,,,,"Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 779-788. , Las Vegas, NV, USA, 27–30 June; Min, H., Beanbonyka, R., Hongchang, L., Hyeonung, J., Joonho, O., Seongjun, C., Multi-class classification of lung diseases using CNN models (2021) Appl. Sci, 11, p. 9289. , [CrossRef]; Gihwi, K., Ilyoung, C., Qinglong, L., Jaekyeong, K., A CNN-based advertisement recommendation through real-time user face recognition (2021) Appl. Sci, 11, p. 9705; Geunwoo, B., Joonhyuk, Y., RT-SPeeDet: Real-time IP–CNN-based small pit defect detection for automatic film manufacturing inspection (2021) Appl. Sci, 11, p. 9632; Oh, Y.R., Park, K., Jeon, H.B., Park, J.G., Designing acoustic scene classification models with CNN variants (2020) ETRI J, 42, pp. 761-772. , [CrossRef]; Song, J., Kim, J., Choi, S., Kim, J., Kim, I., Evaluations of AI-based malicious PowerShell detection with feature optimizations (2021) ETRI J, 43, pp. 549-560. , [CrossRef]; Yun, K., Kwon, Y., Oh, S., Moon, J., Park, J., Vision-based garbage dumping action detection for real-world surveillance (2019) ETRI J, 41, pp. 494-505. , [CrossRef]; Yoon, Y.C., Park, S.Y., Park, S.M., Lim, H., Image classification and captioning model considering a CAM-based disagreement loss (2019) ETRI J, 42, pp. 67-77. , [CrossRef]; Yoo, S.B., Han, M., Temporal matching prior network for vehicle license plate detection and recognition in videos (2020) ETRI J, 42, pp. 411-419. , [CrossRef]; Kim, M., Kim, S., Robust appearance feature learning using pixel-wise discrimination for visual tracking (2019) ETRI J, 41, pp. 483-493. , [CrossRef]; Jeonghyun, L., Sangkyun, L., Robust CNN compression framework for security-sensitive embedded systems (2021) Appl. Sci, 11, p. 1093. , [CrossRef]; Jinsoo, K., Jeongho, C., Low-cost embedded system using convolutional neural networks-based spatiotemporal feature map for real-time human action recognition (2021) Appl. Sci, 11, p. 4940. , [CrossRef]; Sebastian, C., Andrzej, C., Vehicle detection with self-training for adaptative video processing embedded platform (2020) Appl. Sci, 10, p. 5763. , [CrossRef]; Khan, W., Daud, A., Alotaibi, F., Aljohani, N., Arafat, S., Deep recurrent neural networks with word embeddings for Urdu named entity recognition (2019) ETRI J, 42, pp. 90-100. , [CrossRef]; Ha, D., Kim, M., Moon, K., Jeong, C.Y., Accelerating on-device learning with layer-wise processor selection method on unified memory (2021) Sensors, 21, p. 2364. , [CrossRef] [PubMed]; https://pytorch.org/, (accessed on 23 August 2021); https://www.tensorflow.org/, (accessed on 23 August 2021); https://caffe.berkeleyvision.org/, (accessed on 23 August 2021); CUDA, Release: 11.4.1. 2021, , https://developer.nvidia.com/cuda-toolkit, (accessed on 23 August 2021); cuDNN, Release: 8.2.2. 2021, , https://developer.nvidia.com/cudnn, (accessed on 23 August 2021); OpenCL (Open Computing Language), , https://www.khronos.org/opencl/, (accessed on 23 August 2021); http://www.netlib.org/blas/, (accessed on 23 August 2021); Open Neural Network Exchange (ONNX), , https://onnx.ai, (accessed on 25 August 2021); http://www.netlib.org/lapack/, (accessed on 23 August 2021); Automatically Tuned Linear Algebra Software (ATLAS), , http://math-atlas.sourceforge.net/, (accessed on 23 August 2021); Xianyi, Z., Kroeker, M., OpenBLAS: An Optimized BLAS Library, , https://www.openblas.net/, (accessed on 23 August 2021); cuBLAS, Release: 11.4.1. 2021, , https://developer.nvidia.com/cublas, (accessed on 23 August 2021); CUTLASS: A Collection of CUDA C++ Template Abstractions for Implementing High-Performance Matrix-Multiplication (GEMM) at All Levels and Scales within CUDA, , https://github.com/NVIDIA/cutlass, (accessed on 23 August 2021); Abdelfattah, A., Keyes, D., Ltaief, H., Kblas: An optimized library for dense matrix-vector multiplication on gpu accelerators (2016) ACM Trans. Math. Softw, 42, pp. 1-31. , [CrossRef]; https://github.com/clMathLibraries/clBLAS, (accessed on 23 August 2021); Vienna, CL., http://viennacl.sourceforge.net/, Available online: (accessed on 23 August 2021); Nugteren, C., CLBlast: A Tuned OpenCL BLAS Library (2018) Proceedings of the International Workshop on OpenCL (IWOCL), pp. 1-10. , Oxford, UK, 14–16 May; https://github.com/arm-software/ComputeLibrary, (accessed on 23 August 2021); https://github.com/ARM-software/armnn, (accessed on 23 August 2021); https://keras.io/, (accessed on 23 August 2021); https://pypi.org/project/Theano/, (accessed on 23 August 2021); https://mxnet.apache.org/versions/1.8.0/, (accessed on 23 August 2021); https://deeplearning4j.org/, (accessed on 23 August 2021); Darknet: Open Source Neural Networks in C, , https://pjreddie.com/darknet/, (accessed on 23 August 2021); https://github.com/BVLC/caffe/tree/opencl, (accessed on 23 August 2021); Deep, CL, Deep convolutional neural networks in OpenCL, , http://deepcl.hughperkins.com/, (accessed on 23 August 2021); TensorFlow Lite: ML for Mobile and Edge Devices, , https://www.tensorflow.org/lite, (accessed on 23 August 2021); Sowa, P., Izydorczyk, J., (2020) Darknet on OpenCL: A Multi-Platform Tool for Object Detection and Classification, , https://www.preprints.org/manuscript/202007.0506/v1, Preprints 202007.0506.v1. (accessed on 23 August 2021); https://github.com/hughperkins/EasyCL, (accessed on 23 August 2021); Android Neural Networks API, , https://developer.android.google.cn/ndk/guides/neuralnetworks, (accessed on 23 August 2021); https://opencv.org/, (accessed on 23 August 2021); https://symas.com/lmdb/, (accessed on 23 August 2021); Wetzler, A., Add a Padding Layer to Caffe, , https://github.com/twerdster/caffe, (accessed on 23 August 2021); Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Adam, H., (2017) Mobilenets: Efficient convolutional neural networks for mobile vision applications, , arXiv arXiv:1704.04861; Gondhalekar, A., Feng, W.C., Exploring FPGA Optimizations in OpenCL for Breadth-First Search on Sparse Graph Datasets (2020) Proceedings of the 30th International Conference on Field-Programmable Logic and Applications (FPL), Virtual Conference, pp. 133-137. , 31 August–4 September; Kim, S., Oh, S., Yi, Y., Minimizing GPU Kernel Launch Overhead in Deep Learning Inference on Mobile GPUs (2021) Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications (HotMobile), Virtual Conference, pp. 57-63. , 24–26 February; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) Proceedings of the International Conference on Machine Learning (ICML), pp. 448-456. , Lille, France, 6–11 July; https://github.com/NHZlX/Merge_bn_Caffe, (accessed on 23 August 2021); Merge Convolution and Batchnorm Layers in both Caffe and PyTorch, , https://github.com/zym1119/Merge_BN, (accessed on 23 August 2021); Kullback, S., Leibler, R.A., On information and sufficiency (1951) Ann. Math. Stat, 22, pp. 79-86. , [CrossRef]; Oh, C., Park, G., Kim, S., Kim, D., Yi, Y., Towards Real-time CNN Inference from a Video Stream on a Mobile GPU (WiP Paper) (2020) Proceedings of the 21st ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems, pp. 136-140. , London, UK, 15–20 June; Winograd, S., (1980) Arithmetic Complexity of Computations, 33. , Siam: Philadelphia, PA, USA; Lavin, A., Gray, S., Fast algorithms for convolutional neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4013-4021. , Las Vegas, NV, USA, 27–30 June; Exploring the Arm Dot Product Instructions, , https://community.arm.com/developer/tools-software/tools/b/tools-software-ides-blog/posts/exploring-the-arm-dot-product-instructions, (accessed on 23 August 2021); Lutz, R., Visualizer for Neural Networks: Netron, , https://netron.appandhttps://github.com/lutzroeder/netron, (accessed on 25 August 2021); Protocol Buffer, , https://developers.google.com/protocol-buffers, (accessed on 25 August 2021); Torch-script, , https://pytorch.org/docs/stable/jit.html, (accessed on 25 August 2021); http://www.falinux.com/product_SOM_1.html, (accessed on 23 August 2021); ODROID-N2+ with 4GByte RAM, , https://www.hardkernel.com/ko/shop/odroid-n2-with-4gbyte-ram-2/, (accessed on 23 August 2021); Jetson Nano, , https://developer.nvidia.com/embedded/jetson-nano-developer-kit, (accessed on 12 October 2021); Ignatov, A., Timofte, R., Kulik, A., Yang, S., Wang, K., Baum, F., Van Gool, L., (2019) AI benchmark: All about deep learning on smartphones in 2019, , arXiv arXiv:1910.06663; https://github.com/eric612/MobileNet-YOLO, (accessed on 23 August 2021); A Caffe Implementation of EAST Text Detector, , https://github.com/SURFZJY/EAST-caffe, (accessed on 23 August 2021); Convolutional Recurrent Neural Network (CRNN) in Caffe, , https://github.com/yalecyu/crnn.caffe, (accessed on 23 August 2021); https://github.com/davidgengenbach/vgg-caffe, (accessed on 23 August 2021); Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 248-255. , Miami, FL, USA, 20–25 June; https://github.com/HolmesShuan/ResNet-18-Caffemodel-on-ImageNet, (accessed on 23 August 2021); https://github.com/KaimingHe/deep-residual-networks, (accessed on 23 August 2021); https://github.com/shicai/MobileNet-Caffe, (accessed on 23 August 2021); Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A.L., The pascal visual object classes (voc) challenge (2010) Int. J. Comput. Vis, 88, pp. 303-338. , [CrossRef]; https://ai-benchmark.com, (accessed on 23 November 2021); Mali (GPU), , https://en.wikipedia.org/wiki/Mali_(GPU), (accessed on 12 October 2021)","Hong, S.; High Performance Embedded System SW Research Section, South Korea; email: sthong@etri.re.kr",,,"MDPI",,,,,20763417,,,,"English","Appl. Sci.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85120817783
"Raza W., Osman A., Ferrini F., De Natale F.","57314863500;57221207157;57315490500;7003297760;","Energy-efficient inference on the edge exploiting tinyml capabilities for uavs",2021,"Drones","5","4","127","","",,1,"10.3390/drones5040127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118181150&doi=10.3390%2fdrones5040127&partnerID=40&md5=96c8cb9099826dd078f8e7675dbb6702","Department of Information Engineering and Computer Science—DISI, University of Trento, Trento, 38122, Italy","Raza, W., Department of Information Engineering and Computer Science—DISI, University of Trento, Trento, 38122, Italy; Osman, A., Department of Information Engineering and Computer Science—DISI, University of Trento, Trento, 38122, Italy; Ferrini, F., Department of Information Engineering and Computer Science—DISI, University of Trento, Trento, 38122, Italy; De Natale, F., Department of Information Engineering and Computer Science—DISI, University of Trento, Trento, 38122, Italy","In recent years, the proliferation of unmanned aerial vehicles (UAVs) has increased dramatically. UAVs can accomplish complex or dangerous tasks in a reliable and cost-effective way but are still limited by power consumption problems, which pose serious constraints on the flight duration and completion of energy-demanding tasks. The possibility of providing UAVs with advanced decision-making capabilities in an energy-effective way would be extremely beneficial. In this paper, we propose a practical solution to this problem that exploits deep learning on the edge. The developed system integrates an OpenMV microcontroller into a DJI Tello Micro Aerial Vehicle (MAV). The microcontroller hosts a set of machine learning-enabled inference tools that cooperate to control the navigation of the drone and complete a given mission objective. The goal of this approach is to leverage the new opportunistic features of TinyML through OpenMV including offline inference, low latency, energy efficiency, and data security. The approach is successfully validated on a practical application consisting of the onboard detection of people wearing protection masks in a crowded environment. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Edge computing; Energy efficiency; Machine learning; Microcontrollers; TinyML; UAVs",,,,,,,,,,,,,,,,,"Atzori, L., Iera, A., Morabito, G., The internet of things: A survey (2010) Comput. Netw, 54, pp. 2787-2805. , [CrossRef]; Maddikunta, P.K.R., Hakak, S., Alazab, M., Bhattacharya, S., Gadekallu, T.R., Khan, W.Z., Pham, Q.V., Unmanned Aerial Vehicles in Smart Agriculture: Applications, Requirements, and Challenges (2021) IEEE Sens. J, 21, pp. 17608-17619. , [CrossRef]; Roberge, V., Tarbouchi, M., Labonté, G., Fast Genetic Algorithm Path Planner for Fixed-Wing Military UAV Using GPU (2018) IEEE Trans. Aerosp. Electron. Syst, 54, pp. 2105-2117. , [CrossRef]; Qu, T., Zang, W., Peng, Z., Liu, J., Li, W., Zhu, Y., Zhang, B., Wang, Y., Construction Site Monitoring using UAV Oblique Phtogrammetry and BIM Technologies (2017) Proceedings of the 22nd CAADRIA Conference, , Suzhou, China, 5–8 April; Manfreda, S., McCabe, M.F., Miller, P.E., Lucas, R., Pajuelo Madrigal, V., Mallinis, G., Ben Dor, E., Ciraolo, G., On the Use of Unmanned Aerial Systems for Environmental Monitoring (2018) Remote Sens, 10, p. 641. , [CrossRef]; Boukoberine, M.N., Zhou, Z., Benbouzid, M., A critical review on unmanned aerial vehicles power supply and energy management: Solutions, strategies, and prospects (2019) Appl. Energy, 255, p. 113823. , [CrossRef]; Voghoei, S., Tonekaboni, N.H., Wallace, J.G., Arabnia, H.R., Deep learning at the edge (2018) Proceedings of the 2018 International Conference on Computational Science and Computational Intelligence (CSCI), , Las Vegas, NV, USA, 12–14 December; Banbury, C.R., Reddi, V.J., Lam, M., Fu, W., Fazel, A., Holleman, J., Huang, X., Lokhmotov, A., (2020) Benchmarking TinyML systems: Challenges and direction, , arXiv arXiv:2003.04821; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A system for large-scale machine learning (2016) Proceedings of the 12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16), , Savannah, GA, USA, 2–4 November; Ketkar, N., Introduction to keras (2017) Deep Learning with Python, pp. 97-111. , Apress: Berkeley, CA, USA; Marchisio, A., Hanif, M.A., Khalid, F., Plastiras, G., Kyrkou, C., Theocharides, T., Shafique, M., Deep Learning for Edge Computing: Current Trends, Cross-Layer Optimizations, and Open Research Challenges Proceedings of the 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), pp. 553-559. , Miami, FL, USA, 15–17 July 2019; [CrossRef]; Lu, L., Hu, Y., Zhang, Y., Jia, G., Nie, J., Shikh-Bahaei, M., Machine Learning for Predictive Deployment of UAVs with Rate Splitting Multiple Access Proceedings of the 2020 IEEE Globecom Workshops, , Taipei, Taiwan, 7–11 December 2020; Hoseini, S.A., Hassan, J., Bokani, A., Kanhere, S.S., Trajectory optimization of flying energy sources using q-learning to recharge hotspot uavs Proceedings of the IEEE INFOCOM 2020-IEEE Conference on Computer Communications Workshops, , Toronto, ON, Canada, 6–9 July 2020; Wang, S., Hosseinalipour, S., Gorlatova, M., Brinton, C.G., Chiang, M., (2021) UAV-assisted Online Machine Learning over Multi-Tiered Networks: A Hierarchical Nested Personalized Federated Learning Approach, , arXiv arXiv:2106.15734; Pustokhina, I.V., Pustokhin, D.A., Kumar Pareek, P., Gupta, D., Khanna, A., Shankar, K., Energy-efficient cluster-based unmanned aerial vehicle networks with deep learning-based scene classification model (2021) Int. J. Commun. Syst, 34, p. e4786. , [CrossRef]; Qi, H., Hu, Z., Huang, H., Wen, X., Lu, Z., Energy efficient 3-D UAV control for persistent communication service and fairness: A deep reinforcement learning approach (2020) IEEE Access, 8, pp. 53172-53184. , [CrossRef]; Ghavimi, F., Riku, J., Energy-efficient uav communications with interference management: Deep learning framework Proceedings of the 2020 IEEE Wireless Communications and Networking Conference Workshops (WCNCW), , Seoul, Korea, 6–9 April 2020; Sanchez-Iborra, R., Skarmeta, A.F., Tinyml-enabled frugal smart objects: Challenges and opportunities (2020) IEEE Circuits Syst. Mag, 20, pp. 4-18. , [CrossRef]; (2019), https://www.ryzerobotics.com/kr/tello, RAZE. Tello. (accessed on 13 March 2021); Abdelkader, I., El-Sonbaty, Y., El-Habrouk, M., (2017) Openmv: A Python powered, extensible machine vision camera, , arXiv arXiv:1711.10464; Krishnamoorthi, R., (2018) Quantizing deep convolutional networks for efficient inference: A whitepaper, , arXiv arXiv:1806.08342; David, R., Duke, J., Jain, A., Reddi, V.J., Jeffries, N., Li, J., Kreeger, N., Regev, S., (2020) Tensorflow lite micro: Embedded machine learning on tinyml systems, , arXiv arXiv:2010.08678; Joyo, M.K., Ahmed, S.F., Bakar, M.I.A., Ali, A., Horizontal Motion Control of Underactuated Quadrotor Under Disturbed and Noisy Circumstances (2018) Information and Communication Technology, pp. 63-79. , Springer: Singapore; Mohan, P., Aditya, J.P., Abhay, C., Aditya, J.P., Abhay, C., A tiny CNN architecture for medical face mask detection for resourceconstrained endpoints (2021) Innovations in Electrical and Electronic Engineering, pp. 657-670. , Springer: Singapore; https://www.kaggle.com/prasoonkottarathil/face-mask-lite-dataset, Available online: (accessed on 8 July 2021); Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C., Mobilenetv2: Inverted residuals and linear bottlenecks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Salt Lake City, UT, USA, 18–23 June; Warden, P., Situnayake, D., (2019) Tinyml: Machine Learning with Tensorflow Lite on Arduino and Ultra-Low-Power Microcontrollers, , O’Reilly Media: Newton, MA, USA; Heim, L., Biri, A., Qu, Z., Thiele, L., Measuring what Really Matters: Optimizing Neural Networks for TinyML, , arXiv 2021, arXiv:2104.10645","Raza, W.; Department of Information Engineering and Computer Science—DISI, Italy; email: wamiq.raza@studenti.unitn.it",,,"MDPI",,,,,2504446X,,,,"English","Drones",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85118181150
"Westby I., Yang X., Liu T., Xu H.","57223610659;55783197400;57226048824;57190581366;","FPGA acceleration on a multi-layer perceptron neural network for digit recognition",2021,"Journal of Supercomputing","77","12",,"14356","14373",,3,"10.1007/s11227-021-03849-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105925159&doi=10.1007%2fs11227-021-03849-7&partnerID=40&md5=07739cd5dbdd5c542a186b3475275e78","University of Houston Clear Lake, 2700 Bay Area Blvd, Houston, TX  77058, United States; Lawrence Technological University, 21000 West Ten Mile Road, Southfield, MI  48075, United States; California State University Long Beach, 1250 Bellflower Blvd., Long Beach, CA  90840, United States","Westby, I., University of Houston Clear Lake, 2700 Bay Area Blvd, Houston, TX  77058, United States; Yang, X., University of Houston Clear Lake, 2700 Bay Area Blvd, Houston, TX  77058, United States; Liu, T., Lawrence Technological University, 21000 West Ten Mile Road, Southfield, MI  48075, United States; Xu, H., California State University Long Beach, 1250 Bellflower Blvd., Long Beach, CA  90840, United States","This paper proposes field-programmable gate array (FPGA) acceleration on a scalable multi-layer perceptron (MLP) neural network for classifying handwritten digits. First, an investigation to the network architectures is conducted to find the optimal FPGA design corresponding to different classification rates. As a case study, then a specific single-hidden-layer MLP network is implemented with an eight-stage pipelined structure on Xilinx Ultrascale FPGA. It mainly contains a timing controller designed by Verilog Hardware Description Language (HDL) and sigmoid neurons integrated by Xilinx IPs. Finally, experimental results show a greater than × 10 speedup compared with prior implementations. The proposed FPGA architecture is expandable to other specifications on different accuracy (up to 95.82%) and hardware cost. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Digit recognition; Field-programmable gate array (FPGA); Modified national institute of standards and technology (MNIST); Multi-layer perceptron (MLP); Neural network (NN)","Computer hardware description languages; Field programmable gate arrays (FPGA); Network architecture; Network layers; Classification rates; Digit recognition; FPGA architectures; Handwritten digit; Multi layer perceptron; Multi-layer perceptron neural networks; Timing controller; Verilog hardware description languages; Multilayer neural networks",,,,,,,,,,,,,,,,"Benidis, K., Rangapuram, S., Flunkert, V., (2020) Neural Forecasting: Introduction and Literature Overview, , . arXiv; Ismayilov, G., Topcuoglu, H.R., Neural network based multi-objective evolutionary algorithm for dynamic workflow scheduling in cloud computing (2020) Future Gen Comput Syst, 102, pp. 307-322; Molchanov, P., Mallya, A., Tyree, S., Frosio, I., Kautz, J., Importance estimation for neural network pruning (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 11264-11272. , pp; Son, C., Park, S., Lee, J., Paik, J., Deep learning-based number detection and recognition for gas meter reading (2019) IEIE Trans Smart Process Comput, 8 (5), pp. 367-372; Shawahna, A., Sait, S.M., El-Maleh, A., FPGA-based accelerators of deep learning networks for learning and classification: a review (2019) IEEE Access, 7, pp. 7823-7859; Nurvitadhi, E., Kwon, D., Jafari, A., Evaluating and enhancing Intel Stratix 10 FPGAs for persistent real-time AI (2019) Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, p. 119; Guo, K., Zeng, S., Yu, J., Wang, Y., Yang, H., (2017) A Survey of FPGA Based Neural Network Accelerator, , . arXiv; Albert, R., (2019) Survey and Benchmarking of Machine Learning Accelerators.; Gschwend, D., (2020) Zynqnet: An Fpga-Accelerated Embedded Convolutional Neural Network, , . arXiv; Gao, C., Braun, S., Kiselev, I., Anumula, J., Delbruck, T., Liu, S., Real-time speech recognition for IoT purpose using a delta recurrent neural network accelerator (2019) 2019 IEEE International Symposium on Circuits and Systems (ISCAS), pp. 1-5; Vaca, K., Gajjar, A., Yang, X., Real-time automatic music transcription (AMT) with Zync FPGA (2019) IEEE Computer Society Annual Symposium on VLSI (ISVLSI), pp. 378-384; Li, Q., Zhang, X., Xiong, J., Hwu, W., Chen, D., Implementing neural machine translation with bi-directional GRU and attention mechanism on FPGAs using HLS (2019) Proceedings of the 24Th Asia and South Pacific Design Automation Conference, pp. 693-698; Rongshi, D., Yongming, T., Accelerator implementation of Lenet-5 convolution neural network based on FPGA with HLS (2019) 2019 3rd International Conference on Circuits, System and Simulation (ICCSS), pp. 64-67. , Nanjing, China; Zhang, Q., Cao, J., Zhang, Y., Zhang, S., Zhang, Q., Yu, D., FPGA implementation of quantized convolutional neural networks (2019) 2019 IEEE 19Th International Conference on Communication Technology (ICCT), pp. 1605-1610. , pp; Cong, J., Liu, B., Neuendorffer, S., High-level synthesis for FPGAs: from prototyping to deployment (2011) IEEE Trans Comput Aided Des Integr Circuits Syst, 30 (4), pp. 473-491; Akgun, O.C., Mei, J., An energy efficient time-mode digit classification neural network implementation (2020) Philos Trans R Soc A; Xiang, Y., Hardware implementation of energy efficient deep learning neural network based on nanoscale flash computing array (2019) Adv Mater Technol, 4 (5), p. 1800720; Ma, Y., Guo, J., Wei, W., An exceedingly fast model for low resolution handwritten digit string recognition (2019) IEEE 7Th International Conference on Computer Science and Network Technology (ICCSNT), pp. 282-288. , pp; Abdulrazzaq, M.B., Saeed, J.N., A comparison of three classification algorithms for handwritten digit recognition (2019) International Conference on Advanced Science and Engineering (ICOASE), pp. 58-63. , pp; Ahlawat, S., Choudhary, A., Nayyar, A., Singh, S., Yoon, B., Improved handwritten digit recognition using convolutional neural networks (CNN) (2020) Sensors, 20, p. 3344; Ali, S., Shaukat, Z., Azeem, M., An efficient and improved scheme for handwritten digit recognition based on convolutional neural network (2019) SN Appl Sci, 1, p. 1125; Cho, M., Kim, Y., Implementation of data-optimized FPGA-based accelerator for convolutional neural network (2020) International Conference on Electronics, Information, and Communication (ICEIC), pp. 1-2; Madadum, H., Becerikli, Y., FPGA-based optimized convolutional neural network framework for handwritten digit recognition (2019) 1St International Informatics and Software Engineering Conference (UBMYK), pp. 1-6; Tsai, T.-H., Ho, Y.-C., Sheu, M.-H., Implementation of FPGA-based accelerator for deep neural networks (2019) 2019 IEEE 22Nd International Symposium on Design and Diagnostics of Electronic Circuits and Systems, , DDECS; Xiao, R., Shi, J., Zhang, C., FPGA implementation of CNN for handwritten digit recognition (2020) IEEE Information Technology, Networking, Electronic and Automation Control Conference (ITNEC), pp. 1128-1133; Si, J., Yfantis, E., Harris, S.L., A SS-CNN on an FPGA for handwritten digit recognition. In: 2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON) (2019) Pp 88–93; Si, J., Harris, S.L., Handwritten digit recognition system on an FPGA (2018) 2018 IEEE 8Th Annual Computing and Communication Workshop and Conference (CCWC), pp. 402-407; Lecun, Y., (2010) Cortes C, , Burges C, MNIST handwritten digit database; Nielsen, M., (2019) Neural Networks and Deep Learning, , Determination Press, neuralnetworksanddeeplearning.com, Neural Networks and Deep Learning; (2018) Zynq-7000 Soc Data Sheet: Overview. V1.11.1, , Xilinx, July 2; (2018) Zynq-7000 Soc Technical Reference Manual. V1.12.2, , Xilinx, July","Yang, X.; University of Houston Clear Lake, 2700 Bay Area Blvd, United States; email: YangXia@uhcl.edu",,,"Springer",,,,,09208542,,JOSUE,,"English","J Supercomput",Article,"Final","",Scopus,2-s2.0-85105925159
"Jiang W., Lv S.","7403697465;57218142677;","Hierarchical deployment of deep neural networks based on fog computing inferred acceleration model",2021,"Cluster Computing","24","4",,"2807","2817",,2,"10.1007/s10586-021-03298-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105550248&doi=10.1007%2fs10586-021-03298-0&partnerID=40&md5=52e1faa713f19478f422f3f092aeaed9","College of Computer and Information Engineering, Hunan University of Technology and Business, Changsha, 410205, China; Mobile E-business Collaborative Innovation Center of Hunan Province, Changsha, 410205, China","Jiang, W., College of Computer and Information Engineering, Hunan University of Technology and Business, Changsha, 410205, China, Mobile E-business Collaborative Innovation Center of Hunan Province, Changsha, 410205, China; Lv, S., College of Computer and Information Engineering, Hunan University of Technology and Business, Changsha, 410205, China","With the widespread adoption of deep neural network approaches in mobile devices, the drawbacks of traditional cloud-based or local deployment solutions are becoming apparent. The high latency caused by cloud-based inferred neural networks and the high power consumption caused by local inference of mobile devices greatly reduce the actual user experience of neural network applications. To solve this problem, this paper proposes a hierarchical deployment and inference acceleration model for deep neural networks based on fog computing. Firstly, a search reallocation of the solution space of a deep neural network is performed, and a Solution Space Tree Pruning (SSTP) based deployment algorithm is designed to select the appropriate network layer for deployment in order to reduce the overall inferred delay of a deep neural network. Next, an algorithm for Maximizing Accuracy based on Guaranteed Latency (MAL) is designed. On the pruned solution-space tree of the SSTP algorithm, the appropriate fog computation nodes are selected for mobile devices in different geographic locations to achieve early exit from the inference task according to the operational delay and inference accuracy requirements of real device terminals. The experimental results show that the proposed solution reduces the average latency of the fog computing-based inference acceleration model by 44.79% compared to the traditional cloud-deployed deep neural network inference, and by 28.75% compared to the edge computing acceleration framework in existing studies. The model meets the minimum latency and accuracy of neural network inference in multiple fog computing scenarios. At the same time, it greatly reduces the performance occupation and case cost of the cloud under the traditional cloud computing model. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Branching neural networks; Cloud; Fog computing; Inferential acceleration","Deep neural networks; Fog; Forestry; Green computing; Inference engines; Multilayer neural networks; Network layers; Trees (mathematics); User experience; Acceleration models; Computation nodes; Deployment algorithms; Geographic location; High power consumption; Network inference; Neural network application; Solution space trees; Fog computing",,,,,"2020JGYB234; 2020JJ4249; 2016ZDB006; XSP 19ZD1005; National Natural Science Foundation of China, NSFC: 61472136, 61772196","This work was s upported by the National Natural Science Foundation of China (61772196; 61472136), the Hunan Provincial Focus Natural Science Fund (2020JJ4249), the Hunan Provincial Focus Social Science Fund (2016ZDB006), the Key Project of Hunan Provincial Social Science Achievement Review Committee (XSP 19ZD1005), the Degree and Graduate Education Reform Research Project of Hunan Provincial (No. 2020JGYB234).",,,,,,,,,,"Su, J., Vargas, D.V., Sakurai, K., One pixel attack for fooling deep neural networks (2019) IEEE Trans. Evol. Comput., 23 (5), pp. 828-841; Mahmud, R., Kotagiri, R., Buyya, R., Fog computing: A taxonomy, survey and future directions (2018) Internet of Everything, pp. 103-130. , Springer; Jiang, W., Lv, S., Jiang, Y., Chen, J., Ye, F., Liu, X., Evolutionary dynamics modeling of symbolic social network structure equilibrium (2020) China Commun., 17 (10), pp. 229-240; Elashri, S., Azim, A., Energy-efficient offloading of real-time tasks using cloud computing (2020) Clust. Comput., 23, pp. 3273-3288; Keshavarznejad, M., Rezvani, M.H., Adabi, S., Delay-aware optimization of energy consumption for task offloading in fog environments using metaheuristic algorithms (2021) Clust. Comput.; Kang, Y., Hauswald, J., Gao, C., Rovinski, A., Mudge, T., Mars, J., Tang, L., Neurosurgeon: collaborative intelligence between the cloud and mobile edge (2017) ACM SIGARCH Comput. Architect. News, 45 (1), pp. 615-629; Mao, J., Chen, X., Nixon, K.W., Krieger, C., Chen, Y., Modnn: Local distributed mobile computing system for deep neural network (2017) Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 1396-1401. , . IEEE; Li, H., Ota, K., Dong, M., Learning IoT in edge: deep learning for the Internet of Things with edge computing (2018) IEEE Netw., 32 (1), pp. 96-101; Talaat, F.M., Ali, S.H., Saleh, A.I., Ali, H.A., Effective cache replacement strategy (ECRS) for real-time fog computing environment (2020) Clust. Comput., 23, pp. 3309-3333; Memon, S., Maheswaran, M., Using machine learning for handover optimization in vehicular fog computing (2019) Proceedings of the 34Th ACM/SIGAPP Symposium on Applied Computing, pp. 182-190; Kim, Y., Choi, H., Lee, J., Kim, J.-S., Jei, H., Roh, H., Towards an optimized distributed deep learning framework for a heterogeneous multi-GPU cluster (2020) Clust. Comput., 23 (3), pp. 2287-2300; Jiang, W., Lv, S., Wang, Y., Chen, J., Liu, X., Sun, Y., Computational experimental study on social organization behavior prediction problems (2020) IEEE Trans. Comput. Soc. Syst.; Li, L., Ota, K., Dong, M., Deep learning for smart industry: efficient manufacture inspection system with fog computing (2018) IEEE Trans. Industr. Inf., 14 (10), pp. 4665-4673; Abeshu, A., Chilamkurti, N., Deep learning: the frontier for distributed attack detection in fog-to-things computing (2018) IEEE Commun. Mag., 56 (2), pp. 169-175; Gupta, O., Raskar, R., Distributed learning of deep neural network over multiple agents (2018) J. Netw. Comput. Appl., 116, pp. 1-8; Qi, F., Zhuo, L., Xin, C., Inference delay optimization of branchy neural network model based on edge computing (2020) J. Comput. Appl., 40 (2), pp. 342-346; Li, E., Zeng, L., Zhou, Z., Chen, X., Edge AI: on-demand accelerating deep neural network inference via edge computing (2019) IEEE Trans. Wirel. Commun., 19 (1), pp. 447-457; Ciobanu, R.-I., Negru, C., Pop, F., Dobre, C., Mavromoustakis, C.X., Mastorakis, G., Drop computing: ad-hoc dynamic collaborative computing (2019) Futur. Gener. Comput. Syst., 92, pp. 889-899","Lv, S.; College of Computer and Information Engineering, China; email: lvsijian8@foxmail.com",,,"Springer",,,,,13867857,,,,"English","Cluster Comput.",Article,"Final","",Scopus,2-s2.0-85105550248
"Kwon J., Park D.","57215531728;55463943600;","Hardware/software co-design for tinyml voice-recognition application on resource frugal edge devices",2021,"Applied Sciences (Switzerland)","11","22","11073","","",,,"10.3390/app112211073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119936599&doi=10.3390%2fapp112211073&partnerID=40&md5=ae0143d685fd6165c854d665ae0f2975","School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, 41566, South Korea; School of Electronics Engineering, Kyungpook National University, Daegu, 41566, South Korea","Kwon, J., School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, 41566, South Korea; Park, D., School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, 41566, South Korea, School of Electronics Engineering, Kyungpook National University, Daegu, 41566, South Korea","On-device artificial intelligence has attracted attention globally, and attempts to combine the internet of things and TinyML (machine learning) applications are increasing. Although most edge devices have limited resources, time and energy costs are important when running TinyML applications. In this paper, we propose a structure in which the part that preprocesses externally input data in the TinyML application is distributed to the hardware. These processes are performed using software in the microcontroller unit of an edge device. Furthermore, resistor–transistor logic, which perform not only windowing using the Hann function, but also acquire audio raw data, is added to the inter-integrated circuit sound module that collects audio data in the voice-recognition application. As a result of the experiment, the windowing function was excluded from the TinyML application of the embedded board. When the length of the hardware-implemented Hann window is 80 and the quantization degree is 2−5, the exclusion causes a decrease in the execution time of the front-end function and energy consumption by 8.06% and 3.27%, respectively. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Embedded system; Field programmable gate array (FPGA); Inter-IC sound (I2S); Microcontroller unit (MCU); TinyML; Voice recognition",,,,,,"4199990113966; State of New Jersey Economic Development Authority, EDA; Ministry of Science, ICT and Future Planning, MSIP: NRF2019R1A2C2005099; National Research Foundation of Korea, NRF; Institute for Information and Communications Technology Promotion, IITP; Ministry of Science and ICT, South Korea, MSIT: 2021-0-00944; Kementerian Pendidikan Malaysia, KPM: NRF2018R1A6A1A03025109","Funding: This study was supported by the BK21 FOUR project funded by the Ministry of Education, Korea (4199990113966, 10%), and the Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT (NRF2019R1A2C2005099, 10%), and Ministry of Education (NRF2018R1A6A1A03025109, 10%), and Institute of Information & communication Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (no. 2021-0-00944, Metamorphic approach of unstructured validation/verification for analyzing binary code, 70%), and the EDA tool was supported by the IC Design Education Center (IDEC), Korea.",,,,,,,,,,"De Prado, M., Donze, R., Capotondi, A., Rusci, M., Monnerat, S., Pazos, N., (2020) Robust navigation with tinyML for autonomous mini-vehicles, , arXiv arXiv:2007.00302; Kukreja, N., Shilova, A., Beaumont, O., Huckelheim, J., Ferrier, N., Hovland, P., Gorman, G., Training on the Edge: The why and the how Proceedings of the 2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW), pp. 899-903. , Rio de Janeiro, Brazil, 20–24 May 2019; Kolcun, R., Popescu, D.A., Safronov, V., Yadav, P., Mandalari, A.M., Xie, Y., Mortier, R., Haddadi, H., (2020) The case for retraining of ML models for IoT device identification at the edge, , arXiv arXiv:2011.08605; Disabato, S., Roveri, M., Incremental on-device tiny machine learning Proceedings of the 2nd International Workshop on Challenges in Artificial Intelligence and Machine Learning for Internet of Things, pp. 7-13. , Online, 16 November 2020; Luo, T., Liu, S., Li, L., Wang, Y., Zhang, S., Chen, T., Xu, Z., Chen, Y., DaDianNao: A Neural Network Supercomputer (2017) IEEE Trans. Comput, 66, pp. 73-88; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C., (2019) MobileNetV2: Inverted Residuals and Linear Bottlenecks, , arXiv arXiv:1801.04381; Sanchez-Iborra, R., Skarmeta, A.F., TinyML-Enabled Frugal Smart Objects: Challenges and Opportunities (2020) IEEE Circuits Syst. Mag, 20, pp. 4-18; Ren, H., Anicic, D., Runkler, T.A., TinyOL: TinyML with Online-Learning on Microcontrollers Proceedings of the 2021 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , Shenzhen, China, 18–22 July 2021; Reddi, V.J., Plancher, B., Kennedy, S., Moroney, L., Warden, P., Agarwal, A., Banbury, C., Brown, B., Widening Access to Applied Machine Learning with TinyML, , arXiv 2021, arXiv:2106.04008; Banbury, C., Zhou, C., Fedorov, I., Matas, R., Thakker, U., Gope, D., Janapa Reddi, V., Whatmough, P., Micronets: Neural network architectures for deploying tinyml applications on commodity microcontrollers, , arXiv 2021, arXiv:2010.11267; Dutta, L., Bharali, S., TinyML Meets IoT: A Comprehensive Survey (2021) Internet Things, 16, p. 100461; David, R., Duke, J., Jain, A., Janapa Reddi, V., Jeffries, N., Li, J., Kreeger, N., Wang, T., (2020) TensorFlow Lite Micro: Embedded Machine Learning for TinyML Systems, , arXiv arXiv:2010.08678; Soro, S., TinyML for Ubiquitous Edge AI, , arXiv 2021, arXiv:2102.01255; Deng, Y., Deep learning on mobile devices: A review (2019) Mobile Multimedia/Image Processing, Security, and Applications 2019, 10993, p. 109930A. , International Society for Optics and Photonics: Bellingham, WA, USA; Chen, Y., Zheng, B., Zhang, Z., Wang, Q., Shen, C., Zhang, Q., Deep Learning on Mobile and Embedded Devices: State-of-the-Art, Challenges, and Future Directions (2020) ACM Comput. Surv, 53, pp. 1-37; Zeroual, A., Derdour, M., Amroune, M., Bentahar, A., Using a Fine-Tuning Method for a Deep Authentication in Mobile Cloud Computing Based on Tensorflow Lite Framework Proceedings of the 2019 International Conference on Networking and Advanced Systems (ICNAS), pp. 1-5. , Annaba, Algeria, 26–27 June 2019; Ahmed, S., Bons, M., (2020) Edge Computed NILM: A Phone-Based Implementation Using MobileNet Compressed by Tensorflow Lite; NILM’20, pp. 44-48. , Association for Computing Machinery: New York, NY, USA; Lee, J., Chirkov, N., Ignasheva, E., Pisarchyk, Y., Shieh, M., Riccardi, F., Sarokin, R., Grundmann, M., (2019) On-Device Neural Net Inference with Mobile GPUs, , arXiv arXiv:1907.01989; Lacey, G., Taylor, G.W., Areibi, S., (2016) Deep Learning on FPGAs: Past, Present, and Future, , arXiv arXiv:1602.04283; Mouselinos, S., Leon, V., Xydis, S., Soudris, D., Pekmestzi, K., TF2FPGA: A Framework for Projecting and Accelerating Tensorflow CNNs on FPGA Platforms Proceedings of the 2019 8th International Conference on Modern Circuits and Systems Technologies (MOCAST), pp. 1-4. , Thessaloniki, Greece, 13–15 May 2019; Lee, D., Moon, H., Oh, S., Park, D., mIoT: Metamorphic IoT Platform for On-Demand Hardware Replacement in Large-Scale IoT Applications (SCI) (2020) Sensors, 20, p. 3337; Kwon, J., Park, D., Toward Data-Adaptable TinyML using Model Partial Replacement for Resource Frugal Edge Device Proceedings of the International Conference on High Performance Computing in Asia-Pacific Region, pp. 133-135. , Online, 20–21 January 2021; Kwon, J., Seok, M.G., Park, D., Low-Power Fast Partial Firmware Update Technique of On-Chip Flash Memory for Reliable Embedded IoT Microcontroller (SCI) (2021) IEICE Trans. Electron, E104-C, pp. 226-236; Moon, H., Park, D., Efficient On-Demand Hardware Replacement Platform toward Metamorphic Functional Processing in Edge-Centric IoT Applications (SCI) (2021) Electronics, 10, p. 2088; Baek, J., Jung, J., Kim, M., Kwon, J., Park, D., Low-Power Metamorphic MCU using Partial Firmware Update Method for Irregular Target Systems Control (KCI) (2021) J. Korea Inst. Inf. Commun. Eng, 25, pp. 301-307; Fedorov, I., Adams, R.P., Mattina, M., Whatmough, P.N., (2019) SpArSe: Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers, , arXiv arXiv:1905.12107; Lawrence, T., Zhang, L., IoTNet: An Efficient and Accurate Convolutional Neural Network for IoT Devices (2019) Sensors, 19, p. 5541; Liberis, E., Lane, N.D., (2020) Neural networks on microcontrollers: Saving memory at inference via operator reordering, , arXiv arXiv:1910.05110; Lin, J., Chen, W.M., Lin, Y., Cohn, J., Gan, C., Han, S., MCUNet: Tiny Deep Learning on IoT Devices, , arXiv 2020, arXiv:2007.10319; Rusci, M., Capotondi, A., Benini, L., (2019) Memory-Driven Mixed Low Precision Quantization For Enabling Deep Network Inference On Microcontrollers, , arXiv arXiv:1905.13082; Mao, W., Xiao, Z., Xu, P., Ren, H., Liu, D., Zhao, S., An, F., Yu, H., Energy-efficient machine learning accelerator for binary neural networks Proceedings of the 2020 on Great Lakes Symposium on VLSI, pp. 77-82. , Online, 7–9 September 2020; https://www.tensorflow.org/lite, TensorFlow Lite. (accessed on 1 June 2020); Essenwanger, O.M., (1986) Elements of Statistical Analysis, , Elseview: Amsterdam, The Netherlands; Zybo-Z7, , https://reference.digilentinc.com/programmable-logic/zybo-z7/start, Digilent. (accessed on 1 April 2021); https://github.com/tensorflow/tensorflow, TensorFlow Source Code. (accessed on 1 June 2020); Warden, P., Situnayake, D., (2019) Tinyml: Machine Learning with Tensorflow Lite on Arduino and Ultra-Low-Power Microcontrollers, , O’Reilly Media: Sevastopol, CA, USA; Warden, P., (2018) Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition, , arXiv arXiv:1804.03209","Park, D.; School of Electronic and Electrical Engineering, South Korea; email: boltanut@knu.ac.kr",,,"MDPI",,,,,20763417,,,,"English","Appl. Sci.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85119936599
"De Vita A., Pau D., Di Benedetto L., Rubino A., Pétrot F., Licciardo G.D.","57203900286;6603575177;35298955900;7102614070;10144748500;57191366650;","Highly-accurate binary tiny neural network for low-power human activity recognition",2021,"Microprocessors and Microsystems","87",,"104371","","",,,"10.1016/j.micpro.2021.104371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118834748&doi=10.1016%2fj.micpro.2021.104371&partnerID=40&md5=16570d58fa6ae0fe02d8a3258be813aa","Department of Industrial Engineering, University of Salerno, Fisciano (SA), Italy; System Research and Applications, STMicroelectronics, Agrate Brianza (MI), Italy; Univ. Grenoble Alpes, CNRS, University of Grenoble Alpes, Grenoble, France","De Vita, A., Department of Industrial Engineering, University of Salerno, Fisciano (SA), Italy; Pau, D., System Research and Applications, STMicroelectronics, Agrate Brianza (MI), Italy; Di Benedetto, L., Department of Industrial Engineering, University of Salerno, Fisciano (SA), Italy; Rubino, A., Department of Industrial Engineering, University of Salerno, Fisciano (SA), Italy; Pétrot, F., Univ. Grenoble Alpes, CNRS, University of Grenoble Alpes, Grenoble, France; Licciardo, G.D., Department of Industrial Engineering, University of Salerno, Fisciano (SA), Italy","An ultra low power hardware implementation of Human Activity Recognition systems imposes very tight constraints. Therefore it requires a very thoughtful balancing between highly accurate results and the reduction of the allocated physical resources. Deep Learning models provide the highest accuracies, however their typical computational complexity and memory requirements are not easily deployable in handheld or wearable devices which embody very constrained memory and computation capabilities. In this work, we introduce a new HAR system built with a new Hybrid Binarized Neural Network suitable for a very compact and ultra low-power hardware implementation. The system receives data from MEMS based inertial sensors and makes the acquisitions independent from the sensor spatial orientation and the gravity acceleration signal. The system has been trained and validated on the PAMAP2 and SHL dataset. In both cases, it achieves accuracies higher than 99% in the best case, with different input sensor configurations. A custom circuit has been implemented, which extensively shares circuitry between the different functional sub-modules of the system to minimize the amount of mapped physical resources. The FPGA implementation on a Xilinx Artix 7 achieves a total power dissipation of 72 mW and occupies 6788 LUTs. © 2021 Elsevier B.V.","Binarized neural networks; FPGA; Human activity recognition; Inertial sensors","Deep learning; Field programmable gate arrays (FPGA); Low power electronics; Pattern recognition; Wearable sensors; Binarized neural network; Hardware implementations; Highly accurate; Human activity recognition; Inertial sensor; Low Power; Lowpower hardware; Neural-networks; Physical resources; Ultra-low power; Inertial navigation systems",,,,,,,,,,,,,,,,"Lara, O.D., Labrador, M.A., A Survey on Human Activity Recognition using Wearable Sensors (2013) IEEE Commun. Surveys & Tutorials, 15 (3), pp. 1192-1209. , Third Quarter; Eskofier, B.M., Recent machine learning advancements in sensor-based mobility analysis: deep learning for Parkinson's disease assessment (2016) 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Orlando,FL, pp. 655-658; Bisio, I., Delfino, A., Lavagetto, F., Sciarrone, A., Enabling IoT for in-home rehabilitation: accelerometer signals classification methods for activity and movement recognition (2017) IEEE Internet of Things J., 4 (1), pp. 135-146. , Feb; De, P., Chatterjee, A., Rakshit, A., Recognition of human behavior for assisted living using dictionary learning approach (2018) IEEE Sens. J., 18 (6), pp. 2434-2441. , 15 March15; Xian, Y., Rong, X., Yang, X., Tian, Y., Evaluation of low-level features for real-world surveillance event detection (2017) IEEE Trans. Circuits and Syst. Video Technol., 27 (3), pp. 624-634; Normani, N., A machine learning approach for gesture recognition with a lensless smart sensor system (2018) 2018 IEEE 15th International Conference on Wearable and Implantable Body Sensor Networks (BSN), LasVegas,NV, pp. 136-139; Cola, G., Avvenuti, M., Vecchio, A., Real-time identification using gait pattern analysis on a standalone wearable accelerometer (2017) Comput. J., 60, pp. 1-14; Chinimilli, P.T., Redkar, S., Zhang, W., Human activity recognition using inertial measurement units and smart shoes (2017) 2017 American Control Conference (ACC), Seattle,WA, pp. 1462-1467; Bulling, A., Blanke, U., Schiele, B., (2014), 46 (3). , ""A tutorial on human activity recognition using body-worn inertial sensors,"" in ACM Computing Surveys, Jan; Yu, H., Cang, S., Wang, Y., A review of sensor selection, sensor devices and sensor deployment for wearable sensor-based human activity recognition systems (2016) 2016 10th International Conference on Software, Knowledge, Information Management & Applications (SKIMA), Chengdu, pp. 250-257; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Wang, J., Chen, Y., Hao, S., Peng, X., Hu, L., Deep learning for sensor-based activity recognition: a Survey (2018) Pattern Recognit. Lett., , ISSN 0167-8655; Bianchi, V., Bassoli, M., Lombardo, G., Fornacciari, P., Mordonini, M., De Munari, I., IoT wearable sensor and deep learning: an integrated approach for personalized human activity recognition in a smart home environment (2019) IEEE Internet Things J., 6 (5), pp. 8553-8562; Sze, V., Chen, Y., Yang, T., Emer, J.S., Efficient processing of deep neural networks: a tutorial and survey (2017) Proceedings of the IEEE, 105 (12), pp. 2295-2329; Vita, A.D., Pau, D., Benedetto, L.D., Rubino, A., Pétrot, F., Licciardo, G.D., Low power tiny binary neural network with improved accuracy in human recognition systems (2020) 2020 23rd Euromicro Conference on Digital System Design (DSD), Kranj,Slovenia, pp. 309-315; Guo, Y., (2018), ""A survey on methods and theories of quantized neural networks,"" arXiv:1808.04752; Geiger, L., , 5, pp. 1746-1749. , Plumerai Team, “Larq: an Open-Source Library for Training Binarized Neural Networks”, J. Open Source Software; (2020), C.N. Coelho “Ultra low-latency, low-area inference accelerators using heterogeneous deep quantization with QKeras and hls4ml” arXiv:2006.10159. [Online]. Available:; Simons, T., Lee, D.J., A review of binarized neural networks (2019) MDPI Electronics, 8 (6), pp. 661-686; Alemdar, H., Leroy, V., Prost-Boucle, A., Pétrot, F., Ternary neural networks for resource-efficient AI applications (2017) 2017 International Joint Conference on Neural Networks (IJCNN), Anchorage,AK, pp. 2547-2554; Vita, A.D., Pau, D., Parrella, C., Benedetto, L.D., Rubino, A., Licciardo, G.D., Low-power HWAccelerator for AI Edge-Computing in human activity recognition systems (2020) 2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS), Genova,Italy, pp. 291-295; Dua, D., Graff, C., UCI Machine Learning Repository (2019), http://archive.ics.uci.edu/ml, University of California, School of Information and Computer Science Irvine, CA; Gjoreski, H., The university of sussex-huawei locomotion and transportation dataset for multimodal analytics with mobile devices (2018) IEEE Access, 6, pp. 42592-42604; De Vita, A., Low-Power Integrated Circuit for Orientation Independent Acquisitions from Smart Accelerometers (2020) Lecture Notes in Electrical Eng., 629, pp. 35-41; Ioffe, S., Szegedy, C., Batch normalization: accelerating deep network training by reducing internal covariate shift (2015) ICML’15: Proceedings of the 32nd International Conference on Machine Learning¸vol. 37, Lille, pp. 448-456; (2015), https://lasagne.readthedocs.io/en/latest/index.html#, “Welcome to Lasagne” [Online]. Available:; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., (2016), “Binarized neural networks: training deep neural networks with weights and activations constrained to +1 or -1,” arXiv preprint arXiv: 1602.02830; De Vita, A., Licciardo, G.D., Femia, A., Di Benedetto, L., Rubino, A., Pau, D., Embeddable circuit for orientation independent processing in ultra low-power tri-axial inertial sensors (2020) IEEE Trans. Circuits and Syst. II: Express Briefs, 67 (6), pp. 1124-1128; Mizell, D., Using gravity to estimate accelerometer orientation (2003) Seventh IEEE International Symposium on Wearable Computers, 2003. Proceedings., NY,USA, pp. 252-253. , White Plains; Bennett, T.R., Wu, J., Kehtarnavaz, N., Jafari, R., Inertial measurement unit-based wearable computers for assisted living applications: a signal processing perspective (2016) IEEE Signal Process Mag., 33 (2), pp. 28-35; Vaidyanathan, P., Mitra, S., Neuvo, Y., A new approach to the realization of low-sensitivity IIR digital filters (1986) IEEE Trans. Acoust., 34 (2), pp. 350-361; De Vita, A., Licciardo, G.D., Femia, A., Di Benedetto, L., Pau, D., µW pre-processing unit for virtual sensors based on tri-axial smart accelerometers (2019) 2019 17th IEEE International New Circuits and Systems Conference (NEWCAS), Munich,Germany, pp. 1-4; Licciardo, G.D., Cappetta, C., Di Benedetto, L., Rubino, A., Liguori, R., Multiplier-less stream processor for 2D filtering in visual search applications (2018) IEEE Trans. Circuits and Syst. Video Technol., 28 (1), pp. 267-272; Licciardo, G.D., Cappetta, C., Di Benedetto, L., Vigliar, M., Weighted Partitioning for Fast Multiplierless Multiple-Constant Convolution Circuit (2017) IEEE Trans. Circuits and Syst. II: Express Briefs, 64 (1), pp. 66-70; Licciardo, G.D., Cappetta, C., Di Benedetto, L., FPGA optimization of convolution-based 2D filtering processor for image processing (2016) 2016 8th Computer Science and Electronic Engineering (CEEC), pp. 180-185. , Colchester; https://www.st.com/resource/en/datasheet/stm32f411re.pdf, STMicroelectronics, “STM32F411xC STM32F411xE,” Dec. 2017. [Online].Available:; Jafari, A., SensorNet: a Scalable and Low-Power Deep Convolutional Neural Network for Multimodal Data Classification (2019) IEEE Trans. Circuits and Syst. I: Regular Papers, 66 (1), pp. 274-287; Gaikwad, N.B., Tiwari, V., Keskar, A., Shivaprakash, N.C., Efficient FPGA implementation of multilayer perceptron for real-time human activity classification (2019) IEEE Access, 7, pp. 26696-26706; Zhang, S., Zhang, S., Wang, B., Habetler, T.G., Deep Learning Algorithms for Bearing Fault Diagnostics - A Review (2019) 2019 IEEE 12th International Symposium on Diagnostics for Electrical Machines, Power Electronics and Drives (SDEMPED), Toulouse,France","Licciardo, G.D.; Department of Industrial Engineering, Italy; email: gdlicciardo@unisa.it",,,"Elsevier B.V.",,,,,01419331,,MIMID,,"English","Microprocessors Microsyst",Article,"Final","",Scopus,2-s2.0-85118834748
"Torti E., D'Amato C., Danese G., Leporati F.","56091390500;57219974509;6604051702;55937698500;","A low power and real-time hardware recurrent neural network for time series analysis on wearable devices",2021,"Microprocessors and Microsystems","87",,"104374","","",,1,"10.1016/j.micpro.2021.104374","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117898967&doi=10.1016%2fj.micpro.2021.104374&partnerID=40&md5=c477f6662f492c7487ce1e11a89b54bb","Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy","Torti, E., Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy; D'Amato, C., Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy; Danese, G., Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy; Leporati, F., Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy","The research presented in this paper addresses the exploitation of Deep Learning methods on wearable devices. We propose a hardware architecture capable of analyzing time series signals through a Recurrent Neural Network implemented on FPGA technology. This architecture has been validated using a real dataset, which includes three-axial accelerometer data acquired by a wearable device used for fall detection. The experiments have been conducted considering different devices and demonstrates that the proposed hardware architecture outperforms the state of the art solutions both in terms of processing time and power consumption. Indeed, the proposed architecture is real-time compliant in the elaboration of the fall detection dataset adopted for the validation. The power consumption is in the order of dozens μW. Finally, futher functionalities could be added in the same chip since the resource usage is low. © 2021 Elsevier B.V.","Deep learning; Embedded systems; FPGA; Hardware architectures; Wearable devices","Electric power utilization; Embedded systems; Long short-term memory; Low power electronics; Network architecture; Real time systems; Time series analysis; Deep learning; Embedded-system; Fall detection; Hardware architecture; Learning methods; Low Power; Real-time hardware; Time series signals; Time-series analysis; Wearable devices; Field programmable gate arrays (FPGA)",,,,,,,,,,,,,,,,"Orjuela-Cañón, A.D., Cerquera, A., Freund, J.A., Juliá-Serdá, G., Ravelo-García, A.G., Sleep apnea: tracking effects of a first session of CPAP therapy by means of Granger causality (2020) Comput. Methods Programs Biomed., 187; Pierleoni, P., Belli, A., Bazgir, O., Maurizi, L., Paniccia, M., Palma, L., A smart inertial system for 24 h monitoring and classification of tremor and freezing of gait in Parkinson's disease (2019) IEEE Sens. J., 19, pp. 11612-11623; Posthuma, L.M., Downey, C., Visscher, M.J., Ghazali, D.A., Joshi, M., Ashrafian, H., Khan, S., Preckel, B., Remote wireless vital signs monitoring on the ward for early detection of deteriorating patients: a case series (2020) Int. J. Nurs. Stud., 104; Torti, E., Fontanella, A., Musci, M., Blago, N., Pau, D., Leporati, F., Piastra, M., Embedded real-time fall detection with deep learning on wearable devices (2018) Proc. - 21st Euromicro Conf. Digit. Syst. Des. DSD 2018, pp. 405-412. , Prague; Nizam, Y., Jamil, M.M.A., Classification of daily life activities for human fall detection: a systematic review of the techniques and approaches (2020) Stud. Syst. Decis. Control, pp. 137-179. , Springer; Khan, S., Qamar, R., Zaheen, R., Al-Ali, A.R., Al Nabulsi, A., Al-Nashash, H., Internet of things based multi-sensor patient fall detection system (2019) Healthc. Technol. Lett., 6, pp. 132-137; Nguyen, T.H., Nguyen, T.T., Ngo, B.V., A SVM algorithm for falling detection in an IoTs-based system (2020) Intell. Syst. Ref. Libr., pp. 139-170. , Springer Science and Business Media Deutschland GmbH; Mauldin, T., Canby, M., Metsis, V., Ngu, A., Rivera, C., Mauldin, T.R., Canby, M.E., Rivera, C.C., SmartFall: A smartwatch-based fall detection system using deep learning (2018) Sensors, 18, p. 3363; Danese, G., Giachero, M., Leporati, F., Nazzicari, N., An embedded multi-core biometric identification system (2011) Microprocess. Microsyst., 35, pp. 510-521; Torti, E., Koliopoulos, D., Matraxia, M., Danese, G., Leporati, F., Custom FPGA processing for real-time fetal ECG extraction and identification (2017) Comput. Biol. Med., 80, pp. 30-38; Torti, E., D'Amato, C., Danese, G., Leporati, F., An hardware recurrent neural network for wearable devices (2020) Proc. - 24th Euromicro Conf. Digit. Syst. Des. DSD 2020, pp. 293-300. , Institute of Electrical and Electronics Engineers (IEEE); Mouleeshuwarapprabu, R., Kasthuri, N., Nonlinear vector decomposed neural network based EEG signal feature extraction and detection of seizure (2020) Microprocess. Microsyst., 76; Chettri, B., Kinnunen, T., Benetos, E., Deep generative variational autoencoding for replay spoof detection in automatic speaker verification (2020) Comput. Speech Lang., 63; Fabelo, H., Halicek, M., Ortega, S., Shahedi, M., Szolna, A., Piñeiro, J., Sosa, C., Fei, B., Deep learning-based framework for in vivo identification of glioblastoma tumor using hyperspectral images of human brain (2019) Sensors, 19, p. 920; Torti, E., Fontanella, A., Plaza, A., Plaza, J., Leporati, F., Hyperspectral image classification using parallel autoencoding diabolo networks on multi-core and many-core architectures (2018) Electronics, 7, p. 411; Goodfellow, I., Bengio, Y., Courville, A., Deep Learning (2016), MIT Press; Jozefowicz, R., Zaremba, W., Sutskever, I., An empirical exploration of recurrent network architectures (2015) ICML’15 Proc. 32nd Int. Conf. Int. Conf. Mach. Learn, 37, pp. 2342-2350; Hermans, M., Schrauwen, B., Training and Analysing Deep Recurrent Neural Networks (2013) Adv. Neural Inf. Process. Syst. 26, pp. 190-198. , http://papers.nips.cc/paper/5166-training-and-analysing-deep-recurrent-neural-networks.pdf, C.J.C. Burges L. Bottou M. Welling Z. Ghahramani K.Q. Weinberger Curran Associates, Inc; Guan, Y., Yuan, Z., Sun, G., Cong, J., FPGA-based accelerator for long short-term memory recurrent neural networks (2017) Proc. Asia South Pacific Des. Autom. Conf. ASP-DAC, pp. 629-634. , Institute of Electrical and Electronics Engineers Inc; Chang, A.X.M., Culurciello, E., Hardware accelerators for recurrent neural networks on FPGA (2017) Proc. - IEEE Int. Symp. Circuits Syst., , Institute of Electrical and Electronics Engineers Inc; Chen, K., Huang, L., Li, M., Zeng, X., Fan, Y., A compact and configurable long short-term memory neural network hardware architecture (2018) Proc. - Int. Conf. Image Process. ICIP, pp. 4168-4172. , IEEE Computer Society; Bank-Tavakoli, E., Ghasemzadeh, S.A., Kamal, M., Afzali-Kusha, A., Pedram, M., POLAR: a pipelined/overlapped FPGA-based LSTM accelerator (2020) IEEE Trans. Very Large Scale Integr. Syst., 28, pp. 838-842; Yoshimura, U., Inoue, T., Tsuchiya, A., Kishine, K., Implementation of low-energy LSTM with parallel and pipelined algorithm in small-scale FPGA (2021) Int. Conf. Electron. Information, Commun., pp. 1-4. , Institute of Electrical and Electronics Engineers (IEEE) Jeju, Korea (South); Yin, J., Han, J., Xie, R., Wang, C., Duan, X., Rong, Y., Zeng, X.Y., Tao, J., MC-LSTM: real-time 3D human action detection system for intelligent healthcare applications (2021) IEEE Trans. Biomed. Circuits Syst.; Zhang, W., Ge, F., Cui, C., Yang, Y., Zhou, F., Wu, N., Design and implementation of LSTM accelerator based on FPGA (2020) Int. Conf. Commun. Technol. Proceedings, pp. 1675-1679. , ICCT, Institute of Electrical and Electronics Engineers Inc","Torti, E.; Department of Electrical, Italy; email: emanuele.torti@unipv.it",,,"Elsevier B.V.",,,,,01419331,,MIMID,,"English","Microprocessors Microsyst",Article,"Final","",Scopus,2-s2.0-85117898967
"Zhang X., Tang Z., Du L., Yang L.","57216314818;7403306139;57223440116;57193750707;","An Incremental Iterative Acceleration Architecture in Distributed Heterogeneous Environments with GPUs for Deep Learning",2021,"IEEE Transactions on Parallel and Distributed Systems","32","11","9426412","2823","2837",,1,"10.1109/TPDS.2021.3078254","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105846989&doi=10.1109%2fTPDS.2021.3078254&partnerID=40&md5=c69e349296a827ca1168fc6b6271cf7b","College of Computer Science and Electronic Engineering, National Supercomputing Center in Changsha, Hunan University, Changsha, China; College of Computer and Communication Engineering, Changsha University of Science and Technology, Hunan, China; Science and Technology on Parallel and Distributed Processing Laboratory, National University of Defense Technology, Changsha, 410073, China","Zhang, X., College of Computer Science and Electronic Engineering, National Supercomputing Center in Changsha, Hunan University, Changsha, China; Tang, Z., College of Computer Science and Electronic Engineering, National Supercomputing Center in Changsha, Hunan University, Changsha, China, Science and Technology on Parallel and Distributed Processing Laboratory, National University of Defense Technology, Changsha, 410073, China; Du, L., College of Computer Science and Electronic Engineering, National Supercomputing Center in Changsha, Hunan University, Changsha, China; Yang, L., College of Computer and Communication Engineering, Changsha University of Science and Technology, Hunan, China","The parallel computing capabilities of GPUs have a significant impact on computationally intensive iterative tasks. Offloading part or all of the deep learning tasks from the CPU to the GPU for execution is mainstream. However, a large number of redundant iterative calculations exist in the iterative process of computing tasks. Therefore, we propose a GPU-based distributed incremental iterative computing architecture that can make full use of distributed parallel computing and GPU memory structure. The architecture supports deep learning and other computationally intensive iterative applications by optimizing data placement and reducing redundant iterative calculations. To support block-based data partitioning and coalesced memory access on GPUs, we propose GDataSet, an abstract data set. The GPU incremental iteration manager called GTracker is designed to be responsible for GDataSet cache management on the GPU. In order to solve the limitation of on-chip memory size, we propose a variable sliding window mechanism. It improves the hit rate of cache access and the speed of data access by realizing the best block arrangement between on-chip memory and off-chip memory. Besides, a communication channel based on an incremental iterative model is designed to support data transmission and task communication in cluster computing. Finally, we implement the proposed architecture based on Spark 2.4.1 and CUDA 10.0. Comparative experiments with widely used computationally intensive iterative applications (K-means, LSTM, etc.) show that the incremental iterative acceleration architecture can significantly improve the efficiency of iterative computing. © 1990-2012 IEEE.","Deep learning; distributed computing; GPU; incremental iteration","Cache memory; Cluster computing; Iterative methods; Long short-term memory; Memory architecture; Program processors; Coalesced memory access; Comparative experiments; Distributed parallel computing; Heterogeneous environments; Iterative calculation; Parallel com- puting; Proposed architectures; Variable Sliding windows; Deep learning",,,,,"National Natural Science Foundation of China, NSFC: 61873090, 62002114, 92055213, L1924056; National Key Research and Development Program of China, NKRDPC: 2017YFB0202201, 2018YFB0203804, 2018YFB1701400; China Knowledge Centre for Engineering Sciences and Technology, CKCEST: CKCEST-2020-2-5","This work was supported in part by the National Key Research and Development Program of China under Grants 2018YFB1701400, 2018YFB0203804, and 2017YFB0202201, in part by the National Natural Science Foundation of China under Grants 92055213, 61873090, L1924056, and 62002114, and in part by the China Knowledge Centre for Engineering Sciences and Technology under Project CKCEST-2020-2-5.",,,,,,,,,,"Dean, J., Ghemawat, S., MapReduce: Simplified data processing on large clusters (2008) Commun. Acm, 51, pp. 107-113; http://flink.apache.org/, Flink programming guide, 2021. Accessed: May 18, 2021; Tang, Z., Zeng, A., Zhang, X., Yang, L., Li, K., Dynamic memory-aware scheduling in spark computing environment (2020) J.Parallel Distrib. Comput., 141, pp. 10-22; Yuan, Y., Lee, R., Zhang, X., The yin and yang of processing data warehousing queries on GPU devices (2013) Proc. Vldb Endowment, 6 (10), pp. 817-828; Coates, A., Huval, B., Wang, T., Wu, D.J., Ng, A.Y., Catanzaro, B., Deep learning with COTS HPC systems (2013) Proc. Int. Conf. Mach. Learn., pp. III1337-III1345; Harish, P., Narayanan, P.J., Accelerating large graph algorithms on the GPU using CUDA (2007) Proc. Int. Conf. High-Perform. Comput., pp. 197-208; Hong, S., Choi, W., Jeong, W.K., GPU in-memory processing using spark for iterative computation (2017) Proc. IEEE/ACM Int. Symp. Cluster, Cloud Grid Comput., pp. 31-41; Yuan, Y., Salmi, M.F., Yin, H., Wang, K., Lee, R., Zhang, X., Spark-GPU: An accelerated in-memory data processing engine on clusters (2017) Proc. Ieee Int. Conf. Big Data, pp. 273-283; Grossman, M., Sarkar, V., SWAT: A programmable, in-memory, distributed, high-performance computing platform (2016) Proc. Acm Int. Symp. High-Perform. Parallel Distrib. Comput., pp. 81-92; Zhang, J., Chen, X., Song, M., Li, T., Eager pruning: Algorithm and architecture support for fast training of deep neural networks (2019) Proc. 46th Int. Symp. Comput. Archit., pp. 292-303; Mariappan, M., Vora, K., GraphBolt: Dependency-driven synchronous processing of streaming graphs (2019) Proc. 14th EuroSys Conf., pp. 1-16; Bhatotia, P., Wieder, A., Rodrigues, R., Acar, U.A., Pasquin, R., Incoop: MapReduce for incremental computations (2011) Proc. Acm Symp. Cloud Comput., pp. 1-14; Murray, D.G., Mcsherry, F., Isaacs, R., Isard, M., Barham, P., Naiad: A timely dataflow system (2013) Proc. 24th Acm Symp. Oper. Syst. Princ., pp. 439-455; Zhang, Y., Chen, S., I2MapReduce: Incremental iterative MapReduce (2013) Proc. 2nd Int. Workshop Cloud Intell., pp. 1-4; Tang, Z., He, M., Fu, Z., Yang, L., IncGraph: An improved distributed incremental graph computing model and framework based on spark graphX Ieee Trans. Knowl. Data Eng., , to be published; Fang, W., He, B., Luo, Q., Govindaraju, N.K., Mars: Accelerating mapReduce with graphics processors (2011) Ieee Trans. Parallel Distrib. Syst., 22 (4), pp. 608-620. , Apr; Hong, C., Chen, D., Chen, W., Zheng, W., Lin, H., MapCG: Writing parallel program portable between CPU and GPU (2010) Proc. Int. Conf. Parallel Archit. Compilation Techn., pp. 217-226; Chen, L., Huo, X., Agrawal, G., Accelerating mapReduce on a coupled CPU-GPU architecture (2012) Proc. Int. Conf. High Perform. Comput., Netw., Storage Anal., pp. 1-11; Elteir, M., Lin, H., Feng, W.C., Scogland, T., StreamMR: An optimized mapReduce framework for AMD GPUS (2011) Proc. Ieee 17th Int. Conf. Parallel Distrib. Syst., pp. 364-371; Adinew, D.M., Shijie, Z., Liao, Y., Spark performance optimization analysis in memory management with deploy mode in standalone cluster computing (2020) Proc. Ieee 36th Int. Conf. Data Eng., pp. 2049-2053; Jayaram, K.R., Gandhi, A., Xin, H., Tao, S., Adaptively accelerating map-reduce/spark with GPUs: A case study (2019) Proc. Ieee Int. Conf. Autonomic Comput., pp. 105-114; Peng, Y., A generic communication scheduler for distributed DNN training acceleration (2019) Proc. 27th Acm Symp. Operating Syst. Princ., pp. 16-29; Moritz, P., Ray: A distributed framework for emerging ai applications (2018) Proc. 13th Usenix Symp. Operating Syst. Des. Implementation, pp. 561-577; Li, P., Luo, Y., Zhang, N., Cao, Y., HeteroSpark: A heterogeneous CPU/GPU spark platform for machine learning algorithms (2015) Proc. Ieee Int. Conf. Netw., Archit. Storage, pp. 347-348; Choi, W., On-chip communication network for efficient training of deep convolutional networks on heterogeneous manycore systems (2018) Ieee Trans. Comput., 67 (5), pp. 672-686. , May; Schuiki, F., Schaffner, M., Gurkaynak, F.K., Benini, L., A scalable near-memory architecture for training deep neural networks on large in-memory datasets (2019) Ieee TransComput., 68 (4), pp. 484-497. , Apr; Meng, X., MLlib: Machine learning in apache spark (2015) J. Mach. Learn. Res, 17 (1), pp. 1235-1241; Jia, J., Kalipatnapu, P., Chiou, R., Yang, Y., Implementing a GPU-based machine learning library on Apache spark (2016) Master's Thesis, Eecs Dept., Univ. California, , Berkeley, CA, USA; Ashraf, I., Khammassi, N., Taouil, M., Bertels, K., Memory and communication profiling for accelerator-based platforms (2018) Ieee Trans. Comput., 67 (7), pp. 934-948. , Jul; Paik, I., Chen, W., Li, Z., Tology-aware optimal data placement algorithm for network traffic optimization (2016) Ieee Trans. Comput., 65 (8), pp. 2603-2617. , Aug; Sethia, A., Jamshidi, D., Mahlke, S., Mascar: Speeding up GPU warps by reducing memory pitstops (2015) Proc. Ieee 21st Int. Symp. High Perform. Comput. Archit., pp. 174-185; Chen, C.H., Hsia, T.Y., Huang, Y.N., Kuo, S.Y., Data prefetching and eviction mechanisms of in-memory storage sytems based on scheduling for big data processing (2019) Ieee Trans. Parallel Distrib. Syst., 30 (8), pp. 1738-1752. , Aug; Yu, Q., Childers, B., Huang, L., Qian, C., Wang, Z., HPE: Hierarchical page eviction policy for unified memory in GPUs (2020) Ieee Trans. Comput.-Aided Des. Integrated Circuits Syst., 39 (10), pp. 2461-2474. , Oct; Chien, S., Peng, I.B., Markidis, S., Performance evaluation of advanced features in CUDA unified memory (2019) Proc. IEEE/ACM Workshop Memory Centric High Perform. Comput., pp. 50-57; Xu, H., Emani, M., Lin, P.H., Hu, L., Liao, C., Machine learning guided optimal use of GPU unified memory (2019) Proc. IEEE/ACM Workshop Memory Centric High Perform. Comput., pp. 64-70; Fang, J., Zhou, K., Tan, C., Zhao, H., Dynamic block size adjustment and workload balancing strategy based on CPU-GPU heterogeneous platform (2019) Proc. Ieee Int. Conf. Parallel Distrib. Process. Appl., Big Data Cloud Comput., Sustain. Comput. Commun., Soc. Comput. Netw., pp. 999-1006","Tang, Z.; College of Computer Science and Electronic Engineering, China; email: ztang@hnu.edu.cn",,,"IEEE Computer Society",,,,,10459219,,ITDSE,,"English","IEEE Trans Parallel Distrib Syst",Article,"Final","",Scopus,2-s2.0-85105846989
"Liang T., Glossner J., Wang L., Shi S., Zhang X.","57219750643;6602569997;57218275461;56286724600;41763031900;","Pruning and quantization for deep neural network acceleration: A survey",2021,"Neurocomputing","461",,,"370","403",,14,"10.1016/j.neucom.2021.07.045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112651139&doi=10.1016%2fj.neucom.2021.07.045&partnerID=40&md5=b2aea422f8c5f399231aebe6df65695d","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China; Hua Xia General Processor Technologies, Beijing, 100080, China; General Processor Technologies, Tarrytown, NY  10591, United States","Liang, T., School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China, Hua Xia General Processor Technologies, Beijing, 100080, China; Glossner, J., School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China, Hua Xia General Processor Technologies, Beijing, 100080, China, General Processor Technologies, Tarrytown, NY  10591, United States; Wang, L., School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China; Shi, S., School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China, Hua Xia General Processor Technologies, Beijing, 100080, China; Zhang, X., School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China","Deep neural networks have been applied in many applications exhibiting extraordinary abilities in the field of computer vision. However, complex network architectures challenge efficient real-time deployment and require significant computation resources and energy costs. These challenges can be overcome through optimizations such as network compression. Network compression can often be realized with little loss of accuracy. In some cases accuracy may even improve. This paper provides a survey on two types of network compression: pruning and quantization. Pruning can be categorized as static if it is performed offline or dynamic if it is performed at run-time. We compare pruning techniques and describe criteria used to remove redundant computations. We discuss trade-offs in element-wise, channel-wise, shape-wise, filter-wise, layer-wise and even network-wise pruning. Quantization reduces computations by reducing the precision of the datatype. Weights, biases, and activations may be quantized typically to 8-bit integers although lower bit width implementations are also discussed including binary neural networks. Both pruning and quantization can be used independently or combined. We compare current techniques, analyze their strengths and weaknesses, present compressed network accuracy results on a number of frameworks, and provide practical guidance for compressing networks. © 2021 Elsevier B.V.","Convolutional neural network; Low-bit mathematics; Neural network acceleration; Neural network pruning; Neural network quantization","Complex networks; Economic and social effects; Network architecture; Surveys; Computation energy; Convolutional neural network; Low-bit mathematic; Network compression; Neural network acceleration; Neural network pruning; Neural network quantization; Neural-networks; Quantisation; Real- time; Deep neural networks; accuracy; algorithm; Article; back propagation; calibration; convolutional neural network; deep neural network; human; mathematics; recurrent neural network; reinforcement learning (machine learning); weight bias",,,,,,,,,,,,,,,,"Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Goodfellow, I., TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems (2016) arXiv preprint arXiv: 1603.04467, , A. Harp G. Irving M. Isard Y. Jia R. Jozefowicz L. Kaiser M. Kudlur J. Levenberg D. Mane R. Monga S. Moore D. Murray C. Olah M. Schuster J. Shlens B. Steiner I. Sutskever K. Talwar P. Tucker V. Vanhoucke V. Vasudevan F. Viegas O. Vinyals P. Warden M. Wattenberg M. Wicke Y. Yu X. Zheng; Abdel-Hamid, O., (2014), http://ieeexplore.ieee.org/document/6857341/, Mohamed, A.r., Jiang, H., Deng, L., Penn, G., Yu, D. Convolutional Neural Networks for Speech Recognition. IEEE/ACM Transactions on Audio, Speech, and Language Processing 22, 1533–1545., 10.1109/TASLP.2014.2339736; Abdelouahab, K., Pelcat, M., Serot, J., Berry, F., (2018), http://arxiv.org/abs/1806.01683, Accelerating CNN inference on FPGAs: A Survey. ArXiv preprint; (2020), pp. 1-15. , Achronix Semiconductor Corporation FPGAs Enable the Next Generation of Communication and Networking Solutions. White Paper WP021; (2020), https://github.com/albanie/convnet-burden, Albanie convnet-burden; Alemdar, H., Leroy, V., Prost-Boucle, A., Petrot, F., Ternary neural networks for resource-efficient AI applications (2017), pp. 2547-2554. , https://ieeexplore.ieee.org/abstract/document/7966166/, 2017 International Joint Conference on Neural Networks (IJCNN), IEEE., DOI: 10.1109/IJCNN.2017.7966166; https://www.amd.com/en/products/professional-graphics/instinct-mi25, AMD, Radeon Instinct MI25 Accelerator; (2015), file. https://developer.arm.com/documentation/ddi0487/latest. https://developer.arm.com/documentation/ddi0487/latest, Arm ARM Architecture Reference Manual ARMv8, for ARMv8-A architecture pro; (2020), https://developer.arm.com/ip-products/processors/cortex-a, Arm Arm Cortex-M Processor Comparison Table; (2020), https://www.arm.com/products/silicon-ip-multimedia/gpu/mali-g76, Arm, Graphics, C. MALI-G76 High-Performance GPU for Complex Graphics Features and Bene ts High Performance for Mixed Realities; (2008), http://caxapa.ru/thumbs/301908/AT_-_NEON_for_Multimedia_Applications.pdf, ARM, Reddy, V.G. Neon technology introduction. ARM Corporation, 1–34; Augasta, M.G., Kathirvalavakumar, T., Pruning algorithms of neural networks - A comparative study (2013) Open Computer Science, 3, pp. 105-115; (2019), https://github.com/PaddlePaddle/Paddle, Baidu PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice; Balzer, W., Takahashi, M., Ohta, J., Kyuma, K., Weight quantization in Boltzmann machines (1991) Neural Networks, 4, pp. 405-409; Banner, R., Hubara, I., Hoffer, E., Soudry, D., Scalable methods for 8-bit training of neural networks (2018) Advances in Neural Information Processing Systems (NIPS), pp. 5145-5153. , http://papers.nips.cc/paper/7761-scalable-methods-for-8-bit-training-of-neural-networks; Banner, R., Nahshan, Y., Soudry, D., Post training 4-bit quantization of convolutional networks for rapid-deployment (2019) Advances in Neural Information Processing Systems (NIPS), pp. 7950-7958; Liu, B., Wang, M., Foroosh, H., Tappen, M., Penksy, M., Sparse Convolutional Neural Networks (2015) 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 806-814. , IEEE; Baskin, C., Schwartz, E., Zheltonozhskii, E., Liss, N., Giryes, R., Bronstein, A.M., Mendelson, A.U., (2018), http://arxiv.org/abs/1804.10969, Uniform Noise Injection for Non-Uniform Quantization of Neural Networks. arXiv preprint arXiv:1804.10969; Bengio, E., Bacon, P.L., Pineau, J., Precup, D., (2015), http://arxiv.org/abs/1511.06297, Conditional Computation in Neural Networks for faster models. ArXiv preprint; Bengio, Y., (2013), http://arxiv.org/abs/1305.2982, Estimating or Propagating Gradients Through Stochastic Neurons. ArXiv preprint; Bethge, J., Bartz, C., Yang, H., Chen, Y., Meinel, C., (2020), http://arxiv.org/abs/2001.05936, MeliusNet: Can Binary Neural Networks Achieve MobileNet-level Accuracy? ArXiv preprint; Bethge, J., Yang, H., Bornstein, M., Meinel, C., BinaryDenseNet: Developing an architecture for binary neural networks (2019) Proceedings - 2019 International Conference on Computer Vision Workshop ICCVW 2019, 1951–196010.1109/ICCVW.2019.00244; Bianco, S., Cadene, R., Celona, L., Napoletano, P., Benchmark analysis of representative deep neural network architectures (2018) IEEE Access, 6, pp. 64270-64277; Blalock, D., Ortiz, J.J.G., Frankle, J., Guttag, J., (2020), http://arxiv.org/abs/2003.03033, What is the State of Neural Network Pruning? ArXiv preprint; Bolukbasi, T., Wang, J., Dekel, O., Saligrama, V., Adaptive Neural Networks for Efficient Inference (2017) Thirty-fourth International Conference on Machine Learning; Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Amodei, D., (2020), http://arxiv.org/abs/2005.14165, Language Models are Few-Shot Learners. ArXiv preprint; Buciluaˇ, C., Caruana, R., Niculescu-Mizil, A., (2006), p. 535. , https://dl.acm.org/doi/abs/10.1145/1150402.1150464, Model compression, in: Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD ’06, ACM Press, New York, New York, USA., DOI: 10.1145/1150402.1150464; (2019), https://github.com/BUG1989/caffe-INT8-convert-tools, BUG1989 BUG1989/caffe-int8-convert-tools: Generate a quantization parameter file for ncnn framework int8 inference; Cai, H., Gan, C., Wang, T., Zhang, Z., Han, S., (2019), http://arxiv.org/abs/1908.09791, Once-for-All: Train One Network and Specialize it for Efficient Deployment. ArXiv preprint, 1–15; Cai, J., Takemoto, M., Nakajo, H., A Deep Look into Logarithmic Quantization of Model Parameters in Neural Networks (2018) Proceedings of the 10th International Conference on Advances in Information Technology - IAIT 2018, pp. 1-8. , ACM Press New York, New York, USA; Cai, Z., He, X., Sun, J., Vasconcelos, N., Deep Learning with Low Precision by Half-Wave Gaussian Quantization (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5406-5414. , IEEE; Cao, S., Ma, L., Xiao, W., Zhang, C., Liu, Y., Zhang, L., Nie, L., Yang, Z., SeerNet: Predicting Convolutional Neural Network Feature-Map Sparsity through Low-Bit Quantization (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR); Carreira-Perpinan, M.A., Idelbayev, Y., Learning-Compression Algorithms for Neural Net Pruning (2018), pp. 8532-8541. , https://ieeexplore.ieee.org/document/8578988/, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), IEEE., DOI: 10.1109/CVPR.2018.00890; Chellapilla, K., Puri, S., Simard, P., High Performance Convolutional Neural Networks for Document Processing (2006), https://hal.inria.fr/inria-00112631/, Tenth International Workshop on Frontiers in Handwriting Recognition., 10.1.1.137.482; Chen, H., Wang, Y., Xu, C., Shi, B., Xu, C., Tian, Q., Xu, C., AdderNet: Do We Really Need Multiplications in Deep Learning? (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1468-1477; Chen, T., Moreau, T., Jiang, Z., Zheng, L., Yan, E., Cowan, M., Shen, H., Krishnamurthy, A.T., (2018), pp. 579-594. , http://arxiv.org/abs/1802.04799, An automated end-to-end optimizing compiler for deep learning, in: Proceedings of the 13th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2018; Chen, W., Wilson, J., Tyree, S., Weinberger, K., Chen, Y., Compressing neural networks with the hashing trick (2015) International Conference on Machine Learning, pp. 2285-2294; Chen, Y., Chen, T., Xu, Z., Sun, N., Temam, O., DianNao family: Energy-Efficient Hardware Accelerators for Machine Learning (2016) Commun. ACM, 59, pp. 105-112; Cheng, J., (2018), http://link.springer.com/10.1631/FITEE.1700789, Wang, P.s., Li, G., Hu, Q.h., Lu, H.q. Recent advances in efficient computation of deep convolutional neural networks. Frontiers of Information Technology & Electronic Engineering 19, 64–77., 10.1631/FITEE.1700789; Cheng, Y., Wang, D., Zhou, P., Zhang, T., (2017), http://arxiv.org/abs/1710.09282, A Survey of Model Compression and Acceleration for Deep Neural Networks. ArXiv preprint; Cheng, Z., Soudry, D., Mao, Z., Lan, Z., (2015), http://cn.arxiv.org/pdf/1503.03562.pdf http://arxiv.org/abs/1503.03562, Training Binary Multilayer Neural Networks for Image Classification using Expectation Backpropagation. ArXiv preprint; Chiliang, Z., Tao, H., Yingda, G., Zuochang, Y., Accelerating Convolutional Neural Networks with Dynamic Channel Pruning (2019) 2019 Data Compression Conference (DCC), p. 563. , IEEE; Choi, B., Lee, J.H., Kim, D.H., Solving local minima problem with large number of hidden nodes on two-layered feed-forward artificial neural networks (2008) Neurocomputing, 71, pp. 3640-3643; Choi, J., Wang, Z., Venkataramani, S., (2018), http://arxiv.org/abs/1805.06085, Chuang, P.I.j., Srinivasan, V., Gopalakrishnan, K. PACT: Parameterized Clipping Activation for Quantized Neural Networks. ArXiv preprint, 1–15; Choi, Y., El-Khamy, M., Lee, J., Towards the Limit of Network Quantization (2017) International Conference on Learning Representations(ICLR), , IEEE; Choi, Y., Member, S.S., Bae, D., Sim, J., Member, S.S., Choi, S., Kim, M., Member, S.S., Energy-Efficient Design of Processing Element for Convolutional Neural Network (2017) IEEE Trans. Circuits Syst. II Express Briefs, 64, pp. 1332-1336. , http://ieeexplore.ieee.org/document/7893765, /; Chollet, F., Google, C., Xception: Deep Learning with Depthwise Separable Convolutions (2017), pp. 1251-1258. , http://ieeexplore.ieee.org/document/8099678/, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE., DOI: 10.1109/CVPR.2017.195; Choudhary, T., Mishra, V., Goswami, A., Sarangapani, J., A comprehensive survey on model compression and acceleration (2020) Artif. Intell. Rev., 53, pp. 5113-5155; Cornea, M., (2015), Intel AVX-512 Instructions and Their Use in the Implementation of Math Functions. Intel Corporation; Cotofana, S., Vassiliadis, S., Logic, T., Addition, B., Addition, S., Low Weight and Fan-In Neural Networks for Basic Arithmetic Operations (1997), pp. 227-232. , 15th IMACS World Congress, 10.1.1.50.4450; Courbariaux, M., Bengio, Y., (2014), pp. 1-10. , http://arxiv.org/abs/1412.7024, David, J.P. Training deep neural networks with low precision multiplications, in: International Conference on Learning Representations(ICLR), arXiv: 1412.7024; Courbariaux, M., Bengio, Y., (2015), pp. 1-9. , http://arxiv.org/abs/1511.00363, David, J.P. BinaryConnect: Training Deep Neural Networks with binary weights during propagations, in: Advances in Neural Information Processing Systems (NIPS), DOI: 10.5555/2969442.2969588; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., (2016), https://github.com/MatthieuCourbariaux/ http://arxiv.org/abs/1602.02830, Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1. ArXiv preprint; Das, D., Mellempudi, N., Mudigere, D., Kalamkar, D., Avancha, S., Banerjee, K., Sridharan, S., Pirogov, V., Mixed Precision Training of Convolutional Neural Networks using Integer Operations (2018), pp. 1-11. , https://www.anandtech.com/show/11741/hot-chips-intel-knights-mill-live-blog-445pm-pt-1145pm-utc http://arxiv.org/abs/1802.00930, International Conference on Learning Representations(ICLR); Dash, M., Liu, H., Feature selection for classification (1997) Intelligent Data Analysis, 1, pp. 131-156; Davis, A., Arel, I., Low-Rank Approximations for Conditional Feedforward Computation in Deep Neural Networks (2013) International Conference on Learning Representations Workshops (ICLRW), pp. 1-10. , http://arxiv.org/abs/1312.4461; Deng, W., Yin, W., Zhang, Y., Group sparse optimization by alternating direction method (2013), http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2024410, Van De Ville, D., Goyal, V.K., Papadakis, M. (Eds.), Wavelets and Sparsity XV, p. 88580R., DOI: 10.1117/12.2024410; Dettmers, T., 8-Bit Approximations for Parallelism in Deep Learning (2015) International Conference on Learning Representations(ICLR); Dong, X., Huang, J., Yang, Y., Yan, S., More is less: A more complicated network with less inference complexity (2017) Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition CVPR 2017 2017-Janua, 1895–1903; Dongarra, J.J., Du Croz, J., Hammarling, S., Duff, I.S., A set of level 3 basic linear algebra subprograms (1990) ACM Transactions on Mathematical Software (TOMS), 16, pp. 1-17; Dukhan, M., Yiming, W., Hao, L., Lu, H.Q., (2019), https://engineering.fb.com/ml-applications/qnnpack/, Open source library for optimized mobile deep learning - Facebook Engineering; Elhoushi, M., Chen, Z., Shafiq, F., Tian, Y.H., (2019), http://arxiv.org/abs/1905.13298, Li, J.Y. DeepShift: Towards Multiplication-Less Neural Networks. ArXiv preprint; Elsken, T., Metzen, J.H., Hutter, F., Neural Architecture Search (2019) J. Mach. Learn. Res., 20, pp. 63-77. , http://link.springer.com/10.1007/978-3-030-05318-5_3; Engelbrecht, A.P., A new pruning heuristic based on variance analysis of sensitivity information (2001) IEEE Trans. Neural Networks, 12, pp. 1386-1389; Esser, S.K., Merolla, P.A., Arthur, J.V., Cassidy, A.S., Appuswamy, R., Andreopoulos, A., Berg, D.J., Barch, D.R., (2016), http://www.pnas.org/lookup/doi/10.1073/pnas.1604850113, di Nolfo, C., Datta, P., Amir, A., Taba, B., Flickner, M.D., Modha, D.S. Convolutional networks for fast, energy-efficient neuromorphic computing. Proceedings of the National Academy of Sciences 113, 11441–11446., DOI: 10.1073/pnas.1604850113; Faraone, J., Fraser, N., Blott, M., Leong, P.H., SYQ: Learning Symmetric Quantization for Efficient Deep Neural Networks (2018) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR); Fiesler, E., Choudry, A., Caulfield, H.J., Weight discretization paradigm for optical neural networks (1990) Optical Interconnections and Networks, 1281, p. 164; Figurnov, M., Collins, M.D., Zhu, Y., Zhang, L., Huang, J., Vetrov, D., Salakhutdinov, R., Spatially Adaptive Computation Time for Residual Networks (2017) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1790-1799. , IEEE; FPGA, I., https://www.intel.com/content/www/us/en/software/programmable/overview.html, Intel FPGA Development Tools - Intel FPGA; Frankle, J., Carbin, M., The lottery ticket hypothesis: Finding sparse, trainable neural networks (2019) International Conference on Learning Representations(ICLR); Fukushima, K., Neocognitron: A hierarchical neural network capable of visual pattern recognition (1988) Neural Networks, 1, pp. 119-130; Gale, T., Elsen, E., Hooker, S., (2019), http://arxiv.org/abs/1902.09574, The State of Sparsity in Deep Neural Networks. ArXiv preprint; Gao, X., Zhao, Y., Dudziak, L., Mullins, R., Xu, C.Z., Dudziak, L., Mullins, R., Xu, C.Z., Dynamic Channel Pruning: Feature Boosting and Suppression (2019) International Conference on Learning Representations (ICLR), pp. 1-14. , http://arxiv.org/abs/1810.05331; Glossner, J., Blinzer, P., Takala, J., HSA-enabled DSPs and accelerators (2016) 2015 IEEE Global Conference on Signal and Information Processing GlobalSIP 2015, pp. 1407-1411; Gong, R., Liu, X., Jiang, S., Li, T., Hu, P., Lin, J., Yu, F., Yan, J., Differentiable soft quantization: Bridging full-precision and low-bit neural networks (2019) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 4851-4860; Gong, Y., Liu, L., Yang, M., Bourdev, L., Compressing Deep Convolutional Networks using Vector Quantization (2014) International Conference on Learning Representations(ICLR); https://www.tensorflow.org/lite/guide/hosted_models, Google, Hosted models — TensorFlow Lite; (2018), https://github.com/google/gemmlowp. https://github.com/google/gemmlowp, Google google/gemmlowp: Low-precision matrix multiplication; Gordon, A., Eban, E., Nachum, O., Chen, B., Wu, H., Yang, T.J., Choi, E., MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks (2018) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1586-1595. , IEEE; Gou, J., Yu, B., Maybank, S.J., Tao, D., (2020), http://arxiv.org/abs/2006.05525, Knowledge Distillation: A Survey. ArXiv preprint; Graham, B., (2017), http://arxiv.org/abs/1702.08231, Low-Precision Batch-Normalized Activations. ArXiv preprint, 1–16; Graves, A., (2016), http://arxiv.org/abs/1603.08983, Adaptive Computation Time for Recurrent Neural Networks. ArXiv preprint, 1–19; Greff, K., Srivastava, R.K., Schmidhuber, J., Highway and Residual Networks learn Unrolled Iterative Estimation (2016) International Conference on Learning Representations(ICLR), pp. 1-14; Gudovskiy, D.A., Rigazio, L., (2017), http://arxiv.org/abs/1706.02393, ShiftCNN: Generalized Low-Precision Architecture for Inference of Convolutional Neural Networks. ArXiv preprint; Guo, K., Sui, L., Qiu, J., Yu, J., Wang, J., Yao, S., Han, S., Yang, H., Angel-Eye: A complete design flow for mapping CNN onto embedded FPGA (2018) IEEE Trans. Comput. Aided Des. Integr. Circuits Syst., 37, pp. 35-47. , https://ieeexplore.ieee.org/abstract/document/7930521, /; Guo, K., Zeng, S., Yu, J., Wang, Y., Yang, H., A Survey of FPGA-Based Neural Network Accelerator (2017) ACM Transactions on Reconfigurable Technology and Systems 9; Guo, Y., (2018), http://arxiv.org/abs/1808.04752, A Survey on Methods and Theories of Quantized Neural Networks. ArXiv preprint; Guo, Y., Yao, A., Chen, Y., Dynamic Network Surgery for Efficient DNNs (2016) Advances in Neural Information Processing Systems (NIPS), pp. 1379-1387. , http://papers.nips.cc/paper/6165-dynamic-network-surgery-for-efficient-dnns; Gupta, S., Agrawal, A., Gopalakrishnan, K., Narayanan, P., Deep learning with limited numerical precision (2015) International Conference on Machine Learning (ICML), pp. 1737-1746; Gysel, P., Pimentel, J., Motamedi, M., Ghiasi, S., Ristretto: A Framework for Empirical Study of Resource-Efficient Inference in Convolutional Neural Networks (2018) IEEE Transactions on Neural Networks and Learning Systems, 29, pp. 1-6. , https://ieeexplore.ieee.org/abstract/document/8318896, /; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: Efficient Inference Engine on Compressed Deep Neural Network (2016) 2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA), pp. 243-254. , IEEE; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding (2016) International Conference on Learning Representations(ICLR), pp. 199-203; Han, S., Pool, J., Narang, S., Mao, H., Gong, E., Tang, S., Elsen, E., Dally, W.J., http://arxiv.org/abs/1607.04381, 2016c. DSD: Dense-Sparse-Dense Training for Deep Neural Networks, in: International Conference on Learning Representations(ICLR); Han, S., Pool, J., Tran, J., (2015), pp. 1135-1143. , http://arxiv.org/abs/1506.02626, Dally, W.J. Learning both Weights and Connections for Efficient Neural Networks, in: Advances in Neural Information Processing Systems (NIPS), DOI: 10.1016/S0140-6736(95)92525-2; Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E., Prenger, R., Coates, A., (2014), http://arxiv.org/abs/1412.5567, Ng, A.Y. Deep Speech: Scaling up end-to-end speech recognition. ArXiv preprint, 1–12; HANSON, S., Comparing biases for minimal network construction with back-propagation (1989), pp. 177-185. , Advances in Neural Information Processing Systems (NIPS); Hassibi, B., Stork, D.G., (1993), Wolff, G.J. Optimal brain surgeon and general network pruning. 10.1109/icnn.1993.298572; He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition (2015) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 171-180. , IEEE; He, Y., Kang, G., Dong, X., Fu, Y., Yang, Y., Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks (2018), pp. 2234-2240. , http://arxiv.org/abs/1808.06866, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18), International Joint Conferences on Artificial Intelligence Organization, California., 10.24963/ijcai.2018/309; He, Y., Liu, P., Wang, Z., Hu, Z., Yang, Y., Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration (2019) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR); He, Y., Zhang, X., Sun, J., Channel Pruning for Accelerating Very Deep Neural Networks (2017) IEEE International Conference on Computer Vision (ICCV), pp. 1398-1406. , IEEE; Hinton, G., (2012), Neural networks for machine learning. Technical Report. Coursera; Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., (2012), http://arxiv.org/abs/1207.0580, Salakhutdinov, R.R. Improving neural networks by preventing co-adaptation of feature detectors. ArXiv preprint, 1–18; Hou, L., Yao, Q., Kwok, J.T., Loss-aware Binarization of Deep Networks (2017) International Conference on Learning Representations(ICLR); Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017), http://arxiv.org/abs/1704.04861, MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. ArXiv preprint; Hu, H., Peng, R., Tai, Y.W., (2016), http://arxiv.org/abs/1607.03250, Tang, C.K. Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures. ArXiv preprint; Hu, Q., Wang, P., Cheng, J., From hashing to CNNs: Training binary weight networks via hashing (2018) AAAI Conference on Artificial Intelligence, pp. 3247-3254; Huang, G., Chen, D., Li, T., Wu, F., (2018), http://image-net.org/challenges/talks/, Van Der Maaten, L., Weinberger, K. Multi-scale dense networks for resource efficient image classification, in: International Conference on Learning Representations(ICLR); Huang, G., Liu, Z., (2017), pp. 2261-2269. , https://ieeexplore.ieee.org/document/8099726/, Van Der Maaten, L., Weinberger, K.Q. Densely Connected Convolutional Networks, in: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), IEEE., 10.1109/CVPR.2017.243; Huang, G.B., Learned-miller, E., (2014), pp. 1-5. , Labeled faces in the wild: Updates and new reporting procedures. Dept. Comput. Sci., Univ. Massachusetts Amherst, Amherst, MA, USA, Tech. Rep 14; Huang, Z., Wang, N., Data-Driven Sparse Structure Selection for Deep Neural Networks (2018), 11220, pp. 317-334. , http://link.springer.com/10.1007/978-3-030-01270-0_19, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)., LNCS; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Binarized Neural Networks (2016) Advances in Neural Information Processing Systems (NIPS), pp. 4114-4122. , http://papers.nips.cc/paper/6573-binarized-neural-networks; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations (2016) Journal of Machine Learning Research, 18 (18), pp. 181-187. , http://arxiv.org/abs/1609.07061; Hwang, K., Sung, W., Fixed-point feedforward deep neural network design using weights +1, 0, and -1 (2014), pp. 1-6. , https://ieeexplore.ieee.org/abstract/document/6986082/, 2014 IEEE Workshop on Signal Processing Systems (SiPS), IEEE., DOI: 10.1109/SiPS.2014.6986082; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016), https://arxiv.org/abs/1602.07360 http://arxiv.org/abs/1602.07360, SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size, in: ArXiv e-prints., DOI: 10.1007/978-3-319-24553-9; Ignatov, A., Timofte, R., Kulik, A., Yang, S., Wang, K., Baum, F., Wu, M., Van Gool, L., AI benchmark: All about deep learning on smartphones in 2019 (2019) Proceedings - 2019 International Conference on Computer Vision Workshop ICCVW 2019, 3617–3635; https://www.imgtec.com/graphics-processors/, Imagination, PowerVR - embedded graphics processors powering iconic products; https://docs.openvinotoolkit.org/latest/index.html, Intel, OpenVINO Toolkit; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning (ICML), pp. 448-456. , http://arxiv.org/abs/1502.03167; Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., Kalenichenko, D., Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference (2018) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2704-2713. , IEEE; Jia, Z., Tillman, B., Maggioni, M., (2019), Scarpazza, D.P. Dissecting the graphcore IPU architecture via microbenchmarking. ArXiv preprint; (2009), Jia Deng, Wei Dong, Socher, R., Li-Jia Li, Kai Li, Li Fei-Fei ImageNet: A large-scale hierarchical image database. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 248–25510.1109/cvprw.2009.5206848; (1994), 3, pp. 622-624. , http://ieeexplore.ieee.org/document/577060/, Jianchang Mao, Mohiuddin, K., Jain, A. Parsimonious network design and feature selection through node pruning, in: Proceedings of the 12th IAPR International Conference on Pattern Recognition, - Conference C: Signal Processing (Cat. No.94CH3440-5), IEEE Comput. Soc. Press., DOI: 10.1109/icpr.1994.577060; Jiao, Y., Han, L., Long, X., Hanguang 800 NPU - The Ultimate AI Inference Solution for Data Centers (2020) 2020 IEEE Hot Chips 32 Symposium (HCS), pp. 1-29. , IEEE; Jouppi, N.P., Borchers, A., Boyle, R., (2017), http://dl.acm.org/citation.cfm?doid=3140659.3080246, Cantin, P.l., Chao, C., Clark, C., Coriell, J., Daley, M., Dau, M., Dean, J., Gelb, B., Young, C., Ghaemmaghami, T.V., Gottipati, R., Gulland, W., Hagmann, R., Ho, C.R., Hogberg, D., Hu, J., Hundt, R., Hurt, D., Ibarz, J., Patil, N., Jaffey, A., Jaworski, A., Kaplan, A., Khaitan, H., Killebrew, D., Koch, A., Kumar, N., Lacy, S., Laudon, J., Law, J., Patterson, D., Le, D., Leary, C., Liu, Z., Lucke, K., Lundin, A., MacKean, G., Maggiore, A., Mahony, M., Miller, K., Nagarajan, R., Agrawal, G., Narayanaswami, R., Ni, R., Nix, K., Norrie, T., Omernick, M., Penukonda, N., Phelps, A., Ross, J., Ross, M., Salek, A., Bajwa, R., Samadiani, E., Severn, C., Sizikov, G., Snelham, M., Souter, J., Steinberg, D., Swing, A., Tan, M., Thorson, G., Tian, B., Bates, S., Toma, H., Tuttle, E., Vasudevan, V., Walter, R., Wang, W., Wilcox, E., Yoon, D.H., Bhatia, S., Boden, N. In-Datacenter Performance Analysis of a Tensor Processing Unit. ACM SIGARCH Computer Architecture News 45, 1–12., 10.1145/3140659.3080246; Judd, P., Delmas, A., Sharify, S., Moshovos, A., (2017), https://arxiv.org/abs/1705.00125, Cnvlutin2: Ineffectual-Activation-and-Weight-Free Deep Neural Network Computing. ArXiv preprint, 1–6; Jung, S., Son, C., Lee, S., Son, J., Kwak, Y., Han, J.J., Hwang, S.J., Choi, C., (2018), http://arxiv.org/abs/1808.05779, Learning to Quantize Deep Networks by Optimizing Quantization Intervals with Task Loss. Revue Internationale de la Croix-Rouge et Bulletin international des Sociétés de la Croix-Rouge, arXiv:1808.05779v2; Kathail, V., Xilinx Vitis Unified Software Platform (2020), pp. 173-174. , https://dl.acm.org/doi/10.1145/3373087.3375887, Proceedings of the 2020 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, ACM, New York, NY, USA., DOI: 10.1145/3373087.3375887; (2018), https://arm-software.github.io/CMSIS_5/NN/html/index.html, Keil CMSIS NN Software Library; Köster, U., Webb, T.J., Wang, X., Nassar, M., Bansal, A.K., Constable, W.H., Elibol, O.H., Rao, N., (2017), http://arxiv.org/abs/1711.02213, Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks. ArXiv preprint; Krishnamoorthi, R., (2018), http://cn.arxiv.org/pdf/1806.08342.pdf http://arxiv.org/abs/1806.08342, Quantizing deep convolutional networks for efficient inference: A whitepaper. ArXiv preprint 8, 667–668., arXiv:1806.08342v1; Krizhevsky, A., (2009), Learning Multiple Layers of Features from Tiny Images. Science Department, University of Toronto, Tech. 10.1.1.222.9220; Krizhevsky, A., Sutskever, I., (2012), pp. 1-9. , http://code.google.com/p/cuda-convnet/, doi: 10.1016/j.protcy.2014.09.007, Hinton, G.E. ImageNet Classification with Deep Convolutional Neural Networks, in: Advances in Neural Information Processing Systems (NIPS); Lattner, C., Amini, M., Bondhugula, U., Cohen, A., Davis, A., Pienaar, J., Riddle, R., Zinenko, O.M., (2020), http://arxiv.org/abs/2002.11054, A Compiler Infrastructure for the End of Moore's Law. ArXiv preprint; Lavin, A., Gray, S., Fast Algorithms for Convolutional Neural Networks (2016), pp. 4013-4021. , http://ieeexplore.ieee.org/document/7780804/ http://arxiv.org/abs/1312.5851, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), IEEE., DOI: 10.1109/CVPR.2016.435; Lebedev, V., Lempitsky, V., Fast ConvNets Using Group-Wise Brain Damage (2016), pp. 2554-2564. , http://openaccess.thecvf.com/content_cvpr_2016/html/Lebedev_Fast_ConvNets_Using_CVPR_2016_paper.html http://ieeexplore.ieee.org/document/7780649/, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), IEEE., DOI: 10.1109/CVPR.2016.280; Lebedev, V., Lempitsky, V., (2018), http://www.czasopisma.pan.pl/Content/109869/PDF/05_799-810_00925_Bpast.No.66-6_31.12.18_K2.pdf?handler=pdf http://www.czasopisma.pan.pl/Content/109869/PDF/05_799-810_00925_Bpast.No.66-6_31.12.18_K2.pdf, Speeding-up convolutional neural networks: A survey. BULLETIN OF THE POLISH ACADEMY OF SCIENCES TECHNICAL SCIENCES 66, 10.24425/bpas.2018.125927; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86, pp. 2278-2323. , http://ieeexplore.ieee.org/document/726791, /; LeCun, Y., Denker, J.S., Solla, S.A., Optimal Brain Damage (1990) Advances in Neural Information Processing Systems (NIPS), pp. 598-605; Lee, N., Ajanthan, T., (2019), Torr, P.H. SnIP: Single-shot network pruning based on connection sensitivity, in: International Conference on Learning Representations(ICLR); Lei, J., Gao, X., Song, J., Wang, X.L., (2018), https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049464636&doi=10.13328 10.13328/j.cnki.jos.005428, Song, M.L. Survey of Deep Neural Network Model Compression. Ruan Jian Xue Bao/Journal of Software 29, 251–266; Lei, W., Chen, H., Wu, Y., Compressing Deep Convolutional Networks Using K-means Based on Weights Distribution (2017) Proceedings of the 2nd International Conference on Intelligent Information Processing, pp. 1-6. , ACM Press New York, New York, USA; Leng, C., Li, H., Zhu, S., Jin, R., Extremely Low Bit Neural Network: Squeeze the Last Bit Out with ADMM (2018) The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18); Leroux, S., Bohez, S., De Coninck, E., Verbelen, T., Vankeirsbilck, B., Simoens, P., Dhoedt, B., The cascading neural network: building the Internet of Smart Things (2017) Knowl. Inf. Syst., 52, pp. 791-814. , http://link.springer.com/10.1007/s10115-017-1029-1; Li, F., Zhang, B., Liu, B., Ternary Weight Networks (2016), http://arxiv.org/abs/1605.04711, Advances in Neural Information Processing Systems (NIPS); Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning Filters for Efficient ConvNets (2017) International Conference on Learning Representations (ICLR); Li, H., Zhang, H., Qi, X., Ruigang, Y., Huang, G., Improved Techniques for Training Adaptive Deep Networks (2019) 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 1891-1900. , IEEE; Li, M., Liu, Y.I., Liu, X., Sun, Q., You, X.I.N., Yang, H., Luan, Z., Qian, D., http://arxiv.org/abs/2002.03794, 2020a. The Deep Learning Compiler: A Comprehensive Survey. ArXiv preprint 1, 1–36; Li, Y., Gu, S., Mayer, C., Van Gool, L., Timofte, R., Group Sparsity: The Hinge Between Filter Pruning and Decomposition for Network Compression (2020) 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8015-8024. , IEEE; Li, Z., Wang, Y., Zhi, T., Chen, T., A survey of neural network accelerators (2017) Front. Computer Sci., 11, pp. 746-761. , http://link.springer.com/10.1007/s11704-016-6159-1; Li, Z., Zhang, Y., Wang, J., Lai, J., A survey of FPGA design for AI era (2020) J. Semiconductors, 41; Lin, J., Rao, Y., Lu, J., Zhou, J., Runtime Neural Pruning (2017) Advances in Neural Information Processing Systems (NIPS), pp. 2178-2188. , https://papers.nips.cc/paper/6813-runtime-neural-pruning.pdf; Lin, M., Chen, Q., Yan, S., Network in network (2014), pp. 1-10. , International Conference on Learning Representations(ICLR); Lin, X., Zhao, C., Pan, W., Towards accurate binary convolutional neural network (2017) Advances in Neural Information Processing Systems (NIPS), pp. 345-353; Lin, Z., Courbariaux, M., Memisevic, R., Bengio, Y., Neural Networks with Few Multiplications (2016) International Conference on Learning Representations(ICLR); Liu, J., Musialski, P., Wonka, P., Ye, J., Tensor Completion for Estimating Missing Values in Visual Data (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35, pp. 208-220. , http://ieeexplore.ieee.org/document/6138863, /; Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C., Learning Efficient Convolutional Networks through Network Slimming (2017) IEEE International Conference on Computer Vision (ICCV), pp. 2755-2763. , IEEE; Liu, Z., Mu, H., Zhang, X., Guo, Z., Yang, X., Cheng, T.K.T., Sun, J., MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning (2019) IEEE International Conference on Computer Vision; Liu, Z., Sun, M., Zhou, T., Huang, G., Darrell, T., Rethinking the Value of Network Pruning (2019) International Conference on Learning Representations (ICLR), pp. 1-11. , http://arxiv.org/abs/1810.05270; Liu, Z., Wu, B., Luo, W., Yang, X., Liu, W., Cheng, K.T., Bi-Real Net: Enhancing the performance of 1-bit CNNs with improved representational capability and advanced training algorithm (2018) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 11219 LNCS, 747–763; Liu, Z.G., Mattina, M., Learning low-precision neural networks without Straight-Through Estimator (STE) (2019), pp. 3066-3072. , https://www.ijcai.org/proceedings/2019/425, IJCAI International Joint Conference on Artificial Intelligence, International Joint Conferences on Artificial Intelligence Organization, California., 10.24963/ijcai.2019/425; Luo, J.H., Wu, J., AutoPruner: An end-to-end trainable filter pruning method for efficient deep model inference (2020) Pattern Recogn., 107. , https://linkinghub.elsevier.com/retrieve/pii/S0031320320302648; Luo, J.H.H., Wu, J., Lin, W., ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression (2017) Proceedings of the IEEE International Conference on Computer Vision (ICCV) 2017-Octob, 5068–5076; Ma, Y., Suda, N., Cao, Y., Seo, J.S., Vrudhula, S., Scalable and modularized RTL compilation of Convolutional Neural Networks onto FPGA (2016) FPL 2016–26th International Conference on Field-Programmable Logic and Applications; Macchi, O., Coincidence Approach To Stochastic Point Process (1975) Adv. Appl. Prob., 7, pp. 83-122; Mariet, Z., Sra, S., Diversity Networks: Neural Network Compression Using Determinantal Point Processes (2016), pp. 1-13. , http://arxiv.org/abs/1511.05077, International Conference on Learning Representations(ICLR); Mathieu, M., Henaff, M., LeCun, Y., (2013), http://arxiv.org/abs/1312.5851, Fast Training of Convolutional Networks through FFTs. ArXiv preprint; Medina, E., Habana Labs presentation. 2019 IEEE Hot Chips 31 Symposium (2019); Mellempudi, N., Kundu, A., Mudigere, D., Das, D., Kaul, B., Dubey, P., (2017), http://arxiv.org/abs/1705.01462, Ternary Neural Networks with Fine-Grained Quantization. ArXiv preprint; Merolla, P., Appuswamy, R., Arthur, J., Esser, S.K., Modha, D., (2016), https://arxiv.org/abs/1606.01981 http://arxiv.org/abs/1606.01981, Deep neural networks are robust to weight binarization and other non-linear distortions. ArXiv preprint; Micikevicius, P., Narang, S., Alben, J., Diamos, G., Elsen, E., Garcia, D., Ginsburg, B., Wu, H., Mixed Precision Training (2017), http://arxiv.org/abs/1710.03740, International Conference on Learning Representations(ICLR); Migacz, S., 8-bit inference with TensorRT (2017) GPU Technology Conference, 2, p. 7. , https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf; Mishra, A., Nurvitadhi, E., Cook, J.J., Marr, D., WRPN: Wide reduced-precision networks (2018) International Conference on Learning Representations(ICLR), pp. 1-11. , IEEE; Miyashita, D., Lee, E.H., Murmann, B., (2016), http://cn.arxiv.org/pdf/1603.01025.pdf http://arxiv.org/abs/1603.01025, Convolutional Neural Networks using Logarithmic Data Representation. ArXiv preprint; Molchanov, D., Ashukha, A., Vetrov, D., Variational dropout sparsifies deep neural networks (2017) International Conference on Machine Learning (ICML), pp. 3854-3863. , https://dl.acm.org/citation.cfm?id=3305939; Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J., Pruning Convolutional Neural Networks for Resource Efficient Inference (2016) International Conference on Learning Representations (ICLR), pp. 1-17. , http://arxiv.org/abs/1611.06440; Moss, D.J.M., Nurvitadhi, E., Sim, J., Mishra, A., Marr, D., Subhaschandra, S., (2017), pp. 1-4. , https://ieeexplore.ieee.org/abstract/document/8056823/, Leong, P.H.W. High performance binary neural networks on the Xeon+FPGA platform, in: 2017 27th International Conference on Field Programmable Logic and Applications (FPL), IEEE., 10.23919/FPL.2017.8056823; Moudgill, M., Glossner, J., Huang, W., Tian, C., Xu, C., Yang, N., Wang, L., Li, K., Heterogeneous Edge CNN Hardware Accelerator (2020) The 12th International Conference on Wireless Communications and Signal Processing, pp. 6-11. , IEEE; Muller, L.K., Indiveri, G., (2015), http://arxiv.org/abs/1504.05767, Rounding Methods for Neural Networks with Low Resolution Synaptic Weights. ArXiv preprint; Muthukrishnan, R., Rohini, R., LASSO: A feature selection technique in predictive modeling for machine learning (2016) 2016 IEEE International Conference on Advances in Computer Applications (ICACA), pp. 18-20. , IEEE; (2020), http://arxiv.org/abs/2006.03669, Neill, J.O. An Overview of Neural Network Compression. ArXiv preprint, 1–73; (2014), http://international.download.nvidia.com/geforce-com/international/pdfs/GeForce_GTX_980_Whitepaper_FINAL.PDF, NVIDIA Corporation NVIDIA GeForce GTX 980 Featuring Maxwell, The Most Advanced GPU Ever Made. White Paper, 1–32; (2015), https://www.nvidia.com/en-us/data-center/tesla-p100/, NVIDIA Corporation NVIDIA Tesla P100. White Paper; Corporation, N., http://images.nvidia.com/content/pdf/dgx1-v100-system-architecture-whitepaper.pdf, 2017a. NVIDIA DGX-1 With Tesla V100 System Architecture. White Paper; Corporation, N., http://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf, 2017b. NVIDIA Tesla V100 GPU Volta Architecture. White Paper, 53; Corporation, N., , pp. 20-21. , 2018a. NVIDIA A100 Tensor Core GPU. White Paper; Corporation, N., https://gpltech.com/wp-content/uploads/2018/11/NVIDIA-Turing-Architecture-Whitepaper.pdf, 2018b. NVIDIA Turing GPU Architecture. White Paper; Odena, A., Lawson, D., Olah, C., Changing Model Behavior at Test-Time Using Reinforcement Learning (2017), http://arxiv.org/abs/1702.07780, International Conference on Learning Representations Workshops (ICLRW), International Conference on Learning Representations, ICLR; https://github.com/onnx/onnx, ONNX, onnx/onnx: Open standard for machine learning interoperability; Ouyang, J., Noh, M., Wang, Y., Qi, W., Ma, Y., Gu, C., Kim, S., (2020), pp. 1-18. , https://ieeexplore.ieee.org/document/9220641/, Hong, K.i., Bae, W.K., Zhao, Z., Wang, J., Wu, P., Gong, X., Shi, J., Zhu, H., Du, X. Baidu Kunlun An AI processor for diversified workloads, in: 2020 IEEE Hot Chips 32 Symposium (HCS), IEEE., DOI: 10.1109/HCS49909.2020.9220641; Park, E., Ahn, J., Yoo, S., Weighted-Entropy-Based Quantization for Deep Neural Networks (2017) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7197-7205. , IEEE; Paszke, A., Gross, S., Bradbury, J., Lin, Z., Devito, Z., Massa, F., Steiner, B., Yang, E., (2019), PyTorch: An Imperative Style, High-Performance Deep Learning Library. ArXiv preprint; Pilipović, R., Bulić, P., Risojević, V., Compression of convolutional neural networks: A short survey (2018) 2018 17th International Symposium on INFOTEH-JAHORINA INFOTEH 2018 - Proceedings, pp. 1-6. , IEEE; Polyak, A., Wolf, L., Channel-level acceleration of deep face representations (2015) IEEE Access, 3, pp. 2163-2175. , http://ieeexplore.ieee.org/document/7303876, /; Preuser, T.B., Gambardella, G., Fraser, N., Blott, M., Inference of quantized neural networks on heterogeneous all-programmable devices (2018), pp. 833-838. , http://ieeexplore.ieee.org/document/8342121/, 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE), IEEE., 10.23919/DATE.2018.8342121; Prost-Boucle, A., Bourge, A., Petrot, F., Alemdar, H., Caldwell, N., Leroy, V., Scalable high-performance architecture for convolutional ternary neural networks on FPGA (2017), pp. 1-7. , https://hal.archives-ouvertes.fr/hal-01563763 http://ieeexplore.ieee.org/document/8056850/, 2017 27th International Conference on Field Programmable Logic and Applications (FPL), IEEE., 10.23919/FPL.2017.8056850; Qin, H., Gong, R., Liu, X., Bai, X., Song, J., Sebe, N., Binary neural networks: A survey (2020) Pattern Recogn., 105. , https://linkinghub.elsevier.com/retrieve/pii/S0031320320300856; Qin, H., Gong, R., Liu, X., Shen, M., Wei, Z., Yu, F., Song, J., Forward and Backward Information Retention for Accurate Binary Neural Networks (2020) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2247-2256. , IEEE; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks (2016), pp. 525-542. , http://arxiv.org/abs/1603.05279 http://link.springer.com/10.1007/978-3-319-46493-0_32, European Conference on Computer Vision, Springer., DOI: 10.1007/978-3-319-46493-0_32; Reed, R., Pruning Algorithms - A Survey (1993) IEEE Trans. Neural Networks, 4, pp. 740-747. , http://ieeexplore.ieee.org/document/248452, /; Reuther, A., Michaleas, P., Jones, M., Gadepally, V., Samsi, S., Kepner, J., Survey and Benchmarking of Machine Learning Accelerators (2019) 2019 IEEE High Performance Extreme Computing Conference (HPEC), pp. 1-9. , IEEE; (2020), Richard Chuang, Oliyide, O., Garrett, B. Introducing the Intel Vision Accelerator Design with Intel Arria 10 FPGA. White Paper; Rodriguez, A., Segal, E., Meiri, E., Fomenko, E., Kim, Y.J., Shen, H., Lower Numerical Precision Deep Learning Inference and Training (2018) Intel White Paper, pp. 1-19. , https://software.intel.com/sites/default/files/managed/db/92/Lower-Numerical-Precision-Deep-Learning-Jan2018.pdf; Rotem, N., Fix, J., Abdulrasool, S., Catron, G., Deng, S., Dzhabarov, R., Gibson, N., Wang, M., (2018), Glow: Graph lowering compiler techniques for neural networks. ArXiv preprint; Ruffy, F., Chahal, K., (2019), http://arxiv.org/abs/1912.10850, The State of Knowledge Distillation for Classification. ArXiv preprint; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet Large Scale Visual Recognition Challenge (2015) Int. J. Comput. Vision, 115, pp. 211-252. , http://link.springer.com/10.1007/s11263-015-0816-y; Saad, D., Marom, E., Training Feed Forward Nets with Binary Weights Via a Modified CHIR Algorithm (1990) Complex Systems, 4, pp. 573-586. , https://www.complex-systems.com/pdf/04-5-5.pdf; Sabour, S., Frosst, N., Hinton, G.E., Dynamic routing between capsules (2017) Advances in Neural Information Processing Systems (NIPS), pp. 3857-3867; Santurkar, S., Tsipras, D., Ilyas, A., Madry, A., How does batch normalization help optimization? (2018) Advances in Neural Information Processing Systems (NIPS), pp. 2483-2493; Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y., OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks (2013) International Conference on Learning Representations(ICLR); Settle, S.O., Bollavaram, M., D'Alberto, P., Delaye, E., Fernandez, O., Fraser, N., Ng, A., Wu, M., (2018), http://arxiv.org/abs/1805.07941, Quantizing Convolutional Neural Networks for Low-Power High-Throughput Inference Engines. ArXiv preprint; Shen, M., Han, K., Xu, C., Wang, Y., Searching for accurate binary neural architectures (2019) Proceedings - 2019 International Conference on Computer Vision Workshop ICCVW 2019, 2041–204410.1109/ICCVW.2019.00256; Shen, X., Yi, B., Zhang, Z., Shu, J., Liu, H., Automatic Recommendation Technology for Learning Resources with Convolutional Neural Network (2016), pp. 30-34. , Proceedings - 2016 International Symposium on Educational Technology, ISET 2016, DOI: 10.1109/ISET.2016.12; Sheng, T., Feng, C., Zhuo, S., Zhang, X., Shen, L., Aleksic, M., (2018), https://ieeexplore.ieee.org/document/8524017/, A Quantization-Friendly Separable Convolution for MobileNets. 2018 1st Workshop on Energy Efficient Machine Learning and Cognitive Computing for Embedded Applications (EMC2), 14–18, DOI: 10.1109/EMC2.2018.00011; Simons, T., Lee, D.J., A review of binarized neural networks (2019) Electronics (Switzerland), 8; Simonyan, K., Zisserman, A., Very Deep Convolutional Networks for Large-Scale Image Recognition (2014) International Conference on Learning Representations(ICLR), pp. 1-14; Singh, P., (2019), pp. 3460-3466. , https://www.ijcai.org/proceedings/2019/480, Kumar Verma, V., Rai, P., Namboodiri, V.P. Play and Prune: Adaptive Filter Pruning for Deep Model Compression, in: Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, International Joint Conferences on Artificial Intelligence Organization, California., 10.24963/ijcai.2019/480; Society, I.C., (2008), Committee, M.S. IEEE Standard for Floating-Point Arithmetic. IEEE Std 754-2008 2008, 1–70. 10.1109/IEEESTD.2008.4610935; Soudry, D., Hubara, I., Meir, R., Expectation backpropagation: Parameter-free training of multilayer neural networks with continuous or discrete weights (2014) Advances in Neural Information Processing Systems (NIPS), pp. 963-971. , https://dl.acm.org/doi/abs/10.5555/2968826.2968934; Srinivas, S., (2015), pp. 1-31. , http://www.bmva.org/bmvc/2015/papers/paper031/index.html http://arxiv.org/abs/1507.06149, Babu, R.V. Data-free parameter pruning for Deep Neural Networks, in: Procedings of the British Machine Vision Conference 2015, British Machine Vision Association., DOI: 10.5244/C.29.31; Srivastava, N., Hinton, G., (2014), http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer, …, A.K.T.j.o.m., 2014, U. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research 15, 1929–1958., 10.5555/2627435.2670313; Sun, J., Luo, X., Gao, H., Wang, W., Gao, Y., Yang, X., Categorizing Malware via A Word2Vec-based Temporal Convolutional Network Scheme (2020) Journal of Cloud Computing, 9; Sun, M., Song, Z., Jiang, X., Pan, J., Pang, Y., Learning Pooling for Convolutional Neural Network (2017) Neurocomputing, 224, pp. 96-104; Sze, V., Chen, Y.H.H., Yang, T.J.J., Emer, J.S., Efficient Processing of Deep Neural Networks: A Tutorial and Survey (2017) Proc. IEEE, 105, pp. 2295-2329. , http://ieeexplore.ieee.org/document/8114708, /; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 1-9. , IEEE; https://www.tensorflow.org/lite/guide, TansorFlow, Fixed Point Quantization; Technologies, Q., (2019), https://developer.qualcomm.com/docs/snpe/index.html, Snapdragon Neural Processing Engine SDK; (2019), https://github.com/Tencent/ncnn, Tencent NCNN is a high-performance neural network inference framework optimized for the mobile platform; Tishbirani, R., (1996), https://statweb.stanford.edu/ tibs/lasso/lasso.pdf, Regression shrinkage and selection via the Lasso; Umuroglu, Y., Fraser, N.J., Gambardella, G., Blott, M., Leong, P., Jahre, M., Vissers, K.F., (2016), http://dl.acm.org/citation.cfm?doid=3020078.3021744, A Framework for Fast, Scalable Binarized Neural Network Inference. Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays - FPGA ’17, 65–74, DOI: 10.1145/3020078.3021744; Vanholder, H., Efficient Inference with TensorRT. Technical Report (2016); Vanhoucke, V., Senior, A., (2011), https://research.google/pubs/pub37631/, Mao, M.Z. Improving the speed of neural networks on CPUs; Venieris, S.I., Kouris, A., Bouganis, C.S., Toolflows for Mapping Convolutional Neural Networks on FPGAs (2018) ACM Comput. Surv., 51, pp. 1-39. , http://dl.acm.org/citation.cfm?doid=3212709.3186332; Venkatesh, G., Nurvitadhi, E., Marr, D., Accelerating Deep Convolutional Networks using low-precision and sparsity (2017) 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2861-2865. , IEEE; Wang, K., Liu, Z., Lin, Y., Lin, J., Han, S., HAQ: Hardware-Aware Automated Quantization With Mixed Precision (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8604-8612. , IEEE; Wang, N., Choi, J., Brand, D., Chen, C.Y., Gopalakrishnan, K., Training deep neural networks with 8-bit floating point numbers (2018) Advances in Neural Information Processing Systems (NIPS), pp. 7675-7684; Wang, P., Cheng, J., Fixed-Point Factorized Networks (2017), pp. 3966-3974. , http://ieeexplore.ieee.org/document/8099905/, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), IEEE., DOI: 10.1109/CVPR.2017.422; Wang, P., Hu, Q., Zhang, Y., Zhang, C., Liu, Y., Cheng, J., Two-Step Quantization for Low-bit Neural Networks (2018) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4376-4384; Wang, Z., Lu, J., Tao, C., Zhou, J., Tian, Q., Learning channel-wise interactions for binary convolutional neural networks (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 568-577; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning Structured Sparsity in Deep Neural Networks (2016), pp. 2074-2082. , https://dl.acm.org/doi/abs/10.5555/3157096.3157329, DOI: 10.1016/j.ccr.2008.06.009, Advances in Neural Information Processing Systems (NIPS), IEEE; Wu, H., Judd, P., Zhang, X., Isaev, M., Micikevicius, P., (2020), pp. 1-20. , Integer quantization for deep learning inference: Principles and empirical evaluation. ArXiv preprint; Wu, J., Leng, C., Wang, Y., Hu, Q., Cheng, J., Quantized Convolutional Neural Networks for Mobile Devices (2016) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4820-4828. , IEEE; Wu, S., Li, G., Chen, F., Shi, L., Training and Inference with Integers in Deep Neural Networks (2018) International Conference on Learning Representations (ICLR); Wu, S., Li, G., Deng, L., Liu, L., Wu, D., Xie, Y., Shi, L., L1-Norm Batch Normalization for Efficient Training of Deep Neural Networks (2019) IEEE Transactions on Neural Networks and Learning Systems, 30, pp. 2043-2051. , https://ieeexplore.ieee.org/abstract/document/8528524, https://ieeexplore.ieee.org/document/8528524; Wu, Z., Nagarajan, T., Kumar, A., Rennie, S., Davis, L.S., Grauman, K., Feris, R., BlockDrop: Dynamic Inference Paths in Residual Networks (2018) IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8817-8826. , IEEE; (2019), https://github.com/XiaoMi/mace/, Xiaomi MACE is a deep learning inference framework optimized for mobile heterogeneous computing platforms; Inc, X., Accelerating DNNs with Xilinx Alveo Accelerator Cards (WP504) (2018) White Paper, 504, pp. 1-11. , www.xilinx.com1; Xu, J., Huan, Y., Zheng, L.R., Zou, Z., A Low-Power Arithmetic Element for Multi-Base Logarithmic Computation on Deep Neural Networks (2019) International System on Chip Conference IEEE, pp. 260-265; Xu, S., Huang, A., Chen, L., Zhang, B., Convolutional Neural Network Pruning: A Survey (2020), pp. 7458-7463. , https://ieeexplore.ieee.org/document/9189610/, 2020 39th Chinese Control Conference (CCC), IEEE., 10.23919/CCC50068.2020.9189610; Xu, X., Lu, Q., Yang, L., Hu, S., Chen, D., Hu, Y., Shi, Y., Quantization of Fully Convolutional Networks for Accurate Biomedical Image Segmentation (2018) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8300-8308; Xu, Z., Hsu, Y.C., Huang, J., Training shallow and thin networks for acceleration via knowledge distillation with conditional adversarial networks (2018) International Conference on Learning Representations (ICLR)-Workshop; Yang, J., Shen, X., Xing, J., Tian, X., Li, H., Deng, B., Huang, J., Hua, X.S., Quantization Networks (2019) 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7300-7308. , IEEE; Yang, Y., Deng, L., Wu, S., Yan, T., Xie, Y., Li, G., Training high-performance and large-scale deep neural networks with full 8-bit integers (2020) Neural Networks, 125, pp. 70-82; Ye, J., Lu, X., Lin, Z., (2018), http://arxiv.org/abs/1802.00124, Wang, J.Z. Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers. ArXiv preprint; Yin, P., Zhang, S., Lyu, J., Osher, S., Qi, Y., Xin, J., Blended coarse gradient descent for full quantization of deep neural networks (2019) Research in Mathematical Sciences, 6; Yogatama, D., Mann, G., (2014) Efficient Transfer Learning Method for Automatic Hyperparameter Tuning Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics, pp. 1077-1085. , S. Kaski J. Corander; Yu, J., Lukefahr, A., Palframan, D., Dasika, G., Das, R., Mahlke, S., Scalpel: Customizing DNN pruning to the underlying hardware parallelism (2017) ACM SIGARCH Computer Architecture News, 45, pp. 548-560. , http://dl.acm.org/citation.cfm?doid=3140659.3080215; Yu, J., Yang, L., Xu, N., Yang, J., Huang, T., Slimmable Neural Networks (2018) International Conference on Learning Representations(ICLR), International Conference on Learning Representations ICLR, pp. 1-12; Yuan, M., Lin, Y., Model selection and estimation in regression with grouped variables (2006) Journal of the Royal Statistical Society: Series B (Statistical Methodology), 68, pp. 49-67. , http://doi.wiley.com/10.1111/j.1467-9868.2005.00532.x; Yuan, Z., Hu, J., Wu, D., Ban, X., A dual-attention recurrent neural network method for deep cone thickener underflow concentration prediction (2020) Sensors (Switzerland), 20, pp. 1-18; Zhang, D., Yang, J., Ye, D., Hua, G., LQ-Nets: Learned quantization for highly accurate and compact deep neural networks (2018) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), pp. 373-390; Zhang, Q., Zhang, M., Chen, T., Sun, Z., Ma, Y., Yu, B., Recent Advances in Convolutional Neural Network Acceleration (2019) Neurocomputing, 323, pp. 37-51. , https://linkinghub.elsevier.com/retrieve/pii/S0925231218311007; Zhang, S., Du, Z., Zhang, L., Lan, H., Liu, S., Li, L., Guo, Q., Chen, Y., Cambricon-X: An accelerator for sparse neural networks (2016) 2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), pp. 1-12. , http://ieeexplore.ieee.org/document/7783723, IEEE URL:/; Zhang, S., Wu, Y., Che, T., Lin, Z., Memisevic, R., Salakhutdinov, R., Bengio, Y., Architectural complexity measures of recurrent neural networks (2016) Advances in Neural Information Processing Systems (NIPS), pp. 1830-1838; Zhang, Y., Zhao, C., Ni, B., Zhang, J., Deng, H., http://arxiv.org/abs/1908.02620, 2019b. Exploiting Channel Similarity for Accelerating Deep Convolutional Neural Networks. ArXiv preprint, 1–14; Zhao, R., Song, W., Zhang, W., Xing, T., Lin, J.H., Srivastava, M., Gupta, R., Zhang, Z., Accelerating Binarized Convolutional Neural Networks with Software-Programmable FPGAs (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays - FPGA ’17, pp. 15-24. , ACM Press New York New York, USA; Zhong, K., Zhao, T., Ning, X., Zeng, S., Guo, K., Wang, Y., Yang, H., (2020), http://arxiv.org/abs/2006.02804, Towards Lower Bit Multiplication for Convolutional Neural Network Training. ArXiv preprint; Zhou, A., Yao, A., Guo, Y., Xu, L., Chen, Y., Incremental Network Quantization: Towards Lossless CNNs with Low-Precision Weights (2017) International Conference on Learning Representations(ICLR); Zhou, H., Alvarez, J.M., Porikli, F., , pp. 662-677. , http://link.springer.com/10.1007/978-3-319-46493-0_40, 2016a. Less Is More: Towards Compact CNNs, in: European Conference on Computer Vision, DOI: 10.1007/978-3-319-46493-0_40; Zhou, S., Kannan, R., Prasanna, V.K., Accelerating low rank matrix completion on FPGA (2018) 2017 International Conference on Reconfigurable Computing and FPGAs, ReConFig 2017, pp. 1-7. , IEEE; Zhou, S., Wu, Y., Ni, Z., Zhou, X., Wen, H., Zou, Y., https://arxiv.org/abs/1606.06160, 2016b. DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients. ArXiv preprint abs/1606.0, 1–13; Zhou, S.C., Wang, Y.Z., Wen, H., He, Q.Y., Zou, Y.H., Balanced Quantization: An Effective and Efficient Approach to Quantized Neural Networks (2017) Journal of Computer Science and Technology, 32, pp. 667-682; Zhu, C., Han, S., Mao, H., Dally, W.J., Trained Ternary Quantization (2017) International Conference on Learning Representations (ICLR), pp. 1-10. , http://arxiv.org/abs/1612.01064; Zhu, F., Gong, R., Yu, F., Liu, X., Wang, Y., Li, Z., Yang, X., Yan, J., Towards Unified INT8 Training for Convolutional Neural Network http://arxiv.org/abs/1912.12607, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR); Zhuang, B., Shen, C., Tan, M., Liu, L., Reid, I., Structured binary neural networks for accurate image classification and semantic segmentation (2019) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2019-June, 413–422; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., Learning Transferable Architectures for Scalable Image Recognition (2017) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8697-8710","Zhang, X.; School of Computer and Communication Engineering, China; email: zxt@ies.ustb.edu.cn",,,"Elsevier B.V.",,,,,09252312,,NRCGE,,"English","Neurocomputing",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85112651139
"Guo Z., Xiao Y., Liao W., Veelaert P., Philips W.","57192104280;57189591414;24830628200;6602129110;7005218159;","FLOPs-efficient filter pruning via transfer scale for neural network acceleration",2021,"Journal of Computational Science","55",,"101459","","",,1,"10.1016/j.jocs.2021.101459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117196414&doi=10.1016%2fj.jocs.2021.101459&partnerID=40&md5=e1527d39fb192a4a3c8c79dee310a41d","Department of Telecommunications and Information Processing, Ghent University-IMEC, St-Pietersnieuwstraat 41, Ghent, 9000, Belgium","Guo, Z., Department of Telecommunications and Information Processing, Ghent University-IMEC, St-Pietersnieuwstraat 41, Ghent, 9000, Belgium; Xiao, Y., Department of Telecommunications and Information Processing, Ghent University-IMEC, St-Pietersnieuwstraat 41, Ghent, 9000, Belgium; Liao, W., Department of Telecommunications and Information Processing, Ghent University-IMEC, St-Pietersnieuwstraat 41, Ghent, 9000, Belgium; Veelaert, P., Department of Telecommunications and Information Processing, Ghent University-IMEC, St-Pietersnieuwstraat 41, Ghent, 9000, Belgium; Philips, W., Department of Telecommunications and Information Processing, Ghent University-IMEC, St-Pietersnieuwstraat 41, Ghent, 9000, Belgium","Model pruning is a useful technique to reduce the computational cost of convolutional neural networks. In this paper, we first propose a simple but effective filter level pruning criterion, which assesses the importance of a filter by exploring the transfer scale (TS) of its feature maps in the next layer. The principle is that for a trained CNN model, an important filter should have strong connections with the next layer, otherwise the transfer scale of its feature map will be low and hence removing it will have little influence on the network. Besides, we observe that filters from the computationally-intensive layers are more sensitive to pruning, which makes it difficult to further compress the floating-point operations (FLOPs) of the model without reducing accuracy. To solve this problem, we propose a FLOPs-efficient group Lasso approach for TS to guide the network to use fewer filters in the computationally-intensive layers, which leads to better FLOPs compression performance after pruning. We refer to the proposed method as FETS. Compared with the state-of-the-art methods, our FETS achieves similar or better accuracy, but with significantly larger FLOPs compression ratio. In particular, with VGG-16, ResNet-56 and DenseNet-40 on CIFAR-10, we achieve similar or better accuracies than other methods, with only 48%, 64% and 58% of the FLOPs. With ResNet-50 on ImageNet, we also achieve a relative FLOPs reduction of 30%. © 2021 Elsevier B.V.","Machine learning; Network compression; Network pruning","Convolutional neural networks; Digital arithmetic; CNN models; Computational costs; Convolutional neural network; Feature map; Floating point operations; Model pruning; Network compression; Network pruning; Neural-networks; Simple++; Machine learning",,,,,"China Scholarship Council, CSC: 201606220043; Electronic Components and Systems for European Leadership, ECSEL","This work is financially supported by the China Scholarship Council [grant number 201606220043], theFlanders AI research program and the EU ECSEL NextPerception project.","This work is financially supported by the C hina Scholarship Council [grant number 201606220043], the Flanders AI research program and the E U ECSEL NextPerception project.",,,,,,,,,"He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Simonyan, K., Zisserman, A., Very Deep Convolutional Networks for Large-Scale Image Recognition (2014); Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4700-4708; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 580-587; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems, pp. 91-99; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: unified, real-time object detection (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 779-788; Sainath, T.N., Kingsbury, B., Sindhwani, V., Arisoy, E., Ramabhadran, B., Low-rank matrix factorization for deep neural network training with high-dimensional output targets (2013) 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 6655-6659; Li, C., Richard Shi, C., Constrained optimization based low-rank approximation of deep neural networks (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 732-747; Bucilua, C., Caruana, R., Niculescu-Mizil, A., Model compression (2006) Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 535-541; Zhu, X., Gong, S., Knowledge distillation by on-the-fly native ensemble (2018) Advances in Neural Information Processing Systems, pp. 7517-7527; Han, S., Mao, H., Dally, W.J., Deep Compression: Compressing Deep Neural Networks With Pruning, Trained Quantization and Huffman Coding (2015); Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning Filters for Efficient Convnets (2016); Choudhary, T., Mishra, V., Goswami, A., Sarangapani, J., A comprehensive survey on model compression and acceleration (2020) Artif. Intell. Rev., pp. 1-43; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Advances in Neural Information Processing Systems, pp. 1135-1143; Louizos, C., Welling, M., Kingma, D.P., Learning Sparse Neural Networks Through l _ 0 Regularization (2017); Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C., Learning efficient convolutional networks through network slimming (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 2736-2744; He, Y., Liu, P., Wang, Z., Hu, Z., Yang, Y., Filter pruning via geometric median for deep convolutional neural networks acceleration (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4340-4349; Huang, Z., Wang, N., Data-driven sparse structure selection for deep neural networks (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 304-320; Liu, Z., Sun, M., Zhou, T., Huang, G., Darrell, T., Rethinking the Value of Network Pruning (2018); He, Y., Kang, G., Dong, X., Fu, Y., Yang, Y., Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks (2018); Hu, H., Peng, R., Tai, Y.-W., Tang, C.-K., Network Trimming: A Data-Driven Neuron Pruning Approach Towards Efficient Deep Architectures (2016); Yu, R., Li, A., Chen, C.-F., Lai, J.-H., Morariu, V.I., Han, X., Gao, M., Davis, L.S., Nisp: Pruning networks using neuron importance score propagation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9194-9203; LeCun, Y., Denker, J.S., Solla, S.A., Optimal brain damage (1990) Advances in Neural Information Processing Systems, pp. 598-605; Carreira-Perpinán, M.A., Idelbayev, Y., learning-compression” algorithms for neural net pruning (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8532-8541; Ye, X., Yang, J., Dai, P., Accelerating CNN Training by Pruning Activation Gradients (2019); Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Quantized neural networks: training neural networks with low precision weights and activations (2017) J. Mach. Learn. Res., 18 (1), pp. 6869-6898; Wang, D., Zhou, L., Zhang, X., Bai, X., Zhou, J., Exploring Linear Relationship in Feature Map Subspace for Convnets Compression (2018); Luo, J.-H., Wu, J., Neural network pruning with residual-connections and limited-data (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1458-1467; Lin, M., Ji, R., Wang, Y., Zhang, Y., Zhang, B., Tian, Y., Shao, L., Hrank: filter pruning using high-rank feature map (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1529-1538; Luo, J.-H., Wu, J., Lin, W., Thinet: A filter level pruning method for deep neural network compression (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 5058-5066; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning structured sparsity in deep neural networks (2016) Advances in Neural Information Processing Systems, pp. 2074-2082; He, Y., Zhang, X., Sun, J., Channel pruning for accelerating very deep neural networks (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 1389-1397; Yuan, M., Lin, Y., Model selection and estimation in regression with grouped variables (2006) J. R. Stat. Soc.: Ser. B Stat. Methodol., 68 (1), pp. 49-67; Krizhevsky, A., Hinton, G., Learning Multiple Layers of Features from Tiny Images (2009); Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) Int. J. Comput. Vision, 115 (3), pp. 211-252; Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Lerer, A., Automatic Differentiation in Pytorch (2017); Lin, S., Ji, R., Yan, C., Zhang, B., Cao, L., Ye, Q., Huang, F., Doermann, D., Towards optimal structured cnn pruning via generative adversarial learning (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2790-2799; Zhao, C., Ni, B., Zhang, J., Zhao, Q., Zhang, W., Tian, Q., Variational convolutional neural network pruning (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2780-2789; Lin, S., Ji, R., Li, Y., Wu, Y., Huang, F., Zhang, B., Accelerating convolutional networks via global & dynamic filter pruning (2018) IJCAI, pp. 2425-2432; Molchanov, P., Mallya, A., Tyree, S., Frosio, I., Kautz, J., Importance estimation for neural network pruning (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 11264-11272; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? the kitti vision benchmark suite (2012) 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 3354-3361","Xiao, Y.; Department of Telecommunications and Information Processing, St-Pietersnieuwstraat 41, Belgium; email: xiao.yifan@ugent.be",,,"Elsevier B.V.",,,,,18777503,,,,"English","J. Comput. Sci.",Article,"Final","",Scopus,2-s2.0-85117196414
"Chen Z., Wu M., Gao K., Wu J., Ding J., Zeng Z., Li X.","56470052400;56415331800;36443489100;57215128195;57191904975;57194337704;35487931000;","A Novel Ensemble Deep Learning Approach for Sleep-Wake Detection Using Heart Rate Variability and Acceleration",2021,"IEEE Transactions on Emerging Topics in Computational Intelligence","5","5",,"803","812",,6,"10.1109/TETCI.2020.2996943","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086746132&doi=10.1109%2fTETCI.2020.2996943&partnerID=40&md5=92fbedb28a111eb7a906fba0aaebae85","Institute for Infocomm Research, ASTAR, Singapore, 138632, Singapore; Computer School, Liaocheng University, Liaocheng, 252000, China","Chen, Z., Institute for Infocomm Research, ASTAR, Singapore, 138632, Singapore; Wu, M., Institute for Infocomm Research, ASTAR, Singapore, 138632, Singapore; Gao, K., Computer School, Liaocheng University, Liaocheng, 252000, China; Wu, J., Computer School, Liaocheng University, Liaocheng, 252000, China; Ding, J., Computer School, Liaocheng University, Liaocheng, 252000, China; Zeng, Z., Institute for Infocomm Research, ASTAR, Singapore, 138632, Singapore; Li, X., Institute for Infocomm Research, ASTAR, Singapore, 138632, Singapore","Sleep-wake detection is of great importance for the measurement of sleep quality. In this article, a novel ensemble deep learning framework is proposed to detect sleep-wake states based on heart rate variability (HRV) and acceleration. We firstly design a local feature based long short-term memory (LF-LSTM) network to encode temporal dependency and learn features from acceleration data with high sampling frequency. In the meantime, some handcrafted features are extracted from HRV which has a special data format. After that, we develop a unified framework to integrate these two types of features, i.e., the features extracted from HRV and the features learned by LF-LSTM from acceleration, to form a complete feature set. Finally, an efficient ensemble learning scheme is proposed to further boost the performance of sleep-wake classification. A real dataset has been collected to verify the effectiveness of the proposed approach. We also compare with some well-known benchmark approaches for sleep-wake detection. The results demonstrate that the proposed ensemble deep learning method outperforms all the benchmark approaches. © 2017 IEEE.","Ensemble deep learning; Local features; LSTM; Sensor data; Sleep-wake detection","Heart; Learning systems; Long short-term memory; Sleep research; Wakes; Acceleration data; Ensemble learning; Heart rate variability; High sampling frequencies; Learning approach; Learning frameworks; Learning methods; Unified framework; Deep learning",,,,,,,,,,,,,,,,"Wilckens, K.A., Woo, S.G., Kirk, A.R., Erickson, K.I., Wheeler, M.E., Role of sleep continuity and total sleep time in executive function across the adult lifespan (2014) Psychol. Aging, 29 (3), pp. 658-665; Buxton, O.M., Adverse metabolic consequences in humans of prolonged sleep restriction combined with circadian disruption (2012) Sci. Transl. Med, 4 (129). , Art. no. 129ra43; Kushida, C.A., Practice parameters for the indications for polysomnography and related procedures: An update for 2005 (2005) Sleep, 28 (4), pp. 499-523; Supriya, S., Siuly, S., Wang, H., Zhang, Y., EEG sleep stages analysis and classification based on weighed complex network features IEEE Trans. Emerg. Topics Comput. Intell, , to be published; Tilmanne, J., Urbain, J., Kothare, M.V., Wouwer, A.V., Kothare, S.V., Algorithms for sleep-wake identification using actigraphy: A comparative study and new results (2009) J. Sleep Res, 18 (1), pp. 85-98; Van Hees, V.T., Anovel, open accessmethod to assess sleep duration using a wrist-worn accelerometer (2015) PloS One, 10 (11). , Art. no. e0142533; Karlen, W., Mattiussi, C., Floreano, D., Sleep and wake classification with ECG and respiratory effort signals (2009) IEEE Trans. Biomed. Circuits Syst, 3 (2), pp. 71-78. , Apr; Adnane, M., Jiang, Z., Yan, Z., Sleep-wake stages classification and sleep efficiency estimation using single-lead electrocardiogram (2012) Expert Syst. Appl, 39 (1), pp. 1401-1413; Devot, S., Dratwa, R., Naujokat, E., Sleep/wake detection based on cardiorespiratory signals and actigraphy (2010) Proc IEEE 32th Annu. Int. Conf. Eng. Med. Biol. Soc, pp. 5089-5092; Long, X., Fonseca, P., Foussier, J., Haakma, R., Aarts, R.M., Sleep and wake classification with actigraphy and respiratory effort using dynamic warping (2014) IEEE J. Biomed. Health Informat, 18 (4), pp. 1272-1284. , Jul; Willemen, T., An evaluation of cardiorespiratory and movement featureswith respect to sleep-stage classification (2014) IEEE J. Biomed. Health Informat, 18 (2), pp. 661-669. , Mar; Pouyan, M.B., Nourani, M., Pompeo, M., Sleep state classification using pressure sensor mats (2015) Proc IEEE 37th Annu. Int. Conf. Eng. Med. Biol. Soc, pp. 1207-1210; Fonseca, P., Den Teuling, N., Long, X., Aarts, R.M., Cardiorespiratory sleep stage detection using conditional random fields (2017) IEEE J. Biomed. Health Informat, 21 (4), pp. 956-966. , Jul; Miotto, R., Wang, F., Wang, S., Jiang, X., Dudley, J.T., Deep learning for healthcare: Review, opportunities and challenges (2018) Briefings Bioinformatics, 19 (6), pp. 1236-1246; Chen, Q., A survey on an emerging area: Deep learning for smart city data (2019) IEEE Trans. Emerg. Topics Comput. Intell, 3 (5), pp. 392-410. , Oct; Granovsky, L., Shalev, G., Yacovzada, N., Frank, Y., Fine, S., (2018) Actigraphy-based Sleep/wake Pattern Detection Using Convolutional Neural Networks, , arXiv 1802 07945; Chen, W., Multimodal ambulatory sleep detection (2017) Proc. IEEEEMBS Int. Conf. Biomed. Health Informat, 2017, pp. 465-468; Chen, Z., A deep learning approach for sleep-wake detection from HRV and accelerometer data (2019) Proc IEEE EMBS Int. Conf. Biomed. Health Informat, pp. 1-4; Chen, Y., Automatic sleep stage classification based on subthalamic local field potentials (2019) IEEE Trans. Neural Syst. Rehabil. Eng, 27 (2), pp. 118-128. , Feb; Sokolovsky, M., Guerrero, F., Paisarnsrisomsuk, S., Ruiz, C., Alvarez, S.A., Deep learning for automated feature discovery and classification of sleep stages IEEE/ ACM Trans. Comput. Biol. Bioinformatics, , to be published; Zhang, Y., Sleep stage classification using bidirectional LSTM in wearable multi-sensor systems (2019) Proc IEEE Conf. Comput. Commun. Workshops, pp. 443-448; Stein, P.K., Pu, Y., Heart rate variability, sleep and sleep disorders (2012) Sleep Med. Rev, 16 (1), pp. 47-66; Ebrahimi, F., Setarehdan, S.-K., Ayala-Moyeda, J., Nazeran, H., Automatic sleep staging using empirical mode decomposition, discrete wavelet transform, time-domain, and nonlinear dynamics features of heart rate variability signals (2013) Comput. Methods Programs Biomedicine, 112 (1), pp. 47-57; Ameen, M.S., Cheung, L.M., Hauser, T., Hahn, M.A., Schabus, M., About the accuracy and problems of consumer devices in the assessment of sleep (2019) Sensors, 19 (19), p. 4160; Shambroom, J.R., Fábregas, S.E., Johnstone, J., Validation of an automated wireless system to monitor sleep in healthy adults (2012) J. Sleep Res, 21 (2), pp. 221-230; Hochreiter, S., Schmidhuber, J., Long short-Term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Wang, S., Jiang, J., Learning natural language inference with LSTM (2016) Proc. 2016 Conf. North Amer. Chapter Assoc. Comput. Linguistics: Human Lang. Technologies, pp. 1442-1451; Chen, Z., Zhao, R., Zhu, Q., Masood, M.K., Soh, Y.C., Mao, K., Building occupancy estimation with environmental sensors via CDBLSTM (2017) IEEE Trans. Ind. Electron, 64 (12), pp. 9549-9559. , Dec; Chen, Z., Zhang, L., Jiang, C., Cao, Z., Cui, W., WiFi CSI based passive human activity recognition using attention based BLSTM (2019) IEEE Trans. Mobile Comput, 18 (11), pp. 2714-2724. , Nov; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Wu, M., Cao, H., Nguyen, H.-L., Surmacz, K., Hargrove, C., Modeling perceived stress viaHRVand accelerometer sensor streams (2015) Proc IEEE 37th Annu. Int. Conf. Eng. Med. Biol. Soc, pp. 1625-1628; Khaled, A.S., Owis, M.I., Mohamed, A.S., Employing time-domain methods and poincaré plot of heart rate variability signals to detect congestive heart failure (2006) BIME J, 6 (1), pp. 35-41; Penzel, T., Kantelhardt, J.W., Grote, L., Peter, J.-H., Bunde, A., Comparison of detrended fluctuation analysis and spectral analysis for heart rate variability in sleep and sleep apnea (2003) IEEE Trans. Biomed. Eng, 50 (10), pp. 1143-1151. , Oct; Zhou, Z.-H., (2012) Ensemble Methods: Foundations and Algorithms, , London U.K Chapman and Hall; Qiu, X., Zhang, L., Ren, Y., Suganthan, P.N., Amaratunga, G., Ensemble deep learning for regression and time series forecasting (2014) Proc IEEE Symp. Comput. Intell. Ensemble Learn, pp. 1-6; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv 1412.6980; Tang, Y., Zhang, Y.-Q., Chawla, N.V., Krasser, S., SVMs modeling for highly imbalanced classification (2009) IEEE Trans. Syst., Man, Cybern., Part B, 39 (1), pp. 281-288. , Feb; Chawla, N.V., Bowyer, K.W., Hall, L.O., Kegelmeyer, W.P., Smote: Synthetic minority over-sampling technique (2002) J. Artif. Intell. Res, 16, pp. 321-357; Vaswani, A., Attention is all you need (2017) Proc. Adv. Neural Inf. Process. Syst, pp. 5998-6008","Wu, M.; Institute for Infocomm Research, Singapore; email: wumin@i2r.a-star.edu.sg",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,2471285X,,,,"English","IEEE Trans. Emerging Topics Comp. Intell.",Article,"Final","",Scopus,2-s2.0-85086746132
"Pérez S.N.C., Borz S.A.","57261519200;55414110100;","Improving the event-based classification accuracy in pit-drilling operations: An application by neural networks and median filtering of the acceleration input signal data",2021,"Sensors","21","18","6288","","",,,"10.3390/s21186288","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115058920&doi=10.3390%2fs21186288&partnerID=40&md5=ba4797d67e819b86a8f0dcc6cfccc4fb","Department of Forest Engineering, Forest Management Planning and Terrestrial Measurements, Faculty of Silviculture and Forest Engineering, Transilvania University of Brasov, Şirul Beethoven 1, Brasov, 500123, Romania","Pérez, S.N.C., Department of Forest Engineering, Forest Management Planning and Terrestrial Measurements, Faculty of Silviculture and Forest Engineering, Transilvania University of Brasov, Şirul Beethoven 1, Brasov, 500123, Romania; Borz, S.A., Department of Forest Engineering, Forest Management Planning and Terrestrial Measurements, Faculty of Silviculture and Forest Engineering, Transilvania University of Brasov, Şirul Beethoven 1, Brasov, 500123, Romania","Forestry is a complex economic sector which is relying on resource and process monitoring data. Most of the forest operations such as planting and harvesting are supported by the use of tools and machines, and their monitoring has been traditionally done by the use of pen-and-paper time studies. Nevertheless, modern data collection and analysis methods involving different kinds of platforms and machine learning techniques have been studied lately with the aim of easing the data management process. By their outcomes, improvements are still needed to reach a close to 100% activity recognition, which may depend on several factors such as the type of monitored process and the characteristics of the signals used as inputs. In this paper, we test, thought a case study on mechanized pit-drilling operations, the potential of digital signal processing techniques combined with Artificial Neural Networks (ANNs) in improving the event-based classification accuracy in the time domain. Signal processing was implemented by the means of median filtering of triaxial accelerometer data (window sizes of 3, 5, and up to 21 observations collected at 1 Hz) while the ANNs were subjected to the regularization hyperparameter’s tunning. An acceleration signal processed by a median filter with a window size of 3 observations and fed into an ANN set to learn and generalize by a regularization parameter of α = 0.01 has been found to be the best strategy in improving the event-based classification accuracy (improvements of 1 to 8% in classification accuracy depending on the type of event in question). Improvement of classification accuracy by signal filtering and ANN tuning may depend largely on the type of monitored process and its outcomes in terms of event duration; therefore, other monitoring applications may need particular designs of signal processing and ANN tuning. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Acceleration signal; Artificial neural networks; Classification accuracy; Forestry; Improvement; Median filtering; Pit-drilling operations; Planting; Regularization parameter; Tunning","Digital signal processing; Drilling machines (machine tools); Forestry; Infill drilling; Information management; Learning systems; Median filters; Process monitoring; Time domain analysis; Tuning; Acceleration signals; Activity recognition; Classification accuracy; Digital signal processing techniques; Machine learning techniques; Monitoring applications; Regularization parameters; Triaxial accelerometer; Neural networks; acceleration; physiologic monitoring; signal processing; Acceleration; Monitoring, Physiologic; Neural Networks, Computer; Signal Processing, Computer-Assisted",,,,,"Universitatea Transilvania din Brasov","Funding: This research was funded by Transilvania University of Brasov, through the internal competition of grants “Proiectul meu de diplomă”. The APC was funded by Transilvania University of Brasov.",,,,,,,,,,"Picchio, R., Proto, A.R., Civitarese, V., Di Marzio, N., Latterini, F., Recent contributions of some fields of the electronics in development of forest operations technologies (2019) Electronics, 8, p. 1465. , [CrossRef]; Müller, F., Jaeger, D., Hanewinkel, M., Digitization in wood supply—A review of how Industry 4.0 will change the forest value chain (2019) Comput. Electron. Agric, 162, pp. 206-218. , [CrossRef]; https://web.fpinnovations.ca/forest-operations-solutions-to-help-the-canadian-forest-industry/forestry-4-0/, FPI Innovations, Forestry 4.0. (accessed on 31 July 2021); Smart Forwarder for Sustainable and Efficient Forest Operation and Management, , https://www.forwarder2020-project.eu/, Forwarder2020, (accessed on 31 July 2021); Knowledge and Technologies for Effective Wood Procurement, , http://www.tech4effect.eu/, Tech4Effect, (accessed on 31 July 2021); Rauch, P., Borz, S.A., Reengineering the Romanian Timber Supply Chain from a Process Management Perspective (2020) Croat. J. For. Eng, 4, pp. 85-94. , [CrossRef]; Romania—Forest Sector Rapid Assessment, the World Bank, p. 59. , https://openknowledge.worldbank.org/bitstream/handle/10986/17570/842620WP0P14660Box0382136B00PUBLIC0.pdf?sequence=1&isAllowed=y, Washington DC, (ac-cessed on 2 September 2021); Cheţa, M., Marcu, M.V., Borz, S.A., Effect of training parameters on the ability of artificial neural networks to learn: A simulation on accelerometer data for task recognition in motor-manual felling and processing (2020) Bull. Transilv. Univ. Bras. Ser. II For. Wood Ind. Agric. Food Eng, 131, pp. 19-36. , [CrossRef]; Cheţa, M., Marcu, M.V., Iordache, E., Borz, S.A., Testing the capability of low-cost tools and artificial intelligence techniques to automatically detect operations done by a small-sized manually driven bandsaw (2020) Forests, 11, p. 739. , [CrossRef]; Borz, S.A., Păun, M., Integrating offline object tracking, signal processing and artificial intelligence to classify relevant events in sawmilling operations (2020) Forests, 11, p. 1333. , [CrossRef]; Keefe, R.F., Zimbelman, E.G., Wempe, A.M., Use of smartphone sensors to quantify the productive cycle elements of hand fallers on industrial cable logging operations (2019) Int. J. For. Eng, 30, pp. 132-143. , [CrossRef]; Zimbelman, E.G., Keefe, R.F., Development and validation of smartwatch-based activity recognition models for rigging crew workers on cable logging operations (2021) PLoS ONE, 16, p. e0250624. , [CrossRef]; Borz, S., Development of a Modality-Invariant Multi-Layer Perceptron to Predict Operational Events in Motor-Manual Willow Felling Operations (2021) Forests, 12, p. 406. , [CrossRef]; Moskalik, T., Borz, S.A., Dvorák, J., Ferencik, M., Glushkov, S., Muiste, P., Lazdinš, A., Styranivsky, O., Timber harvesting methods in Eastern European countries: A review (2017) Croat. J. For. Eng, 38, pp. 231-241; Lundbäck, M., Häggström, C., Nordfjell, T., Worldwide trends in methods for harvesting and extracting industrial roundwood (2021) Int. J. For. Eng, , published online. [CrossRef]; Spinelli, R., Magagnotti, N., Visser, R., O’Neal, B., A survey of skidder fleet of Central, Eastern and Southern Europe (2021) Eur. J. For. Res, , published online. [CrossRef]; Acuna, M., Bigot, M., Guerra, S., Hartsough, B., Kanzian, C., Kärhä, K., Lindroos, O., Spinelli, R., (2012) Good Practice Guidelines for Biomass Production Studies, pp. 1-51. , CNR IVALSA Sesto Fiorentino (National Research Council of Italy—Trees and Timber Institute): Sesto Fiorentino, Italy, ISBN 978-88-901660-4-4; McDonald, T.P., Fulton, J.P., Automated time study of skidders using global positioning system data (2005) Comput. Electron. Agric, 48, pp. 19-37. , [CrossRef]; Mamedov, O., Tumanyan, Y., Ishchenko-Padukova, O., Movchan, I., Sustainable economic development and post-economy of artificial intelligence (2018) Entrep. Sustain. Issues, 6, p. 1028. , [CrossRef]; Ramesh, A., Kambhampati, C., Monson, J., Drew, P., Artificial intelligence in medicine (2004) Ann. R. Col. Surg, 86, p. 334. , [CrossRef]; Holzinger, A., Langs, G., Denk, H., Zatloukal, K., Müller, H., Causability and explainability of artificial intelligence in medicine (2019) Wires. Data Min. Knowl, 9, p. e1312. , [CrossRef]; Mintz, Y., Brodie, R., Introduction to artificial intelligence in medicine (2019) Minim. Invasiv. Ther, 28, pp. 73-81. , [CrossRef]; Amisha, P.M., Pathania, M., Rathaur, V.K., Overview of artificial intelligence in medicine (2019) J. Fam. Med. Prim. Care, 8, p. 2328. , [CrossRef]; Guzman, A., Lewis, S., Artificial intelligence and communication: A human–machine communication research agenda (2020) New Media Soc, 22, pp. 70-86. , [CrossRef]; Xu, G., Mu, Y., Liu, J., Inclusion of artificial intelligence in communication networks and services (2017) ITU J. ICT Discov. Spec, 1, pp. 1-6; Gunkel, D., Communication and artificial intelligence: Opportunities and challenges for the 21st century (2021) Communication +, 1 (1), pp. 1-25. , [CrossRef]; Wenger, E., (2014) Artificial Intelligence and Tutoring Systems: Computational and Cognitive Approaches to the Communication of Knowledge, , Morgan Kaufmann: San Francisco, CA, USA; Huang, M., Rust, R., A strategic framework for artificial intelligence in marketing (2021) J. Acad. Market. Sci, 49, pp. 30-50. , [CrossRef]; Dimitrieska, S., Stankovska, A., Efremova, T., Artificial intelligence and marketing (2018) Entrepreneurship, 6, pp. 298-304; De Bruyn, A., Viswanathan, V., Beh, Y.S., Brock, J., Wangenheim, F., Artificial intelligence and marketing: Pitfalls and opportunities (2020) J. Interact. Mark, 51, pp. 91-105. , [CrossRef]; Bannerjee, G., Sarkar, U., Das, S., Ghosh, I., Artificial intelligence in agriculture: A literature survey (2018) Int. J. Sci. Res. Comput. Sci. Appl. Manag. Stud, 7, pp. 1-6; Smith, M., Getting value from artificial intelligence in agriculture (2018) Anim. Prod. Sci, 60, pp. 46-54. , [CrossRef]; Popa, C., Adoption of artificial intelligence in agriculture (2018) Bulletin of University of Agricultural Sciences and Veterinary Medicine Cluj-Napoca. Agriculture, 68, pp. 284-293; Kourtz, P., Artificial intelligence: A new tool for forest management (1990) Can. J. Forest Res, 20, pp. 428-437. , [CrossRef]; Proto, A., Sperandio, G., Costa, C., Maesano, M., Antonucci, F., Macrì, G., Scarascia, G., Zimbalatti, G., A three-step neural network artificial intelligence modeling approach for time, productivity and costs prediction: A case study in Italian forestry (2020) Croat. J. For. Eng, 41, pp. 35-47. , [CrossRef]; Santos, A., Santos, R., Silva, M., Figueiredo, E., Sales, C., Costa, J.C.W.A., A global expectation-maximization approach based on memetic algorithm for vibration-based structural damage detection (2017) IEEE Trans. Instrum. Meas, 66, pp. 661-670. , [CrossRef]; Favarelli, E., Giorgetti, A., Machine learning for automatic processing of modal analysis in damage detection of bridges (2021) IEEE Trans. Instrum. Meas, 70, p. 2504013. , [CrossRef]; Zonzini, F., Giorlami, A., De Marchi, L., Marzani, A., Brunelli, D., Cluster-based vibration analysis of structures with GSP (2021) IEEE Trans. Ind. Electron, 68, pp. 3465-3474. , [CrossRef]; Björheden, R., Apel, K., Shiba, M., Thompson, M., (1995) IUFRO Forest Work Study Nomenclature, p. 16. , Swedish University of Agricultural Science, Department of Operational Efficiency: Grapenberg, Sweden; Neal, C.G., Gary, L.W., A theoretical analysis of the properties of median filters (1981) IEEE Trans. Acoust. Speech, 29, pp. 1136-1141; Leeb, S.B., Shaw, S.R., Applications of real-time median filtering with fast digital and analog sorters (1997) IEEE/ASME Trans. Mechatron, 2, pp. 136-143. , [CrossRef]; Demsar, J., Curk, T., Erjavec, A., Gorup, C., Hocevar, T., Milutinovic, M., Mozina, M., Staric, A., Orange: Data Mining Toolbox in Python (2013) J. Mach. Learn. Res, 14, pp. 2349-2353; Goodfellow, J., Bengio, Y., Courville, A., (2016) Deep Learning, , https://www.deeplearningbook.org/, MIT Press: Cambridge, MA, USA, (accessed on 17 February 2021); Maas, A.L., Hannun, A.Y., Ng, A.Y., Rectifier nonlinearities improve neural network acoustic models (2013) Proceedings of the 30th International Conference on Machine Learning, ICML 2013, , Atlanta, GA, USA, 16–21 June; Nair, V., Hinton, G.E., Rectified linear units improve restricted Boltzmann machines (2010) Proceedings of the 27th International Conference on Machine Learning (ICML 2010), , Haifa, Israel, 21–24 June; Kingma, D.P., Ba, J.L., ADAM: A method for stochastic optimization (2015) Proceedings of the 3rd International Conference on Learning Representations, ICLR 2015, , San Diego, CA, USA, 7–9 May; Kamilaris, A., Prenafeta-Boldu, F.X., Deep learning in agriculture: A survey (2018) Comput. Electron. Agric, 147, pp. 70-90. , [CrossRef]; Fawcett, T., An introduction to ROC analysis (2006) Pattern Recogn. Lett, 27, pp. 861-874. , [CrossRef]; Agatonovic-Kustrin, S., Beresford, R., Basic concepts of artificial neural network (ANN) modeling and its application in pharma-ceutical research (2000) J. Pharmaceut. Biomed, 22, pp. 717-727. , [CrossRef]; Chen, K., Zhang, D., Yao, L., Guo, B., Yu, Z., Liu, Y., Deep learning for sensor-based human activity recognition: Overview, challenges and opportunities (2018) J. ACM, 37, p. 111. , [CrossRef]","Borz, S.A.; Department of Forest Engineering, Şirul Beethoven 1, Romania; email: stelian.borz@unitbv.ro",,,"MDPI",,,,,14248220,,,"34577496","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85115058920
"Belabed T., Ramos Gomes da Silva V., Quenon A., Valderamma C., Souani C.","57202465438;57210457517;57207203584;57250718700;6506039838;","A novel automate python edge-to-edge: From automated generation on cloud to user application deployment on edge of deep neural networks for low power iot systems FPGA-based acceleration",2021,"Sensors","21","18","6050","","",,,"10.3390/s21186050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114483971&doi=10.3390%2fs21186050&partnerID=40&md5=c6dbb2fa25d9a69da76479298c9a2305","Electronics and Microelectronics Unit (SEMi), University of Mons, Mons, 7000, Belgium; Ecole Nationale d’Ingénieurs de Sousse, Université de Sousse, Sousse, 4000, Tunisia; Laboratoire de Microélectronique et Instrumentation, Faculté des Sciences de Monastir, Université de Monastir, Monastir, 5019, Tunisia; Institut Supérieur des Sciences Appliquées et de Technologie de Sousse, Université de Sousse, Sousse, 4003, Tunisia","Belabed, T., Electronics and Microelectronics Unit (SEMi), University of Mons, Mons, 7000, Belgium, Ecole Nationale d’Ingénieurs de Sousse, Université de Sousse, Sousse, 4000, Tunisia, Laboratoire de Microélectronique et Instrumentation, Faculté des Sciences de Monastir, Université de Monastir, Monastir, 5019, Tunisia; Ramos Gomes da Silva, V., Electronics and Microelectronics Unit (SEMi), University of Mons, Mons, 7000, Belgium; Quenon, A., Electronics and Microelectronics Unit (SEMi), University of Mons, Mons, 7000, Belgium; Valderamma, C., Electronics and Microelectronics Unit (SEMi), University of Mons, Mons, 7000, Belgium; Souani, C., Institut Supérieur des Sciences Appliquées et de Technologie de Sousse, Université de Sousse, Sousse, 4003, Tunisia","Deep Neural Networks (DNNs) deployment for IoT Edge applications requires strong skills in hardware and software. In this paper, a novel design framework fully automated for Edge applications is proposed to perform such a deployment on System-on-Chips. Based on a high-level Python interface that mimics the leading Deep Learning software frameworks, it offers an easy way to implement a hardware-accelerated DNN on an FPGA. To do this, our design methodology covers the three main phases: (a) customization: where the user specifies the optimizations needed on each DNN layer, (b) generation: the framework generates on the Cloud the necessary binaries for both FPGA and software parts, and (c) deployment: the SoC on the Edge receives the resulting files serving to program the FPGA and related Python libraries for user applications. Among the study cases, an optimized DNN for the MNIST database can speed up more than 60× a software version on the ZYNQ 7020 SoC and still consume less than 0.43 W. A comparison with the state-of-the-art frameworks demonstrates that our methodology offers the best trade-off between throughput, power consumption, and system cost. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Cloud computing; Deep neural networks (DNNs); Edge computing; Field programmable gate array (FPGA); Hardware acceleration; High-level synthesis (HLS) tools; Internet of things (IoT); Low-cost; Low-power; Python framework","Application programs; Deep learning; Deep neural networks; Economic and social effects; Field programmable gate arrays (FPGA); High level languages; Internet of things; Low power electronics; Neural networks; System-on-chip; Application deployment; Automated generation; Design Methodology; FPGA-based accelerations; Hardware and software; Hardware-accelerated; Learning software; Software versions; Integrated circuit design; acceleration; computer; software; Acceleration; Computers; Neural Networks, Computer; Software",,,,,,,,,,,,,,,,"Balakrishnan, T., Chui, M., Hall, B., Henke, N., The state of AI in 2020, , https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/global-survey-the-state-of-ai-in-2020, (accessed on 18 August 2021); Dahlqvist, F., Patel, M., Rajko, A., Shulman, J., Growing opportunities in the Internet of Things, , https://www.mckinsey.com/industries/private-equity-and-principal-investors/our-insights/growing-opportunities-in-the-internet-of-things, (accessed on 18 August 2021); Hamet, P., Tremblay, J., Artificial intelligence in medicine (2017) Metab. Clin. Exp, 69, pp. S36-S40; Li, B.H., Hou, B.C., Yu, W.T., Lu, X.B., Yang, C.W., Applications of artificial intelligence in intelligent manufacturing: A review (2017) Front. Inf. Technol. Electron. Eng, 18, pp. 86-96; Capra, M., Peloso, R., Masera, G., Roch, M.R., Martina, M., Edge computing: A survey on the hardware requirements in the Internet of Things world (2019) Future Internet, 11, p. 100; Wang, F., Zhang, M., Wang, X., Ma, X., Liu, J., Deep Learning for Edge Computing Applications: A State-of-the-Art Survey (2020) IEEE Access, 8, pp. 58322-58336; Lammie, C., Olsen, A., Carrick, T., Rahimi Azghadi, M., Low-Power and High-Speed Deep FPGA Inference Engines for Weed Classification at the Edge (2019) IEEE Access, 7, pp. 51171-51184; Hao, C., Chen, D., Deep neural network model and FPGA accelerator co-design: Opportunities and challenges (2018) Proceedings of the 2018 14th IEEE International Conference on Solid-State and Integrated Circuit Technology (ICSICT), pp. 1-4. , Qingdao, China, 31 October–3 November; Guo, K., Han, S., Yao, S., Wang, Y., Xie, Y., Yang, H., Software-Hardware Codesign for Efficient Neural Network Acceleration (2017) IEEE Micro, 37, pp. 18-25; Quenon, A., Ramos Gomes Da Silva, V., Towards higher-level synthesis and co-design with python (2021) Proceedings of the Workshop on Languages, Tools, and Techniques for Accelerator Design (LATTE ’21), , ACM: New York, NY, USA; Belabed, T., Coutinho, M.G.F., Fernandes, M.A.C., Sakuyama, C.V., Souani, C., User Driven FPGA-Based Design Automated Framework of Deep Neural Networks for Low-Power Low-Cost Edge Computing (2021) IEEE Access, 9, pp. 89162-89180; Nurvitadhi, E., Sheffield, D., Sim, J., Mishra, A., Venkatesh, G., Marr, D., Accelerating binarized neural networks: Comparison of FPGA, CPU, GPU, and ASIC Proceedings of the 2016 International Conference on Field-Programmable Technology (FPT), pp. 77-84. , Xi’an, China, 7–9 December 2016; Nurvitadhi, E., Sim, J., Sheffield, D., Mishra, A., Krishnan, S., Marr, D., Accelerating recurrent neural networks in analytics servers: Comparison of FPGA, CPU, GPU, and ASIC Proceedings of the 2016 26th International Conference on Field Programmable Logic and Applications (FPL), pp. 1-4. , Lausanne, Switzerland, 29 August–2 September 2016; Nurvitadhi, E., Subhaschandra, S., Boudoukh, G., Venkatesh, G., Sim, J., Marr, D., Huang, R., Srivatsan, K., Can FPGAs beat GPUs in accelerating next-generation deep neural networks? (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays—FPGA ’17, pp. 5-14. , Monterey, CA, USA, 22–24 February ACM Press: New York, NY, USA, 2017; Venieris, S.I., Bouganis, C.S., fpgaConvNet: A framework for mapping convolutional neural networks on FPGAs Proceedings of the 2016 IEEE 24th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), pp. 40-47. , Washington, DC, USA, 1–3 May 2016; Wang, Y., Xu, J., Han, Y., Li, H., Li, X., DeepBurning: Automatic generation of FPGA-based learning accelerators for the Neural Network family (2016) Proceedings of the 53rd Annual Design Automation Conference, pp. 1-6. , Austin, TX, USA, 5–9 June ACM: New York, NY, USA, 2016; Elnawawy, M., Farhan, A., Nabulsi, A.A., Al-Ali, A., Sagahyroon, A., Role of FPGA in internet of things applications Proceedings of the 2019 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT), pp. 1-6. , Ajman, United Arab Emirates, 10–12 December 2019; Chen, Y., Zheng, B., Zhang, Z., Wang, Q., Shen, C., Zhang, Q., Deep Learning on Mobile and Embedded Devices: State-of-the-art, Challenges, and Future Directions (2020) ACM Comput. Surv, 53, pp. 1-37; Wang, C., Gong, L., Yu, Q., Li, X., Xie, Y., Zhou, X., DLAU: A Scalable Deep Learning Accelerator Unit on FPGA (2016) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst, 36, p. 1; Maria, J., Amaro, J., Falcao, G., Alexandre, L.A., Stacked Autoencoders Using Low-Power Accelerated Architectures for Object Recognition in Autonomous Systems (2016) Neural Process. Lett, 43, pp. 445-458; Coutinho, M.G.F., Torquato, M.F., Fernandes, M.A.C., Deep Neural Network Hardware Implementation Based on Stacked Sparse Autoencoder (2019) IEEE Access, 7, pp. 40674-40694; Mouselinos, S., Leon, V., Xydis, S., Soudris, D., Pekmestzi, K., TF2FPGA: A framework for projecting and accelerating tensorflow CNNs on FPGA platforms Proceedings of the 2019 8th International Conference on Modern Circuits and Systems Technologies (MOCAST), pp. 1-4. , Thessaloniki, Greece, 13–15 May 2019; Mousouliotis, P.G., Petrou, L.P., CNN-Grinder: From Algorithmic to High-Level Synthesis descriptions of CNNs for Low-end-low-cost FPGA SoCs (2020) Microprocess. Microsyst, 73, p. 102990; Rivera-Acosta, M., Ortega-Cisneros, S., Rivera, J., Automatic Tool for Fast Generation of Custom Convolutional Neural Networks Accelerators for FPGA (2019) Electronics, 8, p. 641; Mazouz, A., Bridges, C.P., Automated offline design-space exploration and online design reconfiguration for CNNs Proceedings of the 2020 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS), pp. 1-9. , Bari, Italy, 27–29 May 2020; PYNQ PYTHON PRODUCTIVITY: Development Boards, , http://www.pynq.io/board.html, Xilinx. (accessed on 18 August 2021); PYNQ Libraries, , https://pynq.readthedocs.io/en/v2.6.1/pynq_libraries.html, Xilinx. (accessed on 18 August 2021); (2017) Vivado AXI Reference Guide, v4.0, , Xilinx. Technical Report; Xilinx, Inc.: San Jose, CA, USA; (2020) Introduction to AMBA AXI4, , Arm. Technical Report 0101; Arm Limited: Cambridge, UK; Kung, H.T., Leiserson, C.E., Systolic arrays (for VLSI) (1978) Sparse Matrix Proceedings, pp. 256-282. , Duff, I.S., Stewart, G.W., Eds.; Society for Industrial & Applied Mathematics: Philadelphia, PA, USA; Crockett, L.H., Elliot, R.A., Enderwitz, M.A., Stewart, R.W., (2014) The Zynq Book: Embedded Processing with the ARM® Cortex®-A9 on the Xilinx® Zynq®-7000 All Programmable SoC, p. 460. , Strathclyde Academic Media: Glasgow, Scotland, UK; (2019) SDSoC Environment User Guide, , Xilinx. Technical Report; Xilinx, Inc.: San Jose, CA, USA; LeCun, Y., Cortes, C., Burges, C.J., THE MNIST DATABASE of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/, (accessed on 18 August 2021); PYNQ: Python Productivity, , http://www.pynq.io/, Xilinx. (accessed on 18 August 2021); Garola, A.R., Manduchi, G., Gottardo, M., Cavazzana, R., Recchia, M., Taliercio, C., Luchetta, A., A Zynq-Based Flexible ADC Architecture Combining Real-Time Data Streaming and Transient Recording (2021) IEEE Trans. Nucl. Sci, 68, pp. 245-249; Kowalczyk, M., Ciarach, P., Przewlocka-Rus, D., Szolc, H., Kryjak, T., Real-Time FPGA Implementation of Parallel Connected Component Labelling for a 4K Video Stream (2021) J. Signal Process. Syst, 93, pp. 481-498; Krishnamoorthy, R., Krishnan, K., Chokkalingam, B., Padmanaban, S., Leonowicz, Z., Holm-Nielsen, J.B., Mitolo, M., Systematic Approach for State-of-the-Art Architectures and System-on-Chip Selection for Heterogeneous IoT Applications (2021) IEEE Access, 9, pp. 25594-25622; Yvanoff-Frenchin, C., Ramos, V., Belabed, T., Valderrama, C., Edge Computing Robot Interface for Automatic Elderly Mental Health Care Based on Voice (2020) Electronics, 9, p. 419; Farhat, W., Sghaier, S., Faiedh, H., Souani, C., Design of efficient embedded system for road sign recognition (2019) J. Ambient Intell. Humaniz. Comput, 10, pp. 491-507; https://www.digikey.com/, Digikey. (accessed on 18 August 2021); PYNQ: Overlay Design Methodology, , https://pynq.readthedocs.io/en/latest/overlay_design_methodology.html, Xilinx. (accessed on 18 August 2021); Hassan, N., Gillani, S., Ahmed, E., Yaqoob, I., Imran, M., The Role of Edge Computing in Internet of Things (2018) IEEE Commun. Mag, 56, pp. 110-115","Belabed, T.; Electronics and Microelectronics Unit (SEMi), Belgium; email: tarek.belabed@umons.ac.be",,,"MDPI",,,,,14248220,,,"34577258","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85114483971
"Kim Y., Li S., Yadav N., Choi K.K.","57193073016;56645088000;56007545200;23975486700;","A novel ultra-low power 8t sram-based compute-in-memory design for binary neural networks",2021,"Electronics (Switzerland)","10","17","2181","","",,,"10.3390/electronics10172181","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114286260&doi=10.3390%2felectronics10172181&partnerID=40&md5=817646a406d470aff9e238142bbde096","DA-Lab, Department of Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Chicago, IL  60616, United States","Kim, Y., DA-Lab, Department of Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Chicago, IL  60616, United States; Li, S., DA-Lab, Department of Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Chicago, IL  60616, United States; Yadav, N., DA-Lab, Department of Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Chicago, IL  60616, United States; Choi, K.K., DA-Lab, Department of Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Chicago, IL  60616, United States","We propose a novel ultra-low-power, voltage-based compute-in-memory (CIM) design with a new single-ended 8T SRAM bit cell structure. Since the proposed SRAM bit cell uses a single bitline for CIM calculation with decoupled read and write operations, it supports a much higher energy efficiency. In addition, to separate read and write operations, the stack structure of the read unit minimizes leakage power consumption. Moreover, the proposed bit cell structure provides better read and write stability due to the isolated read path, write path and greater pull-up ratio. Compared to the state-of-the-art SRAM-CIM, our proposed SRAM-CIM does not require extra transistors for CIM vector-matrix multiplication. We implemented a 16 k (128 × 128) bit cell array for the computation of 128× neurons, and used 64× binary inputs (0 or 1) and 64 × 128 binary weights (−1 or +1) values for the binary neural networks (BNNs). Each row of the bit cell array corresponding to a single neuron consists of a total of 128 cells, 64× cells for dot-product and 64× replicas cells for ADC reference. Additionally, 64× replica cells consist of 32× cells for ADC reference and 32× cells for offset calibration. We used a row-by-row ADC for the quantized outputs of each neuron, which supports 1–7 bits of output for each neuron. The ADC uses the sweeping method using 32× duplicate bit cells, and the sweep cycle is set to 2N−1 + 1, where N is the number of output bits. The simulation is performed at room temperature (27◦C) using 45 nm technology via Synopsys Hspice, and all transistors in bitcells use the minimum size considering the area, power, and speed. The proposed SRAM-CIM has reduced power consumption for vector-matrix multiplication by 99.96% compared to the existing state-of-the-art SRAM-CIM. Furthermore, because of the decoupled reading unit from an internal node of latch, there is no feedback from the reading unit, with read static noise, and margin-free results. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","AI; Binary neural networks; BNN; CIM; Compute-in-memory; Machine-learning-based platform technology and application; SRAM; SRAM-CIM",,,,,,"Ministry of Trade, Industry and Energy, MOTIE; Korea Evaluation Institute of Industrial Technology, KEIT: 10083639","This work is supported by the Industrial Core Technology Development Program of MOTIE/KEIT, KOREA. (#10083639, Development of Camera-based Real-time Artificial Intelligence System for Detecting Driving Environment & Recognizing Objects on Road Simultaneously).Acknowledgments: We thank our colleagues from KETI and KEIT who provided insight and exper-tise that greatly assisted the research and greatly improved the manuscript.",,,,,,,,,,"Deng, L., Li, G., Han, S., Shi, L., Xie, Y., Model Compression and Hardware Acceleration for Neural Networks: A Comprehensive Survey (2020) Proc. IEEE, 108, pp. 485-532. , [CrossRef]; Mühlroth, C., Grottke, M., Artificial Intelligence in Innovation: How to Spot Emerging Trends and Technologies (2020) IEEE Trans. Eng. Manag, pp. 1-18. , [CrossRef]; Biswas, A., Chandrakasan, A., Conv-RAM: An energy-efficient SRAM with embedded convolution computation for low-power CNN-based machine learning applications Proceedings of the 2018 IEEE International Solid—State Circuits Conference— (ISSCC), pp. 488-490. , San Francisco, CA, USA, 11–15 February 2018; Jiang, Z., Yin, S., Seok, M., Seo, J.S., XNOR-SRAM: In-Memory Computing SRAM Macro for Binary/Ternary Deep Neural Networks (2020) IEEE J. Solid-State Circuits, 55, pp. 1733-1743. , [CrossRef]; Yang, Z., Wei, L., Logic Circuit and Memory Design for In-Memory Computing Applications using Bipolar RRAMs Proceedings of the 2019 IEEE International Symposium on Circuits and Systems (ISCAS), pp. 1-5. , Sapporo, Japan, 26–29 May 2019; [CrossRef]; Jiang, Z., Yin, S., Seo, J.S., Seok, M., C3SRAM: In-Memory-Computing SRAM Macro Based on Capacitive-Coupling Computing (2019) IEEE Solid-State Circuits Lett, 2, pp. 131-134. , [CrossRef]; Yan, B., Li, B., Qiao, X., Xue, C.X., Chang, M.F., Chen, Y., Li, H.H., Resistive Memory-Based In-Memory Computing: From Device and Large-Scale Integration System Perspectives (2019) Adv. Intell. Syst, 1, p. 1900068. , [CrossRef]; Wang, W., Lin, B., Trained Biased Number Representation for ReRAM-Based Neural Network Accelerators (2019) J. Emerg. Technol. Comput. Syst, 15, pp. 1-17. , [CrossRef]; Huang, S., Ankit, A., Silveira, P., Antunes, R., Chalamalasetti, S.R., Hajj, I.E., Kim, D.E., Serebryakov, S., Mixed Precision Quantization for ReRAM-based DNN Inference Accelerators Proceedings of the 2021 26th Asia and South Pacific Design Automation Conference (ASP-DAC), pp. 372-377. , Tokyo, Japan, 18–21 January 2021; Yu, S., Resistive Random Access Memory (RRAM) (2016) Synth. Lect. Emerg. Eng. Technol, 2, pp. 1-79. , [CrossRef]; Suri, M., Gupta, A., Parmar, V., Lee, K.H., Performance Enhancement of Edge-AI-Inference Using Commodity MRAM: IoT Case Study Proceedings of the 2019 IEEE 11th International Memory Workshop (IMW), pp. 1-4. , Monterey, CA, USA, 12–15 May 2019; [CrossRef]; Gao, S., Chen, B., Qu, Y., Zhao, Y., MRAM Acceleration Core for Vector Matrix Multiplication and XNOR-Binarized Neural Network Inference Proceedings of the 2020 International Symposium on VLSI Technology, Systems and Applications (VLSI-TSA), pp. 153-154. , Hsinchu, Taiwan, 10–13 August 2020; [CrossRef]; Xu, T.C., Leppänen, V., Analysing emerging memory technologies for big data and signal processing applications Proceedings of the 2015 Fifth International Conference on Digital Information Processing and Communications (ICDIPC), pp. 104-109. , Sierre, Switzerland, 7–9 October 2015; [CrossRef]; Sun, X., Liu, R., Peng, X., Yu, S., Computing-in-Memory with SRAM and RRAM for Binary Neural Networks Proceedings of the 2018 14th IEEE International Conference on Solid-State and Integrated Circuit Technology (ICSICT), pp. 1-4. , Qingdao, China, 31 October–3 November 2018; [CrossRef]; Zhang, J., Wang, Z., Verma, N., A machine-learning classifier implemented in a standard 6T SRAM array Proceedings of the 2016 IEEE Symposium on VLSI Circuits (VLSI-Circuits), pp. 1-2. , Honolulu, HI, USA, 15–17 June 2016; [CrossRef]; Si, X., Khwa, W.S., Chen, J.J., Li, J.F., Sun, X., Liu, R., Yu, S., Chang, M.F., A Dual-Split 6T SRAM-Based Computing-in-Memory Unit-Macro With Fully Parallel Product-Sum Operation for Binarized DNN Edge Processors (2019) IEEE Trans. Circuits Syst. I Regul. Pap, 66, pp. 4172-4185. , [CrossRef]; Kim, H., Chen, Q., Kim, B., A 16K SRAM-Based Mixed-Signal In-Memory Computing Macro Featuring Voltage-Mode Accumulator and Row-by-Row ADC Proceedings of the 2019 IEEE Asian Solid-State Circuits Conference (A-SSCC), pp. 35-36. , Macao, China, 4–6 November 2019; [CrossRef]; Yu, C., Yoo, T., Kim, T.T., Tshun Chuan, K.C., Kim, B., A 16K Current-Based 8T SRAM Compute-In-Memory Macro with Decoupled Read/Write and 1-5bit Column ADC Proceedings of the 2020 IEEE Custom Integrated Circuits Conference (CICC), pp. 1-4. , Boston, MA, USA, 22–25 March 2020; [CrossRef]; Maddah, R., Melhem, R., Cho, S., RDIS: Tolerating Many Stuck-At Faults in Resistive Memory (2015) IEEE Trans. Comput, 64, pp. 847-861. , [CrossRef]; Dong, X., Wu, X., Sun, G., Xie, Y., Li, H., Chen, Y., Circuit and microarchitecture evaluation of 3D stacking magnetic RAM (MRAM) as a universal memory replacement Proceedings of the 2008 45th ACM/IEEE Design Automation Conference, pp. 554-559. , Anaheim, CA, USA, 8–13 June 2008; Klostermann, U., Angerbauer, M., Gruning, U., Kreupl, F., Ruhrig, M., Dahmani, F., Kund, M., Muller, G., A Perpendicular Spin Torque Switching based MRAM for the 28 nm Technology Node Proceedings of the 2007 IEEE International Electron Devices Meeting, pp. 187-190. , Washington, DC, USA, 10–12 December 2007; [CrossRef]; Raajitha, K., Meenakshi, K., Rao, Y.M., Design of Thermometer Coding and One-Hot Coding Proceedings of the 2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV), pp. 601-609. , Tirunelveli, India, 4–6 February 2021; [CrossRef]; Kim, Y., Patel, S., Kim, H., Yadav, N., Choi, K.K., Ultra-Low Power and High-Throughput SRAM Design to Enhance AI Computing Ability in Autonomous Vehicles (2021) Electronics, 10, p. 256. , [CrossRef]","Kim, Y.; DA-Lab, 3301 South Dearborn Street, United States; email: ykim102@hawk.iit.edu",,,"MDPI",,,,,20799292,,,,"English","Electronics (Switzerland)",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85114286260
"Lin W., Adetomi A., Arslan T.","57237721500;57188721946;57203197921;","Low-power ultra-small edge ai accelerators for image recognition with convolution neural networks: Analysis and future directions",2021,"Electronics (Switzerland)","10","17","2048","","",,3,"10.3390/electronics10172048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113797750&doi=10.3390%2felectronics10172048&partnerID=40&md5=58ca893a25632e9f240735fe0cabb847","Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3FF, United Kingdom","Lin, W., Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3FF, United Kingdom; Adetomi, A., Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3FF, United Kingdom; Arslan, T., Institute for Integrated Micro and Nano Systems, University of Edinburgh, Edinburgh, EH9 3FF, United Kingdom","Edge AI accelerators have been emerging as a solution for near customers’ applications in areas such as unmanned aerial vehicles (UAVs), image recognition sensors, wearable devices, robotics, and remote sensing satellites. These applications require meeting performance targets and resilience constraints due to the limited device area and hostile environments for operation. Numerous research articles have proposed the edge AI accelerator for satisfying the applications, but not all include full specifications. Most of them tend to compare the architecture with other existing CPUs, GPUs, or other reference research, which implies that the performance exposé of the articles are not comprehensive. Thus, this work lists the essential specifications of prior art edge AI accelerators and the CGRA accelerators during the past few years to define and evaluate the low power ultra-small edge AI accelerators. The actual performance, implementation, and productized examples of edge AI accelerators are released in this paper. We introduce the evaluation results showing the edge AI accelerator design trend about key performance metrics to guide designers. Last but not least, we give out the prospect of developing edge AI’s existing and future directions and trends, which will involve other technologies for future challenging constraints. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","CGRA; CNN; Edge AI accelerator",,,,,,,,,,,,,,,,,"Hoang, L.-H., Hanif, M.A., Shafique, M., FT-ClipAct: Resilience Analysis of Deep Neural Networks and Improving their Fault Tolerance using Clipped Activation Proceedings of the 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), , Grenoble, France, 9–13 March 2020; Zhang, J.J., Gu, T., Basu, K., Garg, S., Analyzing and mitigating the impact of permanent faults on a systolic array based neural network accelerator (2018) Proceedings of the 2018 IEEE 36th VLSI Test Symposium (VTS), , San Francisco, CA, USA, 22–25 April; Hanif, M.A., Shafique, M., Dependable Deep Learning: Towards Cost-Efficient Resilience of Deep Neural Network Accelerators against Soft Errors and Permanent Faults Proceedings of the 2020 IEEE 26th International Symposium on On-Line Testing and Robust System Design (IOLTS), , Napoli, Italy, 13–15 July 2020; Yasoubi, A., Hojabr, R., Modarressi, M., Power-Efficient Accelerator Design for Neural Networks Using Computation Reuse (2017) IEEE Comput. Archit. Lett, 16, pp. 72-75; Venkataramani, S., Ranjan, A., Roy, K., Raghunathan, A., AxNN: Energy-efficient neuromorphic systems using approximate computing (2014) Proceedings of the 2014 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED), , La Jolla, CA, USA, 11–13 August; You, Z., Wei, S., Wu, H., Deng, N., Chang, M.-F., Chen, A., Chen, Y., Liu, Y., (2008) White Paper on AI Chip Technologies, , Tsinghua University and Beijing Innovation Centre for Future Chips: Beijing, China; Montaqim, A., Top 25 AI Chip Companies: A Macro Step Change Inferred from the Micro Scale (2019) Robotics and Automation News, , https://roboticsandautomationnews.com/2019/05/24/top-25-ai-chip-companies-a-macro-step-change-on-the-micro-scale/22704/, (accessed on 4 May 2021); Simonyan, K., Zisserman, A., (2015) Very deep convolution networks for large-scale image recognition, , arXiv arXiv:1409.1556; Du, L., Du, Y., Li, Y., Su, J., Kua, Y.-C., Liu, C.-C., Chang, M.C.F., A Reconfigurable Streaming Deep Convolutional Neural Network Accelerator for Internet of Things (2018) IEEE Trans. Circuits Syst, 65, pp. 198-208. , [CrossRef]; Clark, C., Logan, R., (2011) Power Budgets for Mission Success, , http://mstl.atl.calpoly.edu/~{}workshop/archive/2011/Spring/Day%203/1610%20-%20Clark%20-%20Power%20Budgets%20for%20CubeSat%20Mission%20Success.pdf, Clyde Space Ltd.: Glasgow, UK, (accessed on 4 May 2021); Yazdanbakhsh, A., Park, J., Sharma, H., Lotfi-Kamran, P., Esmaeilzadeh, H., Neural acceleration for GPU throughput processors (2015) Proceedings of the 48th International Symposium on Microarchitecture, , Waikiki, HI, USA, 5–9 December; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process. Mag, 29, pp. 82-97. , [CrossRef]; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proceedings of the 22nd ACM International Conference on Multimedia, , New York, NY, USA, 3–7 November; Vasudevan, A., Anderson, A., Gregg, D., Parallel multi channel convolution using general matrix multiplication (2017) Proceedings of the 2017 IEEE 28th International Conference on Application-Specific Systems, Architectures and Processors (ASAP), , Seattle, WA, USA, 10 July; Guo, K., Sui, L., Qiu, J., Yu, J., Wang, J., Yao, S., Han, S., Yang, H., Angel-eye: A complete design flow for mapping CNN onto embedded FPGA (2018) IEEE Trans. Comput. Aided Des. Integr. Circuits Syst, 37, pp. 35-47. , [CrossRef]; https://www.gyrfalcontech.ai/solutions/2801s/, Gyrfalcon Technology Inc. (GTI). Lightspeeur 2801S. (accessed on 4 May 2021); Farahini, N., Li, S., Tajammul, M.A., Shami, M.A., Chen, G., Hemani, A., Ye, W., 39.9 GOPs/watt multi-mode CGRA accelerator for a multi-standard basestation (2013) Proceedings of the 2013 IEEE International Symposium on Circuits and Systems (ISCAS), , Beijing, China, 19–23 May; Abdelfattah, A., Anzt, H., Boman, E.G., Carson, E., Cojean, T., Dongarra, J., Gates, M., Li, S., (2020) A survey of numerical methods utilizing mixed precision arithmetic, , arXiv arXiv:2007.06674; Chen, Y.-H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2017) IEEE J. Solid State Circuits, 52, pp. 262-263. , [CrossRef]; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolution neural networks (2015) Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, , Monterey, CA, USA, 22–24 February; Sim, J., Park, J.-S., Kim, M., Bae, D., Choi, Y., Kim, L.-S., A 1.42TOPS/W deep convolution neural network recognition processor for intelligent IoE systems (2016) Proceedings of the 2016 IEEE International Solid-State Circuits Conference, , San Francisco, CA, USA, 31 January–4 February; Oh, N., Intel Announces Movidius Myriad X VPU, Featuring ‘Neural Compute Engine’, AnandTech 2017, , https://www.anandtech.com/show/11771/intel-announces-movidius-myriad-x-vpu, (accessed on 4 May 2021); JETSON NANO, , https://developer.nvidia.com/embedded/develop/hardware, NVIDIA. (accessed on 4 May 2021); Wikipedia, T., https://en.wikipedia.org/wiki/Tegra#cite_note-103, (accessed on 4 May 2021); http://t.rock-chips.com/portal.php?mod=view&aid=33, Toybrick. TB-RK1808M0. (accessed on 5 May 2021); USB Accelerator, , https://coral.ai/products/accelerator/, Coral. (accessed on 5 May 2021); Google Coral edge TPU, , https://s.fanpiece.com/SmVAxcY, DIY MAKER. (accessed on 5 May 2021); AM5729 Sitara Processor, , https://www.ti.com/product/AM5729, Texas Instruments. (accessed on 5 May 2021); Shafiee, A., Nag, A., Muralimanohar, N., Balasubramonian, R., Paul Strachan, J., Hu, M., Williams, R.S., Srikumar, V., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) Proceedings of the 2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA), , Seoul, Korea, 18–22 June; Arensman, R., (2016) Despite HPs Delays, Memristors Are Now Available, , https://electronics360.globalspec.com/article/6389/despite-hp-s-delays-memristors-are-now-available, Electronics 360. (accessed on 4 May 2021); Podobas, A., Sano, K., Matsuoka, S., A Survey on Coarse-Grained Reconfigurable Architectures from a Performance Perspective (2020) IEEE Access, 8, pp. 146719-146743. , [CrossRef]; Karunaratne, M., Mohite, A.K., Mitra, T., Peh, L.-S., HyCUBE: A CGRA with Reconfigurable Single-cycle Multi-hop Interconnect (2017) Proceedings of the 2017 54th ACM/EDAC/IEEE Design Automation Conference (DAC), , Austin, TX, USA, 18–22 June; Lopes, J.D., de Sousa, J.T., Versat, a Minimal Coarse-Grain Reconfigurable Array (2016) Proceedings of the International Conference on Vector and Parallel Processing, , Porto, Portugal, 28–30 June; Prasad, R., Das, S., Martin, K., Tagliavini, G., Coussy, P., Benini, L., Rossi, D., TRANSPIRE: An energy-efficient TRANSprecision floatingpoint Programmable archItectuRE Proceedings of the 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), , Grenoble, France, 9–13 March 2020; Nowatzki, T., Gangadhar, V., Ardalani, N., Sankaralingam, K., Stream-Dataflow Acceleration (2017) Proceedings of the 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA), , Toronto, ON, Canada, 24–28 June; Cong, J., Huang, H., Ma, C., Xiao, B., Zhou, P., A Fully Pipelined and Dynamically Composable Architecture of CGRA (2014) Proceedings of the 2014 IEEE 22nd Annual International Symposium on Field-Programmable Custom Computing Machines, , Boston, MA, USA, 11–13 May; Mahale, G., Mahale, H., Nandy, S.K., Narayan, R., REFRESH: REDEFINE for Face Recognition Using SURE Homogeneous Cores (2016) IEEE Trans. Parallel Distrib. Syst, 27, pp. 3602-3616. , [CrossRef]; Fan, X., Li, H., Cao, W., Wang, L., DT-CGRA: Dual-Track Coarse Grained Reconfigurable Architecture for Stream Applications (2016) Proceedings of the 2016 26th International Conference on Field Programmable Logic and Applications (FPL), , Lausanne, Switzerland, 29 August–2 September; Fan, X., Wu, D., Cao, W., Luk, W., Wang, L., Stream Processing Dual-Track CGRA for Object Inference (2018) IEEE Trans. VLSI Syst, 26, pp. 1098-1111. , [CrossRef]; Lopes, J., Sousa, D., Ferreira, J.C., Evaluation of CGRA architecture for real-time processing of biological signals on wearable devices (2017) Proceedings of the 2017 International Conference on ReConFigurable Computing and FPGAs (ReConFig), , Cancun, Mexico, 4–6 December; Chen, Y.-H., Yang, T.-J., Emer, J., Sze, V., Eyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices (2019) IEEE Trans. Emerg. Sel. Topics Circuits Syst, 9, pp. 292-308. , [CrossRef]; Das, S., Martin, K.J., Coussy, P., Rossi, D., A Heterogeneous Cluster with Reconfigurable Accelerator for Energy Efficient Near-Sensor Data Analytics (2018) Proceedings of the 2018 IEEE International Symposium on Circuits and Systems (ISCAS), , Florence, Italy, 27–30 May; Nikolskiy, V., Stegailov, V., Floating-point performance of ARM cores and their efficiency in classical molecular dynamics (2016) J. Phys. Conf. Ser, 681, p. 012049. , [CrossRef]; Kim, J.Y., Kim, M., Lee, S., Oh, J., Kim, K., Yoo, H., A 201.4 GOPS 496 mW Real-Time Multi-Object Recognition Processor with Bio-Inspired Neural Perception Engine (2010) IEEE J. Solid-State Circuits, 45, pp. 32-45. , [CrossRef]; Gautschi, M., Schiavone, P.D., Traber, A., Loi, I., Pullini, A., Rossi, D., Flamand, E., Benini, L., Near-Threshold RISC-V Core with DSP Extensions for Scalable IoT Endpoint Devices (2017) IEEE Trans. Very Large Scale Integr. Syst, 25, pp. 2700-2713. , [CrossRef]; Shawahna, A., Sait, S.M., El-Maleh, A., FPGA-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review (2019) IEEE Access, 7, pp. 7823-7859. , [CrossRef]; Lavagno, L., Sangiovanni-Vincentelli, A., System-level design models and implementation techniques (1998) Proceedings of the 1998 International Conference on Application of Concurrency to System Design, , Fukushima, Japan, 23–26 March; Takouna, I., Dawoud, W., Meinel, C., Accurate Mutlicore Processor Power Models for Power-Aware Resource Management (2011) Proceedings of the 2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing, , Sydney, NSW, Australia, 12–14 December; Tesla Autopilot, , https://en.wikipedia.org/wiki/Tesla_Autopilot#Hardware_3, Wikipedia. (accessed on 6 August 2021)","Lin, W.; Institute for Integrated Micro and Nano Systems, United Kingdom; email: Weison.Lin@ed.ac.uk",,,"MDPI AG",,,,,20799292,,,,"English","Electronics (Switzerland)",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85113797750
"Sütő J.","55321144800;","Embedded system‐based sticky paper trap with deep learning‐based insect‐counting algorithm",2021,"Electronics (Switzerland)","10","15","1754","","",,1,"10.3390/electronics10151754","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110532041&doi=10.3390%2felectronics10151754&partnerID=40&md5=099e5d25d543ced8c6ad84fda5d3fff9","Department of IT Systems and Networks, University of Debrecen, Debrecen, 4032, Hungary","Sütő, J., Department of IT Systems and Networks, University of Debrecen, Debrecen, 4032, Hungary","Flying insect detection, identification, and counting are the key components of agricultural pest management. Insect identification is also one of the most challenging tasks in agricultural image processing. With the aid of machine vision and machine learning, traditional (manual) identification and counting can be automated. To achieve this goal, a particular data acquisition device and an accurate insect recognition algorithm (model) is necessary. In this work, we propose a new embedded system‐based insect trap with an OpenMV Cam H7 microcontroller board, which can be used anywhere in the field without any restrictions (AC power supply, WIFI coverage, human interaction, etc.). In addition, we also propose a deep learning‐based insect‐counting method where we offer solutions for problems such as the “lack of data” and “false insect detection”. By means of the proposed trap and insect‐counting method, spraying (pest swarming) could then be accurately scheduled. © 2021 by the author. Licensee MDPI, Basel, Switzerland.","Deep learning; Embedded system; Insect pest counting; Sticky paper trap",,,,,,"European Commission, EC; European Social Fund, ESF","Funding: This work was supported by the construction EFOP‐3.6.3‐VEKOP‐16‐2017‐00002. The pro‐ ject was supported by the European Union, co‐financed by the European Social Fund.",,,,,,,,,,"Zhong, Y., Gao, J., Lei, Q., Zhou, Y., A vision‐based counting and recognition system for flying insects in intelligent agriculture (2018) Sensors, 18, p. 1489; Sun, Y., Liu, X., Yuan, M., Ren, L., Wang, J., Chen, Z., Automatic in‐trap pest detection using deep learning for pheromone‐based Dendroctonus valens monitoring (2018) Biosyst. Eng, 176, pp. 140-150; Rustia, D.J.A., Lin, C.E., Chung, J.Y., Zhuang, Y.J., Hsu, J.C., Lin, T.T., Application of image and environmental sensor network for automated greenhouse insect pest monitoring (2020) J. Asia Pac. Etomol, 23, pp. 17-28; Wang, J., Lin, C., Ji, L., Liang, A., A new automatic identification system of insect images at the order level (2012) Knowl. Based Syst, 33, pp. 102-110; Yalcin, H., Vision Based Automatic Inspection of Insects in Pheromone Traps Proceedings of the 2015 Fourth International Conference on Agro‐Geoinformatics, pp. 333-338. , Istanbul, Turkey, 20–24 July 2015; Bakkay, M.C., Chambon, S., Rashwan, H.A., Lubat, C., Barsotti, S., Automatic detection of individual and touching moths from trap images by combining contour‐based and region‐based segmentation (2018) IET Comput. Vis, 12, pp. 138-145; Wen, C., Guyer, D., Image‐based orchard insect automated identification and classification method (2012) Comput. Electron. Agric, 89, pp. 110-115; Liu, H., Lee, S.H., Chahl, J.S., A review of recent sensing technologies to detect invertebrates on crops (2017) Precis. Agric, 18, pp. 635-666; Martineau, M., Conte, D., Raveaux, R., Arnault, I., Munier, D., Venturini, G., A survey on image‐based insect classification (2017) Pattern Recognit, 65, pp. 273-284; Xie, C., Zhang, J., Rui, L., Li, J., Hong, P., Xia, J., Chen, P., Automatic classification for field crop insects via multiple‐task sparse representation and multiple‐kernel learning (2015) Comput. Electron. Agric, 119, pp. 123-132; Deng, L., Wang, Y., Han, Z., Yu, R., Research on insect pest image detection and recognition based on bio‐inspired method (2018) Biosyst. Eng, 169, pp. 139-148; Wu, X., Zhang, C., Lai, Y.K., Cheng, M.M., Yang, J., IP102: A Large Scale Benchmark Dataset for Insect Pest Recognition Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8787-8796. , Long Beach, CA, USA, 15–20 June 2019; Fieldguide challenge: Moth and Butterflies, , https://www.kaggle.com/c/fieldguide‐challenge‐moths-and‐butterflies/, Kaggle, (accessed on 4 May 2021); Qing, Y., Jun, L.V., Qing‐jie, L., Guang‐qiang, D., Bao‐jun, Y., Hong‐ming, C., Jian, T., An insect imaging system to automated rice light ‐trap pest identification (2012) J. Integr. Agric, 11, pp. 978-985; Cho, J., Choi, J., Qiao, M., Ji, C.W., Kim, H.Y., Uhm, K.B., Chon, T.S., Automatic identification of whiteflies, aphids, and thrips in greenhouse based on image analysis (2007) Int. J. Math. Comput. Simul, 1, pp. 46-53; Wang, Z., Wang, K., Liu, Z., Wang, X., Pan, S., A Cognitive Vision Method for Insect Pest Image Segmentation Proceedings of the 6th IFAC Conference on Bio‐Robotics, pp. 13-15. , Beijing, China, 13–15 July 2018; Wen, C., Wu, D., Hu, H., Pan, W., Pose estimation‐dependent identification method for moth images using deep learning architecture (2015) Biosyst. Eng, 136, pp. 117-128; Ding, W., Taylor, G., Automatic moth detection from trap images for pest management (2016) Comput. Electron. Agric, 123, pp. 17-28; Zhu, Z., Liang, D., Zhang, S., Huang, X., Li, B., Hu, S., Traffic Sign Detection and Classification in the Wild Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2110-2118. , Las Vegas, NV, USA, 27–30 June 2016; Kasinathan, T., Uyyala, S.R., Machine learning ensemble with image processing for pest identification and classification in field crops (2021) Neural Comput. Appl; Xia, D., Chen, P., Wang, B., Zhang, J., Xie, C., Insect detection and classification based on an improved convolutional neural network (2018) Sensors, 18, p. 4169; Hong, S.J., Kim, S.Y., Kim, E., Lee, C.H., Lee, J.S., Lee, D.S., Bang, J., Kim, G., Moth detection from pheromone trap images using deep learning object detectors (2020) Agriculture, 10, p. 170; https://irh.inf.unideb.hu/~sutoj/projects.php, Available online: (accessed on 20 July 2021); Uijlings, J.R.R., Van de Sende, K.E.A., Gevers, T., Smeulders, A.W.M., Selective search for object recognition (2013) Int. J. Comput. Vis, 104, pp. 154-171; Suto, J., Plant leaf recognition with shallow and deep learning: A comprehensive study (2020) Intell. Data Anal, 24, pp. 1311-1328; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C., MobileNetV2: Inverted Residuals and Linear Bottlenecks Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4510-4520. , Salt Lake City, UT, USA, 18–23 June 2018; Bodla, N., Singh, B., Chellappa, R., Davis, L.S., Soft‐NMS‐Improving Object Detection with One Line of Code Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 5561-5569. , Venice, Italy, 22–29 October 2017; Snoek, J., Larochelle, H., Adams, R.P., Practical Bayesian Optimization for Machine Learning Algorithms (2012) Proceedings of the Advances in Neural Information Processing Systems, pp. 2951-2959. , Lake Tahoe, NV, USA, 3–6 December; Suto, J., The effect of hyperparameter search on artificial neural network in human activity recognition (2021) Open Comput. Sci, 11, pp. 411-422","Sütő, J.; Department of IT Systems and Networks, Hungary; email: suto.jozsef@inf.unideb.hu",,,"MDPI AG",,,,,20799292,,,,"English","Electronics (Switzerland)",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85110532041
"Alessandrini M., Biagetti G., Crippa P., Falaschetti L., Turchetti C.","6701651414;6507471336;7004473912;56906921300;7004430901;","Recurrent neural network for human activity recognition in embedded systems using ppg and accelerometer data",2021,"Electronics (Switzerland)","10","14","1715","","",,5,"10.3390/electronics10141715","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110212125&doi=10.3390%2felectronics10141715&partnerID=40&md5=4a3f60aadd73e366a9030db743760e3d","DII—Department of Information Engineering, Università Politecnica delle Marche, Ancona, I-60131, Italy","Alessandrini, M., DII—Department of Information Engineering, Università Politecnica delle Marche, Ancona, I-60131, Italy; Biagetti, G., DII—Department of Information Engineering, Università Politecnica delle Marche, Ancona, I-60131, Italy; Crippa, P., DII—Department of Information Engineering, Università Politecnica delle Marche, Ancona, I-60131, Italy; Falaschetti, L., DII—Department of Information Engineering, Università Politecnica delle Marche, Ancona, I-60131, Italy; Turchetti, C., DII—Department of Information Engineering, Università Politecnica delle Marche, Ancona, I-60131, Italy","Photoplethysmography (PPG) is a common and practical technique to detect human activity and other physiological parameters and is commonly implemented in wearable devices. However, the PPG signal is often severely corrupted by motion artifacts. The aim of this paper is to address the human activity recognition (HAR) task directly on the device, implementing a recurrent neural network (RNN) in a low cost, low power microcontroller, ensuring the required performance in terms of accuracy and low complexity. To reach this goal, (i) we first develop an RNN, which integrates PPG and tri-axial accelerometer data, where these data can be used to compensate motion artifacts in PPG in order to accurately detect human activity; (ii) then, we port the RNN to an embedded device, Cloud-JAM L4, based on an STM32 microcontroller, optimizing it to maintain an accuracy of over 95% while requiring modest computational power and memory resources. The experimental results show that such a system can be effectively implemented on a constrained-resource system, allowing the design of a fully autonomous wearable embedded system for human activity recognition and logging. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Accelerometer; Deep neural network (DNN); Embedded system; Human activity recognition (HAR); Photoplethysmography (PPG); Recurrent neural network (RNN); STM32",,,,,,,,,,,,,,,,,"Cicirelli, F., Fortino, G., Giordano, A., Guerrieri, A., Spezzano, G., Vinci, A., On the design of smart homes: A framework for activity recognition in home environment (2016) J. Med. Syst, 40, pp. 1-17; Rashidi, P., Cook, D.J., Keeping the resident in the loop: Adapting the smart home to the user (2009) IEEE Trans. Syst. Man Cybern. Part A Syst. Hum, 39, pp. 949-959; Boukhechba, M., Chow, P., Fua, K., Teachman, B.A., Barnes, L.E., Predicting social anxiety from global positioning system traces of college students: Feasibility study (2018) JMIR Ment. Health, 5, p. e10101; Boukhechba, M., Daros, A.R., Fua, K., Chow, P.I., Teachman, B.A., Barnes, L.E., DemonicSalmon: Monitoring mental health and social interactions of college students using smartphones (2018) Smart Health, 9, pp. 192-203; Patel, S., Park, H., Bonato, P., Chan, L., Rodgers, M., A review of wearable sensors and systems with application in rehabilitation (2012) J. Neuroeng. Rehabil, 9, pp. 1-17; Avci, A., Bosch, S., Marin-Perianu, M., Marin-Perianu, R., Havinga, P., Activity recognition using inertial sensing for healthcare, wellbeing and sports applications: A survey Proceedings of the 23th International Conference on Architecture of Computing Systems 2010, pp. 1-10. , VDE, Hannover, Germany, 22–25 February 2010; Mazilu, S., Blanke, U., Hardegger, M., Tröster, G., Gazit, E., Hausdorff, J.M., GaitAssist: A daily-life support and training system for parkinson’s disease patients with freezing of gait Proceedings of the SIGCHI conference on Human Factors in Computing Systems, pp. 2531-2540. , Toronto, ON, Canada, 26 April–1 May 2014; Chen, L., Wei, H., Ferryman, J., A survey of human motion analysis using depth imagery (2013) Pattern Recognit. Lett, 34, pp. 1995-2006; Taha, A., Zayed, H.H., Khalifa, M., El-Horbaty, E.S.M., Human activity recognition for surveillance applications Proceedings of the 7th International Conference on Information Technology, pp. 577-586. , Amman, Jordan, 12–15 May 2015; Kranz, M., Möller, A., Hammerla, N., Diewald, S., Plötz, T., Olivier, P., Roalter, L., The mobile fitness coach: Towards individualized skill assessment using personalized mobile devices (2013) Pervasive Mob. Comput, 9, pp. 203-215; Stiefmeier, T., Roggen, D., Ogris, G., Lukowicz, P., Tröster, G., Wearable activity tracking in car manufacturing (2008) IEEE Pervasive Comput, 7, pp. 42-50; Biagetti, G., Crippa, P., Falaschetti, L., Orcioni, S., Motion Artifact Reduction in Photoplethysmography using Bayesian Classification for Physical Exercise Identification Proceedings of the International Conference on Pattern Recognition Applications and Methods, SCITEPRESS 2016, ICPRAM 2016, pp. 467-474. , Rome, Italy, 24–26 February 2016; Biagetti, G., Crippa, P., Falaschetti, L., Orcioni, S., Reduced complexity algorithm for heart rate monitoring from PPG signals using automatic activity intensity classifier (2019) Biomed. Signal Process. Control, 52, pp. 293-301; Zhang, Z., Pi, Z., Liu, B., TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise (2015) IEEE Trans. Biomed. Eng, 62, pp. 522-531; Khan, A.M., Lee, Y., Lee, S.Y., Kim, T., Human Activity Recognition via an Accelerometer-Enabled-Smartphone Using Kernel Discriminant Analysis Proceedings of the 2010 5th International Conference on Future Information Technology, pp. 1-6. , Busan, Korea, 20–24 May 2010; Dernbach, S., Das, B., Krishnan, N.C., Thomas, B.L., Cook, D.J., Simple and Complex Activity Recognition through Smart Phones Proceedings of the 2012 Eighth International Conference on Intelligent Environments, pp. 214-221. , Guanajuato, Mexico, 26–29 June 2012; Boukhechba, M., Cai, L., Wu, C., Barnes, L.E., ActiPPG: Using deep neural networks for activity recognition from wrist-worn photoplethysmography (PPG) sensors (2019) Smart Health, 14, p. 100082; Attal, F., Mohammed, S., Dedabrishvili, M., Chamroukhi, F., Oukhellou, L., Amirat, Y., Physical human activity recognition using wearable sensors (2015) Sensors, 15, pp. 31314-31338; Casale, P., Pujol, O., Radeva, P., Human activity recognition from accelerometer data using a wearable device Proceedings of the Iberian Conference on Pattern Recognition and Image Analysis, pp. 289-296. , Las Palmas de Gran Canaria, Spain, 8–10 June 2011; Lu, Y., Wei, Y., Liu, L., Zhong, J., Sun, L., Liu, Y., Towards unsupervised physical activity recognition using smartphone accelerometers (2017) Multimed. Tools Appl, 76, pp. 10701-10719; Walse, K.H., Dharaskar, R.V., Thakare, V.M., Pca based optimal ann classifiers for human activity recognition using mobile sensors data (2016) Proceedings of the First International Conference on Information and Communication Technology for Intelligent Systems, 1, pp. 429-436. , Springer: Berlin/Heidelberg, Germany; Hammerla, N.Y., Halloran, S., Plötz, T., (2016) Deep, convolutional, and recurrent models for human activity recognition using wearables, , arXiv arXiv:1604.08880; Chen, Y., Xue, Y., A deep learning approach to human activity recognition based on single accelerometer Proceedings of the 2015 IEEE International Conference on Systems, Man, and Cybernetics, pp. 1488-1492. , Hong Kong, China, 9–12 October 2015; Jiang, W., Yin, Z., Human activity recognition using wearable sensors by deep convolutional neural networks Proceedings of the 23rd ACM international conference on Multimedia, pp. 1307-1310. , Brisbane, Australia, 26–30 October 2015; Almaslukh, B., AlMuhtadi, J., Artoli, A., An effective deep autoencoder approach for online smartphone-based human activity recognition (2017) Int. J. Comput. Sci. Netw. Secur, 17, pp. 160-165; Wang, A., Chen, G., Shang, C., Zhang, M., Liu, L., Human activity recognition in a smart home environment with stacked denoising autoencoders Proceedings of the International Conference on Web-Age Information Management, pp. 29-40. , Nanchang, China, 3–5 June 2016; Singh, D., Merdivan, E., Psychoula, I., Kropf, J., Hanke, S., Geist, M., Holzinger, A., Human activity recognition using recurrent neural networks Proceedings of the International Cross-Domain Conference for Machine Learning and Knowledge Extraction, pp. 267-274. , Reggio, Italy, 29 August–1 September 2017; Ordóñez, F.J., Roggen, D., Deep convolutional and LSTM recurrent neural networks for multimodal wearable activity recognition (2016) Sensors, 16, p. 115; Pienaar, S.W., Malekian, R., Human activity recognition using LSTM-RNN deep neural network architecture Proceedings of the 2019 IEEE 2nd Wireless Africa Conference (WAC), pp. 1-5. , Pretoria, South Africa, 18–20 August 2019; Krishna, K., Jain, D., Mehta, S.V., Choudhary, S., An lstm based system for prediction of human activities with durations (2018) Proc. ACM Interact. Mob. Wearable Ubiquitous Technol, 1, pp. 1-31; Nafea, O., Abdul, W., Muhammad, G., Alsulaiman, M., Sensor-Based Human Activity Recognition with Spatio-Temporal Deep Learning (2021) Sensors, 21, p. 2141; Guan, Y., Plötz, T., Ensembles of deep lstm learners for activity recognition using wearables (2017) Proc. ACM Interact. Mobile Wearable Ubiquitous Technol, 1, pp. 1-28; Xia, K., Huang, J., Wang, H., LSTM-CNN architecture for human activity recognition (2020) IEEE Access, 8, pp. 56855-56866; Zebin, T., Sperrin, M., Peek, N., Casson, A.J., Human activity recognition from inertial sensor time-series using batch normalized deep LSTM recurrent networks Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 1-4. , Honolulu, HI, USA, 18–21 July 2018; Mutegeki, R., Han, D.S., A CNN-LSTM approach to human activity recognition Proceedings of the 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), pp. 362-366. , Fukuoka, Japan, 19–21 February 2020; Novac, P.E., Boukli Hacene, G., Pegatoquet, A., Miramond, B., Gripon, V., Quantization and Deployment of Deep Neural Networks on Microcontrollers (2021) Sensors, 21, p. 2984; Novac, P.E., Castagnetti, A., Russo, A., Miramond, B., Pegatoquet, A., Verdier, F., Castagnetti, A., Toward unsupervised Human Activity Recognition on Microcontroller Units Proceedings of the 2020 23rd Euromicro Conference on Digital System Design (DSD), pp. 542-550. , Kranj, Slovenia, 26–28 August 2020; Zhao, Y., Yang, R., Chevalier, G., Gong, M., Deep Residual Bidir-LSTM for Human Activity Recognition Using Wearable Sensors (2017) CoRR, , abs/1708.08989; Mekruksavanich, S., Jitpattanakul, A., Biometric User Identification Based on Human Activity Recognition Using Wearable Sensors: An Experiment Using Deep Learning Models (2021) Electronics, 10, p. 308; Agarwal, P., Alam, M., A Lightweight Deep Learning Model for Human Activity Recognition on Edge Devices (2020) Procedia Comput. Sci, 167, pp. 2364-2373; (2021) STM32 Solutions for Artificial Neural Networks, , https://www.st.com/content/st_com/en/ecosystems/stm32-ann.html, STMicroelectronics. (accessed on 16 April 2021); Zhang, R., Mu, C., Yang, Y., Xu, L., Research on simulated infrared image utility evaluation using deep representation (2018) Procedia Comput. Sci, 27, p. 013012; Zhang, R., Xu, L., Yu, Z., Shi, Y., Mu, C., Xu, M., Deep-IRTarget: An Automatic Target Detector in Infrared Imagery using Dual-domain Feature Extraction and Allocation (2021) IEEE Trans. Multimed; Zhang, R., Wu, L., Yang, Y., Wu, W., Chen, Y., Xu, M., Multi-camera multi-player tracking with deep player identification in sports video (2020) Pattern Recognit, 102, p. 107260; Xu, K., Jiang, X., Ren, H., Liu, X., Chen, W., Deep Recurrent Neural Network for Extracting Pulse Rate Variability from Photoplethysmography During Strenuous Physical Exercise Proceedings of the 2019 IEEE Biomedical Circuits and Systems Conference (BioCAS), pp. 1-4. , Nara, Japan, 17–19 October 2019; Senturk, U., Yucedag, I., Polat, K., Proceedings of the Repetitive Neural Network (RNN) Based Blood Pressure Estimation Using PPG and ECG Signals, pp. 1-4. , Ankara, Turkey, 19–21 October 2018; Reiss, A., Indlekofer, I., Schmidt, P., Van Laerhoven, K., Deep ppg: Large-scale heart rate estimation with convolutional neural networks (2019) Sensors, 19, p. 3079; Shyam, A., Ravichandran, V., Sp, P., Joseph, J., Sivaprakasam, M., PPGnet: Deep Network for Device Independent Heart Rate Estimation from Photoplethysmogram (2019) Proceedings of the 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), , Berlin, Germany, 23–27 July; Hochreiter, S., The vanishing gradient problem during learning recurrent neural nets and problem solutions (1998) Int. J. Uncertain. Fuzziness Knowl. Based Syst, 6, pp. 107-116; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9, pp. 1735-1780; Biagetti, G., Crippa, P., Falaschetti, L., Saraceni, L., Tiranti, A., Turchetti, C., Dataset from PPG wireless sensor for activity monitoring (2020) Data in Brief, 29, p. 105044; Brophy, E., Muehlhausen, W., Smeaton, A.F., Ward, T.E., CNNs for Heart Rate Estimation and Human Activity Recognition in Wrist Worn Sensing Applications Proceedings of the 2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), pp. 1-6. , Austin, TX, USA, 23–27 March 2020; Biagetti, G., Crippa, P., Falaschetti, L., Focante, E., Martínez Madrid, N., Seepold, R., Machine Learning and Data Fusion Techniques Applied to Physical Activity Classification Using Photoplethysmographic and Accelerometric Signals (2020) Procedia Comput. Sci, 176, pp. 3103-3111; Musci, M., De Martini, D., Blago, N., Facchinetti, T., Piastra, M., Online Fall Detection using Recurrent Neural Networks on Smart Wearable Devices (2020) IEEE Trans. Emerg. Top. Comput; Eddins, S., (2018) Classify ECG Signals Using LSTM Networks, , https://blogs.mathworks.com/deep-learning/2018/08/06/classify-ecg-signals-using-lstm-networks/, (accessed on 16 April 2021); Chevalier, G., (2016) LSTMs for Human Activity Recognition, , https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition, (accessed on 16 April 2021); Chavarriaga, R., Sagha, H., Calatroni, A., Digumarti, S.T., Tröster, G., Millán, J.D.R., Roggen, D., The Opportunity Challenge: A Benchmark Database for on-Body Sensor-Based Activity Recognition (2013) Pattern Recogn. Lett, 34, pp. 2033-2042; Zappi, P., Lombriser, C., Stiefmeier, T., Farella, E., Roggen, D., Benini, L., Tröster, G., Activity Recognition from On-Body Sensors: Accuracy-Power Trade-Off by Dynamic Sensor Selection (2008) Wireless Sensor Networks, pp. 17-33. , Springer: Berlin/Heidelberg, Germany; Kwapisz, J.R., Weiss, G.M., Moore, S.A., Activity Recognition Using Cell Phone Accelerometers (2011) SIGKDD Explor. Newsl, 12, pp. 74-82; Anguita, D., Ghio, A., Oneto, L., Parra, X., Reyes-Ortiz, J.L., A public domain dataset for human activity recognition using smartphones (2013) Proceedings of the Esann, 3, p. 3. , others Bruges, Belgium, 24–26 April; Zhang, M., Sawchuk, A.A., USC-HAD: A Daily Activity Dataset for Ubiquitous Activity Recognition Using Wearable Sensors (2012) Proceedings of the 2012 ACM Conference on Ubiquitous Computing, UbiComp ’12, pp. 1036-1043. , Pittsburgh, PA, USA, 5–8 September Association for Computing Machinery: New York, NY, USA, 2012; Biagetti, G., Crippa, P., Falaschetti, L., Orcioni, S., Human Activity Recognition Using Accelerometer and Photoplethysmographic Signals (2018) Intelligent Decision Technologies 2017, pp. 53-62. , Springer International Publishing: Cham, Switzerland; Casson, A.J., Vazquez Galvez, A., Jarchi, D., Gyroscope vs. accelerometer measurements of motion from wrist PPG during physical exercise (2016) ICT Express, 2, pp. 175-179","Crippa, P.; DII—Department of Information Engineering, Italy; email: p.crippa@univpm.it",,,"MDPI AG",,,,,20799292,,,,"English","Electronics (Switzerland)",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85110212125
"Asghar M.S., Arslan S., Kim H.","57221949396;57195938973;56157247800;","A low‐power spiking neural network chip based on a compact lif neuron and binary exponential charge injector synapse circuits",2021,"Sensors","21","13","4462","","",,3,"10.3390/s21134462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108778220&doi=10.3390%2fs21134462&partnerID=40&md5=faf2a705991028f2cff4ae3e473f6d7f","Department of Electronics Engineering, Chungbuk National University, Chungdae‐ro 1, Seowon‐gu, Cheongju, 28644, South Korea; Department of Electrical and Computer Engineering, Abbottabad Campus, COMSATS University Islamabad, University Road, Tobe Camp, Abbottabad, 22044, Pakistan; Department of Electrical and Computer Engineering, COMSATS University Islamabad, Park Road, Tarlai Kalan, Islamabad, 45550, Pakistan","Asghar, M.S., Department of Electronics Engineering, Chungbuk National University, Chungdae‐ro 1, Seowon‐gu, Cheongju, 28644, South Korea, Department of Electrical and Computer Engineering, Abbottabad Campus, COMSATS University Islamabad, University Road, Tobe Camp, Abbottabad, 22044, Pakistan; Arslan, S., Department of Electrical and Computer Engineering, COMSATS University Islamabad, Park Road, Tarlai Kalan, Islamabad, 45550, Pakistan; Kim, H., Department of Electronics Engineering, Chungbuk National University, Chungdae‐ro 1, Seowon‐gu, Cheongju, 28644, South Korea","To realize a large‐scale Spiking Neural Network (SNN) on hardware for mobile applications, area and power optimized electronic circuit design is critical. In this work, an area and power optimized hardware implementation of a large‐scale SNN for real time IoT applications is presented. The analog Complementary Metal Oxide Semiconductor (CMOS) implementation incorporates neuron and synaptic circuits optimized for area and power consumption. The asynchronous neuronal circuits implemented benefit from higher energy efficiency and higher sensitivity. The proposed synapse circuit based on Binary Exponential Charge Injector (BECI) saves area and power consumption, and provides design scalability for higher resolutions. The SNN model implemented is optimized for 9 × 9 pixel input image and minimum bit‐width weights that can satisfy target accuracy, occupies less area and power consumption. Moreover, the spiking neural network is replicated in full digital implementation for area and power comparisons. The SNN chip integrated from neuron and synapse circuits is capable of pattern recognition. The proposed SNN chip is fabricated using 180 nm CMOS process, which occupies a 3.6 mm2 chip core area, and achieves a classification accuracy of 94.66% for the MNIST dataset. The proposed SNN chip consumes an average power of 1.06 mW—20 times lower than the digital implementation. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Artificial neural networks; CMOS; Image classification; Leaky integrate and fire; Neuromorphic; Spiking neural network","Classification (of information); CMOS integrated circuits; Electric power utilization; Energy efficiency; Integrated circuit design; Integrated circuit manufacture; Metals; MOS devices; Neurons; Oxide semiconductors; Pattern recognition; Timing circuits; Analog complementary; Classification accuracy; Digital implementation; Electronic circuit design; Hardware implementations; Mobile applications; Spiking neural network(SNN); Spiking neural networks; Neural networks; computer; nerve cell; semiconductor; synapse; Computers; Neural Networks, Computer; Neurons; Semiconductors; Synapses",,,,,"Ministry of Science, ICT and Future Planning, MSIP; National Research Foundation of Korea, NRF: 2020M3H2A107678611; Institute for Information and Communications Technology Promotion, IITP: 01304, 01462","This work was supported by IITP grant (No. 2020?0?01304), Development of Self?learnable Mobile Recursive Neural Network Processor Technology Project, and also supported by the Grand Information Technology Research Center support program (IITP?2020?0?01462) supervised by the IITP and funded by the MSIT (Ministry of Science and ICT), Korean government. It was also supported by Industry coupled IoT Semiconductor System Convergence Nurturing Center under System Semiconductor Convergence Specialist Nurturing Project funded by the National Research Foundation (NRF) of Korea (2020M3H2A107678611).",,,,,,,,,,"Mead, C., Neuromorphic electronic systems (1990) Proc. IEEE, 78, pp. 1629-1636; Prezioso, M., Merrikh‐Bayat, F., Hoskins, B.D., Adam, G.C., Likharev, K.K., Strukov, D.B., Training and operation of an integrated neuromorphic network based on metal‐oxide memristors (2015) Nature, 521, pp. 61-64; Alex, K., Ilya, S., Geoffrey, E.H., ImageNet classification with deep convolutional neural networks (2012) Proceedings of the 25th International Conference on Neural Information Processing Systems, pp. 1097-1105. , Lake Tahoe, NV, USA, 3–6 December; Lee, J.H., Delbruck, T., Pfeiffer, M., Training Deep Spiking Neural Networks Using Backpropagation (2016) Front. Neurosci, 10, p. 508; kyuho, L., Junyoung, P., Hoi‐Jun, Y., A Low‐power, Mixed‐mode Neural Network Classifier for Robust Scene Classification (2019) J. Semicond. Technol. Sci, 19, pp. 129-136; Schuman, C.D., Potok, T.E., Patton, R.M., Birdwell, J.D., Dean, M.E., Rose, G.S., Plank, J.S., A Survey of Neuromorphic Computing and Neural Networks in Hardware, , http://arxiv.org/abs/1705.06963, (accessed on 25 January 2021); von Neumann, J., First draft of a report on the EDVAC (1993) IEEE Ann. Hist. Comput, 15, pp. 27-75; Kandel, E.R., Schwartz, J.H., Jessell, T.M., (2012) Principles of Neural Science, , 5th ed.; McGraw‐Hill, Health Professions Division: New York, NY, USA; Meier, K., Special report: Can we copy the brain?—The brain as computer (2017) IEEE Spectr, 54, pp. 28-33; Mahowald, M.A., Mead, C., The silicon retina (1991) Scientific American, 264, pp. 76-82. , Springer Nature: New York, NY, USA; Kim, S., Kim, H., Hwang, S., Kim, M.H., Chang, Y.F., Park, B.G., Analog synaptic behavior of a silicon nitride memristor (2017) ACS Appl. Mater. Interfaces, 9, pp. 40420-40427; Rashvand, P., Ahmadzadeh, M.R., Shayegh, F., Design and Implementation of a Spiking Neural Network with Integrate‐and‐ Fire Neuron Model for Pattern Recognition (2021) Int. J. Neural Syst, 31, p. 2050073; Mead, C., (1989) Anlaog VLSI and Neural Systems, , 1st ed.; Addison‐Wesley: Reading, PA, USA; Merolla, P., Arthur, J., Akopyan, F., Imam, N., Manohar, R., Modha, D.S., A Digital Neurosynaptic Core Using Embedded Crossbar Memory with 45pJ per Spike in 45 nm (2011) Proceedings of the IEEE Custom Integrated Circuits Conference, pp. 1-4. , San Jose, CA, USA, 19–21 September; Islas, C., Padilla, P., Prado, M.A., Information Processing in the Brain as Optimal Entropy Transport: A Theoretical Approach (2020) Entropy, 22, p. 1231; Pregowska, A., Kaplan, E., Szczepanski, J., How Far can Neural Correlations Reduce Uncertainty? Comparison of Information Transmission Rates for Markov and Bernoulli Processes (2019) Int. J. Neural Syst, 29, p. 1950003; Crumiller, M., Knight, B., Kaplan, E., The Measurement of Information Transmitted by a Neural Population: Promises and Challenges (2013) Entropy, 15, pp. 3507-3527; Frenkel, C., Lefebvre, M., Legat, J.D., Bol, D., A 0.086‐mm2 12.7‐pJ/SOP 64k‐Synapse 256‐Neuron Online‐Learning Digital Spiking Neuromorphic Processor in 28‐nm CMOS (2019) IEEE Trans. Biomed. Circuits Syst, 13, pp. 145-158; Miyashita, D., Kousai, S., Suzuki, T., Deguchi, J., Time‐Domain Neural Network: A 48.5 TSOp/s/W neuromorphic chip optimized for deep learning and CMOS technology Proceedings of the IEEE Asian SSC Conference, pp. 25-28. , Toyama, Japan, 7–9 November 2016; Harris, J.J., Jolivet, R., Engl, E., Attwell, D., Energy‐Efficient Information Transfer by Visual Pathway Synapses (2015) Curr. Biol, 25, pp. 3151-3160; Aamir, S.A., Stradmann, Y., Müller, P., Pehle, C., Hartel, A., Grübl, A., Schemmel, J., Meier, K., An Accelerated LIF Neuronal Network Array for a Large‐Scale Mixed‐Signal Neuromorphic Architecture (2018) IEEE Trans. Circuits Syst. I Regul. Pap, 65, pp. 4299-4312; Indiveri, G., Horiuchi, T., Frontiers in Neuromorphic Engineering (2011) Front. Neurosci, 5, p. 118; Ebong, I.E., Mazumder, P., CMOS and memristor‐based neural network design for position detection (2012) Proc. IEEE, 100, pp. 2050-2060; Chua, L., Memristor‐the missing circuit element (1971) IEEE Trans. Circuit Theory, 18, pp. 507-519; Li, C., Belkin, D., Li, Y., Yan, P., Hu, M., Ge, N., Jiang, H., Wang, Z., Efficient and self‐adaptive in‐situ learning in multilayer memristor neural networks (2018) Nat. Commun, 9, p. 2385; Benjamin, B.V., Gao, P., McQuinn, E., Choudhary, S., Chandrasekaran, A.R., Bussat, J.M., Alvarez‐Icaza, R., Boahen, K., Neurogrid: A Mixed‐Analog‐Digital Multichip System for Large‐Scale Neural Simulations (2014) Proc. IEEE, 102, pp. 699-716; Park, D., Lee, J., Asghar, M.S., Hong, J., Arslan, S., Kim, H., Compact spiking neural network chip design for image classification (2020) J. RICIC, 28, pp. 21-27; Camuñas‐Mesa, L.A., Linares‐Barranco, B., Serrano‐Gotarredona, T., Neuromorphic Spiking Neural Networks and Their Memristor‐CMOS Hardware Implementations (2019) Materials, 12, p. 2745; Ankit, A., Sengupta, A., Panda, P., Roy, K., RESPARC: A Reconfigurable and Energy‐Efficient Architecture with Memristive Crossbars for Deep SNN Proceedings of the 54th ACM/EDAC/IEEE Design Automation Conference, pp. 1-6. , Austin, TX, USA, 18 22 June 2017; Jolivet, R., Rauch, A., Lüscher, H.R., Gerstner, W., Integrate‐and‐fire models with adaptation are good enough: Predicting spike times under random current injection Proceedings of the NIPS 18, pp. 595-602. , Vancouver, BC, Canada, 5–8 December 2005; Gerstner, W., Kistler, W.M., Naud, R., Paninski, L., (2014) Neuronal Dynamics, , Cambridge University Press: Cambridge, UK; Izhikevich, E.M., Simple model of spiking neurons (2003) IEEE Trans. Neural Netw, 14, pp. 1569-1572; Hodgkin, A.L., Huxley, A.F., A quantitative description of membrane current and its application to conduction and excitation in nerve (1990) Bull. Math. Biol, 52, pp. 25-71; Diehl, P.U., Cook, M., Unsupervised learning of digit recognition using spike‐timing‐dependent plasticity (2015) Front. Comput. Neurosci, 9, p. 99; Kim, S., Choi, B., Lim, M., Yoon, J., Lee, J., Kim, H.D., Choi, S.J., Pattern recognition using carbon nanotube synaptic transistors with an adjustable weight update protocol (2017) ACS Nano, 11, pp. 2814-2822; Merrikh‐Bayat, F., Guo, X., Klachko, M., Prezioso, M., Likharev, K.K., Strukov, D.B., High‐performance mixed‐signal neurocomputing with nanoscale floating‐gate memory cell arrays (2018) IEEE Trans. Neural Netw. Learn. Syst, 29, pp. 4782-4790; Woo, J., Padovani, A., Moon, K., Kwak, M., Larcher, L., Hwang, H., Linking conductive filament properties and evolution to synaptic behavior of RRAM devices for neuromorphic applications (2017) IEEE Electron. Device Lett, 38, pp. 1220-1223; Kim, H., Hwang, S., Park, J., Yun, S., Lee, J.H., Park, B.G., Spiking Neural Network Using Synaptic Transistors and Neuron Circuits for Pattern Recognition with Noisy Images (2018) IEEE Electron. Device Lett, 39, pp. 630-633; O’Connor, P., Welling, M., Deep Spiking Networks, , https://arxiv.org/abs/1602.08323, (accessed on 20 January 2021); Wu, Y., Deng, L., Li, G., Zhu, J., Shi, L., Spatio‐Temporal Backpropagation for Training High‐Performance Spiking Neural Networks (2018) Front. Neurosci, 12, p. 331; Al‐Hamid, A.A., Kim, H., Optimization of Spiking Neural Networks Based on Binary Streamed Rate Coding (2020) Electronics, 9, p. 1599; Asghar, M.S., Arslan, S., Kim, H., Low Power Spiking Neural Network Circuit with Compact Synapse and Neuron Cells Proceedings of the 2020 International SoC Design Conference, pp. 157-158. , Yeosu, Korea, 21–24 October 2020; Dutta, S., Kumar, V., Shukla, A., Mohapatra, N.R., Ganguly, U., Leaky Integrate and Fire Neuron by Charge‐Discharge Dynamics in Floating‐Body MOSFET (2017) Sci. Rep, 7, p. 8257; Indiveri, G., Chicca, E., Douglas, R., A VLSI Array of Low‐Power Spiking Neurons and Bistable Synapses with Spike‐Timing Dependent Plasticity (2006) IEEE Trans. Neural Netw, 17, pp. 211-221; Tang, H., Kim, H., Cho, D., Park, J., Spike Counts Based Low Complexity Learning with Binary Synapse Proceedings of the 2018 International Joint Conference on Neural Networks, pp. 1-8. , Rio de Janeiro, Brazil, 8–13 July 2018","Kim, H.; Department of Electronics Engineering, Chungdae‐ro 1, Seowon‐gu, South Korea; email: hwkim@chungbuk.ac.kr",,,"MDPI AG",,,,,14248220,,,"34210045","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85108778220
"Knaak C., von Eßen J., Kröger M., Schulze F., Abels P., Gillner A.","57195201807;57224626093;57206397362;57220467852;6507270916;6603756860;","A spatio-temporal ensemble deep learning architecture for real-time defect detection during laser welding on low power embedded computing boards",2021,"Sensors","21","12","4205","","",,5,"10.3390/s21124205","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108100229&doi=10.3390%2fs21124205&partnerID=40&md5=b7ea760fddaf7146b0c35d4e9c32b5d8","Fraunhofer-Institute for Laser Technology ILT, Steinbachstrasse 15, Aachen, 52074, Germany; Faculty of Mechanical Engineering, RWTH Aachen University, Steinbachstrasse 15, Aachen, 52074, Germany","Knaak, C., Fraunhofer-Institute for Laser Technology ILT, Steinbachstrasse 15, Aachen, 52074, Germany; von Eßen, J., Fraunhofer-Institute for Laser Technology ILT, Steinbachstrasse 15, Aachen, 52074, Germany; Kröger, M., Faculty of Mechanical Engineering, RWTH Aachen University, Steinbachstrasse 15, Aachen, 52074, Germany; Schulze, F., Fraunhofer-Institute for Laser Technology ILT, Steinbachstrasse 15, Aachen, 52074, Germany; Abels, P., Fraunhofer-Institute for Laser Technology ILT, Steinbachstrasse 15, Aachen, 52074, Germany; Gillner, A., Fraunhofer-Institute for Laser Technology ILT, Steinbachstrasse 15, Aachen, 52074, Germany, Faculty of Mechanical Engineering, RWTH Aachen University, Steinbachstrasse 15, Aachen, 52074, Germany","In modern production environments, advanced and intelligent process monitoring strategies are required to enable an unambiguous diagnosis of the process situation and thus of the final component quality. In addition, the ability to recognize the current state of product quality in real-time is an important prerequisite for autonomous and self-improving manufacturing systems. To address these needs, this study investigates a novel ensemble deep learning architecture based on convolutional neural networks (CNN), gated recurrent units (GRU) combined with high-performance classification algorithms such as k-nearest neighbors (kNN) and support vector machines (SVM). The architecture uses spatio-temporal features extracted from infrared image sequences to locate critical welding defects including lack of fusion (false friends), sagging, lack of penetration, and geometric deviations of the weld seam. In order to evaluate the proposed architecture, this study investigates a comprehensive scheme based on classical machine learning methods using manual feature extraction and state-of-the-art deep learning algorithms. Optimal hyperparameters for each algorithm are determined by an extensive grid search. Additional work is conducted to investigate the significance of various geometrical, statistical and spatio-temporal features extracted from the keyhole and weld pool regions. The proposed method is finally validated on previously unknown welding trials, achieving the highest detection rates and the most robust weld defect recognition among all classification methods investigated in this work. Ultimately, the ensemble deep neural network is implemented and optimized to operate on low-power embedded computing devices with low latency (1.1 ms), demonstrating sufficient performance for real-time applications. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","AI edge device; Convolutional neural network; Feature importance; High-speed infrared imaging; Lack of fusion (false friends); Real-time process monitoring; Recurrent neural network","Computer architecture; Convolutional neural networks; Deep neural networks; Defects; Infrared imaging; Learning systems; Low power electronics; Manufacture; Nearest neighbor search; Network architecture; Process monitoring; Real time systems; Recurrent neural networks; Support vector machines; Welding; Welds; Classification algorithm; Classification methods; Embedded computing devices; Infrared image sequence; K nearest neighbor (KNN); Machine learning methods; Production environments; Spatio temporal features; Learning algorithms; algorithm; laser; welding; Algorithms; Deep Learning; Lasers; Neural Networks, Computer; Welding",,,,,"Horizon 2020 Framework Programme, H2020: 637081, 825030","Funding: This work is under the framework of EU projects QU4LITY and MAShES. These projects have received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 825030 and No 637081, respectively. The dissemination of results herein reflects only the authors’ views, and the Commission is not responsible for any use that may be made of the information it contains.",,,,,,,,,,"You, D.Y., Gao, X.D., Katayama, S., Review of laser welding monitoring (2013) Sci. Technol. Weld. Join, 19, pp. 181-201; Shao, J., Yan, Y., Review of techniques for on-line monitoring and inspection of laser welding (2005) J. Phys. Conf. Ser, 15, pp. 101-107; Stavridis, J., Papacharalampopoulos, A., Stavropoulos, P., Quality assessment in laser welding: A critical review (2017) Int. J. Adv. Manuf. Technol, 94, pp. 1825-1847; Kim, C., Ahn, D.-C., Coaxial monitoring of keyhole during Yb:YAG laser welding (2012) Opt. Laser Technol, 44, pp. 1874-1880; Courtois, M., Carin, M., Le Masson, P., Gaied, S., Balabane, M., A complete model of keyhole and melt pool dynamics to analyze instabilities and collapse during laser welding (2014) J. Laser Appl, 26, p. 042001; Saeed, G., Zhang, Y.M., Weld pool surface depth measurement using a calibrated camera and structured light (2007) Meas. Sci. Technol, 18, pp. 2570-2578; Bertrand, P., Smurov, I., Grevey, D., Application of near infrared pyrometry for continuous Nd:YAG laser welding of stainless steel (2000) Appl. Surf. Sci, 168, pp. 182-185; Kong, F., Ma, J., Carlson, B., Kovacevic, R., Real-time monitoring of laser welding of galvanized high strength steel in lap joint configuration (2012) Opt. Laser Technol, 44, pp. 2186-2196; Purtonen, T., Kalliosaari, A., Salminen, A., Monitoring and Adaptive Control of Laser Processes (2014) Phys. Proc, 56, pp. 1218-1231; Zhang, Y., Zhang, C., Tan, L., Li, S., Coaxial monitoring of the fibre laser lap welding of Zn-coated steel sheets using an auxiliary illuminant (2013) Opt. Laser Technol, 50, pp. 167-175; Knaak, C., Kolter, G., Schulze, F., Kröger, M., Abels, P., Deep learning-based semantic segmentation for in-process monitoring in laser welding applications (2019) Appl. Mach. Learn, 11139, p. 1113905; Tenner, F., Riegel, D., Mayer, E., Schmidt, M., Analytical model of the laser welding of zinc-coated steel sheets by the aid of videography (2017) J. Laser Appl, 29, p. 22411; Schmidt, M., Otto, A., Kägeler, C., Analysis of YAG laser lap-welding of zinc coated steel sheets (2008) CIRP Ann, 57, pp. 213-216; Wuest, T., Weimer, D., Irgens, C., Thoben, K.-D., Machine learning in manufacturing: Advantages, challenges, and applications (2016) Prod. Manuf. Res, 4, pp. 23-45; Xing, B., Xiao, Y., Qin, Q.H., Cui, H., Quality assessment of resistance spot welding process based on dynamic resistance signal and random forest based (2017) Int. J. Adv. Manuf. Technol, 94, pp. 327-339; Knaak, C., Thombansen, U., Abels, P., Kröger, M., Machine learning as a comparative tool to determine the relevance of signal features in laser welding (2018) Procedia CIRP, 74, pp. 623-627; Jager, M., Hamprecht, F., Principal Component Imagery for the Quality Monitoring of Dynamic Laser Welding Processes (2008) IEEE Trans. Ind. Electron, 56, pp. 1307-1313; You, D., Gao, X., Katayama, S., WPD-PCA-Based Laser Welding Process Monitoring and Defects Diagnosis by Using FNN and SVM (2015) IEEE Trans. Ind. Electron, 62, pp. 628-636; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Netw, 61, pp. 85-117; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.-R., Jaitly, N., Senior, A., Sainath, T.N., Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups (2012) IEEE Signal Process. Mag, 29, pp. 82-97; Kruger, N., Janssen, P., Kalkan, S., Lappe, M., Leonardis, A., Piater, J., Rodriguez-Sanchez, A.J., Wiskott, L., Deep Hierarchies in the Primate Visual Cortex: What Can We Learn for Computer Vision? (2013) IEEE Trans. Pattern Anal. Mach. Intell, 35, pp. 1847-1871; Mohamed, A.-R., Sainath, T.N., Dahl, G.E., Ramabhadran, B., Hinton, G.E., Picheny, M.A., Deep Belief Networks using discrim-inative features for phone recognition Proceedings of the 2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5060-5063. , Prague, Czech Republic, 22–27 May 2011; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2017) Commun. ACM, 60, pp. 84-90; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Devin, M., (2015) Tensor-Flow: Large-Scale Machine Learning on Heterogeneous Systems, , http://tensorflow.org/, (accessed on 12 May 2021); Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Antiga, L., PyTorch: An Imperative Style, High-Performance Deep Learning Library (2019) Advances in Neural Information Processing Systems, 32, pp. 8024-8035. , Wallach, H., Larochelle, H., Beygelzimer, A., Alché-Buc, F.D., Fox, E., Garnett, R., Eds.; Curran Associates Inc.: New York, NY, USA; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding, , http://arxiv.org/pdf/1408.5093v1, (accessed on 10 May 2021); Wang, J., Ma, Y., Zhang, L., Gao, R.X., Wu, D., Deep learning for smart manufacturing: Methods and applications (2018) J. Manuf. Syst, 48, pp. 144-156; Knaak, C., Masseling, L., Duong, E., Abels, P., Gillner, A., Improving Build Quality in Laser Powder Bed Fusion Using High Dynamic Range Imaging and Model-Based Reinforcement Learning (2021) IEEE Access, 9, pp. 55214-55231; Xue, B., Chang, B., Du, D., Multi-Output Monitoring of High-Speed Laser Welding State Based on Deep Learning (2021) Sensors, 21, p. 1626; Božic, A., Kos, M., Jezeršek, M., Power Control during Remote Laser Welding Using a Convolutional Neural Network (2020) Sensors, 20, p. 6658; Zhang, Z., Li, B., Zhang, W., Lu, R., Wada, S., Zhang, Y., Real-time penetration state monitoring using convolutional neural network for laser welding of tailor rolled blanks (2020) J. Manuf. Syst, 54, pp. 348-360; Günther, J., Pilarski, P.M., Helfrich, G., Shen, H., Diepold, K., First Steps Towards an Intelligent Laser Welding Architecture Using Deep Neural Networks and Reinforcement Learning (2014) Procedia Technol, 15, pp. 474-483; Gonzalez-Val, C., Pallas, A., Panadeiro, V., Rodriguez, A., A convolutional approach to quality monitoring for laser manufacturing (2019) J. Intell. Manuf, 31, pp. 789-795; Liu, T., Bao, J., Wang, J., Zhang, Y., A Hybrid CNN–LSTM Algorithm for Online Defect Recognition of CO2 Welding (2018) Sensors, 18, p. 4369; Ouyang, X., Xu, S., Zhang, C., Zhou, P., Yang, Y., Liu, G., Li, X., A 3D-CNN and LSTM Based Multi-Task Learning Architecture for Action Recognition (2019) IEEE Access, 7, pp. 40757-40770; Fan, Y., Lu, X., Li, D., Liu, Y., Video-based emotion recognition using CNN-RNN and C3D hybrid networks Proceedings of the 18th ACM International Conference on Multimodal Interaction, pp. 445-450. , Tokyo, Japan, 12–16 November 2016; Ordóñez, F.J., Roggen, D., Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition (2016) Sensors, 16, p. 115; Valiente, R., Zaman, M., Ozer, S., Fallah, Y.P., Controlling Steering Angle for Cooperative Self-driving Vehicles utilizing CNN and LSTM-based Deep Networks Proceedings of the 30th IEEE Intelligent Vehicles Symposium, pp. 2423-2428. , Paris, France, 9–12 June 2019; Yin, W., Kann, K., Yu, M., Schütze, H., (2017) Comparative Study of CNN and RNN for Natural Language Processing, , http://arxiv.org/pdf/1702.01923v1, (accessed on 12 May 2021); He, K., Zhang, X., Ren, S., Sun, J., (2016) Identity Mappings in Deep Residual Networks, , https://arxiv.org/pdf/1603.05027, (accessed on 12 May 2021); Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L., Mobilenetv2: Inverted Residuals and Linear Bottlenecks Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4510-4520. , 39 Salt Lake City, UT, USA, 18 23 June 2018; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., (2015) Rethinking the Inception Architecture for Computer Vision, , https://arxiv.org/pdf/1512.00567, (accessed on 11 May 2021); Bishop, C.M., Pattern recognition and machine learning (2006) Information Science and Statistics, pp. 21-24. , Springer: New York, NY, USA, ISBN 9780387310732; Nixon, M.S., Aguado, A.S., (2012) Feature Extraction & Image Processing for Computer Vision, , (Eds) 3rd ed.; Academic Press: Oxford, UK, ISBN 9780123965493; Runkler, T.A., (2012) Data Analytics: Models and Algorithms for Intelligent Data Analysis, , Vieweg+Teubner Verlag: Wiesbaden, Germany, ISBN 9783834825889; Raschka, S., (2016) Python Machine Learning: Unlock Deeper Insights into Machine Learning with this Vital Guide to Cutting-Edge Predictive Analytics, , Packt Publishing Open Source: Birmingham, UK, ISBN 9781783555130; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Duchesnay, E., Scikit-learn: Machine Learning in Python (2011) J. Mach. Learn. Res, 12, pp. 2825-2830; Lee, K.B., Cheon, S., Kim, C.O., A Convolutional Neural Network for Fault Classification and Diagnosis in Semiconductor Manufacturing Processes (2017) IEEE Trans. Semicond. Manuf, 30, pp. 135-142; Arif, S., Wang, J., Hassan, T.U., Fei, Z., 3D-CNN-Based Fused Feature Maps with LSTM Applied to Action Recognition (2019) Futur. Internet, 11, p. 42; Kim, D., Cho, H., Shin, H., Lim, S.-C., Hwang, W., An Efficient Three-Dimensional Convolutional Neural Network for Inferring Physical Interaction Force from Video (2019) Sensors, 19, p. 3579; Zhu, G., Zhang, L., Shen, P., Song, J., Multimodal Gesture Recognition Using 3-D Convolution and Convolutional LSTM (2017) IEEE Access, 5, pp. 4517-4524; Ullah, A., Ahmad, J., Muhammad, K., Sajjad, M., Baik, S.W., Action Recognition in Video Sequences using Deep Bi-Directional LSTM With CNN Features (2018) IEEE Access, 6, pp. 1155-1166; Rana, R., (2016) Gated Recurrent Unit (GRU) for Emotion Classification from Noisy Speech, , http://arxiv.org/pdf/1612.07778v1, (accessed on 11 May 2021); Cho, K., van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., (2014) Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation, , http://arxiv.org/pdf/1406.1078v3, (accessed on 11 May 2021); Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9, pp. 1735-1780; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, , arXiv arXiv:1412.3555; Ganaie, M.A., Hu, M., Tanveer, M., Suganthan, P.N., (2021) Ensemble Deep Learning: A Review, , https://arxiv.org/pdf/2104.02395, (accessed on 11 May 2021); DeWitt, D.P., Nutter, G.D., (1988) Theory and Practice of Radiation Thermometry, , John Wiley and Sons: New York, NY, USA; Suzuki, S., Be, K., Topological structural analysis of digitized binary images by border following (1985) Comput. Vis. Graph. Image Process, 30, pp. 32-46; (2018) Welding—Electron and Laser-Beam Welded Joints—Guidance on Quality Levels for Imperfections—Part 1: Steel, Nickel, Titanium and Their Alloys, , https://www.iso.org/obp/ui/#iso:std:iso:13919:-1:ed-2:v1:en, ISO 13919-1: International Standard ISO 13919-1:2018, (accessed on 05 June 2021); (2007) Classification of Geometric Imperfections in Metallic Materials—Part 1: Fusion welding, , https://www.iso.org/obp/ui/#iso:std:iso:6520:-1:ed-2:v1:en, ISO 6520-1: International Standard ISO 6520-1:2007, (accessed on 05 June 2021); Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , The MIT Press: Cambridge, MA, USA, ISBN 978-0-262-03561-3; Sun, C., Shrivastava, A., Singh, S., Gupta, A., Revisiting unreasonable effectiveness of data in deep learning era Proceedings of the IEEE International Conference on Computer Vision, pp. 843-852. , Venice, Italy, 22–29 October 2017; Zongker, D., Jain, A., Algorithms for feature selection: An evaluation (1996) Proceedings of the 13th International Conference on Pattern Recognition, 2, pp. 18-22. , Vienna, Austria, 29 August; Kotsiantis, S., Kanellopoulos, D., Pintelas, P., Handling imbalanced datasets: A review (2005) GESTS Int. Trans. Comput. Sci. Eng, 30, pp. 25-36; Chawla, N.V., Bowyer, K.W., Hall, L.O., Kegelmeyer, W.P., SMOTE: Synthetic minority over-sampling technique (2002) J. Artif. Intell. Res, 16, pp. 321-357; Bifet, A., Gavaldà, R., Learning from Time-Changing Data with Adaptive Windowing Proceedings of the 2007 SIAM International Conference on Data Mining, pp. 443-448. , Minneapolis, MN, USA, 26–28 April 2007; Lu, J., Liu, A., Dong, F., Gu, F., Gama, J., Zhang, G., Learning under Concept Drift: A Review (2018) IEEE Trans. Knowl. Data Eng, p. 1; NVIDIA TensorRT: SDK for High-Performance Deep Learning Inference, , https://developer.nvidia.com/tensorrt, NVIDIA Corporation. (accessed on 5 June 2021); Fitzgibbon, A.W., Fisher, R.B., A Buyer’s Guide to Conic Fitting (1995) Proceedings of the 6th British Machine Vision Conference, 51, pp. 1-10. , Birmingham, UK, 11–14 September","Knaak, C.; Fraunhofer-Institute for Laser Technology ILT, Steinbachstrasse 15, Germany; email: christian.knaak@ilt.fraunhofer.de",,,"MDPI AG",,,,,14248220,,,"34207475","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85108100229
"Signoretti G., Silva M., Andrade P., Silva I., Sisinni E., Ferrari P.","57192920994;57207807053;57225443488;36537969500;24777116800;57195277194;","An evolving tinyml compression algorithm for iot environments based on data eccentricity",2021,"Sensors","21","12","4153","","",,7,"10.3390/s21124153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107982881&doi=10.3390%2fs21124153&partnerID=40&md5=e5a531080c0a802966382b71021c8844","UFRN-PPgEEC, Federal University of Rio Grande do Norte, Natal, 59078-970, Brazil; UNIBS-DIE, Department of Information Engineering, University of Brescia, Brescia, 25123, Italy","Signoretti, G., UFRN-PPgEEC, Federal University of Rio Grande do Norte, Natal, 59078-970, Brazil; Silva, M., UFRN-PPgEEC, Federal University of Rio Grande do Norte, Natal, 59078-970, Brazil; Andrade, P., UFRN-PPgEEC, Federal University of Rio Grande do Norte, Natal, 59078-970, Brazil; Silva, I., UFRN-PPgEEC, Federal University of Rio Grande do Norte, Natal, 59078-970, Brazil; Sisinni, E., UNIBS-DIE, Department of Information Engineering, University of Brescia, Brescia, 25123, Italy; Ferrari, P., UNIBS-DIE, Department of Information Engineering, University of Brescia, Brescia, 25123, Italy","Currently, the applications of the Internet of Things (IoT) generate a large amount of sensor data at a very high pace, making it a challenge to collect and store the data. This scenario brings about the need for effective data compression algorithms to make the data manageable among tiny and battery-powered devices and, more importantly, shareable across the network. Additionally, considering that, very often, wireless communications (e.g., low-power wide-area networks) are adopted to connect field devices, user payload compression can also provide benefits derived from better spectrum usage, which in turn can result in advantages for high-density application scenarios. As a result of this increase in the number of connected devices, a new concept has emerged, called TinyML. It enables the use of machine learning on tiny, computationally restrained devices. This allows intelligent devices to analyze and interpret data locally and in real time. Therefore, this work presents a new data compression solution (algorithm) for the IoT that leverages the TinyML perspective. The new approach is called the Tiny Anomaly Compressor (TAC) and is based on data eccentricity. TAC does not require previously established mathematical models or any assumptions about the underlying data distribution. In order to test the effectiveness of the proposed solution and validate it, a comparative analysis was performed on two real-world datasets with two other algorithms from the literature (namely Swing Door Trending (SDT) and the Discrete Cosine Transform (DCT)). It was found that the TAC algorithm showed promising results, achieving a maximum compression rate of 98.33%. Additionally, it also surpassed the two other models regarding the compression error and peak signal-to-noise ratio in all cases. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Eccentricity; Evolving algorithm; Internet of things; LPWAN; Online data compression; TinyML","Data compression; Discrete cosine transforms; Image coding; Low power electronics; Signal to noise ratio; Wide area networks; Battery powered devices; Compression algorithms; Data compression algorithms; Discrete Cosine Transform(DCT); High-density applications; Internet of thing (IOT); Peak signal to noise ratio; Wireless communications; Internet of things; algorithm; article; comparative effectiveness; data compression; discrete cosine transform; internet of things; machine learning; signal noise ratio",,,,,"Coordenação de Aperfeiçoamento de Pessoal de Nível Superior, CAPES; Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq: 435683/2018-7","Acknowledgments: We thank Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES) and the National Council for Scientific and Technological Development (CNPq).","Funding: This study was financed in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES), Finance Code 001, and we thank the Brazilian fostering agency CNPq (National Council for Scientific and Technological Development), Process No. 435683/2018-7.",,,,,,,,,"Marafie, Z., Lin, K., Zhai, Y., Li, J., ProActive Fintech: Using Intelligent IoT to Deliver Positive InsurTech Feedback (2018) Proceedings of the 2018 IEEE 20th Conference on Business Informatics (CBI), 2, pp. 72-81. , Vienna, Austria, 11–14 July; Zanella, A., Bui, N., Castellani, A., Vangelista, L., Zorzi, M., Internet of things for smart cities (2014) IEEE Internet Things J, 1, pp. 22-32. , [CrossRef]; Diniz da Silva, M.B., Vieira, E., Silva, I., Silva, D., Ferrari, P., Rinaldi, S., Carvalho, D.F., A customer feedback platform for vehicle manufacturing in Industry 4.0 Proceedings of the 2018 IEEE Symposium on Computers and Communications (ISCC), pp. 1249-1254. , Natal, Brazil, 25–28 June 2018; Al Homssi, B., Al-Hourani, A., Magowe, K., Delaney, J., Tom, N., Ying, J., Wolf, H., Wang, K., A Framework for the Design and Deployment of Large-Scale LPWAN Network for Smart Cities Applications (2020) IEEE Internet Things Mag, , [CrossRef]; Silva, M., Vieira, E., Signoretti, G., Silva, I., Silva, D., Ferrari, P., A Customer Feedback Platform for Vehicle Manufacturing Compliant with Industry 4.0 Vision (2018) Sensors, 18, p. 3298. , [CrossRef]; Zhang, Z., Li, C., Peng, S., Pei, X., A new task offloading algorithm in edge computing (2021) EURASIP J. Wirel. Commun. Netw, 2021, p. 17. , [CrossRef]; Banbury, C., Zhou, C., Fedorov, I., Matas, R., Thakker, U., Gope, D., Janapa Reddi, V., Whatmough, P., Micronets: Neural Network Architectures for Deploying Tinyml Applications on Commodity Microcontrollers, , https://proceedings.mlsys.org/paper/2021/file/a3c65c2974270fd093ee8a9bf8ae7d0b-Paper.pdf, (accessed on 16 June 2021); Magsi, H., Sodhro, A.H., Zahid, N., Pirbhulal, S., Wang, L., Al-Rakhami, M.S., A Novel Adaptive Battery-Aware Algorithm for Data Transmission in IoT-Based Healthcare Applications (2021) Electronics, 10, p. 367. , [CrossRef]; Azar, J., Makhoul, A., Barhamgi, M., Couturier, R., An energy efficient IoT data compression approach for edge machine learning (2019) Future Gener. Comput. Syst, 96, pp. 168-175. , [CrossRef]; Lounas, R., Salhi, D.E., Mokrani, H., Djerbi, R., Bennai, M.T., Towards a Smart Data Transmission Strategy for IoT Monitoring Systems: Application to Air Quality Monitoring Proceedings of the 2019 International Conference on Theoretical and Applicative Aspects of Computer Science (ICTAACS), 1, pp. 1-7. , Skikda, Algeria, 15–16 December 2019; Correa, J.D.A., Pinto, A.S.R., Montez, C., Leão, E., Swinging Door Trending Compression Algorithm for IoT Environments (2019) Anais do IX Simpósio Brasileiro de Engenharia de Sistemas Computacionais, pp. 143-148. , SBC: Porto Alegre, Brasil; Signoretti, G., Silva, M., Araujo, J., Silva, I., Silva, D., Ferrari, P., Sisinni, E., A Dependability Evaluation for OBD-II Edge Devices: An Internet of Intelligent Vehicles Perspective Proceedings of the 2019 9th Latin-American Symposium on Dependable Computing (LADC), pp. 1-9. , Natal, Brazil, 19–21 November 2019; Sodhro, A.H., Sangaiah, A.K., Sodhro, G.H., Lohano, S., Pirbhulal, S., An energy-efficient algorithm for wearable electrocardiogram signal processing in ubiquitous healthcare applications (2018) Sensors, 18, p. 923. , [CrossRef]; Yamaoka, H., Itakura, K., Takahashi, E., Nakagawa, G., Michaelis, J., Kanemasa, Y., Ueki, M., Inoue, D., Dracena: A Real-Time IoT Service Platform Based on Flexible Composition of Data Streams Proceedings of the 2019 IEEE/SICE International Symposium on System Integration (SII), pp. 596-601. , Paris, France, 14–16 January 2019; Shukla, A., Simmhan, Y., Benchmarking distributed stream processing platforms for iot applications Proceedings of the Technology Conference on Performance Evaluation and Benchmarking 2016, pp. 90-106. , New Delhi, India, 5–9 September 2016; Lu, T., Xia, W., Zou, X., Xia, Q., Adaptively Compressing IoT Data on the Resource-Constrained Edge, , https://www.usenix.org/conference/hotedge20/presentation/lu, (accessed on 16 June 2021); Uthayakumar, J., Vengattaraman, T., Dhavachelvan, P., A survey on data compression techniques: From the perspective of data quality, coding schemes, data type and applications (2018) J. King Saud Univ. Comput. Inf. Sci, , [CrossRef]; Ferrari, P., Sisinni, E., Carvalho, D.F., Signoretti, G., da Silva, M.D., Silva, I., Silva, D., Using LoRaWAN smart city infrastructure as backup network for Industry 4.0 enabled vehicles (2019) Anais do IX Simpósio Brasileiro de Engenharia de Sistemas Computacionais, pp. 119-124. , SBC: Porto Alegre, Brasil; Sisinni, E., Ferrari, P., Fernandes Carvalho, D., Rinaldi, S., Pasetti, M., Flammini, A., Depari, A., A LoRaWAN range extender for Industrial IoT (2019) IEEE Trans. Ind. Inform, 16, p. 1. , [CrossRef]; Georgiou, O., Raza, U., Low power wide area network analysis: Can LoRa scale? (2017) IEEE Wirel. Commun. Lett, 6, pp. 162-165. , [CrossRef]; Hu, Z., Wang, D., Li, Z., Sun, M., Wang, W., Differential Compression for Mobile Edge Computing in Internet of Vehicles Proceedings of the 2019 International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob), pp. 336-341. , Barcelona, Spain, 21–23 October 2019; Nobre, M., Silva, I., Guedes, L.A., Portugal, P., Towards a WirelessHART module for the ns-3 simulator Proceedings of the 2010 IEEE 15th Conference on Emerging Technologies Factory Automation (ETFA 2010), pp. 1-4. , Bilbao, Spain, 13–16 September 2010; Fedorov, I., Adams, R.P., Mattina, M., Whatmough, P., Sparse: Sparse architecture search for CNNs on resource-constrained microcontrollers Proceedings of the Advances in Neural Information Processing Systems, pp. 4978-4990. , Vancouver, BC, Canada, 8–14 December 2019; Porambage, P., Okwuibe, J., Liyanage, M., Ylianttila, M., Taleb, T., Survey on multi-access edge computing for internet of things realization (2018) IEEE Commun. Surv. Tutor, 20, pp. 2961-2991. , [CrossRef]; Mikhaylov, K., Petrov, V., Gupta, R., Lema, M.A., Galinina, O., Andreev, S., Koucheryavy, Y., Dohler, M., Energy Efficiency of Multi-Radio Massive Machine-Type Communication (MR-MMTC): Applications, Challenges, and Solutions (2019) IEEE Commun. Mag, 57, pp. 100-106. , [CrossRef]; Mao, Y., You, C., Zhang, J., Huang, K., Letaief, K.B., A Survey on Mobile Edge Computing: The Communication Perspective (2017) IEEE Commun. Surv. Tutor, 19, pp. 2322-2358. , [CrossRef]; Maitra, S., Richards, D., Abdelgawad, A., Yelamarthi, K., Performance Evaluation of IoT Encryption Algorithms: Memory, Timing, and Energy Proceedings of the 2019 IEEE Sensors Applications Symposium (SAS), pp. 1-6. , Sophia Antipolis, France, 11–13 March 2019; Premsankar, G., Di Francesco, M., Taleb, T., Edge Computing for the Internet of Things: A Case Study (2018) IEEE Internet Things J, 5, pp. 1275-1284. , [CrossRef]; Wang, X., Magno, M., Cavigelli, L., Benini, L., FANN-on-MCU: An open-source toolkit for energy-efficient neural network inference at the edge of the Internet of Things (2020) IEEE Internet Things J, 7, pp. 4403-4417. , [CrossRef]; Guberovic, E., Krišto, F., Krivic, P., Cavrak, I., Assessing compression algorithms on IoT sensor nodes Proceedings of the 2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO), pp. 913-918. , Opatija, Croatia, 20–24 May 2019; Mahdavinejad, M., Rezvan, M., Barekatain, M., Adibi, P., Barnaghi, P., Sheth, A., Machine learning for internet of things data analysis: A survey (2018) Digit. Commun. Netw, 4, pp. 161-175. , [CrossRef]; Gorospe, J., Mulero, R., Arbelaitz, O., Muguerza, J., Antón, M.Á., A Generalization Performance Study Using Deep Learning Networks in Embedded Systems (2021) Sensors, 21, p. 1031. , [CrossRef]; Gopinath, S., Ghanathe, N., Seshadri, V., Sharma, R., Compiling KB-sized machine learning models to tiny IoT devices Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 79-95. , Phoenix, AZ, USA, 22–26 June 2019; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Trans. Pattern Anal. Mach. Intell, 35, pp. 1798-1828. , [CrossRef]; Zoppi, T., Ceccarelli, A., Bondavalli, A., Into the Unknown: Unsupervised Machine Learning Algorithms for Anomaly-Based Intrusion Detection Proceedings of the 2020 50th Annual IEEE-IFIP International Conference on Dependable Systems and Networks-Supplemental Volume (DSN-S), , Valencia, Spain, 29 June–2 July 2020; Angelov, P.P., Gu, X., (2019) Empirical Approach to Machine Learning, , Springer: Berlin/Heidelberg, Germany; Angelov, P., Anomaly detection based on eccentricity analysis Proceedings of the 2014 IEEE Symposium on Evolving and Autonomous Learning Systems (EALS), pp. 1-8. , Orlando, FL, USA, 9–12 December 2014; Signoretti, G., Silva, M., Araujo, J., Guedes, L.A., Silva, I., Sisinni, E., Ferrari, P., Performance Evaluation of an evolving data compression algorithm embedded into an OBD-II edge device Proceedings of the 2020 IEEE International Workshop on Metrology for Industry 4.0 IoT, pp. 696-701. , Roma, Italy, 3–5 June 2020; Yu, X., Peng, Y., Li, F., Wang, S., Shen, X., Mai, H., Xie, Y., Two-Level Data Compression using Machine Learning in Time Series Database Proceedings of the 2020 IEEE 36th International Conference on Data Engineering (ICDE), pp. 1333-1344. , Dallas, TX, USA, 20–24 April 2020; Hamdan, S., Awaian, A., Almajali, S., Compression Techniques Used in Iot: A Comparitive Study Proceedings of the 2019 2nd International Conference on new Trends in Computing Sciences (ICTCS), pp. 1-5. , Amman, Jordan, 9–11 October 2019; Moon, A., Kim, J., Zhang, J., Son, S.W., Evaluating fidelity of lossy compression on spatiotemporal data from an IoT enabled smart farm (2018) Comput. Electron. Agric, 154, pp. 304-313. , [CrossRef]; Silva, I.M.D., Guedes, L.A., Vasques, F., Performance evaluation of a compression algorithm for wireless sensor networks in monitoring applications Proceedings of the 2008 IEEE International Conference on Emerging Technologies and Factory Automation, pp. 672-678. , Hamburg, Germany, 15–18 September 2008; Bristol, E.H., Swinging door trending: Adaptive trend recording (1990) Proceedings of the ISA National Conference, pp. 749-753. , https://ci.nii.ac.jp/naid/10030606241/, (accessed on 16 June 2021); Xu, X.-D., Fu, Y.-P., The Research and Improvement of SDT Algorithm for Historical Data in SCADA (2017) ITM Web Conf, 11, p. 01009. , [CrossRef]; Neto, E.J.M., Augusto, L., Souza, D.C., Guedes, L.A., Adaptive Swinging Door Trending: Um Algoritmo Adaptativo para Compressão de Dados em Tempo Real (2014) Proceedings of the Anais do XX Congresso Brasileiro de Automática, , Belo Horizonte, Brazil, 20–24 September; Gibson, J.K., Lee, D., Choi, J., Sim, A., Dynamic Online Performance Optimization in Streaming Data Compression Proceedings of the 2018 IEEE International Conference on Big Data (Big Data), pp. 534-541. , Seattle, WA, USA, 10–13 December 2018; Park, J., Park, H., Choi, Y., Data compression and prediction using machine learning for industrial IoT Proceedings of the 2018 International Conference on Information Networking (ICOIN), pp. 818-820. , Chiang Mai, Thailand, 10–12 January 2018; Angelov, P., Outside the Box: An Alternative Data Analytics Framework (2014) J. Autom. Mob. Robot. Intell. Syst, 8, pp. 29-35. , [CrossRef]; Sielly Jales Costa, B., Bezerra, C.G., Guedes, L.A., Angelov, P.P., Online fault detection based on Typicality and Eccentricity Data Analytics Proceedings of the 2015 International Joint Conference on Neural Networks (IJCNN), pp. 1-6. , Killarney, Ireland, 12–17 July 2015; Bezerra, C.G., Sielly Jales Costa, B., Guedes, L.A., Angelov, P.P., A new evolving clustering algorithm for online data streams Proceedings of the 2016 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS), pp. 162-168. , Natal, Brazil, 23–25 May 2016; Angelov, P.P., Gu, X., Gutierrez, G., Iglesias, J.A., Sanchis, A., Autonomous Data Density based clustering method Proceedings of the 2016 International Joint Conference on Neural Networks (IJCNN), pp. 2405-2413. , Vancouver, BC, Canada, 24–29 July 2016; Kangin, D., Angelov, P., Iglesias, J.A., Autonomously evolving classifier TEDAClass (2016) Inf. Sci, 366, pp. 1-11. , [CrossRef]; Angelov, P., Typicality distribution function—A new density-based data analytics tool Proceedings of the 2015 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , Killarney, Ireland, 12–17 July 2015; Kangin, D., Angelov, P., Iglesias, J., Sanchis de Miguel, A., Evolving classifier TEDAClass for big data (2015) Procedia Comput. Sci, 53, pp. 9-18. , [CrossRef]; Martins, R.S., Angelov, P., Sielly Jales Costa, B., Automatic Detection of Computer Network Traffic Anomalies based on Eccentricity Analysis Proceedings of the 2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE), pp. 1-8. , Rio de Janeiro, Brazil, 8–13 July 2018; Saw, J.G., Yang, M.C.K., Mo, T.C., Chebyshev Inequality with Estimated Mean and Variance (1984) Am. Stat, 38, pp. 130-132; Balanda, K.P., MacGillivray, H., Kurtosis: A critical review (1988) Am. Stat, 42, pp. 111-119; Flammini, A., Pasetti, M., Rinaldi, S., Bellagente, P., Ciribini, A.C., Tagliabue, L.C., Zavanella, L.E., Pedrazzi, G., A Living Lab and Testing Infrastructure for the Development of Innovative Smart Energy Solutions: The eLUX Laboratory of the University of Brescia Proceedings of the 2018 AEIT International Annual Conference, pp. 1-6. , Bari, Italy, 3–5 October 2018; Rinaldi, S., Pasetti, M., Flammini, A., Ferrari, P., Sisinni, E., Simoncini, F., A Testing Framework for the Monitoring and Performance Analysis of Distributed Energy Systems (2019) IEEE Trans. Instrum. Meas, 68, pp. 3831-3840. , [CrossRef]; Jin, F., Fieguth, P., Winger, L., Jernigan, E., Adaptive Wiener filtering of noisy images and image sequences (2003) Proceedings of the 2003 International Conference on Image Processing (Cat. No.03CH37429), 3. , Barcelona, Spain, 14–17 September; Yoo, J.C., Han, T.H., Fast normalized cross-correlation (2009) Circuits Syst. Signal Process, 28, pp. 819-843. , [CrossRef]; Tsai, D.M., Lin, C.T., Chen, J.F., The evaluation of normalized cross correlations for defect detection (2003) Pattern Recognit. Lett, 24, pp. 2525-2535. , [CrossRef]; Hand, D., Christen, P., A note on using the F-measure for evaluating record linkage algorithms (2018) Stat. Comput, 28, pp. 539-547. , [CrossRef]; Xu, Z., Fuzzy harmonic mean operators (2009) Int. J. Intell. Syst, 24, pp. 152-172. , [CrossRef]; Ferger, W.F., The nature and use of the harmonic mean (1931) J. Am. Stat. Assoc, 26, pp. 36-40. , [CrossRef]","Silva, M.; UFRN-PPgEEC, Brazil; email: marianne.silva.086@ufrn.edu.br
Silva, I.; UFRN-PPgEEC, Brazil; email: ivanovitch.silva@ufrn.br",,,"MDPI AG",,,,,14248220,,,"34204300","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85107982881
"Kim J., Cho J.","57215580048;57215917884;","Low-cost embedded system using convolutional neural networks-based spatiotemporal feature map for real-time human action recognition",2021,"Applied Sciences (Switzerland)","11","11","4940","","",,2,"10.3390/app11114940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107792764&doi=10.3390%2fapp11114940&partnerID=40&md5=424d6ae87a42297fa2d80cbe47c5654a","Department of Electrical Engineering, Soonchunhyang University, Asan, 31538, South Korea","Kim, J., Department of Electrical Engineering, Soonchunhyang University, Asan, 31538, South Korea; Cho, J., Department of Electrical Engineering, Soonchunhyang University, Asan, 31538, South Korea","The field of research related to video data has difficulty in extracting not only spatial but also temporal features and human action recognition (HAR) is a representative field of research that applies convolutional neural network (CNN) to video data. The performance for action recognition has improved, but owing to the complexity of the model, some still limitations to operation in real-time persist. Therefore, a lightweight CNN-based single-stream HAR model that can operate in real-time is proposed. The proposed model extracts spatial feature maps by applying CNN to the images that develop the video and uses the frame change rate of sequential images as time information. Spatial feature maps are weighted-averaged by frame change, transformed into spatiotemporal features, and input into multilayer perceptrons, which have a relatively lower complexity than other HAR models; thus, our method has high utility in a single embedded system connected to CCTV. The results of evaluating action recognition accuracy and data processing speed through challenging action recognition benchmark UCF-101 showed higher action recognition accuracy than the HAR model using long short-term memory with a small amount of video frames and confirmed the real-time operational possibility through fast data processing speed. In addition, the performance of the proposed weighted mean-based HAR model was verified by testing it in Jetson NANO to confirm the possibility of using it in low-cost GPU-based embedded systems. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","CNN; Embedded system; Human action recognition; Real-time; Spatiotemporal feature",,,,,,"Soonchunhyang University, SCH; Ministry of Environment, MOE: 2018R1D1A3B07041729; National Research Foundation of Korea, NRF","Funding: This research was funded by a National Research Foundation of Korea (NRF) grant funded by the Korean government (MOE) (No.2018R1D1A3B07041729) and the Soonchunhyang University Research Fund.",,,,,,,,,,"Qiu, Z., Yao, T., Ngo, C.W., Tian, X., Mei, T., Learning spatio-temporal representation with local and global diffusion Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 12056-12065. , Long Beach, CA, USA, 15–21 June 2019; Rawat, W., Wang, Z., Deep convolutional neural networks for image classification: A comprehensive review (2017) Neural Comput, 29, pp. 2352-2449. , [CrossRef]; Zhao, Z.-Q., Zheng, P., Xu, S.-T., Wu, X., Object detection with deep learning: A review (2019) IEEE Trans. Neural Netw. Learn. Syst, 30, pp. 3212-3232. , [CrossRef] [PubMed]; Wu, Q., Hu, F., Zhu, A., Wang, Z., Bao, Y., Learning spatial-temporal features via a pose-flow relational model for action recognition (2020) AIP Adv, 10, p. 075208. , [CrossRef]; Liu, A.-A., Xu, N., Nie, W.-Z., Su, Y.-T., Wong, Y., Kankanhalli, M., Benchmarking a multimodal and multiview and interactive dataset for human action recognition (2016) IEEE Trans. Cybern, 47, pp. 1781-1794. , [CrossRef] [PubMed]; Gao, Z., Zhang, Y., Zhang, H., Xue, Y.B., Xu, G.P., Multi-dimensional human action recognition model based on image set and group sparsity (2016) Neurocomputing, 215, pp. 138-149. , [CrossRef]; Wang, L., Xiong, Y., Wang, Z., Qiao, Y., Lin, D., Tang, X., Van Gool, L., Temporal segment networks for action recognition in videos (2019) IEEE Trans. Pattern Anal. Mach. Intell, 41, pp. 2740-2755. , [CrossRef] [PubMed]; Leong, M.C., Prasad, D.K., Lee, Y.T., Lin, F., Semi-CNN architecture for effective spatio-temporal learning in action recognition (2020) Appl. Sci, 10, p. 557. , [CrossRef]; Li, S., Zhao, Z., Su, F., A spatio-temporal hybrid network for action recognition Proceedings of the IEEE Visual Communications and Image Processing (VCIP), pp. 1-4. , Sydney, Australia, 1–4 December 2019; Varol, G., Laptev, I., Schmid, C., Long-term temporal convolutions for action recognition (2018) IEEE Trans. Pattern Anal. Mach. Intell, 40, pp. 1510-1517. , [CrossRef]; Ben-Ari, R., Shpigel, M., Azulai, O., Barzelay, U., Rotman, D., TAEN: Temporal aware embedding network for few-shot action recognition, , arXiv 2020, arXiv:2004.10141; Wang, H., Song, Z., Li, W., Wang, P., A hybrid network for large-scale action recognition from RGB and depth modalities (2020) Sensors, 20, p. 3305. , [CrossRef]; Rodríguez-Moreno, I., Martínez-Otzeta, J.M., Sierra, B., Rodriguez, I., Jauregi, E., Video activity recognition: State-of-the-Art (2019) Sensors, 19, p. 3160. , [CrossRef]; Carreira, J., Zisserman, A., Quo Vadis, action recognition? A new model and the kinetics dataset Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4724-4733. , Honolulu, HI, USA, 21–26 July 2017; Diba, A., Fayyaz, M., Sharma, V., Karami, A.H., Arzani, M., Yousefzadeh, R., Gool, L.V., (2017) Temporal 3D ConvNets: New architecture and transfer learning for video classification, , arXiv arXiv:1711.08200; Tran, D., Ray, J., Shou, Z., Chang, S.F., Paluri, M., (2017) ConvNet architecture search for spatiotemporal feature learning, , arXiv arXiv:1708.05038; Simonyan, K., Zisserman, A., (2014) Two-stream convolutional networks for action recognition in videos, , arXiv arXiv:1406.2199; Zhao, Y., Man, K.L., Smith, J., Siddique, K., Guan, S.-U., Improved two-stream model for human action recognition (2020) EURASIP J. Image Video Process, 2020, pp. 1-9. , [CrossRef]; Majd, M., Safabakhsh, R., A motion-aware ConvLSTM network for action recognition (2019) Appl. Intell, 49, pp. 2515-2521. , [CrossRef]; Lee, J., Ahn, B., Real-time human action recognition with a low-cost RGB camera and mobile robot platform (2020) Sensors, 20, p. 2886. , [CrossRef]; Shidik, G.F., Noersasongko, E., Nugraha, A., Andono, P.N., Jumanto, J., Kusuma, E.J., A systematic review of intelligence video surveillance: Trends, techniques, frameworks, and datasets (2019) IEEE Access, 7, pp. 170457-170473. , [CrossRef]; Fahimeh, R., Sareh, S., Upcrofit, B., Michael, M., Action recognition: From static datasets to moving robots Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 3185-3191. , Marina Bay Sands, Singapore, 29 May–3 June 2017; Sreenu, G., Durai, M.A.S., Intelligent video surveillance: A review through deep learning techniques for crowd analysis (2019) J. Big Data, 6, p. 48. , [CrossRef]; Krizhevsky, A., Sutskever, I., Hinton, G.E., Geoffrey, E., ImageNet classification with deep convolutional neural networks (2012) Adv. Neural Inf. Process. Syst, 25, pp. 1097-1105. , [CrossRef]; Zhang, H.-B., Zhang, Y.-X., Zhong, B., Lei, Q., Yang, L., Du, J.-X., Chen, D.-S., A comprehensive survey of vision-based human action recognition methods (2019) Sensors, 19, p. 1005. , [CrossRef] [PubMed]; Chen, C., Liu, K., Kehtarnavaz, N., Real-time human action recognition based on depth motion maps (2016) J. Real-Time Image Process, 12, pp. 155-163. , [CrossRef]; Zhanga, J., Lia, W., Ogunbonaa, P.O., Wanga, P., Tang, C., RGB-D-based action recognition datasets: A survey (2016) Pattern Recognit, 60, pp. 86-105. , [CrossRef]; Yang, X., Tian, Y., Effective 3D action recognition using EigenJoints (2014) J. Vis. Commun. Image Represent, 25, pp. 2-11. , [CrossRef]; Oreifej, O., Liu, Z., HON4D: Histogram of oriented 4D normals for activity recognition from depth sequences Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 716-723. , Portland, OR, USA, 23–28 June 2013; Yang, X., Tian, Y.L., Super normal vector for activity recognition using depth sequences Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 804-811. , Columbus, OH, USA, 24–27 June 2014; Warcho, D., Kapuściński, T., Human action recognition using bone pair descriptor and distance descriptor (2014) Symmetry, 12, p. 1580. , [CrossRef]; Muralikrishna, S.N., Muniyal, B., Acharya, U.D., Holla, R., Enhanced human action recognition using fusion of skeletal joint dynamics and structural features (2020) J. Robot, 2020, p. 3096858. , [CrossRef]; Yang, Y., Cai, Z., Yu, Y.D., Wu, T., Lin, L., Human action recognition based on skeleton and convolutional neural network Proceedings of the Photonics & Electromagnetics Research Symposium-Fall (PIERS-Fall), pp. 1109-1112. , Xiamen, China, 17–20 December 2019; Cao, Z., Hidalgo, G., Simon, T., Wei, S.E., Sheikh, Y., OpenPose: Realtime multi-person 2D pose estimation using part affinity fields (2019) IEEE Trans. Pattern Anal. Mach. Intell, 43, pp. 172-186. , [CrossRef]; Chaaraoui, A.A., Padilla-Lopez, J.R., Florez-Revuelta, F., Fusion of skeletal and silhouette-based features for human action recognition with RGB-D devices Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 91-97. , Portland, OR, USA, 23–28 June 2013; Laptev, I., On Space-Time Interest Points (2005) Int. J. Comput. Vis, 64, pp. 107-123. , [CrossRef]; Klaser, A., Marszałek, M., Schmid, C., A spatio-temporal descriptor based on 3D-gradients (2008) BMVC 2008-19th British Machine Vision Conference 2008, p. 275. , British Machine Vision Association: Durham, UK; Scovanner, P., Ali, S., A 3-dimensional sift descriptor and its application to action recognition Proceedings of the 15th ACM International Conference on Multimedia, pp. 357-360. , Augsburg, Germany, 24–29 September 2007; Yilmaz, A., Shah, M., Actions sketch: A novel action representation Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05), pp. 984-989. , San Diego, CA, USA, 20–25 June 2005; Ji, S., Xu, W., Yang, M., Yu, K., 3D Convolutional neural networks for human action recognition (2013) IEEE Trans. Pattern Anal. Mach. Intell, 35, pp. 221-231. , [CrossRef]; Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L., Large-scale video classification with convolutional neural networks Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1725-1732. , Columbus, OH, USA, 23–28 June 2014; Si, C., Chen, W., Wang, W., Wang, L., Tan, T., An attention enhanced graph convolutional LSTM network for skeleton-based action recognition Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1227-1236. , Long Beach, CA, USA, 15–21 June 2019; Liu, J., Shahroudy, A., Xu, D., Wan, G., Spatio-temporal LSTM with trust gates for 3D human action recognition Proceedings of the European Conference on Computer Vision (ECCV), pp. 816-833. , Amsterdam, The Netherlands, 8–16 October 2016; Sanchez-Caballero, A., López-Diz, S., Fuentes-Jimenez, D., Losada-Gutiérrez, C., Marrón-Romera, M., Casillas-Perez, D., Sarker, M.I., (2020) 3DFCNN: Real-time action recognition using 3D deep neural networks with raw depth information, , arXiv arXiv:2006.07743; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition, , arXiv arXiv:1409.1556; Hara, K., Kataoka, H., Satoh, Y., Towards good practice for action recognition with spatiotemporal 3D convolutions Proceedings of the 24th International Conference on Pattern Recognition (ICPR), pp. 2516-2521. , Beijing, China, 20–24 August 2018; Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M., Learning spatiotemporal features with 3D convolutional networks Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4489-4497. , Boston, MA, USA, 7–12 June 2015; Li, Q., Qiu, Z., Yao, T., Mei, T., Rui, Y., Luo, J., Action recognition by learning deep multi-granular spatio-temporal video representation Proceedings of the ACM on International Conference on Multimedia Retrieval, pp. 159-166. , Melbourne, Australia, 6–9 June 2016; Sun, L., Jia, K., Yeung, D.Y., Shi, B.E., Human action recognition using factorized spatio-temporal convolutional networks Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4597-4605. , Boston, MA, USA, 7–12 June 2015; Ullah, A., Ahmad, J., Muhammad, K., Sajjad, M., Baik, S., Action recognition in video sequences using deep bi-directional LSTM with CNN features (2017) IEEE Access, 6, pp. 1155-1166. , [CrossRef]","Cho, J.; Department of Electrical Engineering, South Korea; email: jcho@sch.ac.kr",,,"MDPI AG",,,,,20763417,,,,"English","Appl. Sci.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85107792764
"Zhang Z., Oh Y., Adams S.D., Bennet K.E., Kouzani A.Z.","57214006092;55809435500;57193228967;9041652500;7003695829;","An FSCV Deep Neural Network: Development, Pruning, and Acceleration on an FPGA",2021,"IEEE Journal of Biomedical and Health Informatics","25","6","9257008","2248","2259",,4,"10.1109/JBHI.2020.3037366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098769491&doi=10.1109%2fJBHI.2020.3037366&partnerID=40&md5=274df72ee8d1bbedd8233382178c3236","School of Engineering, Deakin University, Geelong, Victoria, Australia; Department of Neurologic Surgery and Department of Biomedical Engineering, Mayo Clinic, Rochester, MN, United States; Department of Neurologic Surgery and the Division of Engineering, Mayo Clinic, Rochester, MN, United States","Zhang, Z., School of Engineering, Deakin University, Geelong, Victoria, Australia; Oh, Y., Department of Neurologic Surgery and Department of Biomedical Engineering, Mayo Clinic, Rochester, MN, United States; Adams, S.D., School of Engineering, Deakin University, Geelong, Victoria, Australia; Bennet, K.E., Department of Neurologic Surgery and the Division of Engineering, Mayo Clinic, Rochester, MN, United States; Kouzani, A.Z., School of Engineering, Deakin University, Geelong, Victoria, Australia","Fast-scan cyclic voltammetry (FSCV) is an electrochemical technique for measuring rapid changes in the extracellular concentration of neurotransmitters within the brain. Due to its fast scan rate and large output-data size, the current analysis of the FSCV data is often conducted on a computer external to the FSCV device. Moreover, the analysis is semi-automated and requires a good understanding of the characteristics of the underlying chemistry to interpret, making it unsuitable for real-time implementation on low-resource FSCV devices. This paper presents a hardware-software co-design approach for the analysis of FSCV data. Firstly, a deep neural network (DNN) is developed to predict the concentration of a dopamine solution and identify the data recording electrode. Secondly, the DNN is pruned to decrease its computation complexity, and a custom overlay is developed to implement the pruned DNN on a low-resource FPGA-based platform. The pruned DNN attains a recognition accuracy of 97.2% with a compression ratio of 3.18. When the DNN overlay is implemented on a PYNQ-Z2 platform, it achieves the execution time of 13 ms and power consumption of 1.479 W on the entire PYNQ-Z2 board. This study demonstrates the possibility of operating the DNN for FSCV data analysis on portable FPGA-based platforms. © 2013 IEEE.","deep neural network; Dopamine; fast-scan cyclic voltammetry; hardware-software co-design; low-resource FPGA","Amines; Chemical analysis; Cyclic voltammetry; Deep neural networks; Field programmable gate arrays (FPGA); Hardware-software codesign; Neurophysiology; Real time control; Computation complexity; Electrochemical techniques; Extracellular concentration; Fast scan cyclic voltammetry; FPGA-based platforms; Real-time implementations; Recognition accuracy; Recording electrodes; Neural networks; dopamine; neurotransmitter; dopamine; acceleration; accuracy; algorithm; Article; artificial neural network; compression; computer model; data analysis; decision tree; deep neural network; electroencephalography; fast scan cyclic voltammetry; human; intensive care unit; learning algorithm; mathematical model; mathematical phenomena; metagenomics; miniaturization; nerve cell network; partial least squares regression; principal component analysis; pruning; signal noise ratio; signal processing; speech intelligibility; support vector machine; synapse; training; validation process; acceleration; animal; electrochemical analysis; rat; Sprague Dawley rat; Acceleration; Animals; Dopamine; Electrochemical Techniques; Humans; Neural Networks, Computer; Rats; Rats, Sprague-Dawley",,"dopamine, 51-61-6, 62-31-7; Dopamine","Zynq-7000",,,,,,,,,,,,,"Rodeberg, N.T., Sandberg, S.G., Johnson, J.A., Phillips, P.E., Wightman, R.M., Hitchhiker's guide to voltammetry: Acute and chronic electrodes for in vivo fast-scan cyclic voltammetry (2017) ACSChem. Neurosci., 8 (2), pp. 221-234; Adams, S.D., Doeven, E.H., Tye, S.J., Bennet, K.E., Berk, M., Kouzani, A.Z., TinyFSCV: FSCV for the masses (2020) IEEE Trans. Neural Syst. Rehabil. Eng., 28 (1), pp. 133-142. , Jan; Venton, B.J., Cao, Q., Fundamentals of fast-scan cyclic voltammetry for dopamine detection (2020) Analyst, 145 (4), pp. 1158-1168; Bucher, E.S., Wightman, R.M., Electrochemical analysis of neurotransmitters (2015) Annu. Rev. Anal. Chem., 8, pp. 239-261; Adams, S.D., Kouzani, A.Z., Tye, S.J., Bennet, K.E., Berk, M., An investigation into closed-loop treatment of neurological disorders based on sensing mitochondrial dysfunction (2018) J. Neuroeng. Rehabil., 15 (1); Kim, J., Comparison study of partial least squares regression analysis and principal component analysis in fast-scan cyclic voltammetry (2019) Int. J. Electrochem. Sci, 14, pp. 5924-5937; Johnson, J.A., Rodeberg, N.T., Wightman, R.M., Failure of standard training sets in the analysis of fast-scan cyclic voltammetry data (2016) ACS Chem. Neurosci., 7 (3), pp. 349-359; Jolliffe, I.T., A note on the use of principal components in regression (1982) J. Royal Stat. Soc.: Ser. C (Appl. Statist.), 31 (3), pp. 300-303; Tobias, R.D., An introduction to partial least squares regression (1995) Proc. 20th Annu. SAS Users Group Int. Conf., pp. 1250-1257; Geladi, P., Kowalski, B.R., Partial least-squares regression: Atutorial (1986) Anal. Chimica Acta, 185, pp. 1-17; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Miikkulainen, R., Evolving deep neural networks (2019) Proc. Artif. Intell. Age Neural Netw. Brain Comput., pp. 293-312. , Elsevier; Rivenson, Y., Zhang, Y., Günaydn, H., Teng, D., Ozcan, A., Phase recovery and holographic image reconstruction using deep learning in neural networks (2018) Light: Sci. Appl., 7 (2); Skourt, B.A., El Hassani, A., Majda, A., Lung CT image segmentation using deep neural networks (2018) Procedia Comput. Sci., 127, pp. 109-113; Amodei, D., Deep speech 2: End-to-end speech recognition in english and Mandarin (2016) Proc. Int. Conf. Mach. Learn., pp. 173-182; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Proc. Syst., pp. 1097-1105; Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y., Alsaadi, F.E., A survey of deep neural network architectures and their applications (2017) Neurocomputing, 234, pp. 11-26; Zhang, Z., Kouzani, A.Z., Implementation of DNNs on IoT devices (2019) Neural Comput. Appl., pp. 1-30; Goh, G.B., Hodas, N.O., Vishnu, A., Deep learning for computational chemistry (2017) J. Comput. Chem., 38 (16), pp. 1291-1307; Goh, G.B., Siegel, C., Vishnu, A., Hodas, N.O., Baker, N., (2017) Chemception: A Deep Neural Network with Minimal Chemistry Knowledge Matches the Performance of Expert-developed QSAR/QSPR Models, , https://arxiv.org/abs/1706.06689v1; Segler, M.H., Preuss, M., Waller, M.P., Planning chemical syntheses with deep neural networks and symbolic aI (2018) Nature, 555 (7698); Lusci, A., Pollastri, G., Baldi, P., Deep architectures and deep learning in chemoinformatics: The prediction of aqueous solubility for druglike molecules (2013) J. Chem. Inf. Model., 53 (7), pp. 1563-1575; Matsushita, G.H., Sugi, A.H., Costa, Y.M., Gomez-A, A., Da Cunha, C., Oliveira, L.S., Phasic dopamine release identification using convolutional neural network (2019) Comput. Biol. Med., 114; Kassal, P., Steinberg, M.D., Steinberg, I.M., Wireless chemical sensors and biosensors: A review (2018) Sensors Actuators B: Chem., 266, pp. 228-245; Puthongkham, P., Venton, B.J., Recent advances in fast-scan cyclic voltammetry (2020) Analyst, 145 (4), pp. 1087-1102; Shawahna, A., Sait, S.M., El-Maleh, A., FPGA-based accelerators of deep learning networks for learning and classification: A review (2018) IEEE Access, 7, pp. 7823-7859; Wang, C., Gong, L., Yu, Q., Li, X., Xie, Y., Zhou, X., DLAU: A scalable deep learning accelerator unit on FPGA (2016) IEEE Trans. Comput.-AidedDes. Integr. Circuits Syst., 36 (3), pp. 513-517. , Mar; Oh, Y., Monitoring in vivo changes in tonic extracellular dopamine level by charge-balancing multiple waveform fast-scan cyclic voltammetry (2016) Anal. Chem., 88 (22), pp. 10962-10970; Lee, K.H., WINCS harmoni: Closed-loop dynamic neurochemical control of therapeutic interventions (2017) Sci. Rep., 7; Kimble, C.J., Wireless instantaneous neurotransmitter concentration sensing system (WINCS) for intraoperative neurochemical monitoring (2009) Proc. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc., pp. 4856-4859; Du, X., Tang, R., Yin, S., Zhang, Y., Li, S., Direct segmentation-based full quantification for left ventricle via deep multi-task regression learning network (2018) IEEE J. Biomed. Health Inform., 23 (3), pp. 942-948; Thung, K.-H., Wee, C.-Y., A brief review on multi-task learning (2018) Multimedia Tools Appl., 77 (22), pp. 29705-29725; Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. IEEE, 105 (12), pp. 2295-2329; Pedamonti, D., (2018) Comparison of Non-linear Activation Functions for Deep Neural Networks on MNIST Classification Task, , http://arxiv.org/abs/1804.02763; Klambauer, G., Unterthiner, T., Mayr, A., Hochreiter, S., Selfnormalizing neural networks (2017) Proc. Adv. Neural Inf. Proc. Syst., pp. 971-980; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Proc. Adv. Neural Inf. Proc. Syst., pp. 1135-1143; Han, S., Mao, H., Dally, W.J., (2018) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding, , http://arxiv.org/abs/1804.02763; Zhang, J., Yeung, S.H., Shu, Y., He, B., Wang, W., (2019) Efficient Memory Management for GPU-based Deep Learning Systems, , https://arxiv.org/abs/1903.06631; Courbariaux, M., Bengio, Y., David, J.-P., (2014) Training Deep Neural Networks with Low Precision Multiplications, , https://arxiv.org/abs/1412.7024; Akbari, H., Khalighinejad, B., Herrero, J.L., Mehta, A.D., Mesgarani, N., Towards reconstructing intelligible speech from the human auditory cortex (2019) Sci. Rep., 9 (1), pp. 1-12; Haddock, A., Chizeck, H.J., Ko, A.L., Deep neural networks for context-dependent deep brain stimulation (2019) Proc. 9th Int. IEEE/EMBS Conf. Neural Eng. (NER), pp. 957-960. , IEEE; O'Sullivan, J., Neural decoding of attentional selection in multispeaker environments without access to clean sources (2017) J. Neural Eng., 14 (5)","Kouzani, A.Z.; School of Engineering, Australia; email: abbas.kouzani@deakin.edu.au",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21682194,,ITIBF,"33175684","English","IEEE J. Biomedical Health Informat.",Article,"Final","",Scopus,2-s2.0-85098769491
"Wang Y., Wang Y., Shi C., Cheng L., Li H., Li X.","56104472600;57211418138;57202256183;55600148100;8904472100;56103276300;","An Edge 3D CNN Accelerator for Low-Power Activity Recognition",2021,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","40","5","9145613","918","930",,1,"10.1109/TCAD.2020.3011042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104573544&doi=10.1109%2fTCAD.2020.3011042&partnerID=40&md5=a32bb0872b4cf7990d4ac6f7ba961347","State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; Insight Centre for Data Analytics, School of Computing, Dublin City University, Dublin 9, Ireland","Wang, Y., State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Wang, Y., State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Shi, C., School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; Cheng, L., Insight Centre for Data Analytics, School of Computing, Dublin City University, Dublin 9, Ireland; Li, H., State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Li, X., State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","3D convolutional neural networks (CNNs) are gaining increasing popularity in the area of video-based action/activity analysis. Compared to 2D convolutions that share the filters in a 2D spatial domain, 3D convolutions further reuse filters in the temporal dimension to capture temporal-domain features in the video. How to exploit the data locality in the temporal dimension directly impacts the energy efficiency of specialized architectures for 3D CNN inference. Prior works on specialized 3D-CNN accelerators employ additional on-chip memories and multicluster architecture to reuse data among the process element (PE) arrays, which is very expensive for low-power chip implementation. Instead of harvesting in-memory data locality, we propose the architecture of systolic cube to exploit the spatial and temporal localities in 3D CNNs, which moves the reusable data in-between PEs connected via a 3D-cube network-on-chip. Furthermore, due to the existence of visual feature reappearance in the temporal domain, there exists a considerable portion of repetitive pixels and activations among the feature maps captured at adjacent time slots. To eliminate such temporal redundancy in 3D CNNs, the proposed accelerator architecture is equipped with a redundancy detection and elimination mechanism, capable of skipping the computations with the same activations and parameters when reusing the convolutional filters along the temporal dimension. In our evaluation, the experimental results show that the systolic-cube architecture contributes to a considerable energy-efficiency boost for state-of-the-art activity-recognition benchmarks and datasets. © 1982-2012 IEEE.","3D CNN; activity analysis; CNN accelerator; network-on-chip; video","Chemical activation; Convolution; Energy efficiency; Geometry; Network architecture; Network-on-chip; Pattern recognition; Redundancy; Software architecture; Accelerator architectures; Activity recognition; Adjacent time slots; Process elements; Spatial and temporal locality; State of the art; Temporal dimensions; Temporal redundancy; Convolutional neural networks",,,,,"National Natural Science Foundation of China, NSFC: 61874124, 61876173; Chinese Academy of Sciences, CAS: 2018138; National Key Research and Development Program of China, NKRDPC: 2018AAA0102700; Youth Innovation Promotion Association, YIPA","Manuscript received September 7, 2019; revised February 12, 2020 and May 12, 2020; accepted June 25, 2020. Date of publication July 21, 2020; date of current version April 21, 2021. This work was supported in part by the National Natural Science Foundation of China under Grant 61874124 and Grant 61876173, in part by the Youth Innovation Promotion Association, CAS under Grant 2018138, and in part by the National Key Research and Development Program of China under Grant 2018AAA0102700. This article was recommended by Associate Editor A. K. Coskun. (Corresponding authors: Huawei Li; Xiaowei Li.) Ying Wang, Yongchen Wang, and Xiaowei Li are with the State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China (e-mail: wangying2009@ict.ac.cn; lxw@ict.ac.cn).",,,,,,,,,,"He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778; Canel, C., Scaling video analytics on constrained edged nodes (2019) Proc. SYSML, pp. 1-12; Zhang, Q., Yu, Z., Shi, W., Zhong, H., Demo abstract: EVAPs: Edge video analysis for public safety (2016) Proc. IEEE/ACM Symp. Edge Comput. (SEC), pp. 121-122; Wang, S., Yang, S., Zhao, C., SurveilEdge: Real-time video query based on collaborative cloud-edge deep learning (2020), arXiv:2001.01043; Zhang, T., Chowdhery, A., Bahl, P.V., Jamieson, K., Banerjee, S., The design and implementation of a wireless video surveillance system (2015) Proc. 21st Annu. Int. Conf. Mobile Comput. Netw., pp. 426-438; Xu, Y., Gaze prediction in dynamic 360 immersive videos (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 5333-5342. , Jun; Afzal, S., Chen, J., Ramakrishnan, K.K., Characterization of 360-degree videos (2017) Proc. ACM SIGCOMM Workshop Virtual Real. Augmented Real. Netw., pp. 1-6; Zhang, H., Ananthanarayanan, G., Bodik, P., Philipose, M., Bahl, P., Freedman, M.J., Live video analytics at scale with approximation and delay-tolerance (2017) Proc. USENIX NSDI, pp. 377-392; Ji, S., Xu, W., Yang, M., Yu, K., 3D convolutional neural networks for human action recognition (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (1), pp. 221-231. , Jan; Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M., Learning spatiotemporal features with 3D convolutional networks (2015) Proc. ICCV, pp. 4489-4497; Carreira, J., Zisserman, A., Quo vadis, action recognition? A new model and the kinetics dataset (2017) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 4724-4733; Hara, K., Kataoka, H., Satoh, Y., Can spatiotemporal 3D CNNs retrace the history of 2D CNNs and ImageNet (2018) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 6546-6555. , Jun; Chen, T., DianNao: A small-footprint high-throughput accelerator for ubiquitous machine-learning (2014) Proc. ASPLOS, pp. 269-284; Chen, Y.-H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks. (2017) IEEE J. Solid-State Circuits, 52 (1), pp. 127-138. , Jan; Fan, H., Niu, X., Liu, Q., Luk, W., F-C3D: FPGA-based 3-dimensional convolutional neural network (2017) Proc. FPL, pp. 1-4; Wang, H., Shao, M., Liu, Y., Enhanced efficiency 3D convolution based on optimal FPGA accelerator (2017) IEEE Access, 5, pp. 6909-6916; Shen, J., Huang, Y., Wang, Z., Qiao, Y., Wen, M., Zhang, C., Towards a uniform template-based architecture for accelerating 2D and 3D CNNs on FPGA (2018) Proc. FPGA, pp. 97-106; Hegde, K., Agrawal, R., Yao, Y., Fletcher, C., MORPH: Flexible acceleration for 3D CNN-based video understanding (2018), arXiv:1810.06807; Jouppi, N.P., In-datacenter performance analysis of a tensor processing unit. (2017) Proc. ISCA, pp. 1-12; Wei, X., Automated systolic array architecture synthesis for high throughput CNN inference on FPGAs (2017) Proc. DAC, pp. 1-6; Wang, Y., Wang, Y., Li, H., Shi, C., Li, X., Systolic cube: A 3DCNN accelerator architecture for low power video recognition (2019) Proc. IEEE/ACM Design Autom. Conf., pp. 1-6; Weinland, D., Ronfard, R., Boyer, E., Free viewpoint action recognition using motion history volumes (2006) Comput. Vis. Image Understand., 104 (2-3), pp. 249-257; Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L., Large-scale video classification with convolutional neural networks (2014) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 1725-1732; Donahue, J., Long-term recurrent convolutional networks for visual recognition and description (2015) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 2625-2634; Varol, G., Laptev, I., Schmid, C., Long-term temporal convolutions for action recognition (2018) IEEE Trans. Pattern Anal. Mach. Intell., 40 (6), pp. 1510-1517. , Jun; Diba, A., Sharma, V., Gool, L.V., Deep temporal linear encoding networks (2017) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 1541-1550; Bai, S., Kolter, J.Z., Koltun, V., An empirical evaluation of generic convolutional and recurrent networks for sequence modeling (2018), arxiv.abs/1803.01271; Shi, X., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., Woo, W.-C., Convolutional LSTM network: A machine learning approach for precipitation nowcasting (2015) Proc. NIPS, pp. 802-810; Fernando, B., Chet, C.T.Y., Bilen, H., Weakly supervised Gaussian networks for action detection (2020) Proc. WACV, pp. 526-535; Lu, W., Yan, G., Li, J., Gong, S., Han, Y., Li, X., FlexFlow: A flexible dataflow accelerator architecture for convolutional neural networks. (2017) Proc. HPCA, pp. 553-564; Sim, J., Park, J.-S., Kim, M., Bae, D., Choi, Y., Kim, L.-S., A 1.42TOPS/W deep convolutional neural network recognition processor for intelligent IoE systems (2016) Proc. IEEE Int. Solid-State Circuits Conf. (ISSCC), Jan./Feb, pp. 264-265; Lecun, Y., Kavukcuoglu, K., Farabet, C., Convolutional networks and applications in vision (2010) Proc. IEEE Int. Symp. Circuits Syst. (ISCAS), May/Jun, pp. 253-256; Song, L., Wang, Y., Han, Y., Zhao, X., Liu, B., Li, X., C-Brian: A deep learning accelerator that tames the diversity of CNNs through adaptive data-level parallelization (2016) Proc. DAC, pp. 1-6; Samajdar, A., Zhu, Y., Whatmough, P., Mattina, M., Krishna, T., SCALE-Sim: Systolic CNN accelerator (2018), arXiv:1811.02883; Cavigelli, L., Degen, P., Benini, L., CBinfer: Change-based inference for convolutional neural networks on video data (2017) Proc. ACM 11th Int. Conf. Distrib. Smart Cameras (ICDSC), pp. 1-8; Riera, M., Arnau, J.-M., González, A., Computation reuse in DNNs by exploiting input similarity (2018) Proc. ISCA, pp. 57-68; Mahmoud, M., Siu, K., Moshovos, A., Diffy: A Déjà VU-free differential deep neural network accelerator (2018) Proc. 51st Annu. IEEE/ACM Int. Symp. Microarchitect. (MICRO), pp. 134-147. , Oct; Buckler, M., Bedoukian, P., Jayasuriya, S., Sampson, A., EVA: Exploiting temporal redundancy in live computer vision (2018) Proc. ISCA, pp. 533-546; Wu, C.-Y., Zaheer, M., Hu, H., Manmatha, R., Smola, A.J., Krähenbühl, P., Compressed video action recognition (2018) Proc. Comput. Vis. Pattern Recognit. (CVPR), pp. 6026-6035; Judd, P., Albericio, J., Hetherington, T.H., Asmodt, T.M., Moshovos, A., Stripes: Bit-serial deep neural network computing (2016) Proc. MICRO, pp. 1-12","Li, H.; State Key Laboratory of Computer Architecture, China; email: lihuawei@ict.ac.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Final","",Scopus,2-s2.0-85104573544
"Vatalaro M., Lanuzza M., Crupi F., Moposita T., Trojman L., Vladimirescu A., Strangio S.","57212086387;9738181600;6603839671;57215852252;14032353900;6602819127;56337301700;","A low-voltage, low-power reconfigurable current-mode softmax circuit for analog neural networks",2021,"Electronics (Switzerland)","10","9","1004","","",,3,"10.3390/electronics10091004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104567428&doi=10.3390%2felectronics10091004&partnerID=40&md5=6ba5246d40d92c485b3d104d9c00b987","Dipartimento di Ingegneria Informatica, Modellistica, Elettronica e Sistemistica, Università della Calabria, Rende, 87036, Italy; Institut Supérieur d’Électronique de Paris, 10 rue de Vanves, Issy les Moulineaux, 92130, France; Sorbonne Université, Paris 4 Place Jussieu, Paris, 75252, France; Dipartimento di Ingegneria dell’Informazione, Università di Pisa, Via G. Caruso 16, Pisa, 56122, Italy","Vatalaro, M., Dipartimento di Ingegneria Informatica, Modellistica, Elettronica e Sistemistica, Università della Calabria, Rende, 87036, Italy; Lanuzza, M., Dipartimento di Ingegneria Informatica, Modellistica, Elettronica e Sistemistica, Università della Calabria, Rende, 87036, Italy; Crupi, F., Dipartimento di Ingegneria Informatica, Modellistica, Elettronica e Sistemistica, Università della Calabria, Rende, 87036, Italy; Moposita, T., Dipartimento di Ingegneria Informatica, Modellistica, Elettronica e Sistemistica, Università della Calabria, Rende, 87036, Italy, Institut Supérieur d’Électronique de Paris, 10 rue de Vanves, Issy les Moulineaux, 92130, France, Sorbonne Université, Paris 4 Place Jussieu, Paris, 75252, France; Trojman, L., Institut Supérieur d’Électronique de Paris, 10 rue de Vanves, Issy les Moulineaux, 92130, France; Vladimirescu, A., Institut Supérieur d’Électronique de Paris, 10 rue de Vanves, Issy les Moulineaux, 92130, France; Strangio, S., Dipartimento di Ingegneria dell’Informazione, Università di Pisa, Via G. Caruso 16, Pisa, 56122, Italy","This paper presents a novel low-power low-voltage analog implementation of the softmax function, with electrically adjustable amplitude and slope parameters. We propose a modular design, which can be scaled by the number of inputs (and of corresponding outputs). It is composed of input current–voltage linear converter stages (1st stages), MOSFETs operating in a subthreshold regime implementing the exponential functions (2nd stages), and analog divider stages (3rd stages). Each stage is only composed of p-type MOSFET transistors. Designed in a 0.18 µm CMOS technology (TSMC), the proposed softmax circuit can be operated at a supply voltage of 500 mV. A ten-input/ten-output realization occupies a chip area of 2570 µm2 and consumes only 3 µW of power, representing a very compact and energy-efficient option compared to the corresponding digital implementations. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Activation functions; Deep neural networks; Machine learning; Softmax",,,,,,,,,,,,,,,,,"Sarpeshkar, R., Analog Versus Digital: Extrapolating from Electronics to Neurobiology (1998) Neural Comput, 10, pp. 1601-1638. , [CrossRef] [PubMed]; Haensch, W., Gokmen, T., Puri, R., The Next Generation of Deep Learning Hardware: Analog Computing (2018) Proc. IEEE, 107, pp. 108-122. , [CrossRef]; Paliy, M., Strangio, S., Ruiu, P., Rizzo, T., Iannaccone, G., Analog Vector-Matrix Multiplier Based on Programmable Current Mirrors for Neural Network Integrated Circuits (2020) IEEE Access, 8, pp. 203525-203537. , [CrossRef]; Danial, L., Pikhay, E., Herbelin, E., Wainstein, N., Gupta, V., Wald, N., Roizin, Y., Kvatinsky, S., Two-terminal floating-gate transistors with a low-power memristive operation mode for analogue neuromorphic computing (2019) Nat. Electron, 2, pp. 596-605. , [CrossRef]; Veire, L.V., De Boom, C., De Bie, T., Sigmoidal NMFD: Convolutional NMF with Saturating Activations for Drum Mixture Decomposition (2021) Electronics, 10, p. 284. , [CrossRef]; Xing, S., Wu, C., Implementation of A Neuron Using Sigmoid Activation Function with CMOS Proceedings of the 2020 IEEE 5th International Conference on Integrated Circuits and Microsystems (ICICM), pp. 201-204. , Nanjing, China, 23–25 October 2020; Shamsi, J., Amirsoleimani, A., Mirzakuchaki, S., Ahmade, A., Alirezaee, S., Ahmadi, M., Hyperbolic tangent passive resistive-type neuron Proceedings of the 2015 IEEE International Symposium on Circuits and Systems (ISCAS), pp. 581-584. , Lisbon, Portugal, 24–27 May 2015; Fan, D., Shim, Y., Raghunathan, A., Roy, K., STT-SNN: A Spin-Transfer-Torque Based Soft-Limiting Non-Linear Neuron for Low-Power Artificial Neural Networks (2015) IEEE Trans. Nanotechnol, 14, pp. 1013-1023. , [CrossRef]; Valle, M., Analog VLSI Implementation of Artificial Neural Networks with Supervised On-Chip Learning (2002) Analog. Integr. Circuits Signal Process, 33, pp. 263-287. , [CrossRef]; Ghomi, A., Dolatshahi, M., Design of a new CMOS Low-Power Analogue Neuron (2017) IETE J. Res, 64, pp. 67-75. , [CrossRef]; Joubert, A., Belhadj, B., Temam, O., Héliot, R., Hardware spiking neurons design: Analog or digital? Proceedings of the the 2012 International Joint Conference on Neural Networks (IJCNN), pp. 1-5. , Brisbane, QLD, Australia, 10–15 June 2012; Khodabandehloo, G., MirHassani, M., Ahmadi, M., Analog Implementation of a Novel Resistive-Type Sigmoidal Neuron (2011) IEEE Trans. Very Large Scale Integr. Syst, 20, pp. 750-754. , [CrossRef]; Koosh, V.F., Goodman, R., VLSI neural network with digital weights and analog multipliers (2001) Proceedings of the ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), 2, pp. 233-236. , Sydney, NSW, Australia, 6–9 May; Koosh, V., Goodman, R., Analog VLSI neural network with digital perturbative learning (2002) IEEE Trans. Circuits Syst. II Analog Digit. Signal Process, 49, pp. 359-368. , [CrossRef]; Elfadel, I.M., Wyatt, J.L., The “Softmax” nonlinearity: Derivation using statistical mechanics and useful properties as a multi-terminal analog circuit element (1993) Proceedings of the 6th International Conference on Neural Information Processing Systems (NIPS’93), pp. 882-887. , Denver, CO, USA, 1 January Morgan Kaufmann Publishers Inc.: San Francisco, CA, USA, 1993; Zunino, R., Gastaldo, P., Analog implementation of the SoftMax function (2002) Proceedings of the 2002 IEEE International Symposium on Circuits and Systems. Proceedings (Cat. No.02CH37353), , Phoenix-Scottsdale, AZ, USA, 26–29 May II.117–II.120; Mohammed, A.A., Umaashankar, V., Effectiveness of Hierarchical Softmax in Large Scale Classification Tasks Proceedings of the 2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI), pp. 1090-1094. , Bangalore, India, 19–22 September 2018; Kouretas, I., Paliouras, V., Hardware Implementation of a Softmax-Like Function for Deep Learning (2020) Technologies, 8, p. 46. , [CrossRef]; Li, Z., Li, H., Jiang, X., Chen, B., Zhang, Y., Du, G., Efficient FPGA Implementation of Softmax Function for DNN Applications Proceedings of the 2018 12th IEEE International Conference on Anti-Counterfeiting, Security, and Identification (ASID), pp. 212-216. , Xiamen, China, 9–11 November 2018; Dong, X., Zhu, X., Ma, D., Hardware Implementation of Softmax Function Based on Piecewise LUT Proceedings of the 2019 IEEE International Workshop on Future Computing (IWOFC), pp. 1-3. , Hangzhou, China, 14–15 December 2019; Kagalkar, A., Raghuram, S., CORDIC Based Implementation of the Softmax Activation Function Proceedings of the 2020 24th International Symposium on VLSI Design and Test (VDAT), pp. 1-4. , Bhubaneswar, India, 23–25 July 2020; Alabassy, B., Safar, M., El-Kharashi, M.W., A High-Accuracy Implementation for Softmax Layer in Deep Neural Networks Proceedings of the 2020 15th Design & Technology of Integrated Systems in Nanoscale Era (DTIS), pp. 1-6. , Marrakech, Morocco, 1–3 April 2020; Serrano-Gotarredona, T., Linares-Barranco, B., Andreou, A.G., A general translinear principle for subthreshold MOS transistors (1999) IEEE Trans. Circuits Syst. I Regul. Pap, 46, pp. 607-616. , [CrossRef]; Al-Absi, M.A., Hussein, A., Abuelma’Atti, M.T., A Novel Current-Mode Ultra Low Power Analog CMOS Four Quadrant Multiplier Proceedings of the 2012 International Conference on Computer and Communication Engineering (ICCCE), pp. 13-17. , Kuala Lumpur, Malaysia, 3–5 July 2012; [CrossRef]","Vatalaro, M.; Dipartimento di Ingegneria Informatica, Italy; email: massimo.vatalaro@unical.it",,,"MDPI AG",,,,,20799292,,,,"English","Electronics (Switzerland)",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85104567428
"Biookaghazadeh S., Ravi P.K., Zhao M.","57188843878;57223209159;55130283100;","Toward Multi-FPGA Acceleration of the Neural Networks",2021,"ACM Journal on Emerging Technologies in Computing Systems","17","2","25","","",,2,"10.1145/3432816","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105214298&doi=10.1145%2f3432816&partnerID=40&md5=018c4ed90c17c42dc77bc9cd2b492857","Arizona State University, Tempe, United States","Biookaghazadeh, S., Arizona State University, Tempe, United States; Ravi, P.K., Arizona State University, Tempe, United States; Zhao, M., Arizona State University, Tempe, United States","High-throughput and low-latency Convolutional Neural Network (CNN) inference is increasingly important for many cloud- and edge-computing applications. FPGA-based acceleration of CNN inference has demonstrated various benefits compared to other high-performance devices such as GPGPUs. Current FPGA CNN-acceleration solutions are based on a single FPGA design, which are limited by the available resources on an FPGA. In addition, they can only accelerate conventional 2D neural networks. To address these limitations, we present a generic multi-FPGA solution, written in OpenCL, which can accelerate more complex CNNs (e.g., C3D CNN) and achieve a near linear speedup with respect to the available single-FPGA solutions. The design is built upon the Intel Deep Learning Accelerator architecture, with three extensions. First, it includes updates for better area efficiency (up to 25%) and higher performance (up to 24%). Second, it supports 3D convolutions for more challenging applications such as video learning. Third, it supports multi-FPGA communication for higher inference throughput. The results show that utilizing multiple FPGAs can linearly increase the overall bandwidth while maintaining the same end-to-end latency. In addition, the design can outperform other FPGA 2D accelerators by up to 8.4 times and 3D accelerators by up to 1.7 times. © 2021 ACM.","distributed systems; FPGA; neural networks","Acceleration; Convolution; Convolutional neural networks; Deep learning; Field programmable gate arrays (FPGA); Program processors; Three dimensional computer graphics; Accelerator architectures; Area efficiency; Computing applications; End to end latencies; FPGA-based accelerations; High performance devices; High throughput; Linear speed-up; Integrated circuit design",,,,,"National Science Foundation, NSF: CNS-1562837, CNS-1619653, CNS-1629888, CNS-1955593","This work was supported by National Science Foundation awards CNS-1619653, CNS-1562837, CNS-1629888, and CNS-1955593. Authors’ address: S. Biookaghazadeh, P. K. Ravi, and M. Zhao, Arizona State University, School of Computing, Informatics, and Decision Systems Engineering, 699 S. Mill Avenue, Tempe, AZ 85281; emails: {sbiookag, pravi8, mingzhao}@asu.edu. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2021 Association for Computing Machinery. 1550-4832/2021/04-ART25 $15.00 https://doi.org/10.1145/3432816",,,,,,,,,,"Zhang, C., Wu, D., Sun, J., Sun, G., Luo, G., Cong, J., Energy-efficient CNN implementation on a deeply pipelined FPGA cluster (2016) Proceedings of the 2016 International Symposium on Low Power Electronics and Design. ACM, New York, NY, pp. 326-331; Zhang, C., Sun, G., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: Towards uniformed representation and acceleration for deep convolutional neural networks (2018) IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 38 (11), pp. 2072-2085. , 2018; Jiang, W., Sha-M.E.H., Zhang, X., Yang, L., Zhuge, Q., Shi, Y., Hu, J., Achieving super-linear speedup across multi-FPGA for real-time DNN inference (2019) ACM Transactions on Embedded Computing Systems, 18 (5 s), pp. 1-23. , 2019; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., TensorFlow: A system for large-scale machine learning (2016) Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI '16)., pp. 265-283; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proceedings of the 22nd ACM International Conference on Multimedia. ACM, New York, NY, pp. 675-678; Aydonat, U., O'Connell, S., Capalija, D., Ling, A.C., Chiu, G.R., An OpenCL deep learning accelerator on Arria 10 (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. ACM, New York, pp. 55-64; Litjens, G., Kooi, T., Ehteshami Bejnordi, B., Arindra, A., Ciompi, F., Ghafoorian, M., Laak, J.A., A survey on deep learning in medical image analysis (2017) Medical Image Analysis, 42, pp. 60-88. , 2017; Arulkumaran, K., Peter Deisenroth, M., Brundage, M., Anthony Bharath, A., Deep reinforcement learning: A brief survey (2017) IEEE Signal Processing Magazine, 34 (6), pp. 26-38. , 2017; Maturana, D., Scherer, S., VoxNet: A 3D convolutional neural network for real-time object recognition (2015) Proceedings of the 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS '15). IEEE, Los Alamitos, CA, pp. 922-928; Hegde, K., Agrawal, R., Yao, Y., Fletcher, C.W., Morph: Flexible acceleration for 3D CNN-based video understanding (2018) Proceedings of the 2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO'18). IEEE, Los Alamitos, CA, pp. 933-946; Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M., Learning spatiotemporal features with 3D convolutional networks (2015) Proceedings of the IEEE International Conference on Computer Vision., pp. 4489-4497; Sun, L., Jia, K., Yeung, D., Shi, B.E., Human action recognition using factorized spatio-temporal convolutional networks (2015) Proceedings of the IEEE International Conference on Computer Vision., pp. 4597-4605; Ji, S., Xu, W., Yang, M., Yu, K., 3D convolutional neural networks for human action recognition (2012) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (1), pp. 221-231. , 2012; Lavin, A., Gray, S., Fast algorithms for convolutional neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 4013-4021; Shen, J., Huang, Y., Wang, Z., Qiao, Y., Wen, M., Zhang, C., Towards a uniform template-based architecture for accelerating 2D and 3D CNNs on FPGA (2018) Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. ACM, New York, NY, pp. 97-106; Winograd, S., On multiplication of polynomials modulo a polynomial (1980) SIAM Journal on Computing, 9 (2), pp. 225-229. , 1980; Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., In-datacenter performance analysis of a tensor processing unit (2017) Proceedings of the 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA'17). IEEE, pp. 1-12; Biookaghazadeh, S., Zhao, M., Ren, F., Are FPGAs suitable for edge computing? In Proceedings of the USENIX Workshop on Hot Topics in Edge Computing (HotEdge'18) (2018); Intel. n.d. Intel FPGA SDK for Open CL Programming Guide. Intel; Wang, D., Xu, K., Jiang, D., PipeCNN: An OpenCL-based open-source FPGA accelerator for convolution neural networks (2017) Proceedings of the 2017 International Conference on Field Programmable Technology (ICFPT'17). IEEE, Los Alamitos, CA, pp. 279-282; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. ACM, New York, NY, pp. 161-170; Suda, N., Chandra, V., Dasika, G., Mohanty, A., Ma, Y., Vrudhula, S., Seo, J., Cao, Y., Throughput-optimized OpenCL-based FPGA accelerator for large-scale convolutional neural networks (2016) Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. ACM, New York, NY, pp. 16-25; Ma, Y., Cao, Y., Vrudhula, S., Seo, J., Optimizing the convolution operation to accelerate deep neural networks on FPGA (2018) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 26 (7), pp. 1354-1367. , 2018; Liu, Z., Chow, P., Xu, J., Jiang, J., Dou, Y., Zhou, J., A uniform architecture design for accelerating 2D and 3D CNNS on FPGAs (2019) Electronics, 8 (1), p. 65. , 2019; Boutros, A., Yazdanshenas, S., Betz, V., You cannot improve what you do not measure: FPGA vs (2018) ASIC Efficiency Gaps for Convolutional Neural Network Inference. ACM Transactions on Reconfigurable Technology and Systems, 11 (3), p. 20. , 2018; https://www.intel.com/content/www/us/en/internetof-things/fog-reference-design-overview.html, Intel. n.d. Fog Reference Unit. Retrieved February 22, 2021; (2021), https://pytorch.org, Pytorch. n.d. Home Page. Retrieved February 22; Ma, Y., Kim, M., Cao, Y., Vrudhula, S., Seo, J., End-to-end scalable FPGA accelerator for deep residual networks (2017) Proceedings of the 2017 IEEE International Symposium on Circuits and Systems (ISCAS'17). IEEE, Los Alamitos, CA, pp. 1-4; Fowers, J., Ovtcharov, K., Papamichael, M., Massengill, T., Liu, M., Lo, D., Alkalay, S., A configurable cloud-scale DNN processor for real-time AI (2018) Proceedings of the 2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA'18). IEEE, Los Alamitos, CA, pp. 1-14",,,,"Association for Computing Machinery",,,,,15504832,,,,"English","ACM J. Emerg. Technologies Comput. Syst.",Article,"Final","",Scopus,2-s2.0-85105214298
"Eliahu A., Ronen R., Gaillardon P.-E., Kvatinsky S.","57211141024;57521993700;35117655600;36866322000;","MultiPULPly: A Multiplication Engine for Accelerating Neural Networks on Ultra-low-power Architectures",2021,"ACM Journal on Emerging Technologies in Computing Systems","17","2","24","","",,,"10.1145/3432815","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105120043&doi=10.1145%2f3432815&partnerID=40&md5=64d53323ef8b4f4ec63382e375c8724f","Technion-Israel Institute of Technology, Haifa, Israel; University of Utah, Salt Lake City, UT, United States","Eliahu, A., Technion-Israel Institute of Technology, Haifa, Israel; Ronen, R., Technion-Israel Institute of Technology, Haifa, Israel; Gaillardon, P.-E., University of Utah, Salt Lake City, UT, United States; Kvatinsky, S., Technion-Israel Institute of Technology, Haifa, Israel","Computationally intensive neural network applications often need to run on resource-limited low-power devices. Numerous hardware accelerators have been developed to speed up the performance of neural network applications and reduce power consumption; however, most focus on data centers and full-fledged systems. Acceleration in ultra-low-power systems has been only partially addressed. In this article, we present multiPULPly, an accelerator that integrates memristive technologies within standard low-power CMOS technology, to accelerate multiplication in neural network inference on ultra-low-power systems. This accelerator was designated for PULP, an open-source microcontroller system that uses low-power RISC-V processors. Memristors were integrated into the accelerator to enable power consumption only when the memory is active, to continue the task with no context-restoring overhead, and to enable highly parallel analog multiplication. To reduce the energy consumption, we propose novel dataflows that handle common multiplication scenarios and are tailored for our architecture. The accelerator was tested on FPGA and achieved a peak energy efficiency of 19.5 TOPS/W, outperforming state-of-the-art accelerators by 1.5× to 4.5×. © 2021 ACM.","Memristor; mobile neural networks; ultra-low-power architectures","Acceleration; Electric power utilization; Energy efficiency; Energy utilization; Green computing; Low power electronics; Network architecture; Open systems; Analog multiplication; Hardware accelerators; Low-power devices; Microcontroller systems; Network inference; Neural network application; State of the art; Ultra-low power systems; Neural networks",,,,,"Horizon 2020 Framework Programme, H2020: 757259; European Research Council, ERC; United States-Israel Binational Science Foundation, BSF: 2016016","This work was partially supported by the European Research Council under the European Union’s Horizon 2020 Research and Innovation Program (Grant Agreement No. 757259), by the Genpro consortium, Israel Innovation Authority, and by the U.S.-Israel Binational Science Foundation (Grant No. 2016016). Authors’ addresses: A. Eliahu, Viterbi Faculty of Electrical and Computer Engineering, Technion-Israel Institute of Technology, Haifa, Israel, 3200003; email: adieliahu@campus.technion.ac.il; R. Ronen and S. Kvatinsky, Technion-Israel Institute of Technology, Haifa, Israel, 3200003; emails: ronny.ronen@ef.technion.ac.il, shahar@ee.technion.ac.il; P.-E. Gaillardon, University of Utah, 201 Presidents Circle, Salt Lake City, Utah, 84112; email: pierre-emmanuel.gaillardon@utah.edu. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2021 Association for Computing Machinery. 1550-4832/2021/04-ART24 $15.00 https://doi.org/10.1145/3432815",,,,,,,,,,"(2021), https://greenwaves-technologies.com/gap9-iot-application-processor, GAP9; (2021) Pulp Platform Website, , https://www.pulp-platform.org; (2011) YAML, , https://yaml.org; (2019) stm32h743 Datasheet, , https://www.st.com/resource/en/datasheet/stm32l476je.pdf; Akinaga, H., Shima, H., Resistive random access memory (ReRAM) based on metal oxides (2010) Proc. IEEE, 98 (12), pp. 2237-2251. , https://doi.org/10.1109/JPROC.2010.2070830, Dec. 2010; Andri, R., Cavigelli, L., Rossi, D., Benini, L., YodaNN: An architecture for ultralow power binary-weight CNN acceleration (2018) TCAD, 37 (1), pp. 48-60. , https://doi.org/10.1109/TCAD.2017.2682138, Jan. 2018; Angel Lastras-Montano, M., Cheng, K., Resistive random-access memory based on ratioed memristors (2018) Nature Electron., 1, pp. 466-472. , https://doi.org/10.1038/s41928-018-0115-z, Aug. 2018; Ankit, A., El Hajj, I., Rahul Chalamalasetti, S., Ndu, G., Foltin, M., Stanley Williams, R., Faraboschi, P., Milojicic, D.S., PUMA: A programmable ultraefficient memristor-based accelerator formachine learning inference (2019), http://arxiv.org/abs/1901.10351; Bhattacharjee, D., Merchant, F., Chattopadhyay, A., Enabling in-memory computation of binary BLAS using ReRAM crossbar arrays (2016) Proceedings of VLSI-SoC., pp. 1-6. , https://doi.org/10.1109/VLSI-SoC.2016.7753568; Bhattacharya, S., Lane, N.D., Sparsification and separation of deep learning layers for constrained resource inference on wearables (2016) Proceedings of SenSys. ACM, New York, NY, pp. 176-189. , https://doi.org/10.1145/2994551.2994564; Bong, K., Choi, S., Kim, C., Kang, S., Kim, Y., Yoo, H., 14.6 A 0.62mW ultra-low-power convolutional-neuralnetwork face-recognition processor and a CIS integrated with always-on haar-like face detector (2017) Proceedings of ISSCC, pp. 248-249. , https://doi.org/10.1109/ISSCC.2017.7870354; Bridges, R.A., Imam, N., Mintz, T.M., Understanding GPU power: A survey of profiling, modeling, and simulation methods (2016) ACM Comput. Surv., 49 (3), p. 27. , https://doi.org/10.1145/2962131, Sept. 2016; Cai, E., Juan, D., Stamoulis, D., Marculescu, D., (2017) NeuralPower: Predict and Deploy Energy-efficient Convolutional Neural Networks, , http://arxiv.org/abs/1710.05420; Cavigelli, L., Benini, L., Origami: A 803-GOp/s/W convolutional network accelerator (2017) IEEE Trans. Circ. Syst. Video Technol., 27 (11), pp. 2461-2475. , https://doi.org/10.1109/TCSVT.2016.2592330, Nov. 2017; Chen, Y., Emer, J.S., Sze, V., Eyeriss v2: A flexible and high-performance accelerator for emerging deep neural networks (2018), http://arxiv.org/abs/1807.07928; Chi, P., Li, S., Xu, C., Zhang, T., Zhao, J., Liu, Y., Wang, Y., Xie, Y., PRIME: A novel processing-in-memory architecture for neural network computation in ReRAM-basedmainmemory (2016) SIGARCH Comput. Archit. News, 44 (3), pp. 27-39. , https://doi.org/10.1145/3007787.3001140, June 2016; Cho, K., Van Merrienboer, B., Gülçehre, C., Bougares, F., Schwenk, H., Bengio, Y., (2014) Learning Phrase Representations Using RNN Encoder-decoder for Statistical Machine Translation, , http://arxiv.org/abs/1406.1078; Conti, F., Benini, L., A ultra-low-energy convolution engine for fast brain-inspired vision inmulticore clusters (2015) Proceedings of DATE., pp. 683-688. , https://doi.org/10.7873/DATE.2015.0404; Conti, F., Marongiu, A., Benini, L., Synthesis-friendly techniques for tightly coupled integration of hardware accelerators into shared-memory multi-core clusters (2013) Proceedings of CODES+ISSS'13. IEEE Press, Piscataway, NJ, p. 10. , http://dl.acm.org/citation.cfm?id=2555692.2555697; Cui, J., Qiu, Q., Towards memristor based accelerator for sparse matrix vector multiplication (2016) Proceedings of ISCAS., pp. 121-124. , https://doi.org/10.1109/ISCAS.2016.7527185; Zeiler, MatthewD., Fergus, R., Visualizing and understanding convolutional neural networks (2013) Proceedings of ECCV 2014, 8689. , https://doi.org/10.1007/978-3-319-10590-1-53; Dongarra, J.J., Du Croz, J., Hammarling, S., Duff, I.S., A set of Level 3 basic linear algebra subprograms (1990) ACM Trans. Math. Softw., 16 (1), pp. 1-17. , https://doi.org/10.1145/77626.79170, Mar. 1990; Dongarra, J.J., Croz, J., Hammarling, S., Hanson, R.J., An extended set of FORTRAN basic linear algebra subprograms (1988) ACM Trans. Math. Softw., 14 (1), pp. 1-17. , https://doi.org/10.1145/42288.42291, Mar. 1988; Dreslinski, R.G., Fick, D., Giridhar, B., Kim, G., Seo, S., Fojtik, M., Satpathy, S., Mudge, T., Centip3De: Amany-core prototype exploring 3D integration and near-threshold computing (2013) Commun. ACM, 56 (11), pp. 97-104. , https://doi.org/10.1145/2524713.2524725, Nov. 2013; Du, Z., Fasthuber, R., Chen, T., Ienne, P., Li, L., Luo, T., Feng, X., Temam, O., ShiDianNao: Shifting vision processing closer to the sensor (2015) Proceedings of ISCA., pp. 92-104. , https://doi.org/10.1145/2749469.2750389; Elthakeb, A.T., Pilligundla, P., Yazdanbakhsh, A., Kinzer, S., Esmaeilzadeh, H., ReLeQ: A reinforcement learning approach for deep quantization of neural networks (2018), http://arxiv.org/abs/1811.01704; Giacomin, E., Greenberg-Toledo, T., Kvatinsky, S., Gaillardon, P., A robust digital RRAM-based convolutional block for low-power image processing and learning applications (2019) IEEE Trans. Circ. Syst. I: Reg. Papers, 66 (2), pp. 643-654. , https://doi.org/10.1109/TCSI.2018.2872455, 2019; Gobieski, G., Beckmann, N., Lucia, B., Intelligence beyond the edge: Inference on intermittent embedded systems (2018), http://arxiv.org/abs/1810.07751; Golub, M., Lemieux, G., Lis, M., DropBack: Continuous pruning during training (2018), http://arxiv.org/abs/1806.06949; Hegde, K., Yu, J., Agrawal, R., Yan, M., Pellauer, M., Fletcher, C.W., UCNN: Exploiting computational reuse in deep neural networks via weight repetition (2018) Proceedings of ISCA '18. IEEE Press, Piscataway, NJ, pp. 674-687. , https://doi.org/10.1109/ISCA.2018.00062; Hill, P., Zamirai, B., Lu, S., Chao, Y., Laurenzano, M., Samadi, M., Papaefthymiou, M.C., Mars, J., (2018) Rethinking Numerical Representations for Deep Neural Networks, , http://arxiv.org/abs/1808.02513; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., MobileNets: Efficient convolutional neural networks for mobile vision applications (2017), http://arxiv.org/abs/1704.04861; Hsu, C., Wang, I., Lo, C., Chiang, M., Jang, W., Lin, C., Hou, T., Self-rectifying bipolar TaOx/TiO2 RRAM with superior endurance over 1012 cycles for 3D high-density storage-class memory (2013) Proceedings of VLSI., pp. T166-T167; Huang, S., Xiao, S., Feng, W., On the energy efficiency of graphics processing units for scientific computing (2009) Proceedings of IPDPS., pp. 1-8. , https://doi.org/10.1109/IPDPS.2009.5160980; Huangfu, W., Xia, L., Cheng, M., Yin, X., Tang, T., Li, B., Chakrabarty, K., Yang, H., Computationoriented fault-tolerance schemes for RRAM computing systems (2017) Proceedings of ASP-DAC., pp. 794-799. , https://doi.org/10.1109/ASPDAC.2017.7858421; Iandola, F.N., Moskewicz, M.W., Ashraf, K., Han, S., Dally, W.J., Keutzer, K., SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and 1MB model size (2016) org/abs/1602.07360, , http://penalty-@Marxiv; Imani, M., Samragh, M., Kim, Y., Gupta, S., Koushanfar, F., Rosing, T., RAPIDNN: In-memory deep neural network acceleration framework (2018), http://arxiv.org/abs/1806.05794; Judd, P., Albericio, J., Hetherington, T., Aamodt, T., Enright Jerger, N., Urtasun, R., Moshovos, A., Proteus: Exploiting precision variability in deep neural networks (2018) Parallel Comput., 73, pp. 40-51. , https://doi.org/10.1016/j.parco.2017.05.003ParallelProgrammingforResilienceandEnergyEfficiency, 2018; Kasichayanula, K., Terpstra, D., Luszczek, P., Tomov, S., Moore, S., Peterson, G.D., Power aware computing on GPUs (2012) Proceedings of SAAHPC., pp. 64-73. , https://doi.org/10.1109/SAAHPC.2012.26; Kim, Y., Kim, H., Kim, J., (2018) Neural Network-hardware Co-design for Scalable RRAM-based BNN Accelerators, , http://arxiv.org/abs/1811.02187; Krishnamoorthi, R., (2018) Quantizing Deep Convolutional Networks for Efficient Inference: A Whitepaper, , http://arxiv.org/abs/1806.08342; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2017) Commun. ACM, 60 (6), pp. 84-90. , https://doi.org/10.1145/3065386, May 2017; Kull, L., Toifl, T., Schmatz, M., Francese, P.A., Menolfi, C., Braendli, M., Kossel, M., Leblebici, Y., A 3.1mW 8b 1.2GS/s single-channel asynchronous SAR ADC with alternate comparators for enhanced speed in 32nm digital SOI CMOS (2013) Proceedings of ISSCC., pp. 468-469. , https://doi.org/10.1109/ISSCC.2013.6487818; Kurth, A., Vogel, P., Capotondi, A., Marongiu, A., Benini, L., (2017) HERO: Heterogeneous Embedded Research Platform for Exploring RISC-V Manycore Accelerators on FPGA, , http://arxiv.org/abs/1712.06497; Lai, L., Suda, N., Chandra, V., (2018) CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs, , http://arxiv.org/abs/1801.06601; Lee, S.R., Kim, Y., Chang, M., Kim, K.M., Lee, C.B., Hur, J.H., Park, G., Kim, K., Multi-level switching of triple-layered TaOx RRAM with excellent reliability for storage class memory (2012) Proceedings of VLSIT., pp. 71-72. , https://doi.org/10.1109/VLSIT.2012.6242466; Li, B., Song, L., Chen, F., Qian, X., Chen, Y., Li, H.H., ReRAM-based accelerator for deep learning (2018) Proceedings of DATE., pp. 815-820. , https://doi.org/10.23919/DATE.2018.8342118; Liao, S., Xie, Y., Lin, X., Wang, Y., Zhang, M., Yuan, B., Reduced-complexity deep neural networks design using multi-level compression (2018) IEEE Trans. Sustain. Comput. (2018), pp. 1-1. , https://doi.org/10.1109/TSUSC.2017.2710178; Lin, Z., Chung, A.G., Wong, A., (2018) EdgeSpeechNets:Highly Efficient Deep Neural Networks for Speech Recognition on the Edge, , CoRR abs/1810.08559 (2018); Liu, C., Hu, M., Strachan, J.P., Li, H., Rescuing memristor-based neuromorphic design with high defects (2017) Proceedings of DAC., pp. 1-6. , https://doi.org/10.1145/3061639.3062310; Mittal, S., A survey of ReRAM-based architectures for processing-in-memory and neural networks (2018) Mach. Learn. Knowl. Extract., 1. , https://doi.org/10.3390/make1010005, 04 2018; Miyashita, D., Kousai, S., Suzuki, T., Deguchi, J., Time-domain neural network: A 48.5 TSOp/s/W neuromorphic chip optimized for deep learning and CMOS technology (2016) Proceedings of A-SSCC., pp. 25-28; Nag, A., Balasubramonian, R., Srikumar, V., Walker, R., Shafiee, A., Strachan, J.P., Muralimanohar, N., Newton: Gravitating towards the physical limits of crossbar acceleration (2018) IEEE Micro, 38 (5), pp. 41-49. , https://doi.org/10.1109/MM.2018.053631140, Sep. 2018; Parashar, A., Rhu, M., Mukkara, A., Puglielli, A., Venkatesan, R., Khailany, B., Emer, J., Dally, W.J., SCNN: An accelerator for compressed-sparse convolutional neural networks (2017) Proceedings of ISCA., pp. 27-40. , https://doi.org/10.1145/3079856.3080254; Pawlowski, R., Krimer, E., Crop, J., Postman, J., Moezzi-Madani, N., Erez, M., Chiang, P., A 530mV 10-lane SIMD processor with variation resiliency in 45nm SOI (2012) Proceedings of ISSCC., pp. 492-494. , https://doi.org/10.1109/ISSCC.2012.6177105; Pullini, A., Conti, F., Rossi, D., Loi, I., Gautschi, M., Benini, L., A heterogeneous multicore system on chip for energy efficient brain inspired computing (2018) TCAS II: Express Briefs, 65 (8), pp. 1094-1098. , https://doi.org/10.1109/TCSII.2017.2652982, Aug. 2018; Qiao, X., Cao, X., Yang, H., Song, L., Li, H., Atomlayer: A universal reRAM-based CNN accelerator with atomic layer computation (2018) Proceedings of DAC. ACM, New York, NY, , https://doi.org/10.1145/3195970.3195998; Reagen, B., Whatmough, P., Adolf, R., Rama, S., Lee, H., Kyu Lee, S., Miguelhernández-Lobato, J., Brooks, D., Minerva: Enabling Low-power, highly accurate deep neural network accelerators (2016) Proceedings of ISCA. IEEE, Piscataway, NJ, pp. 267-278. , https://doi.org/10.1109/ISCA.2016.32; Rossi, D., Loi, I., Pullini, A., Benini, L., Ultra-Low-Power Digital Architectures for the Internet of Things (2017) Springer, Cham, pp. 69-93. , https://doi.org/10.1007/978-3-319-51482-6-3; Rossi, D., Pullini, A., Loi, I., Gautschi, M., Gurkaynak, F.K., Bartolini, A., Flatresse, P., Benini, L., A 60 GOPS/W,-1.8 v to.0.9 v body bias ULP cluster in 28 nm UTBB FD-SOI technology (2016) Solid-State Electron., 117 (C), pp. 170-184. , https://doi.org/10.1016/j.sse.2015.11.015, 2016; Schiavone, P.D., Rossi, D., Pullini, A., Di Mauro, A., Conti, F., Benini, L., Quentin: An ultra-low-power PULPissimo SoC in 22nm FDX (2018) Proceedings of S3S, , https://doi.org/10.3929/ethz-b-000314427; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: A unified embedding for face recognition and clustering (2015), http://arxiv.org/abs/1503.03832; Seo, S., Dreslinski, R.G., Woh, M., Chakrabarti, C., Mahlke, S., Mudge, T., Diet SODA: A power-efficient processor for digital cameras (2010) Proceedings of ISLPED., pp. 79-84. , https://doi.org/10.1145/1840845.1840862; Shafiee, A., Nag, A., Muralimanohar, N., Balasubramonian, R., Strachan, J.P., Hu, M., Williams, R.S., Srikumar, V., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) Proceedings of ISCA., pp. 14-26. , https://doi.org/10.1109/ISCA.2016.12; Sifre, L., Mallat, S., (2014) Rigid-motion Scattering for Texture Classification, , http://arxiv.org/abs/1403.1687; Sim, J., Park, J., Kim, M., Bae, D., Choi, Y., Kim, L., 14.6 A 1.42TOPS/W deep convolutional neural network recognition processor for intelligent IoE systems (2016) Proceedings of ISSCC., pp. 264-265. , https://doi.org/10.1109/ISSCC.2016.7418008; Stillmaker, A., Baas, B.M., Scaling equations for the accurate prediction of CMOS device performance from 180 nm to 7 nm (2017) Integration, 58, pp. 74-81. , 2017; Stillmaker, A., Xiao, Z., Baas, B., (2011) Toward More Accurate Scaling Estimates of CMOS Circuits from 180 Nm to 22 Nm, , http://www.ece.ucdavis.edu/cerl/techreports/2011-4/, Technical Report ECE-VCL-2011-4. VLSI Computation Lab, ECE Department, University of California, Davis; Szegedy, C., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of IEEE CVPR., pp. 1-9. , https://doi.org/10.1109/CVPR.2015.7298594; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., DeepFace: Closing the gap to human-level performance in face verification (2014) Proceedings of CVPR; Tang, R., Lin, J., Deep residual learning for small-footprint keyword spotting (2018) Proceedings of ICASSP., pp. 5484-5488. , https://doi.org/10.1109/ICASSP.2018.8462688; Tang, S., Yin, S., Zheng, S., Ouyang, P., Tu, F., Yao, L., Wu, J., Wei, S., AEPE: An area and power efficient RRAM crossbar-based accelerator for deep CNNs (2017) Proceedings of NVMSA., pp. 1-6. , https://doi.org/10.1109/NVMSA.2017.8064475; Termritthikun, C., Kanprachar, S., Muneesawang, P., NU-LiteNet: Mobile landmark recognition using convolutional neural networks (2018), http://arxiv.org/abs/1810.01074; Zee, F.G., Geijn, R.A., BLIS: A framework for rapidly instantiating BLAS functionality (2015) ACM Trans. Math. Softw., 41 (3), p. 33. , https://doi.org/10.1145/2764454, June 2015; Wang, P., Ji, Y., Hong, C., Lyu, Y., Wang, D., Xie, Y., SNrram: An efficient sparse neural network computation architecture based on resistive random-access memory (2018) Proceedings of DAC. ACM, New York, NY, , https://doi.org/10.1145/3195970.3196116; Wang, S., Zhou, D., Han, X., Yoshimura, T., Chain-NN: An energy-efficient 1D chain architecture for accelerating deep convolutional neural networks (2017) Proceedings of DATE., pp. 1032-1037. , https://doi.org/10.23919/DATE.2017.7927142; Waterman, A., Lee, Y., Patterson, D., The RISC-V Instruction Set Manual (2014); Clint Whaley, R., Petitet, A., Minimizing development and maintenance costs in supporting persistently optimized BLAS (2005) Software: Pract. Exper., 35 (2), pp. 101-121. , http://www.cs.utsa.edu/~whaley/papers/spercw04.ps, Feb. 2005; Woods, W., Teuscher, C., Approximate vector matrix multiplication implementations for neuromorphic applications using memristive crossbars (2017) Proceedings of NANOARCH., pp. 103-108; Xu, C., Niu, D., Muralimanohar, N., Balasubramonian, R., Zhang, T., Yu, S., Xie, Y., Overcoming the challenges of crossbar resistive memory architectures (2015) Proceedings of HPCA., pp. 476-488. , https://doi.org/10.1109/HPCA.2015.7056056; Zangeneh, M., Joshi, A., Performance and energy models for memristor-based 1T1R RRAM cell (2012) Proceedings of the Great Lakes Symposium on VLSI (Salt Lake City, Utah, USA) (GLSVLSI'12). Association for Computing Machinery, pp. 9-14. , https://doi.org/10.1145/2206781.2206786; Zangeneh, M., Joshi, A., Design and optimization of nonvolatile multibit 1T1R resistive RAM (2014) TVLSI, 22 (8), pp. 1815-1828. , 2014; Zhou, X., Du, Z., Guo, Q., Liu, S., Liu, C., Wang, C., Zhou, X., Chen, Y., Cambricon-S: Addressing irregularity in sparse neural networks through a cooperative software/hardware approach (2018) Proceedings of MICRO., pp. 15-28. , https://doi.org/10.1109/MICRO.2018.00011",,,,"Association for Computing Machinery",,,,,15504832,,,,"English","ACM J. Emerg. Technologies Comput. Syst.",Article,"Final","",Scopus,2-s2.0-85105120043
"Shen H.","57221466767;","Prediction simulation of sports injury based on embedded system and neural network",2021,"Microprocessors and Microsystems","82",,"103900","","",,,"10.1016/j.micpro.2021.103900","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099250464&doi=10.1016%2fj.micpro.2021.103900&partnerID=40&md5=e813cb97858604660b93910c331cc3c9","Physical Education Department, Xi'an University of Finance and Economics, Xi'an, Shaanxi  710100, China; School of Business and Management, Malaysia University of Science and TechnologySelangor  47810, Malaysia","Shen, H., Physical Education Department, Xi'an University of Finance and Economics, Xi'an, Shaanxi  710100, China, School of Business and Management, Malaysia University of Science and TechnologySelangor  47810, Malaysia","Sports injury prediction is one of the most important parts of the challenge of prevention and harm challenging in motion. Sports injury contemplated wherein a simplified view of the phenomenon to study the reduction unit's cause. A linear analysis is viewed as the unidirectional manner a substantial portion of, and causality. This reduction method depends on the correlation and regression analysis. Despite the extensive efforts to predict sports injuries, the existing method is the inability to identify the predictors that were and have been limited. The risk of the very important element for sports players' injury when developing prevention and risk mitigation strategies for work-related accidents. Some signs can be used in many ways to identify risk factors for injury. However, it can be made from the data and lead to incorrect inferences and difficulty understanding the nuances of different statistical methods. The proposed Neural Network (NN) and the embedded system classify the sports player's injury prediction to solve the problem. The proposed Neural Network (NN) and the embedded system have attracted a simple calculation and interpretation of the reliable results for sports injury prediction. The simulation results show the high performance compared to other existing methods. © 2021","Classification; Embedded system; Neural Network (NN); Player; Prediction; Sports injury","Embedded systems; Forecasting; Health risks; Sports; Sports medicine; Correlation and regression analysis; Injury prediction; Linear analysis; Neural network (nn); Reduction method; Reliable results; Risk mitigation strategy; Sports injuries; Neural networks",,,,,,,,,,,,,,,,"Qi, H., Feng, Y., Analysis of clinical value of weight-bearing magnetic resonance diagnosis of ankle ligament sports injury (2020) IEEE Access, 8, pp. 62725-62737; Ma, H., Pang, X., Research and analysis of sports medical data processing algorithms based on deep learning and Internet of Things (2019) IEEE Access, 7, pp. 118839-118849; Tang, D., Hybridized hierarchical deep convolutional Neural Network for sports rehabilitation exercises (2020) IEEE Access, 8, pp. 118969-118977; Liu, X., Synthesizing foot and ankle kinematic characteristics for lateral collateral ligament injuries detection (2020) IEEE Access, 8, pp. 188429-188440; Zhang, Y., Zhang, Y., Zhao, X., (2020) Design and Data Analysis of Sports Information Acquisition System Based on Internet of Medical Things[J], 99, p. 1. , IEEE Access PP(; Zhou, T., Analysis of the biomechanical characteristics of the knee joint with a meniscus injury (2018) Healthc. Technol. Lett., 5 (6), pp. 247-249. , 12; Fisher, J.A.N., Real-time detection and monitoring of acute brain injury utilizing evoked electroencephalographic potentials (2016) IEEE Trans. Neural Syst. Rehabil. Eng., 24 (9), pp. 1003-1012; Wilk, M.P., Walsh, M., O'Flynn, B., Multimodal Sensor Fusion for Low-Power Wearable Human Motion Tracking Systems in Sports Applications[J] (2020) IEEE Sensors Journal, PP(, 99, p. 1; Wadas, M.J., Detection of traumatic brain injury protein biomarkers with resonant microsystems (2017) IEEE Sens. Lett., 1 (6), pp. 1-4. , Art no. 2501304; Hodkin, E.F., Automated FES for upper limb rehabilitation following stroke and spinal cord injury (2018) IEEE Trans. Neural Syst. Rehabil. Eng., 26 (5), pp. 1067-1074; Ahammad, S.H., Rajesh, V., Rahman, M.Z.U., Lay-Ekuakille, A., A hybrid CNN-based segmentation and boosting classifier for real time sensor spinal cord injury data (2020) IEEE Sens. J., 20 (17), pp. 10092-10101; Hwang, D., Jeon, M., Kang, J., A drug-induced liver injury prediction model using transcriptional response data with graph neural network (2020) 2020 IEEE International Conference on Big Data and Smart Computing (BigComp), Busan, Korea (South), pp. 323-329; Ma, H., Pang, X., Research and Analysis of sports medical data processing algorithms based on deep learning and Internet of Things (2019) IEEE Access, 7, pp. 118839-118849; Shih, H., A survey of content-aware video analysis for sports (2018) IEEE Trans. Circuits Syst. Video Technol., 28 (5), pp. 1212-1231; Qi, M., Wang, Y., Li, A., Luo, J., Sports video captioning via attentive motion representation and group relationship modeling (2020) IEEE Trans. Circuits Syst. Video Technol., 30 (8), pp. 2617-2633; Xu, Y., Guo, X., Application of FPGA and complex embedded system in sports health data monitoring system (2020) Microprocess. Microsyst.; Jing, H., Xiaoqiong, X., Sports image detection based on FPGA hardware system and particle swarm algorithm (2020) Microprocess. Microsyst.",,,,"Elsevier B.V.",,,,,01419331,,MIMID,,"English","Microprocessors Microsyst",Article,"Final","",Scopus,2-s2.0-85099250464
"Zhou Y., Zhang A.","56573033000;57203041712;","Improved integrate-and-fire neuron models for inference acceleration of spiking neural networks",2021,"Applied Intelligence","51","4",,"2393","2405",,3,"10.1007/s10489-020-02017-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095445197&doi=10.1007%2fs10489-020-02017-3&partnerID=40&md5=2db72df06202cfff81661102df9c141a","Research Institute of Ruijie, Ruijie Networks Co., Ltd., Fuzhou, 350002, China; College of Physics and Information Engineering, Fuzhou University, Fuzhou, 350108, China; Key Laboratory of Medical Instrumentation and Pharmaceutical Technology of Fujian Province, Fuzhou, 350116, China","Zhou, Y., Research Institute of Ruijie, Ruijie Networks Co., Ltd., Fuzhou, 350002, China; Zhang, A., College of Physics and Information Engineering, Fuzhou University, Fuzhou, 350108, China, Key Laboratory of Medical Instrumentation and Pharmaceutical Technology of Fujian Province, Fuzhou, 350116, China","We study the effects of different bio-synaptic membrane potential mechanisms on the inference speed of both spiking feed-forward neural networks and spiking convolutional neural networks. These mechanisms are inspired by biological neuron phenomena include electronic conduction in neurons and chemical neurotransmitter attenuation between presynaptic and postsynaptic neurons. In the area of spiking neural networks, we model some biological neural membrane potential updating strategies based on integrate-and-fire (I&F) spiking neurons. These include the spiking neuron model with membrane potential decay (MemDec), the spiking neuron model with synaptic input current superposition at spiking time (SynSup), and the spiking neuron model with synaptic input current accumulation (SynAcc). Experiment results show that compared with the general I&F model (one of the most commonly used spiking neuron models), SynSup and SynAcc can effectively improve the spiking inference speed of spiking feed-forward neural networks and spiking convolutional neural networks. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Inference acceleration; Neural plasticity; Spiking neural network","Convolution; Convolutional neural networks; Neurons; Electronic conduction; Integrate and fires; Integrate-and-fire neurons; Membrane potentials; Post-synaptic neurons; Spiking neural networks; Spiking neuron models; Synaptic membranes; Feedforward neural networks",,,,,,,,,,,,,,,,"Bodyanskiy, Y., Dolotov, A., Pliss, I., Malyar, M., A fast learning algorithm of self-learning spiking neural network (2016) IEEE International Conference on Data Stream Mining & Processing, pp. 104-107. , https://doi.org/10.1109/DSMP.2016.7583517; Bohte, S.M., Kok, J.N., Poutre, H.L., Error-backpropagation in temporally encoded networks of spiking neurons (2002) Neurocomputing, 48 (1), pp. 17-37; Camunas-Mesa, L., Zamarreno-Ramos, C., Linares-barranco, A., An event-driven multi-kernel convolution processor module for event-driven vision sensors (2012) IEEE Journal of Solid-State Circuits, 47 (2), pp. 504-517; Cao, Y., Chen, Y., Spiking deep convolutional neural networks for energy-efficient object recognition (2014) Int J Comput Vis, 113 (1), pp. 54-66; Carlson, K.D., Nageswaran, J.M., Dutt, N., Krichmar, J.L., An efficient automated parameter tuning framework for spiking neural networks (2014) Front Neurosci, 8. , (,),.,., https://doi.org/10.3389/fnins.2014.00010; Diehl, P.U., Neil, D., Binas, J., Cook, M., Liu, S.C., Pfeiffer, M., Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing (2015) International Joint Conference on Neural Networks., , https://doi.org/10.1109/IJCNN.2015.7280696; Fang, H., Wang, Y., He, J., Spiking neural network for cortical neuronal spike train decoding (2010) Neural Comput, 22 (4), pp. 1060-1085; Gutig, R., Sompolinsky, H., The tempotron: a neuron that learns spike timing-based decisions (2006) Nat Neurosci, 9 (3), pp. 420-428; Huang, S., Rozas, C., Associate hebbian synaptic plasticity in primate visual cortex (2014) J Neurosci, 34 (22), pp. 7575-7579; Humphries, M.D., Gurney, K., Solution methods for a new class of simple model neurons (2007) Neural Comput, 19 (12), pp. 3216-3225; Johnson, A.P., Liu, J., Millard, A., Homeostatic fault tolerance in spiking neural networks: A dynamic hardware perspective (2017) IEEE Transactions on Circuits and Systems-I: Regular Papers, pp. 1-13. , https://doi.org/10.1109/TCSI.2017.2726763; Kennedy, J., Eberhart, R., Particle swarm optimization (1995) IEEE International Conference on Neural Networks, p. 4. , In; Lehky, S.R., Decoding poisson spike trains by gaussian filtering (2010) Neural Comput, 22 (5), pp. 1245-1271; Lin, Z., Shen, J., Ma, D., Meng, J., Quantisation and pooling method for low-inference-latency spiking neural networks (2017) Electron Lett, 53 (20), pp. 1347-1348; Maass, W., Networks of spiking neurons: The third generation of neural network models (1997) Neural Netw, 9 (10), pp. 1659-1672; Masquelier, T., Thorpe, S.J., Unsupervised learning of visual features through spike timing dependent plasticity (2007) PLoS Comput Biol, 3 (2); McMahon, D.B., Leoplod, D.A., Stimuls timing-dependent plasticity in high-level vision (2012) Curr Biol, 22 (4), pp. 332-337; Meliza, C.D., Dan, Y., Receptive-field modification in rat visual cortex induced by paired visual stimulation and single-cell spiking (2006) Neuron, 49 (2), pp. 183-189; Merolla, P., Arthur, J., Akopyan, F., A digital neurosynaptic core using embedded crossbar memory with 45pj per spike in 45nm (2011) IEEE Custom Integrated Circuits Conference, , https://doi.org/10.1109/CICC.2011.6055294; O’Connor, P., Neil, D., Liu, S.C., Delbruck, T., Pfeiffer, M., Real-time classification and sensor fusion with a spiking deep belief network (2013) Front Neurosci, 7. , https://doi.org/10.3389/fnins.2013.00178; Rossum, V., W, M.C., Turrigiano, G.G., Nelson, S.B., Fast propagation of firing rates through layered networks of noisy neurons (2002) J Neurosci, 22 (5), pp. 1956-1966. , https://doi.org/10.1523/JNEUROSCI.22-05-01956.2002; Rueckauer, B., Lungu, I.A., Hu, Y., Pfeiffer, M., (2016) Theory and Tools for the Conversion of Analog to Spiking Convolutional Neural Networks., , arXiv: 1612.04052 [cs, stat]; Schrauwen, B., Campenhout, J.V., Improving spike-prop: Enhancements to an error-backpropagation rule for spiking neural networks (2004) Proceedings of ProRISC Workshop, 11, pp. 301-305; Skocik, M.J., Long, L.N., On the capabilities and computational costs of neuron models (2014) IEEE Trans Neural Netw Learn Syst, 25 (8), pp. 1474-1483; Tino, P., Mills, A.J.S., Learning beyond finite memory in recurrent networks of spiking neurons (2006) Neural Comput, 18 (3), pp. 591-613; Ventura, V., Todorova, S., A computationally efficient method for incorporating spike waveform information into decoding algorithms (2015) Neural Comput, 25 (5), pp. 1033-1050; Zhang, A., Zhou, H., Li, X., Zhu, W., Fast and robust learning in Spiking Feed-forward Neural Networks based on Intrinsic Plasticity mechanism (2019) Neurocomputing, 365, pp. 102-112; Zhang, S., Zhang, A., Ma, Y., Zhu, W., Intrinsic plasticity based inference acceleration for spiking Multi-Layer perceptron (2019) IEEE Access, 7, pp. 73685-73693","Zhang, A.; Key Laboratory of Medical Instrumentation and Pharmaceutical Technology of Fujian ProvinceChina; email: anguo.zhang@hotmail.com",,,"Springer",,,,,0924669X,,APITE,,"English","Appl Intell",Article,"Final","",Scopus,2-s2.0-85095445197
"Bilski J., Rutkowski L., Smoląg J., Tao D.","7004089262;56694314600;6506595282;7102600334;","A novel method for speed training acceleration of recurrent neural networks",2021,"Information Sciences","553",,,"266","279",,7,"10.1016/j.ins.2020.10.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094889747&doi=10.1016%2fj.ins.2020.10.025&partnerID=40&md5=8aaf364ef2f886c255e948aeaa218797","Department of Computational Intelligence, Częstochowa University of Technology, Częstochowa, 42-200, Poland; Information Technology Institute, University of Social Sciences, Łódź, 90-113, Poland; UBTECH Sydney Artificial Intelligence Centre and the School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW  2008, Australia","Bilski, J., Department of Computational Intelligence, Częstochowa University of Technology, Częstochowa, 42-200, Poland; Rutkowski, L., Department of Computational Intelligence, Częstochowa University of Technology, Częstochowa, 42-200, Poland, Information Technology Institute, University of Social Sciences, Łódź, 90-113, Poland; Smoląg, J., Department of Computational Intelligence, Częstochowa University of Technology, Częstochowa, 42-200, Poland; Tao, D., UBTECH Sydney Artificial Intelligence Centre and the School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW  2008, Australia","Although recurrent neural networks (RNNs) perfectly solve many difficult problems, their computational complexity significantly increases training time. Therefore, the primary problem with applying RNNs is to shorten the time needed to train and operate a network. An effective solution to this problem is to use parallel processing. In the paper, a particular approach for the Jordan network will be shown, however, the presented idea is applicable to other RNN structures. This type of network is characterized by natural parallelism, and in the paper, this feature is used to significantly accelerate the learning process. High-performance learning has been achieved using a novel parallel three-dimensional architecture. The presented solutions can be implemented in digital hardware. © 2020 Elsevier Inc.","Parallel architectures; Recurrent neural networks; Supervised learning","Digital hardware; Effective solution; Learning process; Natural parallelism; Parallel processing; Recurrent neural network (RNNs); Three-dimensional architecture; Training acceleration; Recurrent neural networks",,,,,"2017/27/B/ST6/02852","This work was supported by the Polish National Science Center under Grant 2017/27/B/ST6/02852.",,,,,,,,,,"Akdeniz, E., Egrioglu, E., Bas, E., Yolcu, U., An ARMA type Pi-Sigma artificial neural network for nonlinear time series forecasting (2017) J. Artif. Intell. Soft Comput. Res., 8 (2), pp. 121-132; Amin, M.A., Hanif, M.K., Sarwar, M.U., Rehman, A., Waheed, F., Rehman, H., (2019), Parallel backpropagation neural network training techniques using graphics processing unit, IJACSA Int. J. Adv. Comput. Sci. Appl. 10 (2); Bilski, J., Smoląg, J., Parallel realisation of the recurrent RTRN neural network learning (2008) Lecture Notes in Artificial Intelligence, no, 5097, pp. 11-16; Bilski, J., Smoląg, J., (2010), 6114, pp. 19-25. , Parallel realisation of the recurrent Elman neural network learning, Lecture Notes in Artificial Intelligence, no; Bilski, J., Smoląg, J., Parallel architectures for learning the RTRN and Elman dynamic neural networks (2015) IEEE Trans. Parallel Distrib. Syst., 26 (9), pp. 2561-2570; Chevitarese, D.S., Szwarcman, D., Vellasco, M., Speeding up the training of neural networks with CUDA technology (2012) Lecture Notes in Artificial Intelligence, 7267, pp. 30-38; Dreyfus, G., Neural Networks Methodology and Applications (2005), Springer; Elman, J., Finding structure in time (1990) Cogn. Sci., 14, pp. 179-211; Frayman, Y., Wang, L., (1998), 1, pp. 646-651. , Robust control of continuous polymerization reactor by dynamically constructed recurrent fuzzy neural network, Proceedings of the 1998 World Multiconference on Systemics, Cybernetics and Informatics; Frayman, Y., Wang, L., (1998), 1394, pp. 122-131. , Data mining using dynamically constructed recurrent fuzzy neural networks, Research and Development in Knowledge Discovery and Data Mining, PAKDD’98; Frayman, Y., Wang, L., (1998), pp. 26-30. , Backup rolls eccentricity control in cold rolling mills using dynamically constructed recurrent fuzzy neural networks, Proc. 1998 Australian Conference on Neural Networks; Ganeshamoorthy, K., Ratnarajah, N., On the performance of parallel back-propagation Neural Network Implementations Using CUDA, Computers and Their Applications (CATA-2017), ISCA 32nd International Conference, March 20–22, Honolulu, Hawaii, USA; Goldberg, Y., Neural network methods in natural language processing (2017) Morgan Claypool; Haykin, S.O., Neural Networks and Learning Machines (2011), Pearson Education; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Jang, H., Park, A., Jung, K., (2008), Neural network implementation using CUDA and OpenMP, w Digital Image Computing: Techniques and Applications, Canberra; Jordan, M., Attractor dynamics and parallelism in a connectionist sequential machine (1986) Proc. 8th Annual Conf. on Cognition Science Society, pp. 531-546; Kirk, D., Hwu, W., (2012), Programming Massively Parallel Processors, A Hands-on Approach, Morgan Kaufmann; Kolen, J., Kremer, S., A Field Guide to Dynamical Recurrent Neural Networks (2001), IEEE Press; Lang, G., Hong, H., Xie, W., Zheng, L., (2018), 6, pp. 36188-36197. , Combining convolutional neural network with recursive neural network for blood cell image classification, IEEE Access J; Liu, J.-B., Zhao, J., Wang, S., Javaid, M., Cao, J., On the topological properties of the certain neural networks (2018) J. Artif. Intell. Soft Comput. Res., 8 (4), pp. 257-268; Ludwig, S.A., Applying a neural network ensemble to intrusion detection (2019) J. Artif. Intell. Soft Comput. Res., 9 (3), pp. 177-188; MacKay, M., Vicol, P., Ba, J., Grosse, R., Reversible recurrent neural networks, 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montreal, Canada, 2018; Maeda, Y., Wakamura, M., Simultaneous perturbation learning rule for recurrent neural networks and its FPGA implementation (2005) IEEE Trans. Neural Networks, 16 (6), pp. 1664-1672; Mandic, D., Chambers, J., Recurrent Neural Networks for Prediction (2001), John Wiley & Sons Ltd; Omarov, B., Suliman, A., Kushibar, K., (2016), Face recognition using artificial neural networks in prarallel architecture, J. Theor. Appl. Inf. Technol. 91 (2); Pineda, F.J., Generalization of backpropagation to recurrent and higher order neural networks (1987), pp. 602-611. , Neural Information Processing Systems, New York, American Institute of Physics; Rashid, T., Recurrent Neural Network Model (2013) Lap Lambert Academic Publishing; Rogerson, J., Recent Progress in Artificial Neural Networks, Clanrye International, 2019; Rogerson, J., (2015), Theory, Concepts and Methods of Recurrent Neural Networks and Soft Computing, Clanrye International; Rutkowski, L., Computational Intelligence. Methods and Techniques (2008), Springer-Verlag; Seiffert, U., Artificial neural networks on massively parallel computer hardware (2004) Neurocomputing, 57, pp. 135-150; Stilkerich, S.C., Graph theoretical representation of ANN architectures on regular two-dimensional grids for VLSI implementations (2007) Neurocomputing, 71, pp. 45-70; Tadeusiewicz, R., Chaki, R., Chaki, N., Exploring Neural Networks with C# (2014), CRC Press, Taylor & Francis Group Boca Raton; Wang, L., Fu, X., Data Mining with Computational Intelligence (2005), Springer Berlin; Wang, L., Ross, J., (1990), 87, pp. 988-992. , Synchronous neural networks of nonlinear threshold elements with hysteresis, Proc. Nat. Acad. Sci. USA; Wei, R., Cao, J., Synchronization analysis of inertial memristive neural networks with time-varying delays (2018) J. Artif. Intell. Soft Comput. Res., 8 (4), pp. 269-282; Werbos, J., (1990), Backpropagation through time: What it does and how to do it, Proc. IEEE 78 (10); Wilamowski, B., Yu, H., Improved computation for Levenberg-Marquardt training (2010) IEEE Trans. Neural Networks, 21 (6), pp. 930-937; Wilamowski, B., Yu, H., Neural network learning without backpropagation (2010) IEEE Trans. Neural Networks, 21 (11), pp. 1793-1803; Williams, R., Zipser, D., A learning algorithm for continually running fully recurrent (1989) Neural Comput., pp. 270-280; Yi, Z., Convergence Analysis of Recurrent Neural Networks (2013), Springer Science and Business Media; Zeng, Z., Wang, J., (2006), Improved conditions for global exponential stability of recurrent neural networks with time-varying delays, IEEE Trans. Neural Networks 17 (3)","Bilski, J.; Department of Computational Intelligence, Poland; email: jaroslaw.bilski@pcz.pl",,,"Elsevier Inc.",,,,,00200255,,ISIJB,,"English","Inf Sci",Article,"Final","",Scopus,2-s2.0-85094889747
"Lin Y., Jiang Z., Gu J., Li W., Dhar S., Ren H., Khailany B., Pan D.Z.","56604399900;57213420698;57213420794;57192211726;57192203522;9335106200;6603491041;57200099742;","DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement",2021,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","40","4","9122053","748","761",,11,"10.1109/TCAD.2020.3003843","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087526836&doi=10.1109%2fTCAD.2020.3003843&partnerID=40&md5=bb53432de9b1b6d75c6854141972199a","Center for Energy-Efficient Computing and Applications, School of Eecs, Peking University, Beijing, 100871, China; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX  78712, United States; Fpga Implementation Software Group, Xilinx Inc., San Jose, CA  95124, United States; Programmable Solutions Group, Intel Corporation, San Jose, CA  95134, United States; Nvidia, Austin, TX  78717, United States","Lin, Y., Center for Energy-Efficient Computing and Applications, School of Eecs, Peking University, Beijing, 100871, China; Jiang, Z., Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX  78712, United States; Gu, J., Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX  78712, United States; Li, W., Fpga Implementation Software Group, Xilinx Inc., San Jose, CA  95124, United States; Dhar, S., Programmable Solutions Group, Intel Corporation, San Jose, CA  95134, United States; Ren, H., Nvidia, Austin, TX  78717, United States; Khailany, B., Nvidia, Austin, TX  78717, United States; Pan, D.Z., Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX  78712, United States","Placement for very large-scale integrated (VLSI) circuits is one of the most important steps for design closure. We propose a novel GPU-accelerated placement framework DREAMPlace, by casting the analytical placement problem equivalently to training a neural network. Implemented on top of a widely adopted deep learning toolkit PyTorch, with customized key kernels for wirelength and density computations, DREAMPlace can achieve around 40× speedup in global placement without quality degradation compared to the state-of-the-art multithreaded placer RePlAce. We believe this work shall open up new directions for revisiting classical EDA problems with advancements in AI hardware and software. © 1982-2012 IEEE.","Deep learning; GPU acceleration; physical desgin; VLSI placement","Graphics processing unit; VLSI circuits; Analytical Placement; Global placements; GPU accelerations; GPU-accelerated; Hardware and software; Quality degradation; State of the art; Very large scale integrated; Deep learning",,,,,"Nvidia","Manuscript received September 16, 2019; revised January 9, 2020, April 5, 2020, and June 9, 2020; accepted June 12, 2020. Date of publication June 22, 2020; date of current version March 19, 2021. This work was supported in part by NVIDIA. This article was recommended by Associate Editor I. H.-R. Jiang. (Corresponding author: Yibo Lin.) Yibo Lin is with the Center for Energy-Efficient Computing and Applications, School of EECS, Peking University, Beijing 100871, China (e-mail: yibolin@pku.edu.cn).",,,,,,,,,,"Kahng, A.B., Reda, S., Wang, Q., Architecture and details of a high quality, large-scale analytical placer (2005) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 891-898; Chan, T., Cong, J., Sze, K., Multilevel generalized force-directed method for circuit placement (2005) Proc. Acm Int. Symp. Phys. Design (ISPD), pp. 185-192; Kahng, A.B., Wang, Q., A faster implementation of APlace (2006) Proc. Acm Int. Symp. Phys. Design (ISPD), pp. 218-220; Chen, T.-C., Jiang, Z.-W., Hsu, T.-C., Chen, H.-C., Chang, Y.-W., NTUPlace3: An analytical placer for large-scale mixed-size designs with preplaced blocks and density constraints (2008) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., 27 (7), pp. 1228-1240. , Jul; Hsu, M.-K., NTUplace4h: A novel routability-driven placement algorithm for hierarchical mixed-size circuit designs (2014) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., 33 (12), pp. 1914-1927. , Dec; Lu, J., EPlace: Electrostatics-based placement using fast Fourier transform and Nesterov's method (2015) Acm Trans. Design Autom. Electron. Syst., 20 (2), p. 17; Lu, J., EPlace-MS: Electrostatics-based placement for mixed-size circuits (2015) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., 34 (5), pp. 685-698. , May; Cheng, C., Kahng, A.B., Kang, I., Wang, L., RePlAce: Advancing solution quality and routability validation in global placement (2019) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., 38 (9), pp. 1717-1730. , Sep; Zhu, Z., Chen, J., Peng, Z., Zhu, W., Chang, Y.-W., Generalized augmented Lagrangian and its applications to VLSI global placement (2018) Proc. ACM/IEEE Design Autom. Conf. (DAC), pp. 1-6; Viswanathan, N., Pan, M., Chu, C., FastPlace 3.0: A fast multilevel quadratic placement algorithm with placement congestion control (2007) Proc. IEEE/ACM Asia South Pac. Design Autom. Conf. (ASPDAC), pp. 135-140; He, X., Huang, T., Xiao, L., Tian, H., Young, E.F.Y., Ripple: A robust and effective routability-driven placer (2013) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., 32 (10), pp. 1546-1556. , Oct; Lin, T., Chu, C., Shinnerl, J.R., Bustany, I., Nedelchev, I., POLAR: Placement based on novel rough legalization and refinement (2013) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 357-362; Lin, T., Chu, C., Shinnerl, J.R., Bustany, I., Nedelchev, I., POLAR: A high performance mixed-size Wirelengh-driven placer with density constraints (2015) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., 34 (3), pp. 447-459. , Mar; Kim, M.-C., Lee, D.-J., Markov, I.L., SimPL: An effective placement algorithm (2012) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., 31 (1), pp. 50-60. , Jan; Kim, M.-C., Viswanathan, N., Alpert, C.J., Markov, I.L., Ramji, S., MAPLE: Multilevel adaptive placement for mixed-size designs (2012) Proc. Acm Int. Symp. Phys. Design (ISPD), pp. 193-200; Lin, T., Chu, C., Wu, G., POLAR 3.0: An ultrafast global placement engine (2015) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 520-527; Li, W., Lin, Y., Pan, D.Z., ElfPlace: Electrostatics-based placement for large-scale heterogeneous FPGAs (2019) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 1-8. , Nov; (2020) Cadence Innovus, , http://www.cadence.com, Accessed: Jun. 1, [Online]; (2020) Synopsys Ic Compiler, , http://www.synopsys.com, Accessed: Jun. 1, [Online]; Ludwin, A., Betz, V., Padalia, K., High-quality, deterministic parallel placement for FPGAs on commodity hardware (2008) Proc. Acm Symp. FPGAs, pp. 14-23; Li, W., Li, M., Wang, J., Pan, D.Z., UTPlaceF 3.0: A parallelization framework for modern FPGA global placement (2017) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 922-928; Cong, J., Zou, Y., Parallel multi-level analytical global placement on graphics processing units (2009) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 681-688; Lin, C.-X., Wong, M.D., Accelerate analytical placement with GPU: A generic approach (2018) Proc. IEEE/ACM Design Autom. Test Europe (DATE), pp. 1345-1350; Paszke, A., PyTorch: An imperative style, high-performance deep learning library (2019) Proc. Conf. Neural Inf. Process. Syst. (NeurIPS), pp. 8024-8035; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2015) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-6; Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y., (2016) Deep Learning, 1. , Cambridge, MA, USA: MIT Press; Hsu, M.-K., Chang, Y.-W., Balabanov, V., TSV-aware analytical placement for 3D IC designs (2011) Proc. ACM/IEEE Design Autom. Conf. (DAC), pp. 664-669; Hsu, M.-K., Balabanov, V., Chang, Y.-W., TSV-aware analytical placement for 3-D IC designs based on a novel weighted-average wire-length model (2013) Proc. ACM/IEEE Design Autom. Conf. (DAC), 32, pp. 497-509; Naylor, W.C., Donelly, R., Sha, L., (2001) Non-Linear Optimization System and Method for Wire Length and Delay Optimization for An Automatic Electric Circuit Placer, , U.S. Patent, Oct; Lin, Y., Dhar, S., Li, W., Ren, H., Khailany, B., Pan, D.Z., DREAMPlace: Deep learning toolkit-enabled text GPU acceleration for modern VLSI placement (2019) Proc. ACM/IEEE Design Autom. Conf. (DAC), pp. 1-6; Berman, K.A., Paul, J., (1996) Fundamentals of Sequential and Parallel Algorithms, 1st Ed, , Boston, MA, USA: PWS; Makhoul, J., A fast cosine transform in one and two dimensions (1980) Ieee Trans. Signal Process., SP-28 (1), pp. 27-34. , Feb; Zou, F., Shen, L., Jie, Z., Zhang, W., Liu, W., A sufficient condition for convergences of Adam and RMSProp (2019) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 11127-11135; Spindler, P., Schlichtmann, U., Johannes, F.M., Abacus: Fast legalization of standard cell circuits with minimal movement (2008) Proc. Acm Int. Symp. Phys. Design (ISPD), pp. 47-53; Chan, T.F., Sze, K., Shinnerl, J.R., Xie, M., MPL6: Enhanced multilevel mixed-size placement with congestion control (2007) Modern Circuit Placement, pp. 247-288. , G. J. Nam, and J. Cong, Eds. Boston, MA, USA: Springer; Liu, W.-H., Kao, W.-C., Li, Y.-L., Chao, K.-Y., NCTU-GR 2.0: Multithreaded collision-aware global routing with bounded-length maze routing (2013) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., 32 (5), pp. 709-722. , Mar; Kahng, A.B., Wang, Q., An analytic placer for mixed-size placement and timing-driven placement (2004) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 565-572; Nam, G.-J., Alpert, C.J., Villarrubia, P., Winter, B., Yildiz, M., The ISPD2005 placement contest and benchmark suite (2005) Proc. Acm Int. Symp. Phys. Design (ISPD), pp. 216-220; Dhar, S., Pan, D.Z., GDP: GPU accelerated detailed placement (2018) Proc. Ieee High Perform. Extreme Comput. Conf. (HPEC), pp. 1-7; Lin, Y., Li, W., Gu, J., Ren, H., Khailany, B., Pan, D.Z., ABCDPlace: Accelerated batch-based concurrent detailed placement on multi-threaded CPUs and GPUs (2020) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., Early Access, 4. , Feb; Viswanathan, N., Alpert, C., Sze, C., Li, Z., Wei, Y., The DAC 2012 routability-driven placement contest and benchmark suite (2012) Proc. ACM/IEEE Design Autom. Conf. (DAC), pp. 774-782","Lin, Y.; Center for Energy-Efficient Computing and Applications, China; email: yibolin@pku.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Final","",Scopus,2-s2.0-85087526836
"Samiee A., Borulkar P., DeMara R.F., Zhao P., Bai Y.","57207581588;57208747598;6603698741;55459157600;55217532900;","Low-energy acceleration of binarized convolutional neural networks using a spin hall effect based logic-in-memory architecture",2021,"IEEE Transactions on Emerging Topics in Computing","9","2","8709815","928","940",,3,"10.1109/TETC.2019.2915589","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065656009&doi=10.1109%2fTETC.2019.2915589&partnerID=40&md5=9fb1391a221c8a78d705cc7b820c8126","Computer Engineering Program, College of Engineering and Computer Science, California State University, Fullerton, CA  92831, United States; Department of Electrical Engineering and Computer Engineering, University of Central Florida, Orlando, FL  32816, United States; Schmid College of Science and Technology, Chapman University, Orange, CA  92866, United States","Samiee, A., Computer Engineering Program, College of Engineering and Computer Science, California State University, Fullerton, CA  92831, United States; Borulkar, P., Computer Engineering Program, College of Engineering and Computer Science, California State University, Fullerton, CA  92831, United States; DeMara, R.F., Department of Electrical Engineering and Computer Engineering, University of Central Florida, Orlando, FL  32816, United States; Zhao, P., Schmid College of Science and Technology, Chapman University, Orange, CA  92866, United States; Bai, Y., Computer Engineering Program, College of Engineering and Computer Science, California State University, Fullerton, CA  92831, United States","Deep Learning (DL) offers the advantages of high accuracy performance at tasks such as image recognition, learning of complex intelligent behaviors, and large-scale information retrieval problems such as intelligent web search. To attain the benefits of DL, the high computational and energy-consumption demands imposed by the underlying processing, interconnect, and memory devices on which software-based DL executes can benefit substantially from innovative hardware implementations. Logic-in-Memory (LIM) architectures offer potential approaches to attaining such throughput goals within area and energy constraints starting with the lowest layers of the hardware stack. In this paper, we develop a Spintronic Logic-in-Memory (S-LIM) XNOR neural network (S-LIM XNN) which can perform binary convolution with reconfigurable in-memory logic without supplementing distinct logic circuits for computation within the memory module itself. Results indicate that the proposed S-LIM XNN designs achieve 1.2-fold energy reduction, 1.26-fold throughput increase, and 1.4-fold accuracy improvement compared to the state-of-the-art binarized convolutional neural network hardware. Design considerations, architectural approaches, and the impact of process variation on the proposed hybrid spin-CMOS design are identified and assessed, including comparisons and recommendations for future directions with respect to LIM approaches for neuromorphic computing. © 2013 IEEE.","classifier systems; image processing; In-memory computing; post-CMOS computing architectures; STT-MRAM","CMOS integrated circuits; Computation theory; Computer architecture; Convolution; Convolutional neural networks; Deep learning; Energy efficiency; Energy utilization; Green computing; Image processing; Image recognition; Information retrieval; Low power electronics; Mathematical models; Memory architecture; MRAM devices; Network architecture; Neural networks; Spin Hall effect; Technical writing; Architectural approach; Classifier systems; Hardware implementations; Large scale information retrieval; Logic-in-memory architecture; Neuromorphic computing; Post-cmos computing; STT-MRAM; Computer circuits",,,,,"National Science Foundation, NSF: 1739635",,,,,,,,,,,"He, X., Wang, K., Huang, H., Miyazaki, T., Wang, Y., Guo, S., Green resource allocation based on deep reinforcement learning in content-centric IoT IEEE Trans. Emerging Topics Comput, , to be published; Sainath, T.N., Mohamed, A.R., Kingsbury, B., Ramabhadran, B., Deep convolutional neural networks for LVCSR (2013) Proc. IEEE Int. Conf. Acoust. Speech Signal Process., pp. 8614-8618. , May; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural Machine Translation by Jointly Learning to Align and Translate, , http://arxiv.org/abs/1409.0473, CoRR, vol. abs/1409.0473; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.E., Anguelov, D., Erhan, D., Rabinovich, A., (2014) Going Deeper with Convolutions, , http://arxiv.org/abs/1409.4842, CoRR, vol. abs/1409.4842; Alawad, M., Bai, Y., Demara, R., Lin, M., Robust large-scale convolution through stochastic-based processing without multipliers IEEE Trans. Emerging Topics Comput, , to be published; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 1097-1105; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Int. Conf. Learn. Representations; Coates, A., Huval, B., Wang, T., Wu, D.J., Ng, A.Y., Catanzaro, B., Deep learning with COTS HPC systems (2013) Proc. Int. Conf. Int. Conf. Mach. Learn., pp. 31337-31345; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. 22nd ACM Int. Conf. Multimedia, pp. 675-678; (2016) Theano:Apython Framework for Fast Computation Ofmathematical Expressions, , T.D. Team, et al.,CoRR, vol. abs/1605.02688; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Devin, M., (2016) TensorFlow: Large-scale Machine Learning on Heterogeneous Distributed Systems, , Softw. available from tensorflow. org; Zhao, R., Song, W., Zhang, W., Xing, T., Lin, J.-H., Srivastava, M., Gupta, R., Zhang, Z., Accelerating binarized convolutional neural networks with software-programmable FPGAS (2017) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 15-24. , http://doi.acm.org/10.1145/3020078.3021741; Venkatesh, G., Nurvitadhi, E., Marr, D., (2016) Accelerating Deep Convolutional Networks Using Low-precision and Sparsity, , http://arxiv.org/abs/1610.00324, CoRR, vol. abs/ 1610.00324; Suda, N., Chandra, V., Dasika, G., Mohanty, A., Ma, Y., Vrudhula, S., Seo, J.-S., Cao, Y., Throughput-optimized OpenCL-based FPGA accelerator for large-scale convolutional neural networks (2016) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 16-25. , http://doi.acm.org/10.1145/2847263.2847276; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., (2016) XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks, , http://arxiv.org/abs/1603.05279, CoRR, vol. abs/1603.05279; Pala, D., Causapruno, G., Vacca, M., Riente, F., Turvani, G., Graziano, M., Zamboni, M., Logic-in-Memory architecture made real (2015) Proc. IEEE Int. Symp. Circuits Syst., pp. 1542-1545. , May; Grossi, A., Zambelli, C., Olivo, P., Pellati, P., Ramponi, M., Wenger, C., Alvarez-Hrault, J., Mackay, K., An automated test equipment for characterization of emerging MRAM and RRAM arrays (2018) IEEE Trans. Emerging Topics Comput., 6 (2), pp. 269-277. , Apr.-Jun; Fan, D., Angizi, S., Energy efficient in-memory binary deep neural network accelerator with dual-mode SOT-MRAM (2017) Proc. IEEE 35th Int. Conf. Comput. Des., pp. 609-612; Tang, T., Xia, L., Li, B., Wang, Y., Yang, H., Binary convolutional neural network on RRAM (2017) Proc. 22nd Asia South Pacific Des. Autom. Conf., pp. 782-787. , Jan; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., (2016) XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks, , http://arxiv.org/abs/1603.05279, CoRR, vol. abs/1603.05279; Stone, H.S., A logic-in-memory computer (1970) IEEE Trans. Comput., C19 (1), pp. 73-78. , https://doi.org/10.1109/TC.1970.5008902, Jan; Kautz, W.H., Cellular logic-in-memory arrays (1969) IEEE Trans. Comput., C18 (8), pp. 719-727. , Aug; Shah, F.A., Sankar, V.K., Li, P., Csaba, G., Chen, E., Bernstein, G.H., Compensation of orange-peel coupling effect in magnetic tunnel junction free layer via shape engineering for nanomagnet logic applications (2014) J. Appl. Physics, 115 (17). , http://dx.doi.org/10.1063/1.4863935; He, Z., Fan, D., Energy efficient reconfigurable threshold logic circuit with spintronic devices (2017) IEEE Trans. Emerging Topics Comput., 5 (2), pp. 223-237. , Apr.-Jun; Kwon, K.-W., Fong, X., Wijesinghe, P., Panda, P., Roy, K., Highdensity and robust STT-MRAM array through device/circuit/architecture interactions (2015) IEEE Trans. Nanotechnol., 14 (6), pp. 1024-1034. , Nov; Bai, Y., Fan, D., Lin, M., Stochastic-based synapse and soft-limiting neuron with spintronic devices for low power and robust artificial neural networks (2018) IEEE Trans. Multi-Scale Comput. Syst., 4 (3), pp. 463-476. , Jul.-Sep; Gupta, S.K., Park, S.P., Mojumder, N.N., Roy, K., Layout-aware optimization of STT MRAMs (2012) Proc. Conf. Des. Autom. Test Eur., pp. 1455-1458. , http://dl.acm.org/citation.cfm?id=2492708.2493064; Seo, Y., Kwon, K., Fong, X., Roy, K., High performance and energyefficient on-chip cache using dual port (1R/1W) spin-orbit torque MRAM (2016) IEEE J. Emerging Sel. Topics Circuits Syst., 6 (3), pp. 293-304. , Sep; Oliveira, C.H., Moreira, M.T., Guazzelli, R.A., Calazans, N.L., ASCEnD-FreePDK45: An open source standard cell library for asynchronous design (2016) Proc. IEEE Int. Conf. Electron. Circuits Syst., pp. 652-655; Ye, Y., Liu, F., Nassif, S., Cao, Y., Statistical modeling and simulation of threshold variation under dopant fluctuations and line-edge roughness (2008) Proc. 45th ACM/IEEE Des. Autom. Conf., pp. 900-905. , Jun; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 3431-3440; Jabeur, K., Pendina, G.D., Prenat, G., Buda-Prejbeanu, L.D., Dieny, B., Compact modeling of a magnetic tunnel junction based on spin orbit torque (2014) IEEE Trans. Magn., 50 (7), pp. 1-8. , Jul; Prenat, G., Jabeur, K., Vanhauwaert, P., Pendina, G.D., Oboril, F., Bishnoi, R., Ebrahimi, M., Gaudin, G., Ultra-fast and high-reliability SOT-MRAM: From cache replacement to normally-off computing (2016) IEEE Trans. Multi-Scale Comput. Syst., 2 (1), pp. 49-60. , Jan.-Mar; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , http://arxiv.org/abs/1412.6980, CoRR, vol. abs/1412.6980; Tang, W., Hua, G., Wang, L., How to train a compact binary neural network with high accuracy? (2017) Proc. AAAI Conf. Artif. Intell., pp. 2625-2631; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2014) Int. Conf. On Learn. Representations; Courbariaux, M., Bengio, Y., (2016) BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1, , http://arxiv.org/abs/1602.02830, CoRR, vol. abs/ 1602.02830; Dong, X., Xu, C., Xie, Y., Jouppi, N.P., NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory (2012) IEEE Trans. Comput.-AidedDes. Integr. Circuits Syst., 31 (7), pp. 994-1007. , Jul; Sheu, S., Chang, M., Lin, K., Wu, C., Chen, Y., Chiu, P., Kuo, C., Tsai, M., A 4Mb embedded SLC resistive-RAM macro with 7.2 ns read-write random-access time and 160 ns MLC-access capability (2011) Proc. IEEE Int. Solid-State Circuits Conf., pp. 200-202. , Feb; Boroumand, A., Ghose, S., Patel, M., Hassan, H., Lucia, B., Hsieh, K., Malladi, K.T., Mutlu, O., LazyPIM: An efficient cache coherence mechanism for processing-in-memory (2017) IEEE Comput. Archit. Lett., 16 (1), pp. 46-50. , Jan.-Jun; Ghose, S., Hsieh, K., Boroumand, A., Ausavarungnirun, R., Mutlu, O., (2018) Enabling the Adoption of Processing-in-memory: Challenges, Mechanisms, Future Research Directions, , CoRR, vol. abs/1802.00320; Han, L., Shen, Z., Shao, Z., Huang, H.H., Li, T., A novel ReRAMbased processing-in-memory architecture for graph computing (2017) Proc. IEEE 6th Non-Volatile Memory Syst. Appl. Symp., pp. 1-6; Xu, S., Chen, X., Wang, Y., Han, Y., Qian, X., Li, X., PIMSim: A flexible and detailed processing-in-memory simulator (2019) IEEE Comput. Archit. Lett., 18 (1), pp. 6-9. , Jan.-Jun","Bai, Y.; Computer Engineering Program, United States; email: ybai@fullerton.edu",,,"IEEE Computer Society",,,,,21686750,,,,"English","IEEE Trans. Emerg. Top. Comput.",Article,"Final","",Scopus,2-s2.0-85065656009
"He D., He J., Liu J., Yang J., Yan Q., Yang Y.","35728843100;57205554447;55821583800;56979781200;55307568700;57192546579;","An fpga-based LSTM acceleration engine for deep learning frameworks",2021,"Electronics (Switzerland)","10","6","681","1","15",,3,"10.3390/electronics10060681","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102368196&doi=10.3390%2felectronics10060681&partnerID=40&md5=b2ba9f847dc1d2a2894f2ceb04796c68","Beijing Laboratory of Advanced Information Networks and Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China","He, D., Beijing Laboratory of Advanced Information Networks and Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China, School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; He, J., Beijing Laboratory of Advanced Information Networks and Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China, School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Liu, J., Beijing Laboratory of Advanced Information Networks and Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China, School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Yang, J., Beijing Laboratory of Advanced Information Networks and Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China, School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Yan, Q., Beijing Laboratory of Advanced Information Networks and Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China, School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Yang, Y., Beijing Laboratory of Advanced Information Networks and Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China, School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China","Over the past two decades, Long Short-Term Memory (LSTM) networks have been used to solve problems that require modeling of long sequence because they can selectively remember certain patterns over a long period, thus outperforming traditional feed-forward neural networks and Recurrent Neural Network (RNN) on learning long-term dependencies. However, LSTM is characterized by feedback dependence, which limits the high parallelism of general-purpose processors such as CPU and GPU. Besides, in terms of the energy efficiency of data center applications, the high consumption of GPU and CPU computing cannot be ignored. To deal with the above problems, Field Programmable Gate Array (FPGA) is becoming an ideal alternative. FPGA has the characteristics of low power consumption and low latency, which are helpful for the acceleration and optimization of LSTM and other RNNs. This paper proposes an implementation scheme of the LSTM network acceleration engine based on FPGA and further optimizes the implementation through fixed-point arithmetic, systolic array and lookup table for nonlinear function. On this basis, for easy deployment and application, we integrate the proposed acceleration engine into Caffe, one of the most popular deep learning frameworks. Experimental results show that, compared with CPU and GPU, the FPGA-based acceleration engine can achieve performance improvement of 8.8 and 2.2 times and energy efficiency improvement of 16.9 and 9.6 times, respectively, within Caffe framework. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Fixed-point arithmetic; FPGA; Hardware acceleration; LSTM; Matrix multiplication; Systolic array",,,,,,"National Key Research and Development Program of China, NKRDPC: 2017YFB0802701; 6142208180205; Higher Education Discipline Innovation Project: B08004, B17007; Natural Science Foundation of Beijing Municipality: L182024; Fundamental Research Funds for the Central Universities: 2018XKJC04; National Natural Science Foundation of China, NSFC: 61801035, 61701031, 61671078; Beijing University of Posts and Telecommunications, BUPT: 500418763, 142208180205","This work was supported partially by the National Natural Science Foundation of China (61671078, 61701031 and 61801035), Beijing Natural Science Foundation (L182024), basic BUPT scientific research project (500418763), research project of BUPT (142208180205), Science and Technology on Space Intelligent Control Laboratory (6142208180205), Funds of Beijing Laboratory of Advanced Information Networks and Beijing Key Laboratory of Network System Architecture and Convergence of BUPT, the Fundamental Research Funds for the Central Universities (2018XKJC04), the National Key Research and Development Program of China (2017YFB0802701) and the 111 Project of China (B08004 and B17007).",,,,,,,,,,"Graves, A., Jaitly, N., Mohamed, A., Hybrid speech recognition with deep bidirectional lstm Proceedings of the 2013 IEEE Workshop on Automatic Speech Recognition and Understanding, pp. 273-278. , Olomouc, Czech Republic, 8–12 December 2013; Sutskever, I., Vinyals, O., Le, Q.V., (2014) Sequence to sequence learning with neural networks, , arXiv arXiv:1409.3215; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9, pp. 1735-1780; Appleyard, J., Kocisky, T., Blunsom, P., (2016) Optimizing performance of recurrent neural networks on gpus, , arXiv arXiv:1604.01946; Collobert, R., Bengio, S., Mariethoz, J., (2002) Torch: A Modular Machine Learning Software Library, , Idiap: Martigny, Switzerland; Seide, F., Agarwal, A., Cntk: Microsoft’s open-source deeplearning toolkit Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 2135-2135. , San Francisco, CA, USA, 13–17 August 2016; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A system for largescale machine learning Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16), pp. 265-283. , Savannah, GA, USA, 2–4 November 2016; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding Proceedings of the 22nd ACM international conference on Multimedia, pp. 675-678. , Orlando, Florida, USA, 3–7 November 2014; Ortiz, M., Cristal, A., Ayguadé, E., Casas, M., (2018) Low-precision floating-point schemes for neural network training, , arXiv arXiv:1804.05267; DiCecco, R., Sun, L., Chow, P., Fpga-based training of convolutional neural networks with a reduced precision floating-point library Proceedings of the 2017 International Conference on Field Programmable Technology (ICFPT), pp. 239-242. , Melbourne, VIC, Australia, 11–13 December 2017; Gupta, S., Agrawal, A., Gopalakrishnan, K., Narayanan, P., Deep learning with limited numerical precision Proceedings of the International Conference on Machine Learning, pp. 1737-1746. , Lille, France, 6–11 July 2015; Lian, X., Liu, Z., Song, Z., Dai, J., Zhou, W., Ji, X., High-performance fpga-based cnn accelerator with block-floating-point arithmetic (2019) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 27, pp. 1874-1885. , IEEE: Piscataway, NJ, USA; Lu, L., Liang, Y., Xiao, Q., Yan, S., Evaluating fast algorithms for convolutional neural networks on fpgas Proceedings of the 2017 IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), pp. 101-108. , Napa, CA, USA, 30 April–2 May 2017; Kala, S., Jose, B.R., Mathew, J., Nalesh, S., High-performance cnn accelerator on fpga using unified winograd-gemm architecture (2019) IEEE Trans. Very Large Scale Integr. (VLSI) Syst, 27, pp. 2816-2828; Bai, L., Zhao, Y., Huang, X., A CNN accelerator on FPGA using depthwise separable convolution (2018) IEEE Trans. Circuits Syst. II Express Briefs, 65, pp. 1415-1419; Yu, Y., Zhao, T., Wang, K., He, L., Light-opu: an fpga-based overlay processor for lightweight convolutional neural networks Proceedings of the 2020 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 122-132. , Seaside, CA, USA, 23–25 February 2020; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.S., Performance modeling for cnn inference accelerators on fpga (2020) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst, 39, pp. 843-856; Cariow, A., Cariowa, G., (2020) Minimal filtering algorithms for convolutional neural networks, , arXiv arXiv:2004.05607; Cariow, A., Paplinski, J.P., Some algorithms for computing short-length linear convolution (2020) Electronics, 9, p. 2115; Chang, A.X.M., Martini, B., Culurciello, E., (2015) Recurrent neural networks hardware implementation on FPGA, , arXiv arXiv:1511.05552; Han, S., Kang, J., Mao, H., Hu, Y., Li, X., Li, Y., Xie, D., Wang, Y., Ese: Efficient speech recognition engine with sparse lstm on fpga Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 75-84. , February Monterey, CA, USA, 22–24 February 2017; Wang, S., Li, Z., Ding, C., Yuan, B., Qiu, Q., Wang, Y., Liang, Y., C-LSTM: Enabling efficient LSTM using structured compression techniques on FPGAs Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 11-20. , February Monterey, CA, USA, 25–27 February 2018; Cao, S., Zhang, C., Yao, Z., Xiao, W., Nie, L., Zhan, D., Liu, Y., Zhang, L., Efficient and effective sparse LSTM on FPGA with bank-balanced sparsity Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 63-72. , February Seaside, CA, USA, 24–26 February 2019; Kung, H.T., Why systolic architectures? (1982) IEEE Comput, 15, pp. 37-46; Lin, C.W., Wang, J.S., A digital circuit design of hyperbolic tangent sigmoid function for neural networks Proceedings of the 2008 IEEE International Symposium on Circuits and Systems, pp. 856-859. , Seattle, WA, USA, 18–21 May 2008; Ferreira, J.C., Fonseca, J., An fpga implementation of a long short term memory neural network Proceedings of the 2016 International Conference on ReConFigurable Computing and FPGAs (ReConFig), pp. 1-8. , Cancun, Mexico, 30 November–2 December 2016; Kornerup, P., Muller, J.M., Panhaleux, A., Performing arithmetic operations on round-to-nearest representations (2010) IEEE Trans. Comput, 60, pp. 282-291; Stone, J.E., Gohara, D., Shi, G., Opencl: A parallel programming standard for heterogeneous computing systems (2010) Comput. Sci. Eng, 12, pp. 66-72","Yang, Y.; Beijing Laboratory of Advanced Information Networks and Beijing Key Laboratory of Network System Architecture and Convergence, China; email: buptyy1015@gmail.com
Yang, Y.; School of Artificial Intelligence, China; email: buptyy1015@gmail.com",,,"MDPI AG",,,,,20799292,,,,"English","Electronics (Switzerland)",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85102368196
"Adler A., Araya-Polo M., Poggio T.","36607557500;8569092300;7004817656;","Deep Learning for Seismic Inverse Problems: Toward the Acceleration of Geophysical Analysis Workflows",2021,"IEEE Signal Processing Magazine","38","2","9363496","89","119",,8,"10.1109/MSP.2020.3037429","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102044463&doi=10.1109%2fMSP.2020.3037429&partnerID=40&md5=6c848bb94637afa09ae1b352ba173e9f","Electrical Engineering, Braude College of Engineering, Karmiel, 2161002, Israel; Total EandP Rt, Houston, TX  77002, United States; Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA  02139, United States","Adler, A., Electrical Engineering, Braude College of Engineering, Karmiel, 2161002, Israel; Araya-Polo, M., Total EandP Rt, Houston, TX  77002, United States; Poggio, T., Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA  02139, United States","Seismic inversion is a fundamental tool in geophysical analysis, providing a window into Earth. In particular, it enables the reconstruction of large-scale subsurface Earth models for hydrocarbon exploration, mining, earthquake analysis, shallow hazard assessment, and other geophysical tasks. © 1991-2012 IEEE.",,"Inverse problems; Petroleum prospecting; Seismology; Earth models; Earthquake analysis; Fundamental tools; Geophysical analysis; Hydrocarbon exploration; Seismic inverse problems; Seismic inversion; Shallow hazards; Deep learning",,,,,,,,,,,,,,,,"Iske, A., Randen, T., (2005) Mathematical Methods and Modelling in Hydrocarbon Exploration and Production, , New York: Springer-Verlag; Rudolph, K.W., Goulding, F.J., Benchmarking exploration predictions and performance using 20+ yr of drilling results: One company's experience (2017) Aapg Bull., 101 (2), pp. 161-176; Lucas, A., Iliadis, M., Molina, R., Katsaggelos, A.K., Using deep neural networks for inverse problems in imaging: Beyond analytical methods (2018) Ieee Signal Process. Mag., 35 (1), pp. 20-36. , Jan; Liang, D., Cheng, J., Ke, Z., Ying, L., Deep magnetic resonance image reconstruction: Inverse problems meet neural networks (2020) Ieee Signal Process. Mag., 37 (1), pp. 141-151; Dziewonski, A.M., Anderson, D.L., Preliminary reference earth model (1981) Phys. Earth Planetary Interiors, 25 (4), pp. 297-356; Billette, F., Brandsberg-Dahl, S., The 2004 BP velocity benchmark (2005) Proc. 67th Eage Conf. Exhib.; Shearer, P.M., (2009) Introduction to Seismology, , Cambridge, U.K.: Cambridge Univ. Press; Inversion of seismic reflection data in the acoustic approximation (1984) Geophysics, 49 (8), pp. 1259-1266. , A. Ta rantola; Araya-Polo, M., Assessing accelerator-based HPC reverse time migration (2011) Ieee Trans. Parallel Distrib. Syst., 22 (1), pp. 147-162; De La Cruz, R., Araya-Polo, M., Algorithm 942: Semi-stencil (2014) Acm Trans. Math. Softw., 40 (3). , Apr; Yilmaz, O., (2001) Seismic Data Analysis, , https://library.seg.org/doi/abs/10.1190/1.9781560801580, Tulsa OK: Society of Exploration Geophysicists, [Online]; Ikelle, L.T., Amundsen, L., (2018) Introduction to Petroleum Seismology 2nd Ed, , https://library.seg.org/doi/book/10.1190/1.9781560803447, Tulsa OK: Society of Exploration Geophysicists, [Online]; Schuster, G.T., (2017) Seismic Inversion, , https://library.seg.org/doi/abs/10.1190/1.9781560803423, Tulsa OK: Society of Exploration Geophysicists, [Online]; Virieux, J., Operto, S., An overview of full-waveform inversion in exploration geophysics (2009) Geophysics, 74 (6), pp. WCC1-WCC26. , Nov; Virieux, J., Brossier, R., Mtivier, L., Etienne, V., Operto, S., Challenges in the full waveform inversion regarding data, model and optimisation (2012) Proc. 74th Eage Conf. Exhib.-Workshops; Landa, E., Treitel, S., Seismic inversion: What it is, and what it is not (2016) Leading Edge, 35 (3), pp. 277-279; Bunks, C., Saleck, F.M., Zaleski, S., Chavent, G., Multiscale seismic waveform inversion (1995) Geophysics, 60 (5), pp. 1457-1473; Becquey, M., Lavergne, M., Willm, C., Acoustic impedance logs computed from seismic traces (1979) Geophysics, 44 (9), pp. 1485-1501; Latimer, R.B., Davidson, R., Van Riel, P., An interpreter's guide to understanding and working with seismic-derived acoustic impedance data (2000) Leading Edge, 19 (3), pp. 242-256; Zhou, H.-W., (2014) Practical Seismic Data Analysis, , Cambridge, U.K.: Cambridge Univ. Press; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , http://www.deeplearningbook.org, Cambridge MA: MIT Press, [Online]; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) Ieee Trans. Pattern Anal. Mach. Intell., 35 (8), pp. 1798-1828; Masci, J., Meier, U., Cireşan, D., Schmidhuber, J., Stacked convolutional auto-encoders for hierarchical feature extraction (2011) Proc. 21th Int. Conf. Artif. Neural Netw. (ICANN'11), pp. 52-59. , New York: Springer-Verlag; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional networks for biomedical image segmentation (2015) Medical Image Computing and ComputerAssisted Intervention (MICCAI), Ser. Lncs, 9351, pp. 234-241. , N. Navab, J. Hornegger, W. Wells, and A. Frangi, Eds. New York: Springer-Verlag; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), June, pp. 770-778; Lewis, W., Vigh, D., Deep learning prior models from seismic images for full-waveform inversion (2017) Proc. Seg Tech. Program Expanded Abstracts, Tulsa: Society of Exploration Geophysicists, pp. 1512-1517; Richardson, A., (2018) Seismic Full-waveform Inversion Using Deep Learning Tools and Techniques, , Jan; Araya-Polo, M., Jennings, J., Adler, A., Dahlke, T., Deep-learning tomography (2018) Leading Edge, 37 (1), pp. 58-66; Kim, Y., Nakata, N., Geophysical inversion versus machine learning in inverse problems (2018) Leading Edge, 37 (12), pp. 894-901; Wang, W., Yang, F., Ma, J., Velocity model building with a modified fully convolutional network (2018) Proc. Seg Tech. Program Expanded Abstracts, Tulsa: Society of Exploration Geophysicists, pp. 2086-2090; Wu, Y., Lin, Y., Zhou, Z., Inversionet: Accurate and efficient seismic-waveform inversion with convolutional neural networks (2018) Proc. Seg Tech. Program Expanded Abstracts, Tulsa: Society of Exploration Geophysicists, pp. 2096-2100; Alfarraj, M., AlRegib, G., Petrophysical property estimation from seismic data using recurrent neural networks (2018) Proc. Seg Tech. Program Expanded Abstracts, Tulsa: Society of Exploration Geophysicists, pp. 2141-2146; Das, V., Pollack, A., Wollner, U., Mukerji, T., Convolutional neural network for seismic impedance inversion Proc. Seg Tech. Program Expanded Abstracts 2018, pp. 2071-2075. , Tulsa: Society of Exploration Geophysicists; Biswas, R., Sen, M.K., Das, V., Mukerji, T., Prestack and poststack inversion using a physics-guided convolutional neural network (2019) Interpretation, 7 (3), pp. SE161-SE174; Yang, F., Ma, J., Deep-learning inversion: A next generation seismic velocity-model building method (2019) Geophysics, 84 (4), pp. R583-R599; Adler, A., Araya-Polo, M., Poggio, T., Deep recurrent architectures for seismic tomography (2019) Proc. 81st Eage Conf. Exhib., pp. 1-5; Mao, B., Han, L.-G., Feng, Q., Yin, Y.-C., Subsurface velocity inversion from deep learning-based data assimilation (2019) J. Appl. Geophys., 167, pp. 172-179. , Aug; Zheng, Y., Zhang, Q., Yusifov, A., Shi, Y., Applications of supervised deep learning for seismic interpretation and inversion (2019) Leading Edge, 38 (7), pp. 526-533; Araya-Polo, M., Farris, S., Florez, M., Deep learning-driven velocity model building workflow (2019) Leading Edge, 38 (11), pp. 872a1-872a9; Das, V., Pollack, A., Wollner, U., Mukerji, T., Convolutional neural network for seismic impedance inversion (2019) Geophysics, 84 (6), pp. R869-R880; Duque, L., Gutiérrez, G., Arias, C., Rüger, A., Jaramillo, H., Automated velocity estimation by deep learning based seismic-to-velocity mapping (2019) Proc. Eage Annu. Meeting, 2019 (1), pp. 1-5; Alfarraj, M., AlRegib, G., Semi-supervised learning for acoustic impedance inversion (2019) Proc. Seg Tech. Program Expanded Abstracts, Tulsa: Society of Exploration Geophysicists; Ovcharenko, O., Kazei, V., Kalita, M., Peter, D., Alkhalifah, T., Deep learning for low-frequency extrapolation from multioffset seismic data (2019) Geophysics, 84 (6), pp. R989-R1001; Wang, Y., Ge, Q., Lu, W., Yan, X., Seismic impedance inversion based on cycle-consistent generative adversarial network (2019) Proc. Seg Technical Program Expanded Abstracts, Tulsa: Society of Exploration Geophysicists, pp. 2498-2502; Fabien-Ouellet, G., Sarkar, R., Seismic velocity estimation: A deep recurrent neural-network approach (2020) Geophysics, 85 (1), pp. 1-35; Park, M.J., Sacchi, M.D., Automatic velocity analysis using convolutional neural network and transfer learning (2020) Geophysics, 85 (1), pp. V33-V43; Li, S., Liu, B., Ren, Y., Chen, Y., Yang, S., Wang, Y., Jiang, P., Deep-learning inversion of seismic data (2020) Ieee Trans. Geosci. Remote Sens., 58 (3), pp. 1-15; Mosser, L., Dubrule, O., Blunt, M., Stochastic seismic waveform inversion using generative adversarial networks as a geological prior (2020) Math. Geosci., 52 (1), pp. 53-79; Sun, H., Demanet, L., Extrapolated full waveform inversion with deep learning (2020) Geophysics, 85 (3), pp. 1-71; Wu, B., Meng, D., Wang, L., Liu, N., Wang, Y., Seismic impedance inversion using fully convolutional residual network and transfer learning (2020) Ieee Geosci. Remote Sens. Lett., Early Access; Wang, W., Ma, J., Velocity model building in a crosswell acquisition geometry with image-trained artificial neural networks (2020) Geophysics, 85 (2), pp. U31-U46; Zhang, Z., Lin, Y., Data-driven seismic waveform inversion: A study on the robustness and generalization (2020) Ieee Trans. Geosci. Remote Sens., 58 (10), pp. 1-14; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2014) Proc. Int. Conf. Learning Representations, , Dec; Virieux, J., Operto, S., An overview of full-waveform inversion in exploration geophysics (2009) Geophysics, 74 (6), pp. WCC1-WCC26. , Nov; Creswell, A., White, T., Dumoulin, V., Arulkumaran, K., Sengupta, B., Bharath, A.A., Generative adversarial networks: An overview (2018) Ieee Signal Process. Mag., 35 (1), pp. 53-65. , Jan; Wang, Z., Simoncelli, E.P., Bovik, A.C., Multiscale structural similarity for image quality assessment (2003) Proc. 37th Asilomar Conf. Signals, Syst. Comput., 2, pp. 1398-1402; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) Ieee Trans. Image Process., 13 (4), pp. 600-612. , Apr; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2017) Commun. Acm, 60 (6), pp. 84-90; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. Int. Conf. Learning Representations; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L., Microsoft COCO: Common objects in context (2014) Proc. Comput. Vis.-ECCV, pp. 740-755; Lu, W., Li, F., Seismic spectral decomposition using deconvolutive short-time fourier transform spectrogram (2013) Geophysics, 78 (2), pp. V43-V51; Hershey, S., CNN architectures for large-scale audio classification Proc. 2017 Ieee Int. Conf. Acoustics, Speech Signal Process. (ICASSP), pp. 131-135; Dong, C., Loy, C.C., He, K., Tang, X., Image super-resolution using deep convolutional networks (2016) Ieee Trans. Pattern Anal. Mach. Intell., 38 (2), pp. 295-307; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) Ieee Trans. Image Process., 13 (4), pp. 600-612; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., Improved training of wasserstein gans (2017) Proc. Adv. Neural Inform. Process. Syst., pp. 5767-5777; Oh, S., Noh, K., Yoon, D., Seol, S.J., Byun, J., (2019) Cooperative Deep Learning Inversion: Seismic-Constrained Csem Inversion for Salt Delineation, pp. 1055-1059. , Tulsa, OK: Society of Exploration Geophysicists; Benning, M., Burger, M., Modern regularization methods for inverse problems (2018) Acta Numerica, 27, pp. 1-111. , Jan; Lunz, S., Öktem, O., Schönlieb, C.-B., Adversarial regularizers in inverse problems (2018) Proc. 32nd Int. Conf. Neural Inform. Process. Syst., Ser. NIPS'18, pp. 8516-8525; Yuan, X., He, P., Zhu, Q., Li, X., Adversarial examples: Attacks and defenses for deep learning (2019) Ieee Trans. Neural Netw. Learn. Syst., 30 (9), pp. 2805-2824",,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,10535888,,ISPRE,,"English","IEEE Signal Process Mag",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85102044463
"Xu D., Zhu Z., Liu C., Wang Y., Zhao S., Zhang L., Liang H., Li H., Cheng K.-T.","56102483500;57218933235;57191676782;56104472600;57304154200;57211152445;55575028100;8904472100;57215800621;","Reliability Evaluation and Analysis of FPGA-Based Neural Network Acceleration System",2021,"IEEE Transactions on Very Large Scale Integration (VLSI) Systems","29","3","9316989","472","484",,4,"10.1109/TVLSI.2020.3046075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099605873&doi=10.1109%2fTVLSI.2020.3046075&partnerID=40&md5=62731305432492a308611309ad7298ee","School of Electronic Science and Applied Physics, Hefei University of Technology, Hefei, 230009, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong","Xu, D., School of Electronic Science and Applied Physics, Hefei University of Technology, Hefei, 230009, China, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Zhu, Z., School of Electronic Science and Applied Physics, Hefei University of Technology, Hefei, 230009, China, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Liu, C., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Wang, Y., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Zhao, S., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Zhang, L., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Liang, H., School of Electronic Science and Applied Physics, Hefei University of Technology, Hefei, 230009, China; Li, H., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Cheng, K.-T., Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong","Prior works typically conducted the fault analysis of neural network accelerator computing arrays with simulation and focused on the prediction accuracy loss of the neural network models. There is still a lack of systematic fault analysis of the neural network acceleration system that considers both the accuracy degradation and system exceptions, such as system stall and running overtime. To that end, we implemented a representative neural network accelerator and corresponding fault injection modules on a Xilinx ARM-FPGA platform and evaluated the reliability of the system under different fault injection rates when a series of typical neural network models are deployed on the neural network acceleration system. The entire fault injection and reliability evaluation system is open-sourced on GitHub. With comprehensive experiments on the system, we identify the system exceptions based on the various abnormal behaviors of the FPGA-based neural network acceleration system and analyze the underlying reasons. Particularly, we find that the probability of the system exceptions dominates the reliability of the system. The faults also incur accuracy degradation of the neural network models, but the influence depends on the applications of the models and can vary greatly. In addition, we also evaluated the use of conventional triple modular redundancy (TMR) and demonstrated the challenge of TMR with both experiments and analytical models, which may shed light on the reliability design of the FPGA-based neural network acceleration system. © 1993-2012 IEEE.","Integrated circuit reliability; reliability","Acceleration; Fault tolerant computer systems; Field programmable gate arrays (FPGA); Redundancy; Reliability analysis; Software testing; Abnormal behavior; Acceleration systems; Neural network model; Prediction accuracy; Reliability design; Reliability Evaluation; Systematic fault analysis; Triple modular redundancy; Neural networks",,,,,"National Natural Science Foundation of China, NSFC: 61674048, 61834006, 61874124, 61902375; Chinese Academy of Sciences, CAS: XDC05030201","This work was supported in part by the National Natural Science Foundation of China under Grant 61874124, Grant 61902375, Grant 61674048, and Grant 61834006 and in part by the Strategic Priority Research Program of the Chinese Academy of Sciences under Grant XDC05030201.",,,,,,,,,,"Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y., Alsaadi, F.E., A survey of deep neural network architectures and their applications (2017) Neurocomputing, 234, pp. 11-26. , Apr; Stoica, I., (2017) A Berkeley View of Systems Challenges for AI, , http://arxiv.org/abs/1712.05855; Protzel, P.W., Palumbo, D.L., Arras, M.K., Performance and fault-tolerance of neural networks for optimization (1993) IEEE Trans. Neural Netw., 4 (4), pp. 600-614. , Jul; Vassighi, A., Sachdev, M., Thermal runaway in integrated circuits (2006) IEEE Trans. Device Mater. Rel., 6 (2), pp. 300-305. , Jun; Fernandez, R., Martin-Martinez, J., Rodriguez, R., Nafria, M., Aymerich, X.H., Gate oxide wear-out and breakdown effects on the performance of analog and digital circuits (2008) IEEE Trans. Electron Devices, 55 (4), pp. 997-1004. , Apr; Guo, K., Zeng, S., Yu, J., Wang, Y., Yang, H., A survey of FPGA-based neural network inference accelerators (2019) ACM Trans. Reconfigurable Technol. Syst., 12 (1), pp. 1-26; Reagen, B., Ares: A framework for quantifying the resilience of deep neural networks (2018) Proc. 55th ACM/ESDA/IEEE Design Automat. Conf. (DAC), pp. 1-6. , Jun; Kausar, F., Aishwarya, P., Artificial neural network: Framework for fault tolerance and future (2016) Proc. Int. Conf. Electr., Electron., Optim. Techn. (ICEEOT), pp. 648-651. , Mar; Li, G., Pattabiraman, K., DeBardeleben, N., TensorFI: A configurable fault injector for TensorFlow applications (2018) Proc. IEEE Int. Symp. Softw. Rel. Eng. Workshops (ISSREW), pp. 313-320. , Oct; Li, G., Understanding error propagation in deep learning neural network (DNN) accelerators and applications (2017) Proc. Int. Conf. High Perform. Comput., Netw., Storage Anal., pp. 1-12. , Nov; Salami, B., Unsal, O., Cristal, A., (2018) On the Resilience of RTL NN Accelerators: Fault Characterization and Mitigation, , http://arxiv.org/abs/1806.09679; Xu, D., A hybrid computing architecture for fault-tolerant deep learning accelerators (2020) Proc. IEEE 38th Int. Conf. Comput. Design (ICCD), pp. 1-8. , Oct; Redmon, J., Farhadi, A., (2016) YOLO9000: Better, Faster, Stronger, , http://arxiv.org/abs/1612.08242; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Sak, H., Senior, A., Beaufays, F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling (2014) Proc. 15th Annu. Conf. Int. Speech Commun. Assoc., pp. 1-5; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, , http://arxiv.org/abs/1511.06434; Cireşan, D.C., Meier, U., Masci, J., Gambardella, L.M., Schmidhuber, J., Flexible, high performance convolutional neural networks for image classification (2011) Proc. 22nd Int. Joint Conf. Artif. Intell. (IJCAI), 2, pp. 1237-1242; Wang, Y., Xu, J., Han, Y., Li, H., Li, X., DeepBurning: Automatic generation of FPGA-based learning accelerators for the neural network family (2016) Proc. 53nd ACM/EDAC/IEEE Design Automat. Conf. (DAC), pp. 1-6. , Jun; Wang, Y., Li, H., Li, X., Real-time meets approximate computing: An elastic CNN inference accelerator with adaptive trade-off between QoS and QoR (2017) Proc. 54th ACM/EDAC/IEEE Design Automat. Conf. (DAC), pp. 1-6. , Jun; Whatmough, P.N., Lee, S.K., Lee, H., Rama, S., Brooks, D., Wei, G.-Y., A 28 nm SoC with a 1. 2 GHz 568nJ/prediction sparse deep-neural-network engine with >0. 1 timing error rate tolerance for IoT applications (2017) IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, pp. 242-243. , Feb; Mohammadi, M., Al-Fuqaha, A., Sorour, S., Guizani, M., Deep learning for IoT big data and streaming analytics: A survey (2018) IEEE Commun. Surveys Tuts., 20 (4), pp. 2923-2960. , Jun; Kim, H., Choi, K., Low power FPGA-SoC design techniques for CNN-based object detection accelerator (2019) Proc. IEEE 10th Annu. Ubiquitous Comput., Electron. Mobile Commun. Conf. (UEMCON), pp. 1130-1134. , Oct; Tang, K.-T., Considerations of integrating computing-in-memory and processing-in-sensor into convolutional neural network accelerators for low-power edge devices (2019) Proc. Symp. VLSI Circuits, Jun., pp. T166-T167; Constantinescu, C., Impact of deep submicron technology on dependability of VLSI circuits (2002) Proc. Int. Conf. Dependable Syst. Netw., pp. 205-209; Suk, S.S., Reddy, S.M., A March test for functional faults in semiconductor random access memories (1981) IEEE Trans. Comput., C-30 (12), pp. 982-985. , Dec; Banerjee, S.S., Jha, S., Cyriac, J., Kalbarczyk, Z.T., Iyer, R.K., Hands off the wheel in autonomous vehicles: A systems perspective on over a million miles of field data (2018) Proc. 48th Annu. IEEE/IFIP Int. Conf. Dependable Syst. Netw. (DSN), pp. 586-597. , Jun; Jha, S., Banerjee, S.S., Cyriac, J., Kalbarczyk, Z.T., Iyer, R.K., AVFI: Fault injection for autonomous vehicles (2018) Proc. 48th Annu. IEEE/IFIP Int. Conf. Dependable Syst. Netw. Workshops (DSN-W), pp. 55-56. , Jun; Sterpone, L., Violante, M., A new partial reconfiguration-based faultinjection system to evaluate SEU effects in SRAM-based FPGAS (2007) IEEE Trans. Nucl. Sci., 54 (4), pp. 965-970. , Aug; Pancholy, A., Rajski, J., McNaughton, L.J., Empirical failure analysis and validation of fault models in CMOS VLSI circuits (1992) IEEE Des. Test. Comput., 9 (1), pp. 72-83. , Mar; De Andres, D., Ruiz, J.C., Gil, D., Gil, P., Fault emulation for dependability evaluation of VLSI systems (2008) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 16 (4), pp. 422-431. , Apr; Hanif, M.A., Hafiz, R., Shafique, M., Error resilience analysis for systematically employing approximate computing in convolutional neural networks (2018) Proc. Design, Automat. Test Eur. Conf. Exhib. (DATE), pp. 913-916. , Mar; Xu, D., Persistent fault analysis of neural networks on FPGAbased acceleration system (2020) Proc. IEEE 31st Int. Conf. Appl.-Specific Syst., Archit. Processors (ASAP), pp. 85-92. , Jul; Matsumoto, K., Mori, H., Uehara, M., Fault tolerance in small world cellular neural networks for image processing (2007) Proc. 21st Int. Conf. Adv. Inf. Netw. Appl. Workshops (AINAW), pp. 835-839; Dos Santos, F.F., Draghetti, L., Weigel, L., Carro, L., Navaux, P., Rech, P., Evaluation and mitigation of soft-errors in neural networkbased object detection in three GPU architectures (2017) Proc. 47th Annu. IEEE/IFIP Int. Conf. Dependable Syst. Netw. Workshops (DSN-W), pp. 169-176. , Jun; Torres-Huitzil, C., Girau, B., Fault and error tolerance in neural networks: A review (2017) IEEE Access, 5, pp. 17322-17341; Holt, J.L., Baker, T.E., Back propagation simulations using limited precision calculations (1991) Proc. Seattle Int. Joint Conf. Neural Netw (IJCNN), 2, pp. 121-126; Xu, D., Resilient neural network training for accelerators with computing errors (2019) Proc. IEEE 30th Int. Conf. Appl.-Specific Syst., Archit. Processors (ASAP), pp. 99-102. , Jul; Reagen, B., Minerva: Enabling low-power, highly-accurate deep neural network accelerators (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit. (ISCA), pp. 267-278. , Jun; Li, W., Ning, X., Ge, G., Chen, X., Wang, Y., Yang, H., FTT-NAS: Discovering fault-tolerant neural architecture (2020) Proc. 25th Asia South Pacific Design Automat. Conf. (ASP-DAC), pp. 211-216. , Jan; Xu, Z., Abraham, J., Safety design of a convolutional neural network accelerator with error localization and correction (2019) Proc. IEEE Int. Test Conf. (ITC), pp. 1-10. , Nov; Leung, C.-S., Wan, W.Y., Feng, R., A regularizer approach for RBF networks under the concurrent weight failure situation (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (6), pp. 1360-1372. , Jun; Ozen, E., Orailoglu, A., Sanity-check: Boosting the reliability of safety-critical deep neural network applications (2019) Proc. IEEE 28th Asian Test Symp. (ATS), pp. 7-75. , Dec; Zhang, J.J., Basu, K., Garg, S., Fault-tolerant systolic array based accelerators for deep neural network execution (2019) IEEE Des. Test. Comput., 36 (5), pp. 44-53. , Oct; Xia, L., Liu, M., Ning, X., Chakrabarty, K., Wang, Y., Fault-tolerant training enabled by on-line fault detection for RRAM-based neural computing systems (2019) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 38 (9), pp. 1611-1624. , Sep; Liu, T., Wen, W., Jiang, L., Wang, Y., Yang, C., Quan, G., A faulttolerant neural network architecture (2019) Proc. 56th Annu. Design Automat. Conf., pp. 1-6. , Jun; (2019) DeepBurning: Automatic Generation of FPGA-Based Learning Accelerators for the Neural Network Family, , https://labfor.github.io/, Institute of Computing Technology. Dec; (2018) Vivado Design Suite 7 Series FPGA and Zynq-7000 SoC Libraries Guide, , http://www.xilinx.com/support/documentation/sw_manuals/xilinx2017_4/ug953-vivado-7series-libraries.pdf, Dec; (2016) AXI HWICAP v3. 0 LogiCORE IP Product Guide, , http://www.xilinx.com/support/documentation/ip_documentation/axi_hwicap/v3_0/pg134-axihwicap.pdf, Oct; (2018) 7 Series FPGAS Configuration User Guide, , http://www.xilinx.com/support/documentation/user_guides/ug470_7Series_Config.pdf, Aug; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) IEEE Trans. Image Process., 13 (4), pp. 600-612. , Apr; Temam, O., A defect-tolerant accelerator for emerging high-performance applications (2012) ACM SIGARCH Comput. Archit. News, 40 (3), pp. 356-367; Zhang, J.J., Gu, T., Basu, K., Garg, S., Analyzing and mitigating the impact of permanent faults on a systolic array based neural network accelerator (2018) Proc. IEEE 36th VLSI Test Symp. (VTS), pp. 1-6. , Apr; Deng, J., Retraining-based timing error mitigation for hardware neural networks (2015) Proc. Design, Automat. Test Eur. Conf. Exhib. (DATE), pp. 593-596; Li, L., Squeezing the last MHz for CNN acceleration on FPGAS (2019) Proc. IEEE Int. Test Conf. Asia (ITC-Asia), pp. 151-156. , Sep; Everingham, M., Eslami, S.M.A., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., The Pascal visual object classes challenge: A retrospective (2015) Int. J. Comput. Vis., 111 (1), pp. 98-136. , Jan; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252. , Dec; Warden, P., (2018) Speech Commands: A Dataset for Limited-vocabulary Speech Recognition, , http://arxiv.org/abs/1804.03209, Apr","Liu, C.; Institute of Computing Technology, China; email: liucheng@ict.ac.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,10638210,,IEVSE,,"English","IEEE Trans Very Large Scale Integr VLSI Syst",Article,"Final","",Scopus,2-s2.0-85099605873
"Lee S., Yu H., Yang H., Song I., Choi J., Yang J., Lim G., Kim K.-S., Choi B., Kwon J.","57218118438;57200608051;57219813438;57222012796;57222026233;57219809221;54395813900;7409322267;7402755209;55646002200;","A study on deep learning application of vibration data and visualization of defects for predictive maintenance of gravity acceleration equipment",2021,"Applied Sciences (Switzerland)","11","4","1564","1","15",,1,"10.3390/app11041564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100999972&doi=10.3390%2fapp11041564&partnerID=40&md5=0c1890e711b3b0bf878d7d7c54e7bbdd","Deparment Electric Computer Engineering, Inha University, 100 Inha-ro, Michuhol-gu, Incheon, 22201, South Korea; Department Mechanical Engineering, Gyeong-Sang National University, 38, Cheondaegukchi-gil, Tongyeong-si, 530-64, South Korea; R&D Center, ATG, Seongnam-daero, Bundang-gu, Seongnam-si, 13558, South Korea; Department of Otolaryngology-Head and Neck Surgery, Inha Research Institute for Aerospace Medicine, College of Medicine, Inha University, 3-Ga Shinheungdong, Jung-Gu, Incheon, 400-711, South Korea","Lee, S., Deparment Electric Computer Engineering, Inha University, 100 Inha-ro, Michuhol-gu, Incheon, 22201, South Korea; Yu, H., Department Mechanical Engineering, Gyeong-Sang National University, 38, Cheondaegukchi-gil, Tongyeong-si, 530-64, South Korea; Yang, H., Deparment Electric Computer Engineering, Inha University, 100 Inha-ro, Michuhol-gu, Incheon, 22201, South Korea; Song, I., Deparment Electric Computer Engineering, Inha University, 100 Inha-ro, Michuhol-gu, Incheon, 22201, South Korea; Choi, J., Deparment Electric Computer Engineering, Inha University, 100 Inha-ro, Michuhol-gu, Incheon, 22201, South Korea; Yang, J., R&D Center, ATG, Seongnam-daero, Bundang-gu, Seongnam-si, 13558, South Korea; Lim, G., R&D Center, ATG, Seongnam-daero, Bundang-gu, Seongnam-si, 13558, South Korea; Kim, K.-S., Department of Otolaryngology-Head and Neck Surgery, Inha Research Institute for Aerospace Medicine, College of Medicine, Inha University, 3-Ga Shinheungdong, Jung-Gu, Incheon, 400-711, South Korea; Choi, B., Department Mechanical Engineering, Gyeong-Sang National University, 38, Cheondaegukchi-gil, Tongyeong-si, 530-64, South Korea; Kwon, J., Deparment Electric Computer Engineering, Inha University, 100 Inha-ro, Michuhol-gu, Incheon, 22201, South Korea","Hypergravity accelerators are a type of large machinery used for gravity training or medical research. A failure of such large equipment can be a serious problem in terms of safety or costs. This paper proposes a prediction model that can proactively prevent failures that may occur in a hypergravity accelerator. An experiment was conducted to evaluate the performance of the method proposed in this paper. A 4-channel accelerometer was attached to the bearing housing, which is a rotor, and time-amplitude data were obtained from the measured values by sampling. The method proposed in this paper was trained with transfer learning, a deep learning model that replaced the VGG19 model with a Fully Connected Layer (FCL) and Global Average Pooling (GAP) by converting the vibration signal into a short-time Fourier transform (STFT) or Mel-Frequency Cepstral Coefficients (MFCC) spectrogram and converting the input into a 2D image. As a result, the model proposed in this paper has seven times decreased trainable parameters of VGG19, and it is possible to quantify the severity while looking at the defect areas that cannot be seen with 1D. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Deep learning; Fault detection; Hyper-gravity machine; Vibration monitoring",,,,,,"Kementerian Pendidikan Malaysia, KPM: 2018R1A6A1A03025523; National Research Foundation of Korea, NRF","Author Contributions: Methodology, H.Y. (HoJun Yang); validation, H.Y. (HyeonTak Yu) and J.C.; resources, K.-S.K.; data curation, H.Y. (HyeonTak Yu); writing—original draft, S.L.; writing—review and editing, I.S. and J.K.; supervision, J.Y. and B.C.; funding acquisition, G.L. All authors have read and agreed to the published version of the manuscript Funding: This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (No. 2018R1A6A1A03025523).",,,,,,,,,,"Gurovsky, N.N., Gazenko, O.G., Adamovich, B.A., Ilyin, E.A., Genin, A.M., Korolkov, V.I., Shipov, A.A., Serova, L.V., Study of physiological effects of weightlessness and artificial gravity in the flight of the biosatellite Cosmos-936 (1980) Acta Astronaut, 7, pp. 113-121. , [CrossRef]; Jang, T.Y., Kim, K.-S., Kim, Y.H., Altered Gravity and Immune Response (2018) Korean J. Aerosp. Environ. Med, 28, pp. 6-8; Lee, W.-K., Cheong, D.-Y., Park, D.-H., Choi, B.-K., Performance Improvement of Feature-Based Fault Classification for Rotor System (2020) Int. J. Precis. Eng. Manuf, 21, pp. 1065-1074. , [CrossRef]; Aydmj, T., Duin, R.P.W., (1999) Pump Failure Determination Using Support Vector Data Description, pp. 415-425. , Lecture Notes in Computer Science; Springer: Berlin/Heidelberg, Germany; Zhang, Z.-Y., Wang, K.-S., Wind turbine fault detection based on SCADA data analysis using ANN (2014) Adv. Manuf, 2, pp. 70-78. , [CrossRef]; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition, , arXiv arXiv:1409.1556; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Adv. Neural Inf. Process. Syst, 25, pp. 1097-1105. , [CrossRef]; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016) SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5 MB model size, , arXiv arXiv:1602.07360; Riaz, S., Elahi, H., Javaid, K., Shahzad, T., Vibration feature extraction and analysis for fault diagnosis of rotating machinery—A literature survey (2017) Asia Pac. J. Multidiscip. Res, 5, pp. 103-110; Mellit, A., Tina, G.M., Kalogirou, S.A., Fault detection and diagnosis methods for photovoltaic systems: A review (2018) Renew. Sustain. Energy Rev, 91, pp. 1-17. , [CrossRef]; Liu, R., Yang, B., Zio, E., Chen, X., Artificial intelligence for fault diagnosis of rotating machinery: A review (2018) Mech. Syst. Signal Process, 108, pp. 33-47. , [CrossRef]; Song, L., Wang, H., Chen, P., Vibration-based intelligent fault diagnosis for roller bearings in low-speed rotating machinery (2018) IEEE Trans. Instrum. Meas, 67, pp. 1887-1899. , [CrossRef]; Khlaief, A., Nguyen, K., Medjaher, K., Picot, A., Maussion, P., Tobon, D., Chauchat, B., Cheron, R., Feature engineering for ball bearing combined-fault detection and diagnostic (2019) Proceedings of the 2019 IEEE 12th International Symposium on Diagnostics for Electrical Machines, Power Electronics and Drives (SDEMPED), pp. 384-390. , Toulouse, France, 27–30 August IEEE: Piscataway, NJ, USA, 2019; Le, V., Yao, X., Miller, C., Tsao, B.-H., Series dc arc fault detection based on ensemble machine learning (2020) IEEE Trans. Power Electron, 35, pp. 7826-7839. , [CrossRef]; Yang, C., Liu, J., Zeng, Y., Xie, G., Real-time condition monitoring and fault detection of components based on machine-learning reconstruction model (2019) Renew. Energy, 133, pp. 433-441. , [CrossRef]; Abdelgayed, T.S., Morsi, W.G., Sidhu, T.S., Fault detection and classification based on co-training of semisupervised machine learning (2017) IEEE Trans. Ind. Electron, 65, pp. 1595-1605. , [CrossRef]; Wang, Y., Wang, Z., He, S., Wang, Z., A practical chiller fault diagnosis method based on discrete Bayesian network (2019) Int. J. Refrig, 102, pp. 159-167. , [CrossRef]; Zhang, H., Chen, H., Guo, Y., Wang, J., Li, G., Shen, L., Sensor fault detection and diagnosis for a water source heat pump air-conditioning system based on PCA and preprocessed by combined clustering (2019) Appl. Therm. Eng, 160, p. 114098. , [CrossRef]; Yoo, Y.-J., Fault Detection Method Using Multi-mode Principal Component Analysis Based on Gaussian Mixture Model for Sewage Source Heat Pump System (2019) Int. J. Control Autom. Syst, 17, pp. 2125-2134. , [CrossRef]; Kim, I.-S., On-line fault detection algorithm of a photovoltaic system using wavelet transform (2016) Sol. Energy, 126, pp. 137-145. , [CrossRef]; Yi, Z., Etemadi, A.H., Line-to-line fault detection for photovoltaic arrays based on multiresolution signal decomposition and two-stage support vector machine (2017) IEEE Trans. Ind. Electron, 64, pp. 8546-8556. , [CrossRef]; Ince, T., Kiranyaz, S., Eren, L., Askar, M., Gabbouj, M., Real-time motor fault detection by 1-D convolutional neural networks (2016) IEEE Trans. Ind. Electron, 63, pp. 7067-7075. , [CrossRef]; Eren, L., Bearing fault detection by one-dimensional convolutional neural networks (2017) Math. Probl. Eng, 2017. , [CrossRef]; Meng, Z., Zhan, X., Li, J., Pan, Z., An enhancement denoising autoencoder for rolling bearing fault diagnosis (2018) Measurement, 130, pp. 448-454. , [CrossRef]; Shao, H., Jiang, H., Zhao, H., Wang, F., A novel deep autoencoder feature learning method for rotating machinery fault diagnosis (2017) Mech. Syst. Signal Process, 95, pp. 187-204. , [CrossRef]; Shao, H., Jiang, H., Wang, F., Zhao, H., An enhancement deep feature fusion method for rotating machinery fault diagnosis (2017) Knowl. Based Syst, 119, pp. 200-220. , [CrossRef]; Li, C., Sánchez, R.-V., Zurita, G., Cerrada, M., Cabrera, D., Fault diagnosis for rotating machinery using vibration measurement deep statistical feature learning (2016) Sensors, 16, p. 895. , [CrossRef] [PubMed]; Sohaib, M., Kim, J.-M., Reliable fault diagnosis of rotary machine bearings using a stacked sparse autoencoder-based deep neural network (2018) Shock Vib, 2018, p. 2919637. , [CrossRef]; He, X., Wang, D., Li, Y., Zhou, C., A novel bearing fault diagnosis method based on gaussian restricted boltzmann machine (2016) Math. Probl. Eng, 2016, p. 2957083. , [CrossRef]; Shao, H., Jiang, H., Zhang, H., Duan, W., Liang, T., Wu, S., Rolling bearing fault feature learning using improved convolutional deep belief network with compressed sensing (2018) Mech. Syst. Signal Process, 100, pp. 743-765. , [CrossRef]; Jiao, J., Zhao, M., Lin, J., Ding, C., Deep coupled dense convolutional network with complementary data for intelligent fault diagnosis (2019) IEEE Trans. Ind. Electron, 66, pp. 9858-9867. , [CrossRef]; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9. , Boston, MA, USA, 7–12 June 2015; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , Las Vegas, NV, USA, 27–30 June 2016; Hasan, M.J., Islam, M.M., Kim, J.-M., Acoustic spectral imaging and transfer learning for reliable bearing fault diagnosis under variable speed conditions (2019) Measurement, 138, pp. 620-631. , [CrossRef]; Verstraete, D., Ferrada, A., Droguett, E.L., Meruane, V., Modarres, M., Deep learning enabled fault diagnosis using time-frequency image analysis of rolling element bearings (2017) Shock Vib, 2017, p. 5067651. , [CrossRef]; Salamon, J., Bello, J.P., Deep convolutional neural networks and data augmentation for environmental sound classification (2017) IEEE Signal Process. Lett, 24, pp. 279-283. , [CrossRef]; Wen, L., Li, X., Gao, L., Zhang, Y., A new convolutional neural network-based data-driven fault diagnosis method (2017) IEEE Trans. Ind. Electron, 65, pp. 5990-5998. , [CrossRef]; Davis, S., Mermelstein, P., Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences (1980) IEEE Trans. Acoust. Speech Signal Process, 28, pp. 357-366. , [CrossRef]; Huang, X., Acero, A., Hon, H.-W., Reddy, R., (2001) Spoken Language Processing: A Guide to Theory, Algorithm, and System Development, , Prentice Hall PTR: Upper Saddle River, NJ, USA, ISBN 0-13-022616-5; Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2921-2929. , Las Vegas, NV, USA, 27–30 June 2016; Xu, M., Marangoni, R.D., Vibration analysis of a motor-flexible coupling-rotor system subject to misalignment and unbalance, part I: Theoretical model and analysis (1994) J. Sound Vib, 176, pp. 663-679. , [CrossRef]; Muszynska, A., Goldman, P., Chaotic responses of unbalanced rotor/bearing/stator systems with looseness or rubs (1995) Chaos Solitons Fractals, 5, pp. 1683-1704. , [CrossRef]; Wang, S., Huang, W., Zhu, Z.K., Transient modeling and parameter identification based on wavelet and correlation filtering for rotating machine fault diagnosis (2011) Mech. Syst. Signal Process, 25, pp. 1299-1320. , [CrossRef]; McClellan, J.H., Schafer, R.W., Yoder, M.A., (2003) Signal Processing First, , Pearson Education: Upper Saddle River, NJ, USA, ISBN 0-13-120265-0; Müller, M., (2015) Fundamentals of Music Processing: Audio, Analysis, Algorithms, Applications, , Springer: Berlin/Heidelberg, Germany, ISBN 3-319-21945-6; Loshchilov, I., Hutter, F., (2016) Sgdr: Stochastic gradient descent with warm restarts, , arXiv arXiv:1608.03983; Prechelt, L., Early stopping-but when? (1998) Neural Networks: Tricks of the Trade, pp. 55-69. , Springer: Berlin/Heidelberg, Germany; McFee, B., Raffel, C., Liang, D., Ellis, D.P., McVicar, M., Battenberg, E., Nieto, O., Librosa: Audio and music signal analysis in python (2015) Proceedings of the 14th Python in Science Conference, 8, pp. 18-25. , Austin, TX, USA, 6–12 July; Buitinck, L., Louppe, G., Blondel, M., Pedregosa, F., Mueller, A., Grisel, O., Niculae, V., Grobler, J., (2013) API design for machine learning software: Experiences from the scikit-learn project, , arXiv arXiv:1309.0238","Kwon, J.; Deparment Electric Computer Engineering, 100 Inha-ro, Michuhol-gu, South Korea; email: jwkwon@inha.ac.kr",,,"MDPI AG",,,,,20763417,,,,"English","Appl. Sci.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85100999972
"de Prado M., Rusci M., Capotondi A., Donze R., Benini L., Pazos N.","57203546375;57189993824;55825787600;57219760326;35556997000;22036417000;","Robustifying the deployment of tinyml models for autonomous mini-vehicles",2021,"Sensors (Switzerland)","21","4","1339","1","16",,5,"10.3390/s21041339","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100798729&doi=10.3390%2fs21041339&partnerID=40&md5=305184c55ed109902d6479ed634cf9f3","He-Arc Ingenierie, HES-SO, Delemont, 2800, Switzerland; Integrated System Lab, ETH Zurich, Zurich, 8092, Switzerland; DEI, University of Bologna, Bologna BO, 40126, Italy; UNIMORE (University of Modena and Reggio Emilia), Modena MO, 41121, Italy","de Prado, M., He-Arc Ingenierie, HES-SO, Delemont, 2800, Switzerland, Integrated System Lab, ETH Zurich, Zurich, 8092, Switzerland; Rusci, M., DEI, University of Bologna, Bologna BO, 40126, Italy; Capotondi, A., UNIMORE (University of Modena and Reggio Emilia), Modena MO, 41121, Italy; Donze, R., He-Arc Ingenierie, HES-SO, Delemont, 2800, Switzerland; Benini, L., Integrated System Lab, ETH Zurich, Zurich, 8092, Switzerland, DEI, University of Bologna, Bologna BO, 40126, Italy; Pazos, N., He-Arc Ingenierie, HES-SO, Delemont, 2800, Switzerland","Standard-sized autonomous vehicles have rapidly improved thanks to the breakthroughs of deep learning. However, scaling autonomous driving to mini-vehicles poses several challenges due to their limited on-board storage and computing capabilities. Moreover, autonomous systems lack robustness when deployed in dynamic environments where the underlying distribution is different from the distribution learned during training. To address these challenges, we propose a closed-loop learning flow for autonomous driving mini-vehicles that includes the target deployment environment in-the-loop. We leverage a family of compact and high-throughput tinyCNNs to control the mini-vehicle that learn by imitating a computer vision algorithm, i.e., the expert, in the target environment. Thus, the tinyCNNs, having only access to an on-board fast-rate linear camera, gain robustness to lighting conditions and improve over time. Moreover, we introduce an online predictor that can choose between different tinyCNN models at runtime—trading accuracy and latency— which minimises the inference’s energy consumption by up to 3.2×. Finally, we leverage GAP8, a parallel ultra-low-power RISC-V-based micro-controller unit (MCU), to meet the real-time inference requirements. When running the family of tinyCNNs, our solution running on GAP8 outperforms any other implementation on the STM32L4 and NXP k64f (traditional single-core MCUs), reducing the latency by over 13× and the energy consumption by 92%. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Autonomous driving; Micro-controllers; Robustness; TinyML","Deep learning; Energy utilization; Microcontrollers; Miniature automobiles; Storage as a service (STaaS); Closed loop learning; Computer vision algorithms; Computing capability; Dynamic environments; Lighting conditions; Micro controller units; Real-time inference; Underlying distribution; Autonomous vehicles",,,,,"Horizon 2020 Framework Programme, H2020: 732204; Singapore Eye Research Institute, SERI: 16.0159; Staatssekretariat für Bildung, Forschung und Innovation, SBFI","Funding: This project has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement number 732204 (Bonseyes). This work is supported by the Swiss State Secretariat for Education, Research and Innovation (SERI) under contract number 16.0159. The opinions expressed and arguments employed herein do not necessarily reflect the official views of these funding bodies.",,,,,,,,,,"Palossi, D., Loquercio, A., Conti, F., Flamand, E., Scaramuzza, D., Benini, L., A 64mW DNN-based Visual Navigation Engine for Autonomous Nano-Drones (2019) IEEE Internet Things J, 6, pp. 8357-8371; Bianco, S., Cadene, R., Celona, L., Napoletano, P., Benchmark analysis of representative deep neural network architectures (2018) IEEE Access, 6, pp. 64270-64277; Mutlu, O., Processing data where it makes sense in modern computing systems: Enabling in-memory computation Proceedings of the 2018 7th Mediterranean Conference on Embedded Computing (MECO), pp. 8-9. , Budva, Montenegro, 10–14 June 2018; Tiny, ML., (2020), https://www.tinyml.org/summit/, (accessed on 30 December 2020); Banbury, C.R., Reddi, V.J., Lam, M., Fu, W., Fazel, A., Holleman, J., Huang, X., Lokhmotov, A., (2020) Benchmarking TinyML Systems: Challenges and Direction, , others. arXiv arXiv:2003.04821; Likas, A., Vlassis, N., Verbeek, J.J., The global k-means clustering algorithm (2003) Pattern Recognit, 36, pp. 451-461; Kramer, O., K-nearest neighbors (2013) Dimensionality Reduction with Unsupervised Nearest Neighbors, pp. 13-23. , Springer: Berlin, Germany; Rokach, L., Maimon, O., Decision trees (2005) Data Mining and Knowledge Discovery Handbook, pp. 165-192. , Springer: Berlin, Germany; Kröse, B., Krose, B., van der Smagt, P., Smagt, P., (1993) An introduction to neural networks; (2020) A Survey on Transformer Models in Machine Learning, , https://hannes-stark.com/assets/transformer_survey.pdf, (accessed on 30 December 2020); Pan, Z., Yu, W., Yi, X., Khan, A., Yuan, F., Zheng, Y., Recent progress on generative adversarial networks (GANs): A survey (2019) IEEE Access, 7, pp. 36322-36333; (2020), https://nxpcup.nxp.com/, NXPcup. (accessed on 30 December 2020); (2019), https://www.nxp.com, NXP K64F. (accessed on 30 December 2020); Flamand, E., Rossi, D., Conti, F., Loi, I., Pullini, A., Rotenberg, F., Benini, L., GAP-8: A RISC-V SoC for AI at the Edge of the IoT Proceedings of the 2018 IEEE 29th International Conference on Application-Specific Systems, Architectures and Processors, pp. 1-4. , Milan, Italy, 10–12 July 2018; Sathya, R., Abraham, A., Comparison of supervised and unsupervised learning algorithms for pattern classification (2013) Int. J. Adv. Res. Artif. Intell, 2, pp. 34-38; Hastie, T., Tibshirani, R., Friedman, J., Overview of supervised learning (2009) The Elements of Statistical Learning, pp. 9-41. , Springer: Berlin, Germany; Noble, W.S., What is a support vector machine? (2006) Nat. Biotechnol, 24, pp. 1565-1567; Kingma, D.P., Welling, M., (2019) An introduction to variational autoencoders, , arXiv arXiv:1906.02691; Sutton, R.S., Barto, A.G., (2018) Reinforcement Learning: An Introduction, , MIT Press: Cambridge, MA, USA; Watkins, C.J., Dayan, P., Q-learning (1992) Mach. Learn, 8, pp. 279-292; Mnih, V., Badia, A.P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D., Kavukcuoglu, K., Asynchronous methods for deep reinforcement learning (2016) International Conference on Machine Learning, pp. 1928-1937. , PMLR: Cambridge, MA, USA; (2019) Introduction to Imitation Learning, , https://blog.statsbot.co/introduction-to-imitation-learning-32334c3b1e7a, (accessed on 30 December 2020); (2018) ICML 2018: Imitation Learning Tutorial, , https://sites.google.com/view/icml2018-imitation-learning/, (accessed o 30 December 2020n); Pomerleau, D.A., Alvinn: An autonomous land vehicle in a neural network (1989) Advances in Neural Information Processing Systems; Bojarski, M., Yeres, P., Choromanska, A., Choromanski, K., Firner, B., Jackel, L., Muller, U., (2017) Explaining how a deep neural network trained with end-to-end learning steers a car, , arXiv arXiv:1704.07911; Kocić, J., Jovičić, N., Drndarević, V., An End-to-End Deep Neural Network for Autonomous Driving Designed for Embedded Automotive Platforms (2019) Sensors, 19, p. 2064; Pan, Y., Cheng, C.A., Saigol, K., Lee, K., Yan, X., Theodorou, E., Boots, B., Agile autonomous driving using end-to-end deep imitation learning (2018) Robotics: science and systems, , arXiv arXiv:1709.07174; Taylor, B., Marco, V.S., Wolff, W., Elkhatib, Y., Wang, Z., (2018) Adaptive selection of deep learning models on embedded systems, , arXiv arXiv:1805.04252; Jin, X.B., Yu, X.H., Wang, X.Y., Bai, Y.T., Su, T.L., Kong, J.L., Deep learning predictor for sustainable precision agriculture based on internet of things system (2020) Sustainability, 12, p. 1433; Beruvides, G., Quiza, R., Rivas, M., Castaño, F., Haber, R.E., Online detection of run out in microdrilling of tungsten and titanium alloys (2014) Int. J. Adv. Manuf. Technol, 74, pp. 1567-1575; Huang, S., Cai, N., Pacheco, P.P., Narrandes, S., Wang, Y., Xu, W., Applications of support vector machine (SVM) learning in cancer genomics (2018) Cancer Genom.-Proteom, 15, pp. 41-51; Beruvides, G., Juanes, C., Castaño, F., Haber, R.E., A self-learning strategy for artificial cognitive control systems Proceedings of the 2015 IEEE 13th International Conference on Industrial Informatics (INDIN), pp. 1180-1185. , Cambridge, UK, 22–24 July 2015; de Prado, M., Mundy, A., Saeed, R., Denna, M., Pazos, N., Benini, L., Automated Design Space Exploration for opti-mised Deployment of DNN on Arm Cortex-A CPUs (2020) IEEE Trans. Comput.-Aided Des. Integr. Circuits and Syst; Kuutti, S., Bowden, R., Jin, Y., Barber, P., Fallah, S., (2019) A Survey of Deep Learning Applications to Autonomous Vehicle Control, , arXiv arXiv:1912.10773; (2019) Auto Pilot, , https://www.tesla.com/autopilot, (accessed on 30 December 2020); https://aws.amazon.com/deepracer/, DeepRacer. (accessed on 30 December 2020); O’Kelly, M., Sukhil, V., Abbas, H., Harkins, J., Kao, C., Pant, Y.V., Mangharam, R., Burgio, P., (2019) F1/10: An Open-Source Autonomous Cyber-Physical Platform, , others. arXiv arXiv:1901.08567; github.com/autorope/donkeycar, DonkeyCar. (accessed on 30 December 2020); Dukhan, M., Wu, Y., Lu, H., QNNPACK: Open Source Library for Optimized Mobile Deep Learning, , https://engineering.fb.com/ml-applications/qnnpack/, (accessed on 12 Spetember 2019); Wang, E., Zhang, Q., Shen, B., Zhang, G., Lu, X., Wu, Q., Wang, Y., Intel math kernel library (2014) High-Performance Computing on the Intel® Xeon Phi™, pp. 167-188. , Springer: Berlin, Germany; Jacob, B., (2017) gemmlowp: a small self-contained low-precision GEMM library, , others. arXiv arXiv:1903.01061; X-CUBE-AI, , https://www.st.com/en/embedded-software/x-cube-ai.html, STMicroelectronics. (accessed on 12 Spetember 2019); Lai, L., Suda, N., Chandra, V., (2018) Cmsis-nn: Efficient neural network kernels for Arm cortex-m cpus, , arXiv arXiv:1801.06601; Zhang, Y., Suda, N., Lai, L., Chandra, V., (2017) Hello edge: Keyword spotting on microcontrollers, , arXiv arXiv:1711.07128; Chowdhery, A., Warden, P., Shlens, J., Howard, A., Rhodes, R., (2019) Visual Wake Words Dataset, , arXiv arXiv:1906.05721; Garofalo, A., Rusci, M., Conti, F., Rossi, D., Benini, L., (2019) PULP-NN: Accelerating Quantized Neural Networks on Parallel Ultra-Low-Power RISC-V Processors, , arXiv arXiv:1908.11263; (2018), https://medium.com/@culurciello/continual-learning-da7995c24bca, Continual Learning. (accessed on 30 December 2020); Lomonaco, V., (2019) Continual Learning with Deep Architectures, , PhD Thesis, ALMA, Antofagasta, Chile; Maltoni, D., Lomonaco, V., Continuous learning in single-incremental-task scenarios (2019) Neural Netw, 116, pp. 56-73; Li, Z., Hoiem, D., Learning without forgetting (2017) IEEE Trans. Pattern Anal. Mach. Intell, 40, pp. 2935-2947; Pellegrini, L., Graffieti, G., Lomonaco, V., Maltoni, D., (2019) Latent replay for real-time continual learning, , arXiv arXiv:1912.01100; LeCun, Y., (2015) LeNet-5, Convolutional Neural Networks, 20, p. 5. , http://yann.lecun.com/exdb/lenet, others; Rusci, M., Capotondi, A., Conti, F., Benini, L., Work-in-progress: Quantized nns as the definitive solution for inference on low-power arm mcus? Proceedings of the2018 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ ISSS), pp. 1-2. , Turin, Italy, 30 September–5 October 2018; Rusci, M., Capotondi, A., Benini, L., (2019) Memory-Driven Mixed Low Precision Quantization For Enabling Deep Network Inference On Microcontrollers, , arXiv arXiv:1905.13082; Prado, M.D., Su, J., Saeed, R., Keller, L., Vallez, N., Anderson, A., Gregg, D., Ouerhani, N., Bonseyes AI Pipeline—Bringing AI to You (2020) ACM Trans Internet Things, 1, pp. 1-25; Sakr, F., Bellotti, F., Berta, R., De Gloria, A., Machine Learning on Mainstream Microcontrollers (2020) Sensors, 20, p. 2638; (2019), https://www.st.com/resource/en/datasheet/stm32l476je.pdf, STMicroelectronics STM32L476xx. (accessed on 30 December 2020)","de Prado, M.; He-Arc Ingenierie, Switzerland; email: miguel.deprado@he-arc.ch
de Prado, M.; Integrated System Lab, Switzerland; email: miguel.deprado@he-arc.ch
Rusci, M.; DEI, Italy; email: manuele.rusci@unibo.it",,,"MDPI AG",,,,,14248220,,,"33668645","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85100798729
"Lee J., Lee S.","57225029853;35092639900;","Robust cnn compression framework for security-sensitive embedded systems",2021,"Applied Sciences (Switzerland)","11","3","1093","1","17",,5,"10.3390/app11031093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100076918&doi=10.3390%2fapp11031093&partnerID=40&md5=819b7df8dfd94caba9134edc87dbee38","School of Cybersecurity, Korea University, Seoul, 02841, South Korea","Lee, J., School of Cybersecurity, Korea University, Seoul, 02841, South Korea; Lee, S., School of Cybersecurity, Korea University, Seoul, 02841, South Korea","Convolutional neural networks (CNNs) have achieved tremendous success in solving complex classification problems. Motivated by this success, there have been proposed various compression methods for downsizing the CNNs to deploy them on resource-constrained embedded systems. However, a new type of vulnerability of compressed CNNs known as the adversarial examples has been discovered recently, which is critical for security-sensitive systems because the adversarial examples can cause malfunction of CNNs and can be crafted easily in many cases. In this paper, we proposed a compression framework to produce compressed CNNs robust against such adversarial examples. To achieve the goal, our framework uses both pruning and knowledge distillation with adversarial training. We formulate our framework as an optimization problem and provide a solution algorithm based on the proximal gradient method, which is more memoryefficient than the popular ADMM-based compression approaches. In experiments, we show that our framework can improve the trade-off between adversarial robustness and compression rate compared to the existing state-of-the-art adversarial pruning approach. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Adversarial robustness; Adversarial training; Distillation; Embedded system; Model compression; Secure AI; Weight pruning",,,,,,"IITP-2020-0-01749; National Research Foundation of Korea, NRF; Kementerian Pendidikan Malaysia, KPM: 2018R1D1A1B07051383","Funding: This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (2018R1D1A1B07051383), and by the MSIT (Ministry of Science and ICT), Korea, under the ITRC(Information Technology Research Center) support program (IITP-2020-0-01749) supervised by the IITP (Institute of Information & Communications Technology Planning & Evaluation).",,,,,,,,,,"Goodfellow, I.J., Shlens, J., Szegedy, C., (2015) Explaining and Harnessing Adversarial Examples, , arXiv arXiv:1412.6572; Papernot, N., McDaniel, P., Goodfellow, I., (2016) Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples, , Technical Report; Pennsylvania State University: State College, PA, USA; Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B., Swami, A., Practical Black-Box Attacks against Machine Learning (2017) Proceedings of the Asia Conference on Computer and Communications Security, , New York, NY, USA, 2–6 April; Carlini, N., Wagner, D., Towards Evaluating the Robustness of Neural Networks (2017) Proceedings of the 2017 IEEE Symposium on Security and Privacy (SP), , San Jose, CA, USA, 22–26 May; Nitin Bhagoji, A., He, W., Li, B., Song, D., Practical Black-box Attacks on Deep Neural Networks using Efficient Query Mechanisms (2018) European Conference on Computer Vision, , Springer: Berlin/Heidelberg, Germany; Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A., (2018) Towards Deep Learning Models Resistant to Adversarial Attacks, , arXiv arXiv:1706.06083; Laidlaw, C., Feizi, S., Functional Adversarial Attacks (2019) Advances in Neural Information Processing Systems, , Curran Associates Inc; Vancouver, Canada; Huang, Z., Zhang, T., (2020) Black-Box Adversarial Attack with Transferable Model-based Embedding, , arXiv arXiv:1911.07140; Han, S., Pool, J., Tran, J., Dally, W.J., Learning both Weights and Connections for Efficient Neural Networks (2015) Adv. Neural Inf. Process. Syst, 28, pp. 1135-1143; Han, S., Mao, H., Dally, W.J., (2016) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding, , arXiv arXiv:1510.00149; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning Structured Sparsity in Deep Neural Networks (2016) Adv. Neural Inf. Process. Syst, 29, pp. 2074-2082; He, Y., Zhang, X., Sun, J., Channel Pruning for Accelerating Very Deep Neural Networks (2017) Proceedings of the IEEE International Conference on Computer Vision, , Venice, Italy, 22–29 Ocotber; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., (2017) Pruning Filters for Efficient ConvNets, , arXiv arXiv:1608.08710; He, Y., Kang, G., Dong, X., Fu, Y., Yang, Y., (2018) Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks, , arXiv arXiv:1808.06866; He, Y., Liu, P., Wang, Z., Hu, Z., Yang, Y., Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, , Long Beach, CA, USA, 16–20 June; Lin, M., Ji, R., Wang, Y., Zhang, Y., Zhang, B., Tian, Y., Shao, L., HRank: Filter Pruning using High-Rank Feature Map Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , Seattle, WA, USA, 14–19 June 2020; Chin, T.W., Ding, R., Zhang, C., Marculescu, D., Towards Efficient Model Compression via Learned Global Ranking Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), , Seattle, WA, USA, 14–19 June 2020; Wang, L., Ding, G.W., Huang, R., Cao, Y., Lui, Y.C., Adversarial Robustness of Pruned Neural Networks (2018) ICLR Workshop Submission, , OpenReview.net; Vancouver, Canada; Ye, S., Lin, X., Xu, K., Liu, S., Cheng, H., Lambrechts, J.H., Zhang, H., Wang, Y., Adversarial Robustness vs. Model Compression, or Both? Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp. 111-120. , Seoul, Korea, 27–28 October 2019; Gui, S., Wang, H., Yu, C., Yang, H., Wang, Z., Liu, J., Model Compression with Adversarial Robustness: A Unified Optimization Framework (2019) Advances in Neural Information Processing Systems, , Curran Associates Inc; Vancouver, Canada; Hinton, G., Vinyals, O., Dean, J., (2014) Distilling the Knowledge in a Neural Network, , arXiv arXiv:1503.02531; Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A., Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks (2016) Proceedings of the IEEE Symposium on Security and Privacy (SP), , San Jose, CA, USA, 23–25 May; Kurakin, A., Goodfellow, I., Bengio, S., (2017) Adversarial Machine Learning at Scale, , arXiv arXiv:1611.01236; Lee, N., Ajanthan, T., Torr, P.H.S., (2019) SNIP: Single-shot Network Pruning based on Connection Sensitivity, , arXiv arXiv:1810.02340; Bucila, C., Caruana, R., Niculescu-Mizil, A., Model compression (2006) Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, , Philadelphia, PA, USA, 20–23 August; Heo, B., Lee, M., Yun, S., Choi, J.Y., Knowledge Distillation with Adversarial Samples Supporting Decision Boundary (2019) Proc. Aaai Conf. Artif. Intell, 33, pp. 3771-3778; Mirzadeh, S.I., Farajtabar, M., Li, A., Levine, N., Matsukawa, A., Ghasemzadeh, H., Improved Knowledge Distillation via Teacher Assistant (2020) Proc. Aaai Conf. Artif. Intell, 34, pp. 5191-5198; Xie, H., Qian, L., Xiang, X., Liu, N., (2020) Blind Adversarial Pruning: Balance Accuracy, Efficiency and Robustness, , arXiv arXiv:2004.05914; Xie, H., Xiang, X., Liu, N., Dong, B., (2020) Blind Adversarial Training: Balance Accuracy and Robustness, , arXiv arXiv:2004.05914; Madaan, D., Shin, J., Hwang, S.J., (2020) Adversarial Neural Pruning with Latent Vulnerability Suppression, , arXiv arXiv:1908.04355; Bernhard, R., Moellic, P.A., Dutertre, J.M., Impact of Low-bitwidth Quantization on the Adversarial Robustness for Embedded Neural Networks (2019) Proceedings of the International Conference on Cyberworlds (CW), , Kyoto, Japan, 2–4 Ocotber; Lin, J., Gan, C., Han, S., (2019) Defensive Quantization: When Efficiency Meets Robustness, , arXiv arXiv:1904.08444; Goldblum, M., Fowl, L., Feizi, S., Goldstein, T., Adversarially Robust Distillation (2020) Proc. Aaai Conf. Artif. Intell, 34, pp. 3996-4003; Cox, D., The Regression Analysis of Binary Sequences (1958) J. R. Stat. Soc. Ser. (Methodological), 20, p. 1958; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86, pp. 2278-2324; Simonyan, K., Zisserman, A., Very Deep Convolutional Networks for Large-Scale Image Recognition (2015) Int. Conf. Learn. Represent. OpenReview.net, , San Diego, CA, USA; He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , Las Vegas, NV, USA, 27–30 June 2016; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical Report, University of Toronto, Toronto, ON, Canada; Renda, A., Frankle, J., Carbin, M., (2020) Comparing Rewinding and Fine-tuning in Neural Network Pruning, , arXiv arXiv:2003.02389; Fletcher, P.T., Venkatasubramanian, S., Joshi, S., Robust statistics on Riemannian manifolds via the geometric median Proceedings of the 2008 IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8. , Anchorage, AK, USA, 23–28 June 2008","Lee, S.; School of Cybersecurity, South Korea; email: sangkyun@korea.ac.kr",,,"MDPI AG",,,,,20763417,,,,"English","Appl. Sci.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85100076918
"Xu R., Tao L., Wang T., Jin X., Li C., Li Z., Ren J.","57202612503;57201675197;56430084400;36611788700;57219729265;57219729752;57693963900;","A hybrid precision low power computing-in-memory architecture for neural networks",2021,"Microprocessors and Microsystems","80",,"103351","","",,1,"10.1016/j.micpro.2020.103351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094968956&doi=10.1016%2fj.micpro.2020.103351&partnerID=40&md5=57c81d27cf12d93fd31482c2ff62ebb0","Key Laboratory of Strongly-Coupled Quantum Matter Physics, Chinese Academy of Sciences, School of Physical Sciences, University of Science and Technology of China. HefeiAnhui, China; Zbit Semiconductor, Inc, China","Xu, R., Key Laboratory of Strongly-Coupled Quantum Matter Physics, Chinese Academy of Sciences, School of Physical Sciences, University of Science and Technology of China. HefeiAnhui, China; Tao, L., Key Laboratory of Strongly-Coupled Quantum Matter Physics, Chinese Academy of Sciences, School of Physical Sciences, University of Science and Technology of China. HefeiAnhui, China; Wang, T., Key Laboratory of Strongly-Coupled Quantum Matter Physics, Chinese Academy of Sciences, School of Physical Sciences, University of Science and Technology of China. HefeiAnhui, China; Jin, X., Key Laboratory of Strongly-Coupled Quantum Matter Physics, Chinese Academy of Sciences, School of Physical Sciences, University of Science and Technology of China. HefeiAnhui, China; Li, C., Zbit Semiconductor, Inc, China; Li, Z., Zbit Semiconductor, Inc, China; Ren, J., Zbit Semiconductor, Inc, China","Recently, non-volatile memory-based computing-in-memory has been regarded as a promising competitor to ultra-low-power AI chips. Implementations based on both binarized (BIN) and multi-bit (MB) schemes are proposed for DNNs/CNNs. However, there are challenges in accuracy and power efficiency in the practical use of both schemes. This paper proposes a hybrid precision architecture and circuit-level techniques to overcome these challenges. According to measured experimental results, a test chip based on the proposed architecture achieves (1) from binarized weights and inputs up to 8-bit input, 5-bit weight, and 7-bit output, (2) an accuracy loss reduction of from 86% to 96% for multiple complex CNNs, and (3) a power efficiency of 2.15TOPS/W based on a 0.22μm CMOS process which greatly reduces costs compared to digital designs with similar power efficiency. With a more advanced process, the architecture can achieve a higher power efficiency. According to our estimation, a power efficiency of over 20TOPS/W can be achieved with a 55nm CMOS process. © 2020 Elsevier B.V.","Computing-In-memory; Neuromorphic computing; Non-volatile memory","CMOS integrated circuits; Digital storage; Efficiency; Low power electronics; Network architecture; Neural networks; Advanced process; Circuit levels; Digital designs; Low-power computing; Non-volatile memory; Power efficiency; Proposed architectures; Ultra low power; Memory architecture",,,,,,,,,,,,,,,,"Merrikh-Bayat, F., Guo, X., Klachko, M., Prezioso, M., Likharev, K.K., Strukov, D.B., High-performance mixed-signal neurocomputing with nanoscale floating-gate memory cell arrays (2018) IEEE Trans. Neural Netw. Learn. Syst., 29 (10), pp. 4782-4790; Mahmoodi, M.R., Strukov, D., An ultra-low energy internally analog, externally digital vector-matrix multiplier based on nor flash memory technology (2018) 2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC), pp. 1-6; Han, R.Z., A novel convolution computing paradigm based on NOR flash array with high computing speed and energy efficient (2018) 2018 IEEE International Symposium on Circuits and Systems (ISCAS), pp. 1-4; Mochida, R., A 4M synapses integrated analog ReRAM based 66.5 TOPS/W neural-network processor with cell current controlled writing and flexible network architecture (2018) 2018 IEEE Symposium on VLSI Technology, pp. 175-176; Chen, W.H., A 65nm 1Mb nonvolatile computing-in-memory ReRAM macro with sub-16ns multiply-and-accumulate for binary DNN AI edge processors (2018) 2018 IEEE International Solid - State Circuits Conference - (ISSCC), pp. 494-496; Xue, C.-X., A 1Mb multibit ReRAM computing-in-memory macro with 14.6 ns parallel MAC computing time for CNN based AI edge processors (2019) 2019 IEEE International Solid-State Circuits Conference-(ISSCC), pp. 388-390. , IEEE; Jain, S., Ranjan, A., Roy, K., Raghunathan, A., Computing in memory with spin-transfer torque magnetic RAM (2018) IEEE Trans. Very Large Scale Integrat. (VLSI) Syst., 26 (3), pp. 470-483; Fan, D., Angizi, S., Energy efficient in-memory binary deep neural network accelerator with dual-mode sot-mram (2017) 2017 IEEE International Conference on Computer Design (ICCD), pp. 609-612. , IEEE; Aziz, A., Breyer, E.T., Chen, A., Chen, X., Datta, S., Gupta, S.K., Hoffmann, M., Computing with ferroelectric FETs: devices, models, systems, and applications (2018) 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 1289-1298. , IEEE; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Binarized neural networks (2016) Advances in Neural Information Processing Systems, pp. 4107-4115; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., Xnor-net: imagenet classification using binary convolutional neural networks (2016) European Conference on Computer Vision, pp. 525-542. , Springer Cham; Krishnamoorthi, R., (2018), ""Quantizing deep convolutional networks for efficient inference: a whitepaper."" arXiv preprint arXiv:1806.08342; Roohi, A., Sheikhfaal, S., Angizi, S., Fan, D., DeMara, R.F., ApGAN: approximate GAN for robust low energy learning from imprecise components (2020) IEEE Transactions on Computers, 69, pp. 349-360; Guo, X., Fast, energy-efficient, robust, and reproducible mixed-signal neuromorphic classifier based on embedded NOR flash memory technology (2017) 2017 IEEE International Electron Devices Meeting (IEDM), , IEEE; Angizi, S., He, Z., Fan, D., ParaPIM: a parallel processing-in-memory accelerator for binary-weight deep neural networks (2019) Proceedings of the 24th Asia and South Pacific Design Automation Conference, pp. 127-132; Beigi, M.V., Memik, G., Thermal-aware optimizations of ReRAM-based neuromorphic computing systems (2018) 2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC), pp. 1-6; Jia, K., Calibrating process variation at system level with in-situ low-precision transfer learning for analog neural network processors (2018) 2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC), pp. 1-6; Mishra, A., Nurvitadhi, E., Cook, J.J., Marr, D., (2017), ""WRPN: wide reduced-precision networks,"" arXiv preprint arXiv:1709.01134; LeCun, Y., (2015), 20, p. 5. , http://yann.lecun.com/exdb/lenet, ""LeNet-5, convolutional neural networks,"" URL:; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Bosi, B., Bois, G., Savaria, Y., Reconfigurable pipelined 2-D convolvers for fast digital signal processing (1999) IEEE Trans. Very Large Scale Integrat. (VLSI) Syst., 7 (3), pp. 299-308; Li, Y., Wang, W., Bai, H., Gong, R., Dong, X., (2020), F. Yu. ""Efficient bitwidth search for practical mixed precision neural network."" arXiv preprint arXiv:2003.07577; Moons, B., Uytterhoeven, R., Dehaene, W., Verhelst, M., 14.5 envision: A 0.26-to-10tops/w subword-parallel dynamic-voltage-accuracy-frequency-scalable convolutional neural network processor in 28nm fdsoi (2017) 2017 IEEE International Solid-State Circuits Conference (ISSCC), pp. 246-247. , IEEE; Liao, H., Tu, J., Xia, J., Zhou, X., DaVinci: a scalable architecture for neural network computing (2019) 2019 IEEE Hot Chips 31 Symposium (HCS), pp. 1-44. , IEEE","Jin, X.; Key Laboratory of Strongly-Coupled Quantum Matter Physics, China; email: jinxi@ustc.edu.cn",,,"Elsevier B.V.",,,,,01419331,,MIMID,,"English","Microprocessors Microsyst",Article,"Final","",Scopus,2-s2.0-85094968956
"Kolodziej K.E., Cookson A.U., Perry B.T.","55638537200;57216342127;56375675100;","RF Canceller Tuning Acceleration Using Neural Network Machine Learning for In-Band Full-Duplex Systems",2021,"IEEE Open Journal of the Communications Society","2",,"9431091","1158","1170",,2,"10.1109/OJCOMS.2021.3080618","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122046260&doi=10.1109%2fOJCOMS.2021.3080618&partnerID=40&md5=398c90ab53689164b8e00f3c360d4c70","Rf Technology Group, Advanced Technology Division, Mit Lincoln Laboratory, Lexington, MA  02421, United States","Kolodziej, K.E., Rf Technology Group, Advanced Technology Division, Mit Lincoln Laboratory, Lexington, MA  02421, United States; Cookson, A.U., Rf Technology Group, Advanced Technology Division, Mit Lincoln Laboratory, Lexington, MA  02421, United States; Perry, B.T., Rf Technology Group, Advanced Technology Division, Mit Lincoln Laboratory, Lexington, MA  02421, United States","The fifth-generation wireless system framework provides the option to evaluate the performance of in-band full-duplex (IBFD) operation through flexible duplexing. The resulting self-interference, however, must be mitigated within a fraction of a symbol duration for successful communication. This paper introduces the use of neural network machine learning to accelerate the tuning of multi-tap adaptive RF cancellers. Additionally, the optimal network configurations, input data structures and training dataset densities that optimize the performance of this technique are presented. The tuning results of a prototype system using a two-tap canceller were measured over 20 and 100 MHz bandwidths centered at 2.5 GHz, and demonstrated averages of 40 dB cancellation and 6 tuning iterations. These results are compared to a survey of previously-reported adaptive cancellers, and illustrate that this novel application of machine learning to RF canceller tuning provides the fastest convergence speed to date, which can enable IBFD operation in dynamic interference environments. © 2020 IEEE.","5G mobile communication; in-band full-duplex; machine learning; RF cancellation; self-interference cancellation","5G mobile communication systems; Machine learning; Adaptive canceller; Convergence speed; Interference environments; Network machines; Novel applications; Optimal network configuration; Self-interferences; Wireless systems; Neural networks",,,,,"FA8702-15-D-0001; U.S. Air Force, USAF","This work was supported by United States Air Force through Air Force under Contract FA8702-15-D-0001.",,,,,,,,,,"Wan, L., Zhou, M., Wen, R., Evolving LTE with flexible duplex (2013) Proc. IEEE Globecom Workshops (GC Wkshps), pp. 49-54; Liu, H., Jiao, Y., Gao, Y., Sang, L., Yang, D., Performance evaluation of flexible duplex implement based on radio frame selection in LTE heterogeneous network (2015) Proc. 22nd Int. Conf. Telecommun. (ICT), pp. 308-312; Balachandran, K., Kang, J.H., Karakayali, K., Rege, K.M., Flexible duplex in FDD spectrum (2017) Proc. IEEE Int. Conf. Commun. Workshops (ICC Workshops), pp. 296-301; Liao, Q., Dynamic uplink/downlink resource management in flexible duplex-enabled wireless networks (2017) Proc. IEEE Int. Conf. Commun. Workshops (ICC Workshops), pp. 625-631; Pirinen, P., Challenges and possibilities for flexible duplexing in 5G networks (2015) Proc. IEEE 20th Int. Workshop Comput. Aided Model. Design Commun. Links Netw. (CAMAD), pp. 6-10; Kolodziej, K.E., (2021) Band Full-Duplex Wireless Systems Handbook, , Norwood, MA, USA: Artech House; Kolodziej, K.E., Perry, B.T., Herd, J.S., In-band full-duplex technology: Techniques and systems survey (2019) IEEE Trans. Microw. Theory Techn, 67 (7), pp. 3025-3041. , Jul; Bai, J., Yeh, S.-P., Xue, F., Choi, Y.-S., Wang, P., Talwar, S., (2019) Fullduplex in 5G Small Cell Access: System Design and Performance Aspects, , arXiv:1903.09893; Beach, M., Laughlin, L., Zhang, C., Morris, K., Haine, J., McCullagh, M., Flexible duplex transceivers for 5G and beyond wireless access (2015) Proc. 1st URSI Atlantic Radio Sci. Conf. (URSI AT-RASC), p. 1; Kim, S.-M., Cha, H., Kim, S.-L., Chae, C.-B., Demo: A reinforcement learning-based flexible duplex systems for B5G with sub-6 GHz (2020) Proc. IEEE Wireless Commun. Netw. Conf. Workshops (WCNCW), pp. 1-2; Palaniappan, R., Gurumurthy, V., Aniruddhan, S., A spectral shaper based two-tap RF self-interference canceller for full-duplex radios (2019) Proc. IEEE MTT-S Int. Microw. Symp. (IMS), pp. 614-617; Zhang, Z., Shen, Y., Shao, S., Pan, W., Tang, Y., Full duplex 2x2 MIMO radios (2014) Proc. 6th Int. Conf. Wireless Commun. Signal Process. (WCSP), pp. 1-6; Keogh, B., Zhu, A., Wideband self-interference cancellation for 5G full-duplex radio using a near-field sensor array (2018) Proc. IEEE MTTS Int. Microw. Workshop Series 5G Hardw. Syst. Technol. (IMWS-5G), pp. 1-3; Kolodziej, K.E., Yegnanarayanan, S., Perry, B.T., Photonicenabled RF canceller for wideband in-band full-duplex wireless systems (2019) IEEE Trans. Microw. Theory Techn, 67 (5), pp. 2076-2086. , May; Kolodziej, K.E., Cookson, A.U., Perry, B.T., Adaptive learning rate tuning algorithm for RF self-interference cancellation (2021) IEEE Trans. Microw. Theory Techn, 69 (3), pp. 1740-1751. , Mar; Bharadia, D., McMilin, E., Katti, S., Full duplex radios (2013) Proc. ACM Conf. (SIGCOMM), pp. 375-386; Jain, M., Practical, real-time, full duplex wireless (2011) Proc. Annu. Int. Conf. Mobile Comput. Netw, pp. 301-312; Kolodziej, K.E., McMichael, J.G., Perry, B.T., Multitap RF canceller for in-band full-duplex wireless communications (2016) IEEE Trans. Wireless Commun, 15 (6), pp. 4321-4334. , Jun; Huusari, T., Choi, Y.-S., Liikkanen, P., Korpi, D., Talwar, S., Valkama, M., Wideband self-adaptive RF cancellation circuit for fullduplex radio: Operating principle and measurements (2015) Proc. IEEE 81st Veh. Technol. Conf. (VTC Spring), pp. 1-7; Tamminen, J., Digitally-controlled RF self-interference canceller for full-duplex radios (2016) Proc. 24th Eur. Signal Process. Conf. (EUSIPCO), pp. 783-787; Cao, Y., Cao, X., Seo, H., Zhou, J., An integrated full-duplex/FDD duplexer and receiver achieving 100Mhz bandwidth 58dB/48dB self-interference suppression using hybrid-analog-digital autonomous adaptation loops (2020) Proc. IEEE/MTT-S Int. Microw. Symp. (IMS), pp. 1203-1206; Bakshi, A., Mao, Y., Srinivasan, K., Parthasarathy, S., Fast and efficient cross band channel prediction using machine learning (2019) Proc. 25th Annu. Int. Conf. Mobile Comput. Netw, pp. 1-16; Balatsoukas-Stimming, A., Non-linear digital self-interference cancellation for in-band full-duplex radios using neural networks (2018) Proc. IEEE 19th Int. Workshop Signal Process. Adv. Wireless Commun. (SPAWC), pp. 1-5; Kurzo, Y., Burg, A., Balatsoukas-Stimming, A., Design and implementation of a neural network aided self-interference cancellation scheme for full-duplex radios (2018) Proc. 52nd Asilomar Conf. Signals Syst. Comput, pp. 589-593; Guo, H., Xu, J., Zhu, S., Wu, S., Realtime software defined selfinterference cancellation based on machine learning for in-band full duplex wireless communications (2018) Proc. Int. Conf. Comput. Netw. Commun. (ICNC), pp. 779-783; Guo, H., Wu, S., Wang, H., Daneshmand, M., DSIC: Deep learning based self-interference cancellation for in-band full duplex wireless (2019) Proc. IEEE Global Commun. Conf. (GLOBECOM), pp. 1-6; Wang, Q., He, F., Meng, J., Performance comparison of real and complex valued neural networks for digital self-interference cancellation (2019) Proc. IEEE 19th Int. Conf. Commun. Technol. (ICCT), pp. 1193-1199; Kurzo, Y., Kristensen, A.T., Burg, A., Balatsoukas-Stimming, A., Hardware implementation of neural self-interference cancellation (2020) IEEE J. Emerg. Sel. Topics Circuits Syst, 10 (2), pp. 204-216. , Jun; Cummings, I.T., Schulz, T.J., Havens, T.C., Doane, J.P., Neural networks for real-time adaptive beamforming in simultaneous transmit and receive digital phased arrays: Student submission (2019) Proc. IEEE Int. Symp. Phased Array Syst. Technol. (PAST), pp. 1-8; Le, A.T., Tran, L.C., Huang, X., Guo, Y.J., Beam-based analog self-interference cancellation in full-duplex MIMO systems (2020) IEEE Trans. Wireless Commun, 19 (4), pp. 2460-2471. , Apr; Kolodziej, K.E., Cookson, A.U., Perry, B.T., Machine learning for accelerated IBFD tuning in 5G flexible duplex networks (2020) Proc. IEEE/MTT-S Int. Microw. Symp. (IMS), pp. 691-694; Kolodziej, K.E., Perry, B.T., Wideband vector modulator for RF cancellers in star systems (2018) Proc. IEEE Radio Wireless Symp. (RWS), pp. 64-67; Hagan, M.T., Menhaj, M.B., Training feedforward networks with the Marquardt algorithm (1994) IEEE Trans. Neural Netw, 5 (6), pp. 989-993. , Nov; Liu, H., On the Levenberg-Marquardt training method for feedforward neural networks (2010) Proc. 6th Int. Conf. Nat. Comput, 1, pp. 456-460; Levenberg, K., A method for the solution of certain non-linear problems in least squares (1944) Quart. Appl. Math, 2 (2), pp. 164-168; Marquardt, D.W., An algorithm for least-squares estimation of nonlinear parameters (1963) J. Soc. Ind. Appl. Math, 11 (2), pp. 431-441; Smith, J.S., Wu, B., Wilamowski, B.M., Neural network training with Levenberg-Marquardt and adaptable weight compression (2019) IEEE Trans. Neural Netw. Learn. Syst, 30 (2), pp. 580-587. , Feb","Kolodziej, K.E.; Rf Technology Group, United States; email: kenneth.kolodziej@ll.mit.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,2644125X,,,,"English","IEEE open J. Commun. Soc.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85122046260
"Gong C., Lu Y., Xie K., Jin Z., Li T., Wang Y.","57211203988;55506538700;57210789492;57214246437;57210469208;36555062200;","Elastic Significant Bit Quantization and Acceleration for Deep Neural Networks",2021,"IEEE Transactions on Parallel and Distributed Systems",,,,"","",,,"10.1109/TPDS.2021.3129615","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120568041&doi=10.1109%2fTPDS.2021.3129615&partnerID=40&md5=6502611f45f4a6c4a0d91ca69b06afea","College of Computer Science, Nankai University, 12538 Tianjin, Tianjin, China, 300071 (e-mail: cheng-gong@mail.nankai.edu.cn); College of Cyber Science, Nankai University, 12538 Tianjin, Tianjin, China, (e-mail: luye@nankai.edu.cn); college of computer, Nankai University, 12538 Tianjin, tj, China, 300071 (e-mail: xkp@mail.nankai.edu.cn); College of Computer Science, Nankai University, 12538 Tianjin, Tianjin, China, (e-mail: zongming_jin@mail.nankai.edu.cn); College of Computer Science, Nankai University, 12538 Tianjin, Tianjin, China, 300071 (e-mail: litao@nankai.edu.cn); ECE, Northeastern University, Boston, Massachusetts, United States, 02115 (e-mail: yanz.wang@northeastern.edu)","Gong, C., College of Computer Science, Nankai University, 12538 Tianjin, Tianjin, China, 300071 (e-mail: cheng-gong@mail.nankai.edu.cn); Lu, Y., College of Cyber Science, Nankai University, 12538 Tianjin, Tianjin, China, (e-mail: luye@nankai.edu.cn); Xie, K., college of computer, Nankai University, 12538 Tianjin, tj, China, 300071 (e-mail: xkp@mail.nankai.edu.cn); Jin, Z., College of Computer Science, Nankai University, 12538 Tianjin, Tianjin, China, (e-mail: zongming_jin@mail.nankai.edu.cn); Li, T., College of Computer Science, Nankai University, 12538 Tianjin, Tianjin, China, 300071 (e-mail: litao@nankai.edu.cn); Wang, Y., ECE, Northeastern University, Boston, Massachusetts, United States, 02115 (e-mail: yanz.wang@northeastern.edu)","Quantization has been proven to be a vital method for improving the inference efficiency of deep neural networks (DNNs). However, it is still challenging to strike a good balance between accuracy and efficiency while quantizing DNN weights or activation values from high-precision formats to their quantized counterparts. We propose a new method called elastic significant bit quantization(ESB) that controls the number of significant bits of quantized values to obtain better inference accuracy with fewer resources. We design a unified mathematical formula to constrain the quantized values of the ESB with a flexible number of significant bits. We also introduce a distribution difference aligner (DDA) to quantitatively align the distributions between the full-precision weight or activation values and quantized values. Consequently, ESB is suitable for various bell-shaped distributions of weights and activation of DNNs, thus maintaining a high inference accuracy. Benefitting from fewer significant bits of quantized values, ESB can reduce the multiplication complexity. We implement ESB as an accelerator and quantitatively evaluate its efficiency on FPGAs. Extensive experimental results illustrate that ESB quantization consistently outperforms state-of-the-art methods and achieves average accuracy improvements of 4.78%, 1.92%, and 3.56% over AlexNet, ResNet18, and MobileNetV2, respectively. Furthermore, ESB as an accelerator can achieve 10.95 GOPS peak performance of 1k LUTs without DSPs on the Xilinx ZCU102 FPGA platform. Compared with CPU, GPU, and state-of-the-art accelerators on FPGAs, the ESB accelerator can improve the energy efficiency by up to 65, 11, and 26, respectively. IEEE","Cheap projection; Computer science; Degradation; Distributed databases; Distribution aligner; DNN quantization; Field programmable gate arrays; Fitting distribution; FPGA accelerator; Hardware; Open area test sites; Quantization (signal); Significant bits","Acceleration; Chemical activation; Distributed computer systems; Energy efficiency; Field programmable gate arrays (FPGA); Quantization (signal); Aligners; Cheap projection; Deep neural network quantization; Distributed database; Distribution aligner; Fitting distribution; FPGA accelerator; Hardware; Open area test sites; Quantisation; Quantization (signal); Significant bit; Deep neural networks",,,,,,,,,,,,,,,,,,,,"IEEE Computer Society",,,,,10459219,,ITDSE,,"English","IEEE Trans Parallel Distrib Syst",Article,"Article in Press","All Open Access, Green",Scopus,2-s2.0-85120568041
"Zhang J., Chen X., Ray S.","57196021731;57221313689;35234758200;","GCONV Chain: Optimizing the Whole-life Cost in End-to-end CNN Acceleration",2021,"IEEE Transactions on Computers",,,,"","",,,"10.1109/TC.2021.3128159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119400776&doi=10.1109%2fTC.2021.3128159&partnerID=40&md5=9a2081077068f196c48deb74aa670242","Electrical and Computer Engineering, University of Florida, 3463 Gainesville, Florida, United States, (e-mail: jiaqizhang@ufl.edu); Electrical and Computer Engineering, University of Florida, 3463 Gainesville, Florida, United States, (e-mail: cxr1994816@ufl.edu); Electrical and Computer Engineering, University of Florida, 3463 Gainesville, Florida, United States, (e-mail: sandip@ece.ufl.edu)","Zhang, J., Electrical and Computer Engineering, University of Florida, 3463 Gainesville, Florida, United States, (e-mail: jiaqizhang@ufl.edu); Chen, X., Electrical and Computer Engineering, University of Florida, 3463 Gainesville, Florida, United States, (e-mail: cxr1994816@ufl.edu); Ray, S., Electrical and Computer Engineering, University of Florida, 3463 Gainesville, Florida, United States, (e-mail: sandip@ece.ufl.edu)","The acceleration of CNNs has gained increasing attention since their success in computer vision. Since the heterogeneous layers cannot be processed by accelerators proposed for convolution layers only, modern end-to-end CNN acceleration solutions either transform diverse computation into matrix/vector arithmetic, which loses data reuse opportunities in convolution, or introduce dedicated functional unit to each kind of layer, which results in underutilization and high update expense. To enhance the whole-life cost efficiency, we need a solution that is efficient in processing CNN layers and has the generality to apply to all kinds of existing and emerging layers. To this end, we propose GCONV Chain, a method to convert the entire CNN computation into a chain of standard general convolutions (GCONV) that can be efficiently processed by existing CNN accelerators with low-overhead hardware support. This paper comprehensively analyzes the GCONV Chain model and proposes a full-stack implementation to support GCONV Chain. Our results on various CNNs demonstrate that GCONV Chain improves the performance and energy efficiency of existing CNN accelerators by an average of 3.4x and 3.2x respectively. Furthermore, we show that GCONV Chain provides low whole-life costs for CNN acceleration, including both developer efforts and total cost of ownership. IEEE","Computer architecture; Convolution; convolution neural network; Convolutional neural networks; Costs; hardware acceleration; Kernel; Lips; neural network; Tensors; Transforms","Acceleration; Chains; Computer architecture; Computer hardware; Convolution; Costs; Energy efficiency; Network architecture; Convolution neural network; Convolutional neural network; Data reuse; End to end; Hardware acceleration; Kernel; Lip; Matrix-vector arithmetics; Neural-networks; Whole life cost; Neural networks",,,,,,,,,,,,,,,,,,,,"IEEE Computer Society",,,,,00189340,,ITCOB,,"English","IEEE Trans Comput",Article,"Article in Press","",Scopus,2-s2.0-85119400776
"Joo Y., Yu Y., Jang I.G.","56460853700;36097416900;55316314100;","Unit Module-Based Convergence Acceleration for Topology Optimization Using the Spatiotemporal Deep Neural Network",2021,"IEEE Access","9",,,"149766","149779",,,"10.1109/ACCESS.2021.3125014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118649073&doi=10.1109%2fACCESS.2021.3125014&partnerID=40&md5=8fca59757838c9e55bb9b446b1afd39f","Korea Institute of Energy Research, Yuseong-gu Daejeon, 34129, South Korea; Korea Atomic Energy Research Institute, Yuseong-gu Daejeon, 34057, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, Yuseong-gu, 34141, South Korea","Joo, Y., Korea Institute of Energy Research, Yuseong-gu Daejeon, 34129, South Korea; Yu, Y., Korea Atomic Energy Research Institute, Yuseong-gu Daejeon, 34057, South Korea; Jang, I.G., Korea Advanced Institute of Science and Technology, Daejeon, Yuseong-gu, 34141, South Korea","This study proposes a unit module-based acceleration method for 2-D topology optimization. For the purpose, the first-stage topology optimization is performed until the predefined iteration. After a whole design domain is divided into a set of unit modules, information on the spatiotemporal characteristics of intermediate designs and a filtering radius is used to separately predict a near-optimal design of each unit module through a trained long short-term memory (convLSTM) network. Then, in the second-stage topology optimization, a combined near-optimal design of a whole design domain is used as an initial design to determine the optimized design in a more efficient way. To train a convLSTM network, a history of intermediate designs is obtained under a randomly generated boundary condition of a unit module. The filtering radius is also used as the training data to reflect the geometric features affected by a filtering process. For four examples with different design domains and boundary conditions, the proposed method successfully provides the accelerated convergence up to 6.09 with a negligible loss of accuracy less than 1.12% error. These numerical results also demonstrate that the proposed unit module-based approach achieves a scalable convergence acceleration at a design domain of an arbitrary size (or resolution). © 2013 IEEE.","Convergence acceleration; deep learning; finite element method; structural topology optimization","Boundary conditions; Deep neural networks; Information filtering; Iterative methods; Optimal systems; Structural optimization; Topology; Convergence; Convergence acceleration; Deep learning; Design domains; Finite element analyse; Network topology; Optimisations; Structural topology optimization; Topology optimisation; Training data; Finite element method",,,,,,,,,,,,,,,,"Bendsoe, M.P., Sigmund, O., (2013) Topology Optimization: Theory, Methods, and Applications, , Springer; Mukherjee, S., Lu, D., Raghavan, B., Breitkopf, P., Dutta, S., Xiao, M., Zhang, W., Accelerating large-scale topology optimization: State-of-the-art and challenges (2021) Arch. Comput. Methods Eng., 1, pp. 1-23. , Jan; Jang, I.G., Kwak, B.M., Evolutionary topology optimization using design space adjustment based on fixed grid (2006) Int. J. Numer. Methods Eng., 66 (11), pp. 1817-1840; Kim, S.Y., Kim, I.Y., Mechefske, C.K., A new efficient convergence criterion for reducing computational expense in topology optimization: Reducible design variable method (2012) Int. J. Numer. Methods Eng., 90 (6), pp. 752-783. , May; Liao, Z., Zhang, Y., Wang, Y., Li, W., A triple acceleration method for topology optimization (2019) Struct. Multidisciplinary Optim., 60 (2), pp. 727-744. , Aug; Zheng, W., Wang, Y., Zheng, Y., Da, D., Efficient topology optimization based on DOF reduction and convergence acceleration methods (2020) Adv. Eng. Softw., 149. , Nov. Art; Nguyen, T.H., Paulino, G.H., Song, J., Le, C.H., A computational paradigm for multiresolution topology optimization (MTOP) (2010) Struct. Multidisciplinary Optim., 41 (4), pp. 525-539. , Apr; Nguyen, T.H., Paulino, G.H., Song, J., Le, C.H., Improving multiresolution topology optimization via multiple discretizations (2012) Int. J. Numer. Methods Eng., 92 (6), pp. 507-530. , Nov; Yoo, J., Jang, I.G., Lee, I., Multi-resolution topology optimization using adaptive isosurface variable grouping (MTOP-aIVG) for enhanced computational efficiency (2021) Struct. Multidisciplinary Optim., 63 (4), pp. 1743-1766. , Apr; Carleo, G., Troyer, M., Solving the quantum many-body problem with artificial neural networks (2017) Science, 355, pp. 602-606. , Feb; Mills, K., Spanner, M., Tamblyn, I., Deep learning and the Schrödinger equation (2017) Phys. Rev. A, Gen. Phys., 96 (4). , Oct. Art; Singh, A.P., Medida, S., Duraisamy, K., Machine-Learning-Augmented predictive modeling of turbulent separated flows over airfoils (2017) AIAA J, 55 (7), pp. 2215-2227. , Jul; Tompson, J., Schlachter, K., Sprechmann, P., Perlin, K., Accelerating Eulerian fluid simulation with convolutional networks (2017) Proc. Int. Conf. Mach. Learn., pp. 3424-3433; Chandrasekhar, A., Suresh, K., Tounn: Topology optimization using neural networks (2021) Struct. Multidisciplinary Optim., 63 (3), pp. 1135-1149. , Mar; Ulu, E., Zhang, R., Kara, L.B., A data-driven investigation and estimation of optimal topologies under variable loading configurations (2016) Comput. Methods Biomech. Biomed. Eng., Imag. Visualizat., 4 (2), pp. 61-72. , Mar; Aulig, N., Olhofer, M., Topology optimization by predicting sensitivities based on local state features (2014) Proc. 5th Eur. Conf. Comput. Mech. (ECCM V), pp. 1-13. , Barcelona, Spain; Liu, K., Tovar, A., Nutwell, E., Detwiler, D., Towards nonlinear multi-material topology optimization using unsupervised machine learning and metamodel-based optimization (2015) Proc. 41st Design Automat. Conf., , Aug; Sosnovik, I., Oseledets, I., Neural networks for topology optimization (2019) Russian J. Numer. Anal. Math. Model., 34 (4), pp. 215-223. , Aug; Yu, Y., Hur, T., Jung, J., Jang, I.G., Deep learning for determining a near-optimal topological design without any iteration (2019) Struct. Multidisciplinary Optim., 59 (3), pp. 787-799. , Mar; Sasaki, H., Igarashi, H., Topology optimization accelerated by deep learning (2019) IEEE Trans. Magn., 55 (6), pp. 1-5. , Jun; Qian, C., Ye, W., Accelerating gradient-based topology optimization design with dual-model artificial neural networks (2021) Struct. Multidisciplinary Optim., 63 (4), pp. 1687-1707. , Apr; Kallioras, N.A., Kazakis, G., Lagaros, N.D., Accelerated topology optimization by means of deep learning (2020) Struct. Multidisciplinary Optim., 62 (3), pp. 1185-1212. , Sep; Shi, X., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., Woo, W.-C., Convolutional LSTM network: A machine learning approach for precipitation nowcasting (2015) Proc. Adv. Neural Inf. Process. Syst., 28, pp. 802-810; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Pfeuffer, A., Dietmayer, K., Separable convolutional LSTMs for faster video segmentation (2019) Proc. IEEE Intell. Transp. Syst. Conf. (ITSC), pp. 1072-1078. , Oct; Arbelle, A., Raviv, T.R., Microscopy cell segmentation via convolutional LSTM networks (2019) Proc. IEEE 16th Int. Symp. Biomed. Imag. (ISBI), pp. 1008-1012. , Apr; Cook, R.D., (2007) Concepts and Applications of Finite Element Analysis, , Hoboken, NJ, USA: Wiley; Andreassen, E., Clausen, A., Schevenels, M., Lazarov, B.S., Sigmund, O., Efficient topology optimization in MATLAB using 88 lines of code (2010) Struct. Multidiscipl. Optim., 43 (1), pp. 1-16. , Jan; Choi, K.K., Kim, N.-H., (2004) Structural Sensitivity Analysis and Optimization 1: Linear Systems, , Springer; Qing, X., Niu, Y., Hourly day-ahead solar irradiance prediction using weather forecasts by LSTM (2018) Energy, 148, pp. 461-468. , Apr; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional networks for biomedical image segmentation (2015) Proc. Int. Conf. Med. Image Comput.-Assist. Intervent., pp. 234-241; Schuldt, C., Recognizing human actions: A local SVM approach (2004) Proc. 17th Int. Conf. Pattern Recognit. (ICPR), pp. 32-36. , Aug; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Jang, I.G., Kwak, B.M., Design space optimization using design space adjustment and refinement (2008) Struct. Multidisciplinary Optim., 35 (1), pp. 41-54","Jang, I.G.; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; email: igjang@kaist.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85118649073
"Labintsev A., Khasanshin I., Balashov D., Bocharov M., Bublikov K.","57298172700;57221783699;57298575800;57211562947;56347676300;","Recognition Punches in Karate Using Acceleration Sensors and Convolution Neural Networks",2021,"IEEE Access","9",,,"138106","138119",,1,"10.1109/ACCESS.2021.3118038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117185058&doi=10.1109%2fACCESS.2021.3118038&partnerID=40&md5=7ce5da95921bf7181553d0324f201651","Department of Data Analysis and Machine Learning, Financial University under the Government of the Russian Federation (Financial University), Moscow, 125993, Russian Federation; Institute of Electrical Engineering, Slovak Academy of Sciences, Bratislava, 841 04, Slovakia","Labintsev, A., Department of Data Analysis and Machine Learning, Financial University under the Government of the Russian Federation (Financial University), Moscow, 125993, Russian Federation; Khasanshin, I., Department of Data Analysis and Machine Learning, Financial University under the Government of the Russian Federation (Financial University), Moscow, 125993, Russian Federation; Balashov, D., Department of Data Analysis and Machine Learning, Financial University under the Government of the Russian Federation (Financial University), Moscow, 125993, Russian Federation; Bocharov, M., Department of Data Analysis and Machine Learning, Financial University under the Government of the Russian Federation (Financial University), Moscow, 125993, Russian Federation; Bublikov, K., Institute of Electrical Engineering, Slovak Academy of Sciences, Bratislava, 841 04, Slovakia","Coaches and athletes need to understand the kinematics and dynamics of karate kicks to improve the training process and results. The research was aimed at studying the automatic recognition of punches in karate using only linear acceleration sensors. Accelerometers were part of the Inertial Measurement Units (IMUs), which were attached to the left and right wrist of the athlete. To develop a model of punches, highly qualified athletes with 3-7 years of karate experience participated in the research. We analyzed the acceleration fields of various karate punches: Yun Tsuki, Mawashi Tsuki, Age of Tsuki, Uraken. We have proposed more straightforward approach to extracting features without calculating their statistical characteristics. To solve the classification problem, we have used various architectures of convolutional neural networks: multilayer perceptron, 1- and 2-dimension Convolution Networks. Since the recognition of punches was carried out in the conditions of a shadow fight, in addition to the recognition of punches, another output parameter was introduced - movement without punches. Studies have shown a high level of punch recognition based on the developed models. The multi-class accuracy value is 0.96, and the average F1 value is 0.97 for five different punch classes. Thus, the proposed approach is more suitable for practical implementation in automatic learning systems. © 2013 IEEE.","classification; kinematic analysis; neural networks; Punch; recognition; sensors","Convolution; Kinematics; Learning systems; Sports; Acceleration sensors; Automatic recognition; Convolution neural network; Kinematic Analysis; Kinematics and dynamics; Neural-networks; Punch; Recognition; Sensor; Training process; Multilayer neural networks",,,,,,,,,,,,,,,,"Zago, M., Codari, M., Iaia, F.M., Sforza, C., Multi-segmental movements as a function of experience in karate (2017) J. Sports Sci., 35 (15), pp. 1515-1522. , Aug; Cust, E.E., Sweeting, A.J., Ball, K., Robertson, S., Machine and deep learning for sport-specific movement recognition: A systematic review of model development and performance (2019) J. Sports Sci., 37 (5), pp. 568-600. , Mar; Lawton, B., Nauright, J., Globalization of the traditional Okinawan art of Shotokan karate (2019) Sport Soc., 22 (11), pp. 1762-1768. , Nov; Alinaghipour, M., Zareian, E., Ardakani, Z.P., The scoring techniques in the final competitions of the karate world championships 2016 (2020) Ann. Appl. Sport Sci., 8 (2), p. e760. , http://aassjournal.com/article-1-760-en.html; Seyedi, R., Zhong, Y., Khodaparast, S., Sigillo, D., Azizi, A., Yiming, Q., Identifying keys to win in the world karate championship (2021) Ann. Appl. Sport Sci., 9 (2), p. e936. , http://aassjournal.com/article-1-936-en.html; Polak, E., Kulasa, J., VencesBrito, A., Castro, M., Fernandes, O., Motion analysis systems as optimization training tools in combat sports and martial arts (2016) Revista de Artes Marciales Asiáticas, 10 (2), pp. 105-123; Petrosov, D.A., Lomazov, V.A., Petrosova, N.V., Model of an artificial neural network for solving the problem of controlling a genetic algorithm using the mathematical apparatus of the theory of Petri nets (2021) Appl. Sci., 11 (9), p. 3899. , Apr; Dogadina, E.P., Smirnov, M.V., Osipov, A.V., Suvorov, S.V., Formation of the optimal load of high school students using a genetic algorithm and a neural network (2021) Appl. Sci., 11 (11), p. 5263. , Jun; Ivanyuk, V.A., Pashchenko, F.F., Neural networks and their application in forecasting problems (2020) J. Phys., Conf. Ser., 1703. , Dec; Yerznkyan, B., Bychkova, S., Gataullin, T., Gataullin, S., The sufficiency principle as the ideas quintessence of the club of Rome (2019) Montenegrin J. Econ., 15 (1), pp. 21-29. , Mar; Korchagin, S., Serdechny, D., Kim, R., Terin, D., Bey, M., The use of machine learning methods in the diagnosis of diseases of crops (2020) Proc. Int. Sci. Practical Conf. Inertia Develop, Res. Innovation Support Agricult. (IDSISA), E3S Web Conf., 176, p. 04011. , June Jun. 2020; Worsey, M., Espinosa, H., Shepherd, J., Thiel, D., Inertial sensors for performance analysis in combat sports: A systematic review (2019) Sports, 7 (1), p. 28. , Jan; Kimm, D., Thiel, D.V., Hand speed measurements in boxing (2015) Proc. Eng., 112, pp. 502-506. , Jan; Dinu, D., Millot, B., Slawinski, J., Louis, J., An examination of the biomechanics of the cross, hook and uppercut between two elite boxing groups (2020) Proceedings, 49 (1), p. 61. , Jun; Haralabidis, N., Saxby, D.J., Pizzolato, C., Needham, L., Cazzola, D., Minahan, C., Fusing accelerometry with videography to monitor the effect of fatigue on punching performance in elite boxers (2020) Sensors, 20 (20), p. 5749. , Oct; Khasanshin, I., Application of an artificial neural network to automate the measurement of kinematic characteristics of punches in boxing (2021) Appl. Sci., 11 (3), p. 1223. , Jan; Worsey, M.T.O., Espinosa, H.G., Shepherd, J.B., Thiel, D.V., An evaluation of wearable inertial sensor configuration and supervised machine learning models for automatic punch classification in boxing (2020) IoT, 1 (2), pp. 360-381. , Nov; Malawski, F., Kwolek, B., Recognition of action dynamics in fencing using multimodal cues (2018) Image Vis. Comput., 75, pp. 1-10. , Jul; Kasiri, S., Fookes, C., Sridharan, S., Morgan, S., Fine-grained action recognition of boxing punches from depth imagery (2017) Comput. Vis. Image Understand., 159, pp. 143-153. , Jun; Hülsmann, F., Göpfert, J.P., Hammer, B., Kopp, S., Botsch, M., Classification of motor errors to provide real-time feedback for sports coaching in virtual reality A case study in squats and Tai Chi pushes (2018) Comput. Graph., 76, pp. 47-59. , Nov; https://www.st.com/en/microcontrollers-microprocessors/stm32f103.html, STM32 Overview. Accessed: Apr. 9, 2021; https://invensense.tdk.com/wp-content/uploads/2015/02/MPU-6000-Datasheet1.pdf, MPU-6000 Product Specification. Accessed: Apr. 9, 2021; Khan, S.U., Hussain, T., Ullah, A., Baik, S.W., Deep-ReID: Deep features and autoencoder assisted image patching strategy for person re-identification in smart cities surveillance (2021) Multimedia Tools Appl., pp. 1-22. , Jan; Khan, S.U., Haq, I.U., Rho, S., Baik, S.W., Lee, M.Y., Cover the violence: A novel deep-learning-based approach towards violencedetection in movies (2019) Appl. Sci., 9 (22); Li, K., Ma, W., Sajid, U., Wu, Y., Wang, G., Object detection with convolutional neural networks (2020) Deep Learning in Computer Vision: Principles and Applications, pp. 41-63. , Boca Raton, FL, USA: CRC Press, , ch. 2; Ullah, A., Muhammad, K., Hussain, T., Lee, M., Baik, S., Deep LSTM-based sequence learning approaches for action and activity recognition (2020) Deep Learning in Computer Vision: Principles and Applications, p. 127. , Boca Raton, FL, USA: CRC Press; Yang, X., Chen, P., Person re-identification based on multi-scale convolutional network (2020) Multimedia Tools Appl., 79 (13-14), pp. 9299-9313. , Apr; Zhang, X., Yao, L., Wang, X., Monaghan, J., McAlpine, D., Zhang, Y., A survey on deep learning-based non-invasive brain signals: Recent advances and new frontiers (2021) J. Neural Eng., 18 (3). , Jun; Zhao, P., A review on machine learning and gesture recognition (2020) Proc. Int. Conf. Comput. Data Sci. (CDS), pp. 425-428. , Aug; Lee, K.-S., Chae, S., Park, H.-S., Optimal time-window derivation for human-activity recognition based on convolutional neural networks of repeated rehabilitation motions (2019) Proc. IEEE 16th Int. Conf. Rehabil. Robot. (ICORR), pp. 583-586. , Jun; Hu, Z., Lee, E.-J., Human motion recognition based on improved 3-dimensional convolutional neural network (2019) Proc. IEEE Int. Conf. Comput., Commun. Eng. (ICCCE), pp. 154-156. , Nov; Nithyakani, P., Shanthini, A., Ponsam, G., Human gait recognition using deep convolutional neural network (2019) Proc. 3rd Int. Conf. Comput. Commun. Technol. (ICCCT), pp. 208-211. , Feb; Zhiqi, Y., Gesture recognition based on improved VGGNET convolutional neural network (2020) Proc. IEEE 5th Inf. Technol. Mechatronics Eng. Conf. (ITOEC), pp. 1736-1739. , Jun; Dhall, I., Vashisth, S., Aggarwal, G., Automated hand gesture recognition using a deep convolutional neural network model (2020) Proc. 10th Int. Conf. Cloud Comput., Data Sci. Eng. (Confluence), pp. 811-816. , Jan; Yang, Q., Ding, W., Zhou, X., Zhao, D., Yan, S., Leap motion hand gesture recognition based on deep neural network (2020) Proc. Chin. Control Decis. Conf. (CCDC), pp. 2089-2093. , Aug; Zhu, D., Wei, R., Zhan, W., Hao, Z., Individual soldier gesture intelligent recognition system (2019) Proc. IEEE Int. Conf. Power, Intell. Comput. Syst. (ICPICS), pp. 231-235. , Jul; Rahagiyanto, A., Basuki, A., Sigit, R., Anwar, A., Zikky, M., Hand gesture classification for sign language using artificial neural network (2017) Proc. 21st Int. Comput. Sci. Eng. Conf. (ICSEC), pp. 1-5. , Nov; Gao, R., Guo, J., He, Y., Dong, S., Liu, P., Sun, L., Gesture recognition algorithm based on new EMG representation and convolutional neural network (2020) Proc. Chin. Autom. Congr. (CAC), pp. 3697-3701. , Nov; Kajan, S., Goga, J., Zsíros, O., Comparison of algorithms for dynamic hand gesture recognition (2020) Proc. Cybern. Informat. (K&I), pp. 1-5; Benalcázar, M.E., González, J., Jaramillo-Yánez, A., Anchundia, C.E., Zambrano, P., Segura, M., A model for real-time hand gesture recognition using electromyography (EMG), covariances and feed-forward artificial neural networks (2020) Proc. IEEE Andescon, pp. 1-6. , Oct; Panda, A.K., Chakravarty, R., Moulik, S., Hand gesture recognition using flex sensor and machine learning algorithms (2021) Proc. Ieeeembs Conf. Biomed. Eng. Sci. (IECBES), pp. 449-453. , Mar; Lee, M., Bae, J., Deep learning based real-time recognition of dynamic finger gestures using a data glove (2020) IEEE Access, 8, pp. 219923-219933; Chu, X., Liu, J., Shimamoto, S., A sensor-based hand gesture recognition system for Japanese sign language (2021) Proc. IEEE 3rd Global Conf. Life Sci. Technol. (LifeTech), pp. 311-312. , Mar; Noveletto, F., Filho, P.B., Soares, A.V., Low cost biofeedback system for muscular strength analysis and training (2016) IEEE Latin Amer. Trans., 14 (2), pp. 575-581. , Feb; Howard, R., Wireless sensor devices in sports performance (2016) IEEE Potentials, 35 (4), pp. 40-42. , Jul./Aug; Zhang, X., Chen, X., Li, Y., Lantz, V., Wang, K., Yang, J., A framework for hand gesture recognition based on accelerometer and EMG sensors (2011) IEEE Trans. Syst., Man, Cybern. A, Syst., Humans, 41 (6), pp. 1064-1076. , Nov; Shin, S.-W., Jeong, S.-H., Shin, S.-J., Cho, D.-S., Chung, S.-T., Developing a device using accelerometers and EMG for hand movement recognition (2013) Proc. 6th Int. Conf. Biomed. Eng. Informat., pp. 398-402. , Dec; Yuan, G., Liu, X., Yan, Q., Qiao, S., Wang, Z., Yuan, L., Hand gesture recognition using deep feature fusion network based on wearable sensors (2021) IEEE Sensors J., 21 (1), pp. 539-547. , Jan; Kudrinko, K., Flavin, E., Zhu, X., Li, Q., Wearable sensor-based sign language recognition: A comprehensive review (2021) IEEE Rev. Biomed. Eng., 14, pp. 82-97; Pan, T.-Y., Tsai, W.-L., Chang, C.-Y., Yeh, C.-W., Hu, M.-C., A hierarchical hand gesture recognition framework for sports referee trainingbased EMG and accelerometer sensors (2020) IEEE Trans. Cybern., , early access, Aug. 10; Yao, J., Chen, H., Xu, Z., Huang, J., Li, J., Jia, J., Wu, H., Development of a wearable electrical impedance tomographic sensor for gesture recognition with machine learning (2020) IEEE J. Biomed. Health Informat., 24 (6), pp. 1550-1556. , Jun; Wong, W.K., Juwono, F.H., Khoo, B.T.T., Multi-features capacitive hand gesture recognition sensor: A machine learning approach (2021) IEEE Sensors J., 21 (6), pp. 8441-8450. , Mar; Ren, Y., Lu, J., Beletchi, A., Huang, Y., Karmanov, I., Fontijne, D., Patel, C., Xu, H., Hand gesture recognition using 802.11ad mmWave sensor in the mobile device (2021) Proc. IEEE Wireless Commun. Netw. Conf. Workshops (WCNCW), pp. 1-6. , Mar; Achenbach, P., Müller, P.N., Wach, T.A., Tregel, T., Göbel, S., Rock beats scissor: SVM based gesture recognition with data gloves (2021) Proc. IEEE Int. Conf. Pervasive Comput. Commun. Workshops Affiliated Events (PerComWorkshops), pp. 617-622. , https://ieeexplore.ieee.org/document/9430962, Mar; Pezzuoli, F., Corona, D., Corradini, M.L., Dynamic gestures recognition through a low-cost data glove (2020) Proc. IEEE Int. Conf. Hum.-Mach. Syst. (ICHMS), pp. 1-3. , Sep; https://github.com/balezz/Punch_DL, Deep Learning Models for Punch Classification in Karate. Accessed: Jun. 12, 2021; Wang, Z., Yan, W., Oates, T., (2016) Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline, , http://arxiv.org/abs/1611.06455","Bocharov, M.; Department of Data Analysis and Machine Learning, Russian Federation; email: mibocharov@fa.ru",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85117185058
"Lee J., Jang J., Lee J., Chun D., Kim H.","57254099900;57254334100;57254214500;57210795044;34770344200;","CNN-Based Mask-Pose Fusion for Detecting Specific Persons on Heterogeneous Embedded Systems",2021,"IEEE Access","9",,"9525080","120358","120366",,3,"10.1109/ACCESS.2021.3108776","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114665503&doi=10.1109%2fACCESS.2021.3108776&partnerID=40&md5=701fbf1d9ea07672cbd6d91ade3a0abe","Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, 01811, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, 08826, South Korea","Lee, J., Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, 01811, South Korea; Jang, J., Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, 01811, South Korea; Lee, J., Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, 01811, South Korea; Chun, D., Department of Electrical and Computer Engineering, Seoul National University, Seoul, 08826, South Korea; Kim, H., Department of Electrical and Information Engineering, Research Center for Electrical and Information Technology, Seoul National University of Science and Technology, Seoul, 01811, South Korea","In recent times, numerous convolutional neural network (CNN) based detection models have been proposed and have shown excellent performance. However, because these models are generally developed to detect objects in class units (e.g., person, car), additional training processes with numerous datasets are required to find a specific object. This paper proposes a model that accurately detects specific persons by using top clothing color information without any additional training processes. The proposed method combines CNN-based instance segmentation and pose estimation, utilizing all the advantages of each technique. To avoid redundant computations, these two schemes are implemented as a filtering-based sequential operation structure. As a result, the proposed method has a 92.57% of accuracy in detecting a specific person with only a slight processing speed decrease. Furthermore, in this paper, the proposed model is efficiently ported on the heterogeneous embedded platform (i.e., NVIDIA Jetson AGX Xavier) with a parallel processing technique to maximize the hardware utilization. © 2013 IEEE.","AlphaPose; deep learning; embedded systems; instance segmentation; NVIDIA Jetson AGX Xavier; object detection; pose estimation; YOLACT","Convolutional neural networks; Embedded systems; Gesture recognition; Detection models; Embedded platforms; Hardware utilization; Heterogeneous embedded system; Parallel processing; Redundant computation; Sequential operations; Training process; Object detection",,,,,"Seoul National University of Science and Technology","This work was supported by the Research Program through Seoul National University of Science and Technology (SeoulTech).",,,,,,,,,,"Zhang, J., Xie, Y., Wu, Q., Xia, Y., Medical image classification using synergic deep learning (2019) Med. Image Anal., 54, pp. 10-19. , May; Mikolajczyk, A., Grochowski, M., Data augmentation for improving deep learning in image classification problem (2018) Proc. Int. Interdiscipl. PhD Workshop (IIPhDW), pp. 117-122. , Swinoujfficie, Poland, May; Perez, L., Wang, J., (2017) The Effectiveness of Data Augmentation in Image Classification Using Deep Learning, , http://arxiv.org/abs/1712.04621; Chan, T.-H., Jia, K., Gao, S., Lu, J., Zeng, Z., Ma, Y., PCANet: A simple deep learning baseline for image classification? (2015) IEEE Trans. Image Process, 24 (12), pp. 5017-5032. , Dec; Redmon, J., Farhadi, A., (2018) YOLOv3: An Incremental Improvement, , http://arxiv.org/abs/1804.02767; Choi, J., Chun, D., Kim, H., Lee, H.-J., Gaussian YOLOv3: An accurate and fast object detector using localization uncertainty for autonomous driving (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 502-511. , Oct; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., Berg, A., SSD: Single shot multibox detector (2016) Proc. Eur. Conf. Com-put. Vis. (ECCV), pp. 21-37; He, K., Zhang, X., Ren, S., Sun, J., Spatial pyramid pooling in deep convolutional networks for visual recognition (2014) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 346-361; Bolya, D., Zhou, C., Xiao, F., Lee, Y.J., YOLACT: Real-time instance segmentation (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 9157-9166. , Oct; Bolya, D., Zhou, C., Xiao, F., Lee, Y.J., YOLACTCC: Better real-time instance segmentation (2020) IEEE Trans. Pattern Anal. Mach. Intell., , early access, Aug. 5; He, K., Gkioxari, G., Dollar, P., Girshick, R., Mask R-CNN (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 2961-2969. , Oct; Cheih, L., Zhu, Y., Papandreou, G., Schroff, F., Adam, H., Encoderdecoder with atrous separable convolution for semantic image segmentation (2018) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 801-818; Andriluka, M., Pishchulin, L., Gehler, P., Schiele, B., 2D human pose estimation: New benchmark and state of the art analysis (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 3686-3693. , Jun; Belagiannis, V., Zisserman, A., Recurrent human pose estimation (2017) Proc. 12th IEEE Int. Conf. Autom. Face Gesture Recognit. (FG), pp. 468-475. , May; Chen, Y., Wang, Z., Peng, Y., Zhang, Z., Yu, G., Sun, J., Cascaded pyramid network for multi-person pose estimation (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 7103-7112. , Jun; Fan, X., Zheng, K., Lin, Y., Wang, S., Combining local appearance and holistic view: Dual-source deep neural networks for human pose estimation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1347-1355. , Jun; Abraham, N.S., Rajan, R.A., George, R.E., Gopinath, S., Jeyakrishnan, V., Finding missing child in shopping mall using deep learning (2021) Advances in Smart System Technologies, 1163, pp. 477-482. , Singapore: Springer; Rao, Y., Lu, J., Zhou, J., Learning discriminative aggregation network for video-based face recognition and person re-identification (2019) Int. J. Com-put. Vis., 127 (6-7), pp. 701-718. , Jun; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional networks for biomedical image segmentation (2015) Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., pp. 234-241; Fang, H.-S., Xie, S., Tai, Y.-W., Lu, C., RMPE: Regional multi-person pose estimation (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 2334-2343. , Oct; Chandran, P.S., Byju, N.B., Deepak, R.U., Nishakumari, K.N., Devanand, P., Sasi, P.M., Missing child identification system using deep learning and multiclass SVM (2018) Proc. IEEE Recent Adv. Intell. Comput. Syst. (RAICS), pp. 113-116. , Dec; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards realtime object detection with region proposal networks (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (6), pp. 1137-1149. , Jun; Il Lee, S., Kim, H., Instant and accurate instance segmentation equipped with path aggregation and attention gate (2020) Proc. Int. SoC Design Conf. (ISOCC), pp. 320-321. , Oct; Eden, A., Christoudias, C.M., Darrell, T., Finding lost children (2011) Proc. IEEE Workshop Person-Oriented Vis., pp. 7-12. , Jan; Chen, T., Ding, S., Xie, J., Yuan, Y., Chen, W., Yang, Y., Ren, Z., Wang, Z., ABD-Net: Attentive but diverse person re-identification (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 8350-8360. , Oct; West, M.G., (2018) Pooling Resources to Fight Child Abuse and Abduc-tion, , https://on.wsj.com/32R9Vgz; (2018) Missing Person and Unidentified Person Statistics, , https://www.fbi.gov/-le-repository/2018-ncicmissing-personandunidentified-person-statistics.pdf/view, NCIC; Kim, H., Rhee, C.E., Lee, H.J., A low-power video recording system with multiple operation modes for H. 264 and light-weight compression (2016) IEEE Trans. Multimedia, 18 (4), pp. 603-613. , Apr; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L., Microsoft COCO: Common objects in context (2014) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 740-755; Choi, J., Chun, D., Lee, H.-J., Kim, H., Uncertainty-based object detector for autonomous driving embedded platforms (2020) Proc. 2nd IEEE Int. Conf. Artif. Intell. Circuits Syst. (AICAS), pp. 16-20. , Aug","Kim, H.; Department of Electrical and Information Engineering, South Korea; email: hyunkim@seoultech.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85114665503
"Jayabalan E., Pugazendi R.","24450829100;24451103200;","Deep learning model-based detection of jamming attacks in low-power and lossy wireless networks",2021,"Soft Computing",,,,"","",,,"10.1007/s00500-021-06111-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113185465&doi=10.1007%2fs00500-021-06111-7&partnerID=40&md5=b17f19273e38426084166c74f155eeaa","Department of Computer Science, Government Arts College (A), Salem, Tamil Nadu  636 007, India","Jayabalan, E., Department of Computer Science, Government Arts College (A), Salem, Tamil Nadu  636 007, India; Pugazendi, R., Department of Computer Science, Government Arts College (A), Salem, Tamil Nadu  636 007, India","Communication in the wireless sensor networks could be disturbed by the jammer and this jamming attacks could be identified as a distinctive type of Denial of Service attacks. This might result in the degradation of the network which could be recognized. Due to the jamming signals, the packet transmission might not be proper. These kinds of attacks are destructive in low power and lossy wireless network due to the attributes such as disruption in communication and rapid trench in the batteries. To detect the attack and to perform the secure data transmission, the illegitimate nodes have to be eradicated. Machine learning and deep learning methods are used for network analysis of intrusion detection and security. Hence, the deep learning model is proposed to identify the attacks which result in secured data transmission. Also, the logistic regression is applied to classify the behaviour of the node so that the deviation could be determined. Deep learning is applied so it can adaptively learn the attacks and classify with higher accuracy. It is efficient as it is adaptive in learning and has improved precision. The performance of the model could be proved with simulations by varying the nodes. The secured data transmission could be proved by analysing several metrics such as packet drop rate, normalized routing overhead, and jitter. The packet drop is decreased to 50%, jitter is decreased to 6% and throughput shows a significant increase by 6% when compared with the Dodge-Jam, a lightweight Mitigating Stealthy Jamming Attacks (MJSA) technique. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Deep learning; Detection; Jamming attacks; Logistics regression; Security-data transmission; Wireless sensor networks","Data transfer; Denial-of-service attack; Drops; Intrusion detection; Jamming; Jitter; Learning systems; Logistic regression; Low power electronics; Network security; Packet loss; Sensor nodes; Jamming attacks; Jamming signals; Learning methods; Learning models; Normalized routing overheads; Packet drop rates; Packet drops; Packet transmissions; Deep learning",,,,,,,,,,,,,,,,"Adam, E.E.B., Deep learning based NLP techniques in text to speech synthesis for communication recognition (2020) J Soft Comput Paradigm (JSCP), 2 (4), pp. 209-215; Ashraf, F., Hu, Y.C., Kravets, R.H., Bankrupting the jammer in WSN (2012) Proceedings of the IEEE MASS; Buczak, A.L., Guven, E., A survey of data mining and machine learning methods for cybersecurity intrusion detection (2016) IEEE Commun Surv Tutor, 18 (2); Cagalj, M., Capkun, S., Hubaux, J.-P., Wormhole-based antijamming techniques in sensor networks (2007) IEEE Trans Mob Comput, 6 (1), pp. 100-114; Chiang, S.S., Huang, C.-H., Chang, K.-C., A minimum hop routing protocol for home security systems using wireless sensor networks (2007) Ieeetransconsum Electron, 53 (4); Dâ A Zoro, S., Ekici, E., Palazzo, S., Optimal power allocation and scheduling under jamming attacks (2017) IEEE/ACM Trans Netw, 25 (3), pp. 1310-1323; Dhaya, R., Flawless identification of fusarium oxysporum in tomato plant leaves by machine learning algorithm (2020) J Innov Image Process (JIIP), 2 (4), pp. 194-201; Duraipandian, M., Performance evaluation of routing algorithm for Manet based on the machine learning techniques (2019) J Trends Comput Sci Smart Technol (TCSST), 1 (1), pp. 25-38; Grover, K., Lim, A., Yangnt, Q., Jamming and anti-jamming techniques in wireless networks: A survey (2014) Int J Ad Hoc Ubiquitous Comput, 17 (4); Heo, J., Kim, J.-J., Mitigating stealthy jamming attacks in low-power and lossy wireless networks (2018) J Commun Netw, 20 (2), pp. 219-230; Huang, H., Xiao, S., Meng, X., Xiong, Y., A remote home security system based on wireless sensor network and GSM technology (2010) Proceedings of the NSWCTC; Huang, J.F., Chang, G.-Y., Huang, J.-X., Anti-jamming rendezvous scheme for cognitive radio networks (2017) IEEE Trans Mob Comput, 16 (3), pp. 648-661; Hussain, A., Saqib, N.A., Qamar, U., Zia, M., Mahmood, H., Protocol aware radio frequency jamming in Wi-Fi and commercial wireless networks (2014) J Commun Netw, 16 (4), pp. 397-406; Li, M., Koutsopoulos, I., Poovendran, R., Optimal jamming attack strategies and network defence policies in wireless sensor networks (2010) IEEE Trans Mob Comput, 9 (8), pp. 1119-1133; Lu, Z., Wang, W., Wang, C., Hiding traffic with camouflage: Minimizingmessage delay in the smart grid under jamming (2012) Proceedings of the IEEE INFOCOM; Mpitziopoulos, A., Gavalas, D., Konstantopoulos, C., Pantziou, G., A survey on jamming attacks and countermeasures in WSNs (2009) IEEE Commun Surv Tutor, 11 (4), pp. 42-56; Murugesan, S., Senthil Kumar, T., Priyanka, U.S., Abinaya, K., Towards an approach for improved security in wireless networks (2013) Int J Comput Appl, 1, pp. 9-13; Noubir, G., Lin, G., Low-power DoS attacks in data wireless LANs and countermeasures (2003) Proceedings of the Mobihoc, pp. 29-30; Paek, J., Fast and adaptive mesh access control in low-power and lossy networks (2015) IEEE Internet Things J, 2 (5), pp. 435-444; Park, M.H., Challenge-response based ACK message authentication (2012) Electron Lett, 48 (16), pp. 1021-1023; Ranganathan, G., A study to find facts behind preprocessing on deep learning algorithms (2021) J Innov Image Process (JIIP), 3 (1), pp. 66-74; Rossi, D., Omana, M., Giaffreda, D., Metra, C., Secure communication protocol for wireless sensor networks (2010) Proc. EWDTS, pp. 17-20; Rughiniş, R., Gheorghe, L., Storm control mechanism in wireless sensor networks (2010) Proceedings of the 9Th IEEE Roedunet International Conference, pp. 430-435; Shakya, S., Lalitpur, N.P., Smys, S., Anomalies detection in fog computing architectures using deep learning (2020) J Trends Comput Sci Smart Technol, (1), pp. 46-55; Sharma, R., Sungheetha, A., An efficient dimension reduction based fusion of CNN and SVM model for detection of abnormal incident in video surveillance (2021) J Soft Comput Paradigm (JSCP), 3 (2), pp. 55-69; Smys, S., Jennifer, S.R., Analysis of deep learning techniques for early detection of depression on social media network-a comparative study (2021) J Trends Comput Sci Smart Technol (TCSST), 3 (1), pp. 24-39; Wood, A.D., Stankovic, J.A., Zhou, G., DEEJAM: Defeating energy-efficient jamming in IEEE 802.15. 4-based wireless networks (2007) Proceedings of the IEEE SECON; Xin, Y., Machine learning and deep learning methods for cybersecurity (2018) IEEE Access, 16, pp. 35365-35381; Xu, W., Trappe, W., Zhang, Y., Wood, T., The feasibility of launching and detecting jamming attacks in wireless networks (2005) Proceedings of the 6Th ACM International Symposium on Mobile Ad Hoc Networking and Computing, , ACM; Xu, W., Trappe, W., Zhang, Y., Wood, T., The feasibility of launching and detecting jamming attacks in wireless networks (2007) Proceedings of the ACM Mobihoc; Xu, K., Wang, Q., Ren, K., Joint UFH and power control for effective wireless anti-jamming communication (2012) Proceedings of the IEEE INFOCOM, pp. 738-746; Zhang, Z., Wu, J., Deng, J., Qiu, M., Jamming ack attack to wireless networks and a mitigation approach (2009) Proceeding of IEEE Global Telecommunications Conference; Zhang, C., Patras, P., Haddadi, H., Deep learning in mobile and wireless networking: A survey (2019) IEEE Commun Surv Tutor","Jayabalan, E.; Department of Computer Science, India; email: jayabalane032@gmail.com",,,"Springer Science and Business Media Deutschland GmbH",,,,,14327643,,,,"English","Soft Comput.",Article,"Article in Press","",Scopus,2-s2.0-85113185465
"Belabed T., Coutinho M.G.F., Fernandes M.A.C., Sakuyama C.V., Souani C.","57202465438;57208260908;7202947679;6602815648;6506039838;","User Driven FPGA-Based Design Automated Framework of Deep Neural Networks for Low-Power Low-Cost Edge Computing",2021,"IEEE Access","9",,"9458248","89162","89180",,2,"10.1109/ACCESS.2021.3090196","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112731154&doi=10.1109%2fACCESS.2021.3090196&partnerID=40&md5=8874efe5e7cf5f28f635a2dca8f5fcdb","Université de Mons, Faculté Polytechnique, SEMi, Mons, 7000, Belgium; Université de Sousse, Ecole Nationale d'Ingénieurs de Sousse, Sousse, 4000, Tunisia; Université de Monastir, Faculté des Sciences, Laboratoire de Microélectronique et Instrumentation, Monastir, 5019, Tunisia; Department of Computer and Automation Engineering, Federal University of Rio Grande Do Norte, Natal, 59078-970, Brazil; Université de Sousse, Institut Supérieur des Sciences Appliquées et de Technologie de Sousse, Sousse, 4003, Tunisia","Belabed, T., Université de Mons, Faculté Polytechnique, SEMi, Mons, 7000, Belgium, Université de Sousse, Ecole Nationale d'Ingénieurs de Sousse, Sousse, 4000, Tunisia, Université de Monastir, Faculté des Sciences, Laboratoire de Microélectronique et Instrumentation, Monastir, 5019, Tunisia; Coutinho, M.G.F., Department of Computer and Automation Engineering, Federal University of Rio Grande Do Norte, Natal, 59078-970, Brazil; Fernandes, M.A.C., Department of Computer and Automation Engineering, Federal University of Rio Grande Do Norte, Natal, 59078-970, Brazil; Sakuyama, C.V., Université de Mons, Faculté Polytechnique, SEMi, Mons, 7000, Belgium; Souani, C., Université de Sousse, Institut Supérieur des Sciences Appliquées et de Technologie de Sousse, Sousse, 4003, Tunisia","Deep Learning techniques have been successfully applied to solve many Artificial Intelligence (AI) applications problems. However, owing to topologies with many hidden layers, Deep Neural Networks (DNNs) have high computational complexity, which makes their deployment difficult in contexts highly constrained by requirements such as performance, real-time processing, or energy efficiency. Numerous hardware/software optimization techniques using GPUs, ASICs, and reconfigurable computing (i.e, FPGAs), have been proposed in the literature. With FPGAs, very specialized architectures have been developed to provide an optimal balance between high-speed and low power. However, when targeting edge computing, user requirements and hardware constraints must be efficiently met. Therefore, in this work, we only focus on reconfigurable embedded systems based on the Xilinx ZYNQ SoC and popular DNNs that can be implemented on Embedded Edge improving performance per watt while maintaining accuracy. In this context, we propose an automated framework for the implementation of hardware-accelerated DNN architectures. This framework provides an end-to-end solution that facilitates the efficient deployment of topologies on FPGAs by combining custom hardware scalability with optimization strategies. Cutting-edge comparisons and experimental results demonstrate that the architectures developed by our framework offer the best compromise between performance, energy consumption, and system costs. For instance, the low power (0.266W) DNN topologies generated for the MNIST database achieved a high throughput of 3,626 FPS. © 2013 IEEE.","Deep learning; edge computing; electronic design automation; FPGA; low power systems","Computer hardware; Costs; Deep learning; Deep neural networks; Edge computing; Embedded systems; Energy efficiency; Energy utilization; Field programmable gate arrays (FPGA); Low power electronics; Multilayer neural networks; Network architecture; Program processors; Reconfigurable architectures; System-on-chip; Topology; User centered design; End-to-end solutions; Hardware constraints; Hardware-accelerated; Improving performance; Optimization strategy; Optimization techniques; Reconfigurable computing; Reconfigurable embedded systems; Integrated circuit design",,,,,,,,,,,,,,,,"Li, B.-H., Hou, B.-C., Yu, W.-T., Lu, X.-B., Yang, C.-W., Applications of artificial intelligence in intelligent manufacturing: A review (2017) Frontiers Inf. Technol. Electron. Eng., 18 (1), pp. 86-96. , http://link.springer.com/10.1631/FITEE.1601885; Hamet, P., Tremblay, J., Artificial intelligence in medicine (2017) Metabolism, Clin. Experim., 69, pp. S36-S40. , Apr; Pham, Q.-V., Nguyen, D.C., Huynh-The, T., Hwang, W.-J., Pathirana, P.N., Artificial intelligence (AI) and big data for coronavirus (COVID-19) pandemic: A survey on the state-of-the-arts (2020) IEEE Access, 8, pp. 130820-130839. , https://ieeexplore.ieee.org/document/9141265/; Zeadally, S., Adi, E., Baig, Z., Khan, I.A., Harnessing artifi-cial intelligence capabilities to improve cybersecurity (2020) IEEE Access, 8, pp. 23817-23837. , https://ieeexplore.ieee.org/document/8963730/; Ma, Y., Wang, Z., Yang, H., Yang, L., Artificial intelligence applications in the development of autonomous vehicles: A survey (2020) IEEE/CAA J. Automatica Sinica, 7 (2), pp. 315-329. , Mar; Atkinson, K., Bench-Capon, T., Bollegala, D., Explanation in AI and law: Past, present and future (2020) Artif. Intell., 289. , https://linkinghub.elsevier.com/retrieve/pii/S0004370220301375, Dec; Dwivedi, Y.K., Hughes, L., Ismagilova, E., Aarts, G., Coombs, C., Crick, T., Duan, Y., Galanos, V., Artificial intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy (2019) Int. J. Inf. Manage., 57. , https://linkinghub.elsevier.com/retrieve/pii/S026840121930917X, Aug; Krogh, A., What are artificial neural networks? (2008) Nature Biotech-nol., 26 (2), pp. 195-197. , http://www.nature.com/articles/nbt1386; Livingstone, D.J., (2009) Artificial Neural Networks (Methods in Molecular Biology), 458. , http://link.springer.com/10.1007/978-1-60327-101-1, T. D. J. Livingstone, Ed. Totowa, NJ, USA: Humana Press; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Comput., 18 (7), pp. 1527-1554. , https://www.mitpressjournals.org/doi/abs/10.1162/neco.2006.18.7.1527, Jul; Kim, P., (2017) MATLAB Deep Learning, , Berkeley, CA, USA: Apress; El Naqa, I., Murphy, M.J., (2015) What is Machine Learning? Cham, Switzerland: Springer; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , http://www.deeplearningbook.org, Cambridge, MA, USA: MIT Press; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Netw., 61, pp. 85-117. , Jan; Mamoshina, P., Vieira, A., Putin, E., Zhavoronkov, A., Applications of deep learning in biomedicine (2016) Mol. Pharmaceutics, 13 (5), pp. 1445-1454. , May; Baldi, P., Autoencoders, unsupervised learning, and deep architectures (2012) Proc. ICML Workshop Unsupervised Transf. Learn., Bellevue, WA, USA, , http://proceedings.mlr.press/v27/baldi12a.html, Jun; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444. , http://www.nature.com/articles/nmeth.3707andhttp://www.nature.com/articles/nature14539, May; Voulodimos, A., Doulamis, N., Doulamis, A., Protopapadakis, E., Deep learning for computer vision: A brief review (2018) Comput. Intell. Neurosci., 2018, pp. 1-13. , Feb; Purwins, H., Li, B., Virtanen, T., Schlüter, J., Chang, S.-Y., Sainath, T., Deep learning for audio signal processing (2019) IEEE J. Sel. Topics Signal Process., 13 (2), pp. 206-219. , May; Young, T., Hazarika, D., Poria, S., Cambria, E., Recent trends in deep learning based natural language processing (2018) IEEE Comput. Intell. Mag., 13 (3), pp. 55-75. , Aug; Pierson, H.A., Gashler, M.S., Deep learning in robotics: A review of recent research (2017) Adv. Robot., 31 (16), pp. 821-835. , https://www.tandfonline.com/doi/full/10.1080/01691864.2017.1365009, Aug; Li, Y., Huang, C., Ding, L., Li, Z., Pan, Y., Gao, X., Deep learning in bioinformatics: Introduction, application, and perspective in the big data era (2019) Methods, 166, pp. 4-21. , Aug; Ben Fredj, H., Bouguezzi, S., Souani, C., Face recognition in unconstrained environment with CNN (2021) Vis. Comput., 37 (2), pp. 217-226. , Feb; Faiedh, H., Hamdi, S., Bouguezzi, S., Farhat, W., Souani, C., Architectural exploration of multilayer perceptron models for on-chip and real-time road sign classification (2018) Proc. Inst. Mech. Eng., I, J. Syst. Control Eng., 232 (6), pp. 772-783. , Jul; Huang, J., Chai, J., Cho, S., Deep learning in finance and banking: A literature review and classification (2020) Frontiers Bus. Res. China, 14 (1), p. 13. , Dec; Vinayakumar, R., Alazab, M., Soman, K.P., Poornachandran, P., Al-Nemrat, A., Venkatraman, S., Deep learning approach for intelligent intrusion detection system (2019) IEEE Access, 7, pp. 41525-41550. , https://ieeexplore.ieee.org/document/8681044/; Xin, Y., Kong, L., Liu, Z., Chen, Y., Li, Y., Zhu, H., Gao, M., Wang, C., Machine learning and deep learning methods for cybersecurity (2018) IEEE Access, 6, pp. 35365-35381. , https://ieeexplore.ieee.org/document/8359287/; Maria, J., Amaro, J., Falcao, G., Alexandre, L.A., Stacked autoencoders using low-power accelerated architectures for object recognition in autonomous systems (2016) Neural Process. Lett., 43 (2), pp. 445-458. , http://link.springer.com/10.1007/s11063-015-9430-9, Apr; Coutinho, M.G.F., Torquato, M.F., Fernandes, M.A.C., Deep neural network hardware implementation based on stacked sparse autoencoder (2019) IEEE Access, 7, pp. 40674-40694. , https://ieeexplore.ieee.org/document/8678408/; Sheet, D., Karri, S.P.K., Katouzian, A., Navab, N., Ray, A.K., Chatterjee, J., Deep learning of tissue specific speckle representations in optical coherence tomography and deeper exploration for in situ histology (2015) Proc. IEEE 12th Int. Symp. Biomed. Imag. (ISBI), pp. 777-780. , http://ieeexplore.ieee.org/document/7163987/, Apr; Xiao, Y., Wu, J., Lin, Z., Zhao, X., A semi-supervised deep learning method based on stacked sparse auto-encoder for cancer prediction using RNA-seq data (2018) Comput. Methods Programs Biomed., 166, pp. 99-105. , https://linkinghub.elsevier.com/retrieve/pii/S0169260718304553, Nov; Nurvitadhi, E., Sheffield, D., Sim, J., Mishra, A., Venkatesh, G., Marr, D., Accelerating binarized neural networks: Comparison of FPGA, CPU, GPU, and ASIC (2016) Proc. Int. Conf. Field-Programmable Technol. (FPT), pp. 77-84. , http://ieeexplore.ieee.org/document/7929192/, Dec; Nurvitadhi, E., Sim, J., Sheffield, D., Mishra, A., Krishnan, S., Marr, D., Accelerating recurrent neural networks in analytics servers: Comparison of FPGA, CPU, GPU, and ASIC (2016) Proc. 26th Int. Conf. Field Program. Log. Appl. (FPL), pp. 1-4. , http://ieeexplore.ieee.org/document/7577314/, Aug; Wang, C., Gong, L., Yu, Q., Li, X., Xie, Y., Zhou, X., DLAU: A scalable deep learning accelerator unit on FPGA (2016) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 36 (3), pp. 513-517. , http://ieeexplore.ieee.org/document/7505926/, Jul; Lahti, S., Sjovall, P., Vanne, J., Hamalainen, T.D., Are we there yet? A study on the state of high-level synthesis (2019) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 38 (5), pp. 898-911. , https://ieeexplore.ieee.org/document/8356004/, May; (2021), https://software.intel.com/content/www/us/en/develop/tools/openvinotoolkit.html, Intel. OpenVINO, Accessed: Jun. 10; (2019) Amazon EC2 F1 Instances, , https://aws.amazon.com/ec2/instance-types/f1/, AWS; (2021) Lattice SensAI Stack, Accelerate Integration of Flexible, Low Power Inferencing at the Edge, , https://www.latticesemi.com/Solutions/Solutions/SolutionsDetails02/sensAI, L. Semiconductor, Accessed: Jun. 10; (2021), https://www.xilinx.com/products/som/kria.html, Xilinx. Kria K26, Accessed: Jun. 10; Jayakodi, N.K., Belakaria, S., Deshwal, A., Doppa, J.R., Design and optimization of energy-accuracy tradeoff networks for mobile platforms via pretrained deep models (2020) ACM Trans. Embedded Com-put. Syst., 19 (1), pp. 1-24. , https://dl.acm.org/doi/10.1145/3366636, Feb; Jiang, W., Zhang, X., Sha, E.H.-M., Yang, L., Zhuge, Q., Shi, Y., Hu, J., Accuracy vs. efficiency: Achieving both through FPGA-implementation aware neural architecture search (2019) Proc. 56th Annu. Design Autom. Conf. New York, NY, USA: ACM, pp. 1-6. , https://dl.acm.org/, Jun; Farhat, W., Sghaier, S., Faiedh, H., Souani, C., Design of efficient embedded system for road sign recognition (2019) J. Ambient Intell. Humanized Comput., 10 (2), pp. 491-507. , Feb; Yvanoff-Frenchin, C., Ramos, V., Belabed, T., Valderrama, C., Edge computing robot interface for automatic elderly mental health care based on voice (2020) Electronics, 9 (3), p. 419. , Feb; Nurvitadhi, E., Venkatesh, G., Sim, J., Marr, D., Huang, R., Hock, J.O.G., Liew, Y.T., Boudoukh, G., Can FPGAs beat GPUs in accelerating next-generation deep neural networks? (2017) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays. New York, NY, USA: ACM Press, pp. 5-14. , http://dl.acm.org/citation.cfm?doid=3020078.3021740, Feb; Zhang, C., Sun, G., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: Toward uniformed representation and acceleration for deep convolutional neural networks (2019) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 38 (11), pp. 2072-2085. , https://ieeexplore.ieee.org/document/8497058/, Nov; Venieris, S.I., Bouganis, C.-S., FpgaConvNet: A framework for mapping convolutional neural networks on FPGAs (2016) Proc. IEEE 24th Annu. Int. Symp. Field-Programmable Custom Comput. Mach. (FCCM), pp. 40-47. , May; Zhang, X., Wang, J., Zhu, C., Lin, Y., Xiong, J., Hwu, W.-M., Chen, D., DNNBuilder: An automated tool for building high-performance DNN hardware accelerators for FPGAs (2018) Proc. Int. Conf. Comput.-Aided Design. New York, NY, USA: ACM, pp. 1-8. , https://dl.acm.org/doi/10.1145/3240765.3240801, Nov; (2021) NVIDIA V100 TENSOR CORE GPU, , https://www.nvidia.com/en-us/data-center/v100/, Nvidia, Accessed: Jun. 10; Wang, Y., Xu, J., Han, Y., Li, H., Li, X., DeepBurning: Automatic generation of FPGA-based learning accelerators for the neural network family (2016) Proc. 53rd Annu. Design Autom. Conf. New York, NY, USA: ACM, pp. 1-6. , http://dl.acm.org/citation.cfm?doid=2897937.2898003,http://dl.acm.org/citation.cfm?doid=2897937.2898002, https://dl.acm.org/doi/10.1145/2897937.2898003, Jun; (2016) GPU Vs FPGA Performance Comparison, , http://www.bertendsp.com; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., An automatic RTL compiler for high-throughput FPGA implementation of diverse deep convolutional neural networks (2017) Proc. 27th Int. Conf. Field Pro-gram. Log. Appl. (FPL), pp. 1-8. , http://ieeexplore.ieee.org/document/8056824/, Sep; Blaiech, A.G., Ben Khalifa, K., Valderrama, C., Fernandes, M.A.C., Bedoui, M.H., A survey and taxonomy of FPGA-based deep learning accelerators (2019) J. Syst. Archit., 98, pp. 331-345. , Sep; Guan, Y., Liang, H., Xu, N., Wang, W., Shi, S., Chen, X., Sun, G., Cong, J., FP-DNN: An automated framework for mapping deep neural networks onto FPGAs with RTL-HLS hybrid templates (2017) Proc. IEEE 25th Annu. Int. Symp. Field-Programmable Cus-tom Comput. Mach. (FCCM), pp. 152-159. , http://vast.cs.ucla.edu/sites/default/files/publications/fccm2017.pdfandhttp://ieeexplore.ieee.org/document/7966671/, Apr; Rivera-Acosta, M., Ortega-Cisneros, S., Rivera, J., Automatic tool for fast generation of custom convolutional neural networks accelerators for FPGA (2019) Electronics, 8 (6), p. 641. , https://www.mdpi.com/2079-9292/8/6/641, Jun; Belabed, T., Coutinho, M.G.F., Fernandes, M.A.C., Carlos, V., Souani, C., Low cost and low power stacked sparse autoencoder hardware acceleration for deep learning edge computing applications (2020) Proc. 5th Int. Conf. Adv. Technol. Signal Image Process. (ATSIP). Sousse, Tunisia: IEEE, pp. 1-6. , Sep; Kung, H.T., Leiserson, C.E., Systolic arrays for (VLSI) (1978) Carnegie-Mellon Univ., Pittsburgh, PA, USA, Tech. Rep., p. 29; Waris, H., Wang, C., Liu, W., Lombardi, F., AxSA: On the design of high-performance and power-efficient approximate systolic arrays for matrix multiplication (2021) J. Signal Process. Syst., 93 (6), pp. 605-615. , Jun; Gupta, S., Agrawal, A., Gopalakrishnan, K., Narayanan, P., Deep learning with limited numerical precision (2015) IEEE Trans. Neural Netw., 1 (1), pp. 71-80. , Feb; Wei, X., Yu, C.H., Zhang, P., Chen, Y., Wang, Y., Hu, H., Liang, Y., Cong, J., Automated systolic array architecture synthesis for high throughput CNN inference on FPGAs (2017) Proc. Design Autom. Conf., 12828. , Piscataway, NJ, USA: IEEE, Jun; Ye, H., Zhang, X., Huang, Z., Chen, G., Chen, D., Hybrid-DNN: A framework for high-performance hybrid DNN accelerator design and implementation (2020) Proc. 57th ACM/IEEE Design Autom. Conf. (DAC), pp. 1-6. , https://ieeexplore.ieee.org/document/9218684/, Jul; Mousouliotis, P.G., Petrou, L.P., CNN-grinder: From algorithmic to high-level synthesis descriptions of CNNs for low-end-low-cost FPGA SoCs (2020) Microprocessors Microsyst., 73. , Mar; Mazouz, A., Bridges, C.P., Automated offline design-space exploration and online design reconfiguration for CNNs (2020) Proc. IEEE Conf. Evolv-ing Adapt. Intell. Syst. (EAIS), pp. 1-9. , https://ieeexplore.ieee.org/document/9122697/, May; UG1037, AXI reference guide, V4.0 (2017) Tech. Rep., Xilinx, San Jose, CA, USA, , Xilinx; Limited, A., Introduction to AMBA AXI4 A. Limited, London, U.K., Tech. Rep, , https://developer.arm.com/architectures/learn-the-architecture/introduction-to-ambaaxi/axi-protocol-overview, 2020; Lecun, Y., Cortes, C., Burges, C.J., (2021) THE MNIST DATABASE of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/, Accessed: Jun. 10; (2017) User Guide (V2016.4), , SDSoC Environ, Xilinx, San Jose, CA, USA; (2021) Digikey, , https://www.digikey.com/","Belabed, T.; Université de Mons, Belgium; email: belabed.tarek@gmail.com",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85112731154
"Liu B., Chen X., Han Y., Wu J., Chang L., Liu P., Xu H.","55791167000;57247005300;8577299100;55554077100;57169276800;55574230542;57205693805;","Search-free Inference Acceleration for Sparse Convolutional Neural Networks",2021,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",,,,"","",,,"10.1109/TCAD.2021.3102191","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112595410&doi=10.1109%2fTCAD.2021.3102191&partnerID=40&md5=87c5d5da5b831b859b227ba776179bb2","School of Computer Science and Technology, Guangdong University of Technology, Guangzhou 510006, China, and also with the Center for Intelligent Computing Systems, State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing, China.; Center for Intelligent Computing Systems, State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing, China. (e-mail: chenxiaoming@ict.ac.cn); Center for Intelligent Computing Systems, State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing, China.; School of Computer Science and Technology, Guangdong University of Technology, Guangzhou 510006, China.; Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin 541004, China.","Liu, B., School of Computer Science and Technology, Guangdong University of Technology, Guangzhou 510006, China, and also with the Center for Intelligent Computing Systems, State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing, China.; Chen, X., Center for Intelligent Computing Systems, State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing, China. (e-mail: chenxiaoming@ict.ac.cn); Han, Y., Center for Intelligent Computing Systems, State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing, China.; Wu, J., School of Computer Science and Technology, Guangdong University of Technology, Guangzhou 510006, China.; Chang, L., Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin 541004, China.; Liu, P., School of Computer Science and Technology, Guangdong University of Technology, Guangzhou 510006, China.; Xu, H., Center for Intelligent Computing Systems, State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing, China.","Sparse convolution neural networks (CNNs) are promising in reducing both memory usage and computational complexity while still preserving high inference accuracy. State-of-the-art sparse CNN accelerators can deliver high throughput by skipping zero weights and/or activations. To operate on only nonzero weights and activations, sparse accelerators typically search pairs of nonzero weights and activations for multiplication-accumulation (MAC) operations. However, the conventional search operation results in a severe limitation in the PE array scale because of the enormous demands of internal interconnection and memory bandwidth. In this paper, we first provide a design principle to free the search process of sparse CNN accelerations. Specifically, the indexes of the static compressed weights access the dynamic activations directly to avoid the search process for MAC operations. We then develop two search-free inference accelerators, called Swan and Swan-flexible, for sparse CNN accelerations. Swan supports search-free sparse convolution accelerations for interconnection and bandwidth saving. Compared with Swan, Swan-flexible not only has the search-free capability but also comprises a configurable architecture for optimum throughput. We formulate a mathematical optimization problem by combining the configurable characterization with the compressive dataflow to optimize the overall throughput. Evaluations based on a place-and-route process show that the proposed designs, in a compact factor of 4096 PEs, achieve 1.5&#x2013;2.7&#x00D7; higher speedup and 6.0&#x2013;13.6&#x00D7; better energy efficiency than representative accelerator baselines with the same PE array scale. IEEE","Bandwidth; Convolution; Integrated circuit interconnections; internal interconnection; memory bandwidth.; Neural networks; Optimization; Random access memory; Sparse accelerators; sparse convolution neural networks; Throughput","Acceleration; Bandwidth; Chemical activation; Convolution; Energy efficiency; Optimization; Bandwidth savings; Configurable architectures; Convolution neural network; Design Principles; Mathematical optimization problems; Memory bandwidths; Search operations; State of the art; Convolutional neural networks",,,,,,,,,,,,,,,,,,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Article in Press","",Scopus,2-s2.0-85112595410
"Huang K., Chen S., Li B., Claesen L., Yao H., Chen J., Jiang X., Liu Z., Xiong D.","57226644129;57215971760;57208222708;7004162996;57226636087;57221541727;57192647108;57226642475;57192640951;","Acceleration-aware Fine-grained Channel Pruning for Deep Neural Networks via Residual Gating",2021,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",,,,"","",,,"10.1109/TCAD.2021.3093835","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112222820&doi=10.1109%2fTCAD.2021.3093835&partnerID=40&md5=6784c14f54c034d19217a79b7936eda8","Institute of VLSI Design, Zhejiang University, Hangzhou, 310030, China.; Engineering Technology-Electronics-ICT Department, University of Hasselt, 3590 Diepenbeek, Belgium.; Digital Grid Research Institute, CSG, Guangzhou, 510670, China.; sec-chip, Hangzhou, 310030, China.","Huang, K., Institute of VLSI Design, Zhejiang University, Hangzhou, 310030, China.; Chen, S., Institute of VLSI Design, Zhejiang University, Hangzhou, 310030, China.; Li, B., Institute of VLSI Design, Zhejiang University, Hangzhou, 310030, China.; Claesen, L., Engineering Technology-Electronics-ICT Department, University of Hasselt, 3590 Diepenbeek, Belgium.; Yao, H., Digital Grid Research Institute, CSG, Guangzhou, 510670, China.; Chen, J., Digital Grid Research Institute, CSG, Guangzhou, 510670, China.; Jiang, X., Institute of VLSI Design, Zhejiang University, Hangzhou, 310030, China.; Liu, Z., sec-chip, Hangzhou, 310030, China.; Xiong, D., Institute of VLSI Design, Zhejiang University, Hangzhou, 310030, China.","Deep Neural Networks have achieved remarkable advancement in various intelligence tasks. However, the massive computation and storage consumption limit applications on resource-constrained devices. While channel pruning has been widely applied to compress models, it is challenging to reach very deep compressions for such a coarse-grained pruning structure without significant performance degradation. In this article, we propose an acceleration-aware fine-grained channel pruning (AFCP) framework for accelerating neural networks, which optimizes trainable gate parameters by estimating residual errors between pruned and original channels with hardware characteristics. Our fine-grained concept consists of both algorithm and structure levels. Different from existing methods that leverage a pre-defined pruning criterion, AFCP explicitly considers both zero-out and similar criteria for each channel and adaptively selects the suitable one via residual gate parameters. For structure level, AFCP adopts a fine-grained channel pruning strategy for residual neural networks and a decomposition-based structure, which further extends the pruning optimization space. Moreover, instead of using theoretical computation costs such as FLOPs, we propose the hardware predictor that bridges the gap between realistic acceleration and pruning procedure to guide the learning of pruning, which improves the efficiency of model pruning when deployed on accelerators. Extensive evaluation results demonstrate that AFCP outperforms state-of-the-art methods, and achieves a favorable balance between model performance and computation cost. IEEE","Biological neural networks; Computational modeling; Deep learning system; Logic gates; model compression and acceleration; neural networks.; Optimization; pruning; Residual neural networks; Task analysis; Tensors","Deep neural networks; Evaluation results; Hardware characteristics; Model performance; Original channels; Performance degradation; Pruning procedures; Resourceconstrained devices; State-of-the-art methods; Neural networks",,,,,,,,,,,,,,,,,,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Article in Press","All Open Access, Green",Scopus,2-s2.0-85112222820
"Lopez-Montiel M., Orozco-Rosas U., Sanchez-Adame M., Picos K., Ross O.H.M.","57212031562;56403343400;57208969049;55559043600;57226454348;","Evaluation Method of Deep Learning-Based Embedded Systems for Traffic Sign Detection",2021,"IEEE Access","9",,"9490209","101217","101238",,2,"10.1109/ACCESS.2021.3097969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111005316&doi=10.1109%2fACCESS.2021.3097969&partnerID=40&md5=ded6716d3017118a22f25d829383433a","Instituto Politécnico Nacional, CITEDI-IPN, Tijuana, Baja California  22435, Mexico; CETYS Universidad, Centro de Innovación y Diseño (CEID), Tijuana, Baja California  22210, Mexico","Lopez-Montiel, M., Instituto Politécnico Nacional, CITEDI-IPN, Tijuana, Baja California  22435, Mexico; Orozco-Rosas, U., CETYS Universidad, Centro de Innovación y Diseño (CEID), Tijuana, Baja California  22210, Mexico; Sanchez-Adame, M., Instituto Politécnico Nacional, CITEDI-IPN, Tijuana, Baja California  22435, Mexico; Picos, K., CETYS Universidad, Centro de Innovación y Diseño (CEID), Tijuana, Baja California  22210, Mexico; Ross, O.H.M., Instituto Politécnico Nacional, CITEDI-IPN, Tijuana, Baja California  22435, Mexico","Traffic Sign Detection (TSD) is a complex and fundamental task for developing autonomous vehicles; it is one of the most critical visual perception problems since failing in this task may cause accidents. This task is fundamental in decision-making and involves different internal conditions such as the internal processing system or external conditions such as weather, illumination, and complex backgrounds. At present, several works are focused on the development of algorithms based on deep learning; however, there is no information on a methodology based on descriptive statistical analysis with results from a solid experimental framework, which helps to make decisions to choose the appropriate algorithms and hardware. This work intends to cover that gap. We have implemented some combinations of deep learning models (MobileNet v1 and ResNet50 v1) in a combination of the Single Shot Multibox Detector (SSD) algorithm and the Feature Pyramid Network (FPN) component for TSD in a standardized dataset (LISA), and we have tested it on different hardware architectures (CPU, GPU, TPU, and Embedded System). We propose a methodology and the evaluation method to measure two types of performance. The results show that the use of TPU allows achieving a processing training time 16.3 times faster than GPU and better results in terms of precision detection for one combination. © 2013 IEEE.","autonomous vehicles; computer vision; deep learning; digital systems; embedded systems; hardware acceleration; Traffic sign detection","Accidents; Complex networks; Decision making; Embedded systems; Graphics processing unit; Learning algorithms; Learning systems; Traffic signs; Complex background; External conditions; Feature pyramid; Hardware architecture; Precision detections; Processing systems; Traffic sign detection; Visual perception; Deep learning",,,,,"CETYS Universidad; Consejo Nacional de Ciencia y Tecnología, CONACYT","This work was supported in part by the Coordinaci?n Institucional de Investigaci?n of Centro de Ense?anza T?cnica y Superior (CETYS Universidad), and in part by the Consejo Nacional de Ciencia y Tecnolog?a (CONACYT).","This work was supported in part by the Coordinación Institucional de Investigación of Centro de Enseñanza Técnica y Superior (CETYS Universidad), and in part by the Consejo Nacional de Ciencia y Tecnología (CONACYT).",,,,,,,,,"Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y., Alsaadi, F.E., A survey of deep neural network architectures and their applications (2017) Neurocomputing, 234, pp. 11-26. , http://www.sciencedirect.com/science/article/pii/S0925231216315533, Apr; Dickmanns, E., Zapp, A., Autonomous high speed road vehicle guidance by computer vision1 (1987) IFAC Proc. Volumes, 20 (5), pp. 221-226. , http://www.sciencedirect.com/science/article/pii/S1474667017553203; Piccioli, G., De Micheli, E., Campani, M., A robust method for road sign detection and recognition (1994) Computer Vision-ECCV, J.-O. Eklundh, Ed. Berlin, Germany, pp. 493-500. , Springer; Temel, D., Alshawi, T., Chen, M.-H., Alregib, G., (2019) Challenging Environments for Traf-c Sign Detection: Reliability Assessment under Inclement Conditions, , https://arxiv.org/abs/1902.06857, arXiv:1902 06857. [Online]; Wali, S.B., Abdullah, M.A., Hannan, M.A., Hussain, A., Samad, S.A., Ker, P.J., Mansor, M.B., Vision-based traf-c sign detection and recognition systems: Current trends and challenges (2019) Sensors, 19 (9), p. 2093. , https://www.mdpi.com/1424-8220/19/9/2093, May; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., Man vs. computer: Benchmarking machine learning algorithms for traf-c sign recognition (2012) Neural Netw, 32, pp. 323-332. , http://www.sciencedirect.com/science/article/pii/S0893608012000457, Aug; Lafuente-Arroyo, S., Gil-Jimenez, P., Maldonado-Bascon, R., Lopez-Ferreras, F., Maldonado-Bascon, S., Traf-c sign shape classi-cation evaluation I: SVM using distance to borders (2005) Proc IEEE Intell. Vehicles Symp, pp. 557-562. , Jun; Saadna, Y., Behloul, A., An overview of traf-c sign detection and classi-cation methods (2017) Int. J. Multimedia Inf. Retr, 6 (3), pp. 193-210. , Sep; Liu, L., Ouyang, W., Wang, X., Fieguth, P., Chen, J., Liu, X., Pietikäinen, M., Deep learning for generic object detection: A survey (2020) Int. J. Comput. Vis, 128 (2), pp. 261-318. , Jan; Liu, C., Li, S., Chang, F., Wang, Y., Machine vision based traf-c sign detection methods: Review, analyses and perspectives (2019) IEEE Access, 7, pp. 86578-86596; Carranza-García, M., Torres-Mateo, J., Lara-Benítez, P., García-Gutiérrez, J., On the performance of one-stage and twostage object detectors in autonomous vehicles using camera data (2020) Remote Sens, 13 (1), p. 89. , https://www.mdpi.com/2072-4292/13/1/89, Dec; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Uni-ed, real-Time object detection (2016) Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 779-788; Jocher, G., (2021) Ultralytics/YOLOv5: V5.0-YOLOv5-P6 1280 Models AWS Supervise.ly and YouTube Integrations. [Online], , https://doi.org/10.5281/zenodo.4679653, Apr; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 580-587. , Jun; Cai, Z., Vasconcelos, N., Cascade R-CNN: Delving into high quality object detection (2017) Proc IEEE Conf. Comput. Vis. Pattern Recognit. CVPR, pp. 6154-6162. , Jun; Lopez-Montiel, M., Rubio, Y., Sánchez, M., Orozco-Rosas, U., Evaluation of algorithms for traf-c sign detection (2019) Proc. SPIE 11136, Proc., , https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11136/2529709/Evaluation-of-Algorithms-for-Traf-c-sign-detection/10.1117/12.2529709.full, Art 111360M; Lopez-Montiel, M., Orozco-Rosas, U., Sánchez-Adame, M., Picos, K., Montiel, O., Evaluation of deep learning algorithms for traf-c sign detection to implement on embedded systems (2021) Studies in Computational Intelligence, 915, pp. 95-115. , https://link.springer.com/chapter/10.1007/978-3-030-58728-4-5, Cham, Switzerland Springer; McFarland, M., UBER self-driving car operator charged in pedestrian death (2020) Proc. CNN, , https://edition.cnn.com/2020/09/18/cars/uber-vasquez-charged/index.html; Wiggers, K., (2020) Waymo's Driverless Cars Were Involved in 18 Accidents over 20 Months, , https://venturebeat.com/2020/10/30/waymos-driverless-cars-wereinvolved-in-18-Accidents-over-20-month/, VentureBeat; Cuthbertson, A., (2020) Tesla Autopilot Crash Driver Killed after Playing Video Games, Investigation Reveals, , https://www.independent.co.uk/life-style/gadgets-And-Tech/news/teslacrash-death-Autopilot-video-model-x-self-driving-A9358971.html, The Independent. [Online]; Grigorescu, S., Trasnea, B., Cocias, T., Macesanu, G., A survey of deep learning techniques for autonomous driving (2020) J. Field Robot, 37 (3), pp. 362-386. , Apr; Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J.S., Ef-cient processing of deep neural networks: A tutorial and survey (2017) Proc IEEE, 105 (12), pp. 2295-2329. , Dec; Jeong, H.-J., Park, K.-S., Ha, Y.-G., Image preprocessing for ef-cient training of YOLO deep learning networks (2018) Proc. IEEE Int. Conf. Big Data Smart Comput. BigComp, pp. 635-637. , Jan; Chen, Y., Zheng, B., Zhang, Z., Wang, Q., Shen, C., Zhang, Q., Deep learning on mobile and embedded devices: State-of-The-Art, challenges, and future directions (2020) ACM Comput. Surveys, 53 (4), pp. 1-37. , Sep; Berthelier, A., Chateau, T., Duffner, S., Garcia, C., Blanc, C., Deep model compression and architecture optimization for embedded systems: A survey (2020) J. Signal Process. Syst, pp. 1-16. , Oct; Belmonte, F.J., Martin, S., Sancristobal, E., Ruiperez-Valiente, J.A., Castro, M., Overview of embedded systems to build reliable and safe ADAS and AD systems IEEE Intell. Transp. Syst. Mag., , early access Feb. 12 2020; Muhammad, K., Ullah, A., Lloret, J., Ser, J.D., De Albuquerque, V.H.C., Deep learning for safe autonomous driving: Current challenges and future directions (2021) IEEE Trans. Intell. Transp. Syst, 22 (7), pp. 4316-4336. , Jul; Wang, W., Fu, Y., Pan, Z., Li, X., Zhuang, Y., Real-Time driving scene semantic segmentation (2020) IEEE Access, 8, pp. 36776-36788; Santos, M.M.D., Hoffmann, J.E., Tosso, H.G., Malik, A.W., Rahman, A.U., Justo, J.F., Real-Time adaptive object localization and tracking for autonomous vehicles (2020) IEEE Trans. Intell. Vehicles, Early Access, , Nov. 16; Lee, D.-H., Chen, K.-L., Liou, K.-H., Liu, C.-L., Liu, J.-L., Deep learning and control algorithms of direct perception for autonomous driving (2021) Int. J. Speech Technol, 51 (1), pp. 237-247. , Jan; Cheng, J., Wang, P.-S., Li, G., Hu, Q.-H., Lu, H.-Q., Recent advances in ef-cient computation of deep convolutional neural networks (2018) Frontiers Inf. Technol. Electron. Eng, 19 (1), pp. 64-77. , Jan; Sha-Que, M., Ha-Z, R., Javed, M.U., Abbas, S., Sekanina, L., Vasicek, Z., Mrazek, V., Adaptive and energy-ef-cient architectures for machine learning: Challenges, opportunities, and research roadmap (2017) Proc IEEE Comput. Soc. Annu. Symp. VLSI ISVLSI, pp. 627-632. , Jul; Arcos-García, A., Álvarez-García, J.A., Soria-Morillo, L.M., Evaluation of deep neural networks for traf-c sign detection systems (2018) Neurocomputing, 316, pp. 332-344. , Nov; Ayachi, R., A-F, M., Said, Y., Atri, M., Traf-c signs detection for real-world application of an advanced driving assisting system using deep learning (2020) Neural Process. Lett, 51 (1), pp. 837-851. , Feb; Bangquan, X., Xiong, W.X., Real-Time embedded traf-c sign recognition using ef-cient convolutional neural network (2019) IEEE Access, 7, pp. 53330-53346; William, M.M., Zaki, P.S., Soliman, B.K., Alexsan, K.G., Mansour, M., El-Moursy, M., Khalil, K., Traf-c signs detection and recognition system using deep learning (2019) Proc. 9th Int. Conf. Intell. Comput. Inf. Syst. ICICIS, pp. 160-166. , Dec; Jouppi, N.P., In-datacenter performance analysis of a tensor processing unit (2017), 45 (2), pp. 1-12. , ACM SIGARCH Comput. Archit. News; Feng, X., Jiang, Y., Yang, X., Du, M., Li, X., Computer vision algorithms and hardware implementations: A survey (2019) Integration, 69, pp. 309-320. , http://www.sciencedirect.com/science/article/pii/S0167926019301762, Nov; Hubel, D.H., Wiesel, T.N., Receptive-elds and functional architecture of monkey striate cortex (1968) J. Physiol, 195 (1), pp. 215-243; Fukushima, K., Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position (1980) Biol. Cybern, 36 (4), pp. 193-202. , Apr; Lecun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.E., Jackel, L.D., Handwritten digit recognition with a back-propagation network (1989) Proc. NIPS, pp. 396-404; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc IEEE, 86 (11), pp. 2278-2324. , Nov; Nair, V., Hinton, G.E., Recti-ed linear units improve restricted Boltzmann machines (2010) Proc. 27th Int. Conf. Mach. Learn, pp. 807-814. , Madison, WI, USA: Omni Press; Boureau, Y.-L., Ponce, J., Lecun, Y., A theoretical analysis of feature pooling in visual recognition (2010) Proc. 27th Int. Conf. Mach. Learn, pp. 111-118. , Madison, WI, USA: Omni Press; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Computer Vision-ECCV, pp. 818-833. , D. Fleet, T. Pajdla, B. Schiele, and T. Tuytelaars, Eds. Cham, Switzerland Springer; Gu, J., Wang, Z., Kuen, J., Aa, L.M., Shahroudy, A., Shuai, B., Liu, T., Chen, T., Recent advances in convolutional neural networks (2018) Pattern Recognit, 77, pp. 354-377. , http://www.sciencedirect.com/science/article/pii/S0031320317304120, May; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., Berg, A.C., SSD: Single shot multibox detector (2016) Computer Vision-ECCV (Lecture Notes in Computer Science), pp. 21-37. , Cham, Switzerland Springer; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR, pp. 770-778. , Jun; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) MobileNets: Ef-cient Convolutional Neural Networks for Mobile Vision Applications, , http://arxiv.org/abs/1704.04861, Jul arXiv:1704 04861. [Online]; Lin, T.-Y., Dollar, P., Girshick, R., He, K., Hariharan, B., Belongie, S., Feature pyramid networks for object detection (2017) Proc IEEE Conf. Comput. Vis. Pattern Recognit. CVPR, pp. 936-944. , Jul; Mogelmose, A., Trivedi, M.M., Moeslund, T.B., Vision-based traf-c sign detection and analysis for intelligent driver assistance systems: Perspectives and survey (2012) IEEE Trans. Intell. Transp. Syst, 13 (4), pp. 1484-1497. , Dec; Huang, H., Liu, Z., Chen, T., Hu, X., Zhang, Q., Xiong, X., Design space exploration for YOLO neural network accelerator (2020) Electronics, 9 (11), p. 1921. , https://www.mdpi.com/2079-9292/9/11/1921, Nov; Zhang, X., Wei, X., Sang, Q., Chen, H., Xie, Y., An ef-cient FPGA-based implementation for quantized remote sensing image scene classi-cation network (2020) Electronics, 9 (9), p. 1344. , https://www.mdpi.com/2079-9292/9/9/1344, Aug; Capra, M., Bussolino, B., Marchisio, A., Sha-Que, M., Masera, G., Martina, M., An updated survey of ef-cient hardware architectures for accelerating deep convolutional neural networks (2020) Future Internet, 12 (7), p. 113. , https://www.mdpi.com/1999-5903/12/7/113, Jul; Hossain, S., Lee, D.-J., Deep learning-based real-Time multiple-object detection and tracking from aerial imagery via a-ying robot with GPUbased embedded devices (2019) Sensors, 19 (15), p. 3371. , Jul; Sharma, H., Park, J., Mahajan, D., Amaro, E., Kim, J.K., Shao, C., Mishra, A., Esmaeilzadeh, H., From high-level deep neural models to FPGAs (2016) Proc. 49th Annu IEEE/ACM Int. Symp. Microarchitecture MICRO, pp. 1-12. , Oct; Chen, Y.H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energy-ef-cient recon-gurable accelerator for deep convolutional neural networks (2017) IEEE J. Solid-State Circuits, 52 (1), pp. 127-138. , Jan; Mazzia, V., Khaliq, A., Salvetti, F., Chiaberge, M., Real-Time apple detection system using embedded systems with hardware accelerators: An edge AI application (2020) IEEE Access, 8, pp. 9102-9114; Liu, J., Liu, J., Du, W., Li, D., (2019) Performance Analysis and Characterization of Training Deep Learning Models on Mobile Devices, , http://arxiv.org/abs/1906.04278, Jul arXiv:1906 04278. [Online]; Hanhirova, J., Kämäräinen, T., Seppälä, S., Siekkinen, M., Hirvisalo, V., Ylä-Jääski, A., (2018) Latency and Throughput Characterization of Convolutional Neural Networks for Mobile Computer Vision, , http://arxiv.org/abs/1803.09492, Jul arXiv:1803 09492. [Online]; Taylor, B., Marco, V.S., Wolff, W., Elkhatib, Y., Wang, Z., Adaptive deep learning model selection on embedded systems (2018) ACM SIGPLAN Notices, 53 (6), pp. 31-43. , Dec; Loni, M., Daneshtalab, M., Sjodin, M., ADONN: Adaptive design of optimized deep neural networks for embedded systems (2018) Proc. 21st Euromicro Conf. Digit. Syst. Design DSD, pp. 397-404. , Aug; Wang, J., Jiang, S., Song, W., Yang, Y., A comparative study of small object detection algorithms (2019) Proc. Chin. Control Conf CCC, pp. 8507-8512; You, S., Bi, Q., Ji, Y., Liu, S., Feng, Y., Wu, F., Traf-c sign detection method based on improved SSD (2020) Information, 11 (10), p. 475. , https://www.mdpi.com/2078-2489/11/10/475, Oct; Hatcher, W.G., Yu, W., A survey of deep learning: Platforms, applications and emerging research trends (2018) IEEE Access, 6, pp. 24411-24432; Xu, J., Wang, B., Li, J., Hu, C., Pan, J., Deep learning application based on embedded GPU (2017) Proc. 1st Int. Conf. Electron. Instrum. Inf. Syst. (EIIS, pp. 1-4; Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., The Pascal visual object classes (VOC) challenge (2009) Int. J. Comput. Vis, 88 (2), pp. 303-338. , Sep; Davis, J., Goadrich, M., The relationship between precision-recall and ROC curves (2006) Proc. 23rd Int. Conf. Mach. Learn, pp. 233-240. , New York, NY, USA: Association for Computing Machinery; Teich, A.D., Teich, R.P., PLASTER: A framework for deep learning performance (2018) NVIDIA Santa Clara CA USA Tech. Rep, , https://images.nvidia.com/content/pdf/plasterdeep-learning-framework.pdf; Huang, J., Rathod, V., Sun, C., Zhu, M., Korattikara, A., Fathi, A., Fischer, I., Murphy, K., Speed/accuracy trade-offs for modern convolutional object detectors (2017) Proc IEEE Conf. Comput. Vis. Pattern Recognit. CVPR, pp. 7310-7311. , Jul; Lin, T.-Y., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., Perona, P., Dollár, P., Microsoft COCO: Common objects in context (2015) Proc. Eur. Conf. Comput. Vis, pp. 740-755; Kalamkar, D., Mudigere, D., Mellempudi, N., Das, D., Banerjee, K., Avancha, S., Vooturi, D.T., Dubey, P., (2019) A Study of BFLOAT16 for Deep Learning Training, , https://arxiv.org/abs/1905.12322, arXiv:1905 12322. [Online]; Wang, Y.E., Wei, G.-Y., Brooks, D., (2019) Benchmarking TPU, GPU, and CPU Platforms for Deep Learning, , https://arxiv.org/abs/1907.10701, arXiv:1907 10701. [Online]; (2021) AMD Ryzen 5 3600 Specs, , https://www.techpowerup.com/cpuspecs/ryzen-5-3600.c2132, TechPowerUp Accessed Mar. 10 2020. [Online]; (2021) Nvidia Geforce RTX 2060 Super Specs, , https://www.techpowerup.com/gpu-specs/geforcertx-2060-super.c3441, Accessed Mar. 10 2020. [Online]; (2021) Nvidia Jetson AGX Xavier GPU Specs, , https://www.techpowerup.com/gpu-specs/jetson-Agxxavier-gpu.c3232, Accessed Mar. 10 2020. [Online]; Reddi, V.J., MLPerf inference benchmark (2020) Proc. ACM/ IEEE 47th Annu. Int. Symp. Comput. Archit, pp. 446-459. , May; Mogelmose, A., Liu, D., Trivedi, M.M., Detection of U.S.Traf-c signs (2015) IEEE Trans. Intell. Transp. Syst, 16 (6), pp. 3116-3125. , Sep; Zhang, J., Xie, Z., Sun, J., Zou, X., Wang, J., A cascaded R-CNN with multiscale attention and imbalanced samples for traf-c sign detection (2020) IEEE Access, 8, pp. 29742-29754","Orozco-Rosas, U.; CETYS Universidad, Mexico; email: ulises.orozco@cetys.mx",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85111005316
"Shehzad F., Rashid M., Sinky M.H., Alotaibi S.S., Zia M.Y.I.","57211637486;22735181000;8235014500;57202829227;57192103831;","A Scalable System-on-Chip Acceleration for Deep Neural Networks",2021,"IEEE Access","9",,"9474433","95412","95426",,3,"10.1109/ACCESS.2021.3094675","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110640552&doi=10.1109%2fACCESS.2021.3094675&partnerID=40&md5=0dc4d9fcd297ed3cf4112e223212df7d","Integrated Digital Systems, University of Bremen, Bremen, Germany; Computer Engineering Department, Umm Al-Qura University, Mecca, Saudi Arabia; Department of Information Systems, Umm Al-Qura University, Mecca, Saudi Arabia","Shehzad, F., Integrated Digital Systems, University of Bremen, Bremen, Germany; Rashid, M., Computer Engineering Department, Umm Al-Qura University, Mecca, Saudi Arabia; Sinky, M.H., Computer Engineering Department, Umm Al-Qura University, Mecca, Saudi Arabia; Alotaibi, S.S., Department of Information Systems, Umm Al-Qura University, Mecca, Saudi Arabia; Zia, M.Y.I., Computer Engineering Department, Umm Al-Qura University, Mecca, Saudi Arabia","The size of neural networks in deep learning techniques is increasing and varies significantly according to the requirements of real-life applications. The increasing network size and scalability requirements pose significant challenges for a high performance implementation of deep neural networks (DNN). Conventional implementations, such as graphical processing units and application specific integrated circuits, are either less efficient or less flexible. Consequently, this article presents a system-on-chip (SoC) solution for the acceleration of DNN, where an ARM processor controls the overall execution and off-loads computational intensive operations to a hardware accelerator. The system implementation is performed on a SoC development board. Experimental results show that the proposed system achieves a speed-up of 22.3, with a network architecture size of $64\times 64$ , in comparison with the native implementation on a dual core cortex ARM-A9 processor. In order to generalize the performance of complete system, a mathematical formula is presented which allows to compute the total execution time for any architecture size. The validation is performed by taking Epileptic Seizure Recognition as the target case study. Finally, the results of the proposed solution are compared with various state-of-The-Art solutions in terms of execution time, scalability, and clock frequency. © 2013 IEEE.","Deep neural networks; epileptic seizure recognition; hardware accelerator; scalability; system-on-chip","Application specific integrated circuits; ARM processors; Computer architecture; Deep learning; Deep neural networks; Flexible electronics; Graphics processing unit; Network architecture; Programmable logic controllers; Scalability; System-on-chip; Graphical processing unit (GPUs); Hardware accelerators; High performance implementations; Learning techniques; Mathematical formulas; Real-life applications; System implementation; System-on-chip solutions; Neural networks",,,,,"King Abdulaziz City for Science and Technology, KACST: 14-ELE1049-10","This work was supported in part by the King Abdulaziz City for Science and Technology (KACST) under Grant 14-ELE1049-10, and in part by the Science and Technology Unit (STU), Mecca, Saudi Arabia.",,,,,,,,,,"Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A., Ciompi, F., Ghafoorian, M., Van Der Laak, M.W.J.A., Sánchez, C.I., A survey on deep learning in medical image analysis (2017) Med. Image Anal, 42, pp. 60-88. , Dec; Liu, L., Ouyang, W., Wang, X., Fieguth, P., Chen, J., Liu, X., Pietikäinen, M., Deep learning for generic object detection: A survey (2020) Int. J. Comput. Vis, 128, pp. 261-318. , Feb; Pouyanfar, S., Sadiq, S., Yan, Y., Tian, H., Tao, Y., Reyes, M.P., Shyu, M., Iyengar, S.S., A survey on deep learning: Algorithms, techniques, and applications (2018) ACM Comput. Surv, 51 (5), p. 92; Dargan, S., Kumar, M., Ayyagari, M.R., Kumar, G., A survey of deep learning and its applications: A new paradigm to machine learning (2020) Arch. Comput. Methods Eng, 27 (4), pp. 1071-1092. , Sep; Abiodun, O.I., Jantan, A., Omolara, A.E., Dada, K.V., Mohamed, N.A., Arshad, H., State-of-The-Art in artificial neural network applications: A survey (2018) Heliyon, 4 (11). , NovArt. no. e00938; Shah, S.A.B., Rashid, M., Arif, M., Estimating WCET using prediction models to compute fitness function of a genetic algorithm (2020) Real-Time Syst, 56 (1), pp. 28-63. , Jan; Shrestha, A., Mahmood, A., Review of deep learning algorithms and architectures (2019) IEEE Access, 7, pp. 53040-53065; Montavon, G., Samek, W., Möller, K.-R., Methods for interpreting and understanding deep neural networks (2018) Digit. Signal Process, 73, pp. 1-15. , Feb; Wang, C., Gong, L., Yu, Q., Li, X., Xie, Y., Zhou, X., DLAU: A scalable deep learning accelerator unit on FPGA (2017) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst, 36 (3), pp. 513-517. , Mar; Rashid, M., Shah, S.A.B., Arif, M., Kashif, M., Determination of worst-case data using an adaptive surrogate model for real-Time system (2020) J. Circuits, Syst. Comput, 29 (1). , Jan, Art. no 2050005; Mittal, S., Vaishay, S., A survey of techniques for optimizing deep learning on GPUs (2019) J. Syst. Archit, 99. , Oct, Art 101635; Chen, Y., Xie, Y., Song, L., Chen, F., Tang, T., A survey of accelerator architectures for deep neural networks (2020) Engineering, 6 (3), pp. 264-274. , Mar; Blaiech, A.G., Ben Khalifa, K., Valderrama, C., Fernandes, M.A.C., Bedoui, M.H., A survey and taxonomy of FPGA-based deep learning accelerators (2019) J. Syst. Archit, 98, pp. 331-345. , Sep; Mayer, R., Jacobsen, H.-A., Scalable deep learning on distributed infrastructures: Challenges, techniques, and tools (2020) ACM Comput. Surv, 53 (1), pp. 1-37. , May; Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Boyle, R., In-datacenter performance analysis of a tensor processing unit (2017) Proc. 44th Annual Int. Symp. Comput. Archit., New York, NY, USA, pp. 1-12; (2019) DE1-SoC Board User Manual, pp. 1-2. , https://www.terasic.com.tw/cgibin/page/archive.pl?Language=English&No=836&PartNo=4, ALTERA Corporation ALTERA Univ Programme Terasic Technol. San Jose CA USA. Accessed: May 2021; Pajuelo-Holguera, F., Gómez-Pulido, J.A., Ortega, F., Granado-Criado, J.M., Recommender system implementations for embedded collaborative filtering applications (2020) Microprocessors Microsyst, 73. , Mar, Art 102997; Chen, T., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., Temam, O., DianNao: A small-footprint high-Throughput accelerator for ubiquitous machine-learning (2014) ACM SIGPLAN Notices, 49 (4), pp. 269-284. , Apr; Ly, D.L., Chow, P., A high-performance FPGA architecture for restricted Boltzmann machines (2009) Proc ACM/SIGDA Int. Symp. Field Program. Gate Arrays (FPGA, pp. 73-82; Kim, S.K., McAfee, L.C., McMahon, P.L., Olukotun, K., A highly scalable restricted Boltzmann machine FPGA implementation (2009) Proc. Int. Conf. Field Program. Log. Appl, pp. 367-372. , Aug; Boonyakitanont, P., Lek-Uthai, A., Chomtho, K., Songsiri, J., A review of feature extraction and performance evaluation in epileptic seizure detection using EEG (2020) Biomed. Signal Process. Control, 57. , Mar, Art 101702; Andrzejak, R.G., Lehnertz, K., Mormann, F., Rieke, C., David, P., Elger, C.E., Indications of nonlinear deterministic and finitedimensional structures in time series of brain electrical activity: Dependence on recording region and brain state (2001) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top, 64 (6). , https://repositori.upf.edu/handle/10230/43637, Nov, Art. no 061907. Accessed: May 2021; Epilepsy: A Public Health Imperative. Accessed: May 2021. [Online]. Available, , https://www.who.int/publications-detail/epilepsy-A-public-health-imperative, World Health Organization; Chen, Z., Lu, G., Xie, Z., Shang, W., A unified framework and method for EEG-based early epileptic seizure detection and epilepsy diagnosis (2020) IEEE Access, 8, pp. 20080-20092; Rebsamen, M., Suter, Y., Wiest, R., Reyes, M., Rummel, C., Brain morphometry estimation: From hours to seconds using deep learning (2020) Frontiers Neurol, 11, p. 244. , Apr; Wang, Q., Gao, X., Wan, K., Li, F., Hu, Z., A novel restricted Boltzmann machine training algorithm with fast Gibbs sampling policy (2020) Math. Problems Eng, 2020, pp. 1-19. , Mar; Shen, H., Li, H., A gradient approximation algorithm based weight momentum for restricted Boltzmann machine (2019) Neurocomputing, 361, pp. 40-49. , Oct; Solutions for Data Science Practitioners and Enterprise Machine Learning, , https://www.anaconda.com/, Anaconda. Accessed: May 2021; Platform Designer (Formerly Qsys), , https://www.intel.com/content/www/us/en/programmable/products/design-software/fpga-design/quartus-prime/features/qts-platformdesigner.html, Accessed: May 2021; Quartus Prime Lite Edition, , https://fpgasoftware.intel.com/?edition=lite, Accessed: May 2021. [Online]; Scikit-Learn: Machine Learning in Python, , https://scikit-learn.org/, May 2021; Keras-Pandas 3.1 0, , https://pypi.org/project/keras-pandas/, Accessed: May 2021","Rashid, M.; Computer Engineering Department, Saudi Arabia; email: mfelahi@uqu.edu.sa",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85110640552
"Tang C., Xia S., Qian M., Wang B.","13004005000;57218516826;57222113687;55611805200;","Deep Learning-Based Vein Localization on Embedded System",2021,"IEEE Access","9",,"9350245","27916","27927",,1,"10.1109/ACCESS.2021.3058014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101480395&doi=10.1109%2fACCESS.2021.3058014&partnerID=40&md5=4d2950e901841719ae6fea8b2eb2fa71","College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China","Tang, C., College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China; Xia, S., College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China; Qian, M., College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China; Wang, B., College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China","Venipuncture is a common process in medical treatment. In the fight against pandemic like COVID-19, it is often very difficult for medical staff to carry out venipuncture accurately, since the staff have to wear safety glasses and surgical gloves. In this work, we designed an embedded system which implements deep learning algorithm to localize veins from color skin images. The proposed method consists of a fully convolutional neural network (CNN) as encoder and feature extractor, a dilated convolution module, and a transposed convolution module as decoder. A synchronized RGB/Near Infrared (NIR) image database was constructed to provide the mapping information between the two image fields. A combined loss function which includes a per-pixel loss and a perceptual loss was presented to optimize the network parameters. To make the model adaptive to different images, a histogram specification scheme was adopted to transform the color style of an image. The model was then implemented on a NVIDIA Jetson TX2 development kit. Comprehensive experiments were conducted on different databases to evaluate the proposed method and the embedded system. Experimental results showed that the system has satisfactory performance and a promising perspective in daily medical treatment. © 2013 IEEE.","convolutional neural network; NVIDIA Jetson TX2; Vein localization","Convolution; Convolutional neural networks; Embedded systems; Learning algorithms; Learning systems; Safety glass; Common process; Feature extractor; Histogram specifications; Image database; Loss functions; Mapping information; Medical treatment; Network parameters; Deep learning",,,,,"Key Research and Development Program of Jiangxi Province: BE2018720; Kementerian Pendidikan Malaysia, KPM: NJ2020004","This work was supported in part by the Key Research & Development Programs of Jiangsu Province under Grant BE2018720, and in part by the Open Project of Engineering Center of Ministry of Education under Grant NJ2020004.",,,,,,,,,,"Huang, C., Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China (2020) Lancet, 395, pp. 497-506. , 10233 Jan; https://www.bing.com/covid/, COVID-19 Epidemic Tracking; Wang, C., Horby, P.W., Hayden, F.G., Gao, G.F., A novel coronavirus outbreak of global health concern (2020) Lancet, 395, pp. 470-473. , Jan. 10233; http://www.ruh.nhs.uk/training/prospectus/clinical_skills/documents/cannulation_and_venepuncture_workbook.doc, The Assessment Strategy for Cannulation and Venipuncture; Jacobson, A.F., Winslow, E.H., Variables influencing intravenous catheter insertion difficulty and failure: An analysis of 339 intravenous catheter insertions (2005) Heart Lung, 34 (5), pp. 345-359. , Sep; Mbamalu, D., Banerjee, A., Methods of obtaining peripheral venous access in difficult situations (1999) Postgraduate Med. J., 75 (886), pp. 459-462; Asrar, M., Al-Habaibeh, A., Houda, M.R., A comparative study between visual, near infrared and infrared images for the detection of veins for intravenous cannulation (2015) Proc. Aita Adv. Infrared Technol. Appl., pp. 1-4. , Pisa, Italy; Shahzad, A., Saad, M.N.M., Walter, N., Saeed, M.A., Meriaudeau, F., A review on subcutaneous veins localization using imaging techniques (2014) Current Med. Imag. Rev., 10 (2), pp. 125-132; Yamagami, Y., Ueki, S., Matoba, K., Makimoto, K., Effectiveness of ultrasound-guided peripheral intravenous cannulation in pediatric patients aged under three years: A systematic review protocol (2018) Jbi Database Systematic Rev. Implement. Rep., 16 (1), pp. 35-38. , Jan; Englund, K.M., Rayment, M., Nutcracker syndrome: A proposed ultrasound protocol (2018) Australas. J. Ultrasound Med., 21 (2), pp. 75-78. , May; https://www.veinlite.com/blog/post/nir-ultrasound-transillumination-vein-access/, NIR vs. Ultrasound vs. Transillumination for Vein Access; Sun, C.-Y., Lee, K.-C., Lin, I.-H., Wu, C.-L., Huang, H.-P., Lin, Y.-Y., Hsu, Y.-F., Yu, H.-R., Near-infrared light device can improve intravenous cannulation in critically ill children (2013) Pediatrics Neonatol., 54 (3), pp. 194-197. , Jun; Pan, C.T., Francisco, M.D., Yen, C.K., Wang, S.Y., Shiue, Y.L., Vein pattern locating technology for cannulation: A review of the low-cost vein finder prototypes utilizing near Infrared (NIR) light to improve peripheral subcutaneous vein selection for phlebotomy (2019) Sensors, 16 (16), pp. 3573-3589; Asrar, M., Al-Habaibeh, A., Houda, M., Innovative algorithm to evaluate the capabilities of visual, near infrared, and infrared technologies for the detection of veins for intravenous cannulation (2016) Appl. Opt., 55 (34), pp. 67-75; Xuemin, Q., Zhengzhong, B., Development of ultrasonic positioning detector for vein (2000) (In Chinese), Chin. J. Med. Phys., 17 (1), pp. 32-33; Pavanjeet, S.S., Walter, N., Shahzad, A., Saad, N.M., Optimum illuminant determination based on multispectral spectroscopy for enhanced vein detection (2015) Proc. IEEE Int. Conf. Signal Image Process. Appl. (ICSIPA), pp. 174-179. , Kuala Lumpur, Malaysia, Oct; Shahzad, A., Walter, N., Malik, A.S., Saad, N.M., Meriaudeau, F., Multispectral venous images analysis for optimum illumination selection (2013) Proc. IEEE Int. Conf. Image Process., pp. 2383-2387. , Melbourne, VIC, Australia, Sep; Colak, S., Ozdemir, O.F., Akgul, Y.S., A stereo camera system for palm vein biometrics (2016) Proc. 24th Signal Process. Commun. Appl. Conf. (SIU), pp. 1825-1828. , Zonguldak, Turkey, May; Ozdemir, O.F., Colak, S., Akgul, Y.S., Regression based stereo palm vein extraction and identification system (2016) Proc. 24th Signal Process. Commun. Appl. Conf. (SIU), pp. 1529-1532. , Zonguldak, Turkey, May; Gnee, N.S., A study of hand vein, neck vein and arm vein extraction for authentication (2009) Proc. 7th Int. Conf. Inf. , Commun. Signal Process. (ICICS), pp. 1-4. , Macau, China, Dec; Ahmed, T., Rahman, K.S., Shawlin, S.S., Hasan, M., Bhattacharjee, A., Fattah, S.A., Shahnaz, C., Real time injecting device with automated robust vein detection using near infrared camera and live video (2017) Proc. IEEE Global Humanitarian Technol. Conf. (GHTC), pp. 1-8. , San Jose, CA, USA, Oct; Tang, C., Kong, A.W.K., Craft, N., Uncovering vein patterns from color skin images for forensic analysis (2011) Proc. Cvpr, pp. 665-672. , Providence, RI, USA, Jun; Tang, C., Zhang, H., Wai-Kin Kong, A., Using multiple models to uncover blood vessel patterns in color images for forensic analysis (2016) Inf. Fusion, 32, pp. 26-39. , Nov; Song, J.H., Kim, C., Yoo, Y., Vein visualization using a smart phone with multispectralWiener estimation for point-of-care applications (2015) IEEE J. Biomed. Health Inform., 19 (2), pp. 773-778. , Mar; Watanabe, T., Tanaka, T., Vein authentication using color information and image matching with high performance on natural light (2009) Proc. ICCAS-SICE, pp. 3625-3629. , Fukuoka, Japan, Aug; Ma, G., Wang, B., Tang, C., Uncovering vein pattern using generative adversarial network (2019) Proc. Spie, , Aug. 11179; Blanco-Filgueira, B., Garcia-Lesta, D., Fernandez-Sanjurjo, M., Brea, V.M., Lopez, P., Deep learning-based multiple object visual tracking on embedded system for IoT and mobile edge computing applications (2019) IEEE Internet Things J., 6 (3), pp. 5423-5431. , Jun; Goyal, M., Reeves, N.D., Rajbhandari, S., Yap, M.H., Robust methods for real-time diabetic foot ulcer detection and localization on mobile devices (2019) IEEE J. Biomed. Health Inform., 23 (4), pp. 1730-1741. , Jul; Hoang, T.M., Nam, S.H., Park, K.R., Enhanced detection and recognition of road markings based on adaptive region of interest and deep learning (2019) IEEE Access, 7, pp. 109817-109832; Haut, J.M., Bernabe, S., Paoletti, M.E., Fernandez-Beltran, R., Plaza, A., Plaza, J., Low high-power consumption architectures for deep-learning models applied to hyperspectral image classification (2019) IEEE Geosci. Remote Sens. Lett., 16 (5), pp. 776-780. , May; http://forensics.sce.ntu.edu.sg/, Forensic Skin Image Databases of Nanyang Technological University in Singapore; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), 4, pp. 770-778. , Jun; Yu, F., Koltun, V., Multi-scale context aggregation by dilated convolutions (2016) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 1-13; Johnson, J., Alahi, A., Li, F.F., Perceptual losses for real-time style transfer and super-resolution (2016) Proc. Eccv, pp. 694-711; Benaim, S., Wolf, L., One-sided unsupervised domain mapping (2017) Proc. Nips, pp. 752-762; Zhang, W., Xin, D., Xiong, H., Zhu, W., Qiu, J., Wang, C., A statistical weighting average approach for cognitive radio networks (2016) Proc. 19th Int. Symp. Wireless Pers. Multimedia Commun. (WPMC), pp. 74-78. , Shenzhen, China, Nov; https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/, Stochastic Weight Averaging in PyTorch; Thomas, G., Flores-Tapia, D., Pistorius, S., Histogram specification: A fast and flexible method to process digital images (2011) IEEE Trans. Instrum. Meas., 60 (5), pp. 1565-1578. , May; Otsu, N., Athreshold selection method from gray-level histograms (1979) IEEE Trans. Syst. , Man, Cybern., TSMC-9 (1), pp. 62-66. , Jan; https://en.wikipedia.org/wiki/F1_score, F1 Score. Accessed: Mar. 5, 2019","Wang, B.; College of Automation Engineering, China; email: wangbiao@nuaa.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85101480395
"Liu S., Fan H., Ferianc M., Niu X., Shi H., Luk W.","56610973400;57194654551;57209643749;54179579300;57208867317;26029526200;","Toward Full-Stack Acceleration of Deep Convolutional Neural Networks on FPGAs",2021,"IEEE Transactions on Neural Networks and Learning Systems",,,,"","",,1,"10.1109/TNNLS.2021.3055240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101471464&doi=10.1109%2fTNNLS.2021.3055240&partnerID=40&md5=b31d2ba813325ebcefd0962a05ab697d","Department of Computing, Imperial College London, London SW7 2AZ, U.K. He is now with the School of Physics and Electronics, Hunan Normal University, Changsha 410081, China. (e-mail: liu.shuanglong@hunnu.edu.cn); Department of Computing, Imperial College London, London SW7 2AZ, U.K.; Department of Electronic and Electrical Engineering, University College London, London WC1E 7JE, U.K.; Corerain Technologies Ltd., Shenzhen 518048, China.; State Key Laboratory of Space-Ground Integrated Information Technology (SGIIT), Beijing 100029, China.","Liu, S., Department of Computing, Imperial College London, London SW7 2AZ, U.K. He is now with the School of Physics and Electronics, Hunan Normal University, Changsha 410081, China. (e-mail: liu.shuanglong@hunnu.edu.cn); Fan, H., Department of Computing, Imperial College London, London SW7 2AZ, U.K.; Ferianc, M., Department of Electronic and Electrical Engineering, University College London, London WC1E 7JE, U.K.; Niu, X., Corerain Technologies Ltd., Shenzhen 518048, China.; Shi, H., State Key Laboratory of Space-Ground Integrated Information Technology (SGIIT), Beijing 100029, China.; Luk, W., Department of Computing, Imperial College London, London SW7 2AZ, U.K.","Due to the huge success and rapid development of convolutional neural networks (CNNs), there is a growing demand for hardware accelerators that accommodate a variety of CNNs to improve their inference latency and energy efficiency, in order to enable their deployment in real-time applications. Among popular platforms, field-programmable gate arrays (FPGAs) have been widely adopted for CNN acceleration because of their capability to provide superior energy efficiency and low-latency processing, while supporting high reconfigurability, making them favorable for accelerating rapidly evolving CNN algorithms. This article introduces a highly customized streaming hardware architecture that focuses on improving the compute efficiency for streaming applications by providing full-stack acceleration of CNNs on FPGAs. The proposed accelerator maps most computational functions, that is, convolutional and deconvolutional layers into a singular unified module, and implements the residual and concatenative connections between the functions with high efficiency, to support the inference of mainstream CNNs with different topologies. This architecture is further optimized through exploiting different levels of parallelism, layer fusion, and fully leveraging digital signal processing blocks (DSPs). The proposed accelerator has been implemented on Intel's Arria 10 GX1150 hardware and evaluated with a wide range of benchmark models. The results demonstrate a high performance of over 1.3 TOP/s of throughput, up to 97&#x0025; of compute [multiply-accumulate (MAC)] efficiency, which outperforms the state-of-the-art FPGA accelerators. IEEE","Convolutional neural networks (CNNs); deep learning; field-programmable gate arrays (FPGAs); hardware accelerator; layer fusion; unified architecture.","Acceleration; Convolution; Deep neural networks; Digital signal processing; Energy efficiency; Field programmable gate arrays (FPGA); Network architecture; Computational functions; Fpga accelerators; Hardware accelerators; Multiply accumulate; Real-time application; Reconfigurability; Streaming applications; Streaming hardwares; Convolutional neural networks",,,,,,,,,,,,,,,,,,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,2162237X,,,,"English","IEEE Trans. Neural Networks Learn. Sys.",Article,"Article in Press","",Scopus,2-s2.0-85101471464
"Shin J., Yeon K., Kim S., Sunwoo M., Han M.","55608178300;57209796123;57211019487;55227908300;24343232200;","Comparative Study of Markov Chain with Recurrent Neural Network for Short Term Velocity Prediction Implemented on an Embedded System",2021,"IEEE Access","9",,"9345689","24755","24767",,3,"10.1109/ACCESS.2021.3056882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100793877&doi=10.1109%2fACCESS.2021.3056882&partnerID=40&md5=9085ba2707d6f086bf55c1540b7943dd","Department of Automotive Engineering, Hanyang University, Seoul, 04763, South Korea; Research and Development Division, Hyundai Motor Company, Hwaseong, 18280, South Korea; Department of Mechanical and Automotive Engineering, Keimyung University, Daegu, 42601, South Korea","Shin, J., Department of Automotive Engineering, Hanyang University, Seoul, 04763, South Korea; Yeon, K., Research and Development Division, Hyundai Motor Company, Hwaseong, 18280, South Korea; Kim, S., Department of Automotive Engineering, Hanyang University, Seoul, 04763, South Korea; Sunwoo, M., Department of Automotive Engineering, Hanyang University, Seoul, 04763, South Korea; Han, M., Department of Mechanical and Automotive Engineering, Keimyung University, Daegu, 42601, South Korea","Short-term prediction models for an ego-vehicle's speed contributes to the improvement of vehicle safety, driveability, and fuel economy. To achieve these desired outcomes, an accurate forward speed prediction model and its successful implementation in a real system is a prerequisite. This paper compares six velocity prediction models based on two types of data-driven models, a Markov chain and a Recurrent Neural Network (RNN), by implementing them in an embedded system to evaluate their prediction accuracy and execution time. The inputs to each model are the driving information acquired on a specific route, such as internal vehicle information, relative speed and distance to the vehicle in the front of the ego-vehicle, and ego-vehicle's location estimated by the GPS signal along with the B-spline roadway model. The proposed prediction models predict the velocity profile of the ego-vehicle up to the prediction horizon of 150 m. The parameters of the proposed models have been optimized using Hyper-parameter Optimization via Radial basis function and Dynamic coordinate search. By applying real driving data, the Markov chain-based models show slightly lower prediction accuracy but shorter execution time than those of the RNN-based models. © 2013 IEEE.","Embedded system; execution time; gated recurrent unit (GRU); long short-term momory (LSTM); Markov chain; prediction accuracy; prediction algorithm; recurrent neural network (RNN)","Embedded systems; Forecasting; Fuel economy; Markov chains; Predictive analytics; Comparative studies; Dynamic coordinates; Hyper-parameter optimizations; Prediction accuracy; Radial basis functions; Recurrent neural network (RNN); Short term prediction; Velocity prediction; Recurrent neural networks",,,,,"Ministry of Trade, Industry and Energy, MOTIE: N0001992; National Research Foundation of Korea, NRF; Ministry of Education, Science and Technology, MEST: 2011-0017495","This work was supported in part by the Industrial Strategy Technology Development Program under Grant 10039673, Grant 10060068, Grant 10079961, and Grant 10080284; in part by the International Collaborative Research and Development Program through the Ministry of Trade, Industry and Energy (MOTIE Korea) under Grant N0001992; and in part by the National Research Foundation of Korea (NRF) grant funded by the Korean Government (MEST) under Grant 2011-0017495.",,,,,,,,,,"Kumar, K., Parida, M., Katiyar, V.K., Short term traffic flow prediction for a non urban highway using artificial neural network (2013) Procedia Social Behav. Sei., 104, pp. 755-764. , Dec; Ma, X., Tao, Z., Wang, Y., Yu, H., Wang, Y., Long short-term memory neural network for traffic speed prediction using remote microwave sensor data (2015) Transp. Res. C, Emerg. TechnoL, 54, pp. 187-197. , May; Yao, B., Chen, C., Cao, Q., Jin, L., Zhang, M., Zhu, H., Yu, B., Short-term traffic speed prediction for an urban corridor (2017) Comput.-Aided Civil Infrastruct. Eng., 32 (2), pp. 154-169. , Feb; Wu, Y., Tan, H., Qin, L., Ran, B., Jiang, Z., A hybrid deep learning based traffic flow prediction method and its understanding (2018) Transp. Res. C, Emerg. Technol., 90, pp. 166-180. , May; Wu, C., Peng, L., Huang, Z., Zhong, M., Chu, D., A method of vehicle motion prediction and collision risk assessment with a simulated vehicular cyber physical system (2014) Transp. Res. C, Emerg. Technol., 47, pp. 179-191. , Oct; Jing, J., Ozatay, E., Kurt, A., Michelini, J., Filev, D., Ozguner, U., Design of a fuel economy oriented vehicle longitudinal speed controller with optimal gear sequence (2016) Proc. Ieee 55th Conf. Decis. Control (CDC), Dec., pp. 1595-1601. , http://ieeexplore.ieee.org/document/7798493/, [Online]; Asadi, B., Vahidi, A., Predictive cruise control: Utilizing upcoming traffic signal information for improving fuel economy and reducing trip time (2011) Ieee Trans. Control Syst. Technol., 19 (3), pp. 707-714. , May; Park, S., Rakha, H., Ahn, K., Moran, K., Predictive eco-cruise control: Algorithm and potential benefits (2011) Proc. Ieee Forum Integr. Sustain. Transp. Syst., Jun., pp. 394-399; Lemieux, J., Ma, Y., Vehicle speed prediction using deep learning (2015) Proc. Ieee Vehicle Power Propuls. Conf. (VPPC), Oct., pp. 1-5; Sun, C., Hu, X., Moura, S.J., Sun, F., Velocity predictors for predictive energy management in hybrid electric vehicles (2015) Ieee Trans. Control Syst. Technol., 23 (3), pp. 1197-1204. , May; Sun, C., Sun, F., He, H., Investigating adaptive-ECMS with velocity forecast ability for hybrid electric vehicles (2017) Appl. Energy, 185, pp. 1644-1653. , https://www.sciencedirect.com/science/article/pii/S0306261916301490, Jan., [Online]; Park, J., Li, D., Murphey, Y.L., Kristinsson, J., McGee, R., Kuang, M., Phillips, T., Real time vehicle speed prediction using a neural network traffic model (2011) Proc. Int. Joint Conf. Neural Netw, pp. 2991-2996. , http://ieeexplore.ieee.org/document/6033614/, Jul., [Online]; Vlahogianni, E.I., Golias, J.C., Karlaftis, M.G., Short-term traffic forecasting: Overview of objectives and methods (2004) Transp. Rev., 24 (5), pp. 533-557. , http://www.tandfonline.com/doi/abs/10.1080/0144164042000195072, Sep., [Online]; Vlahogianni, E.I., Karlaftis, M.G., Golias, J.C., Short-term traffic forecasting: Where we are and where we're going (2014) Transp. Res. C, Emerg. Technol., 43, pp. 3-19. , Jun; Liu, R., Xu, S., Park, J., Murphey, Y.L., Kristinsson, J., McGee, R., Kuang, M., Phillips, T., Real time vehicle speed predition using gas-kinetic traffic modeling (2011) Proc. Ieee Symp. Comput. Intell. Vehicles Transp. Syst. (CIVTS), Apr., pp. 80-86. , http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5949536, [Online]; Filev, D.P., Kolmanovsky, I., A generalized Markov chain modeling approach for on board applications (2010) Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-8. , http://ieeexplore.ieee.org/document/5596713/, Jul., [Online]; Jing, J., Kurt, A., Ozatay, E., Michelini, J., Filev, D., Ozguner, U., Vehicle speed prediction in a convoy using V2V communication (2015) Proc. Ieee 18th Int. Conf. Intell. Transp. Syst. (ITSC), Sep., pp. 2861-2868; Liu, K., Asher, Z.D., Gong, X., Huang, M., Kolmanvsky, I., Vehicle Velocity Prediction and Energy Management Strategy Part 1: Deterministic and Stochastic Vehicle Velocity Prediction Using Machine Learning, pp. 1-10. , SAE Techinical Paper 2019-01-1051, Apr. 2019; Filev, D.P., Kolmanovsky, I., Generalized Markov models for real-time modeling of continuous systems (2014) Ieee Trans. Fuzzy Syst., 22 (4), pp. 983-998. , http://ieeexplore.ieee.org/document/6588289/, Aug., [Online]; Kolmanovsky, I., Siverguina, I., Lygoe, B., Optimization of powertrain operating policy for feasibility assessment and calibration: Stochastic dynamic programming approach (2002) Proc. Amer. Control Conf., 2, pp. 1425-1430. , http://ieeexplore, May, [Online]. Available, ieee.org/document/1023221/; Karbowski, D., Kim, N., Rousseau, A., Route-based online energy management of a PHEV and sensitivity to trip prediction (2014) Proc. Ieee Vehicle Power Propuls. Conf. (VPPC), Oct., pp. 1-6. , http://ieeexplore.ieee.org/document/7007126/, [Online]; Jing, J., Filev, D., Kurt, A., Ozatay, E., Michelini, J., Ozguner, U., Vehicle speed prediction using a cooperative method of fuzzy Markov model and auto-regressive model (2017) Proc. Ieee Intell. Vehicles Symp. (IV), Jun., pp. 881-886. , http://ieeexplore.ieee.org/document/7995827/, [Online]; Liu, T., Hu, X., Li, S.E., Cao, D., Reinforcement learning optimized look-ahead energy management of a parallel hybrid electric vehicle (2017) IEEE/ASME Trans. Mechatronics, 22 (4), pp. 1497-1507. , http://ieeexplore.ieee.org/document/7932983/, Aug., [Online]; Shin, J., Sunwoo, M., Vehicle speed prediction using a Markov chain with speed constraints (2019) Ieee Trans. Intell. Transp. Syst., 20 (9), pp. 3201-3211. , https://ieeexplore.ieee.org/document/8534379/, Sep., [Online]; Shin, J., Kim, S., Sunwoo, M., Han, M., Ego-vehicle speed prediction using fuzzy Markov chain with speed constraints (2019) Proc. 4th Ieee Intell. Vehicles Symp., Jun., pp. 1849-1855; Han, S., Zhang, F., Xi, J., Ren, Y., Xu, S., Short-term vehicle speed prediction based on convolutional bidirectional LSTM networks (2019) Proc. Ieee Intell. Transp. Syst. Conf. (ITSC), pp. 4055-4060. , Piscataway, NJ, USA: Institute of Electrical and Electronics Engineers, Oct; Fu, R., Zhang, Z., Li, L., Using LSTM and GRU neural network methods for traffic flow prediction (2016) Proc. 31st Youth Academic Annu. Conf. Chin. Assoc. Autom. (YAC), pp. 324-328. , Nov; Li, J., Li, T., Zhang, Y., Xiang, J., Xu, D., A comparative study on lane-changing decision model using deep learning methods (2019) Proc. Chin. Autom. Congr. (CAC). Piscataway, NJ, USA: Institute of Electrical and Electronics Engineers, pp. 1519-1523. , Nov; Yang, X., Zou, Y., Tang, J., Liang, J., Ijaz, M., Evaluation of short-term freeway speed prediction based on periodic analysis using statistical models and machine learning models (2020) J. Adv. Transp., 2020, pp. 1-16. , Jan; Yu, K., Yang, H., Tan, X., Kawabe, T., Guo, Y., Liang, Q., Fu, Z., Zheng, Z., Model predictive control for hybrid electric vehicle platooning using slope information (2016) Ieee Trans. Intell. Transp. Syst., 17 (7), pp. 1894-1909. , Jul; Abbas, M.A., Milman, R., Eklund, J.M., Obstacle avoidance in real time with nonlinear model predictive control of autonomous vehicles (2017) Can. J. Elect. Comput. Eng., 40 (1), pp. 12-22. , Dec; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, , http://arxiv.org/abs/1412.3555, Dec., [Online]; Lin, C.-C., Peng, H., Grizzle, J.W., A stochastic control strategy for hybrid electric vehicles (2004) Proc. Amer. Control Conf., 5, pp. 4710-4715. , https://ieeexplore.ieee.org/document/1384056/, Jun., [Online]; Liu, J., Peng, H., Modeling and control of a power-split hybrid vehicle (2008) Ieee Trans. Control Syst. Technol., 16 (6), pp. 1242-1251. , http://ieeexplore.ieee.org/document/4475524/, Nov., [Online]; Stockar, S., Marano, V., Canova, M., Rizzoni, G., Guzzella, L., Energy-optimal control of plug-in hybrid electric vehicles for real-world driving cycles (2011) Ieee Trans. Veh. Technol., 60 (7), pp. 2949-2962. , Sep; Kim, J., Jo, K., Lim, W., Lee, M., Sunwoo, M., Curvilinear-coordinate-based object and situation assessment for highly automated vehicles (2015) Ieee Trans. Intell. Transp. Syst., 16 (3), pp. 1559-1575. , http://ieeexplore.ieee.org/document/7012068/, Jun., [Online]; Wang, H., Kearney, J., Atkinson, K., Robust and efficient computation of the closest point on a spline curve (2002) Proc. 5th Int. Conf. Curves Surfaces, pp. 397-405. , Aug; Jo, K., Sunwoo, M., Generation of a precise roadway map for autonomous cars (2014) Ieee Trans. Intell. Transp. Syst., 15 (3), pp. 925-937. , Jun; Lim, H., Su, W., Mi, C.C., Distance-based ecological driving scheme using a two-stage hierarchy for long-term optimization and short-term adaptation (2017) Ieee Trans. Veh. Technol., 66 (3), pp. 1940-1949. , http://ieeexplore.ieee.org/document/7491340/, Mar., [Online]; Jang, C., Sunwoo, M., Semantic segmentation-based parking space detection with standalone around view monitoring system (2019) Mach. Vis. Appl., 30 (2), pp. 309-319. , Mar; Ozatay, E., Ozguner, U., Michelini, J., Filev, D., Analytical solution to the minimum energy consumption based velocity profile optimization problem with variable road grade (2014) Ifac, 19 (3), pp. 7541-7546. , Aug; Lipton, Z.C., Berkowitz, J., Elkan, C., (2015) A Critical Review of Recurrent Neural Networks for Sequence Learning, , http://arxiv.org/abs/1506.00019, Oct., [Online]; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proc. Ieee Int. Conf. Acoust., Speech Signal Process., May, pp. 6645-6649; Dey, R., Salem, F.M., Gate-variants of gated recurrent unit (GRU) neural networks (2017) Proc. Ieee 60th Int. Midwest Symp. Circuits Syst. (MWSCAS), Aug., pp. 1597-1600; Pascanu, R., Mikolov, T., Bengio, Y., On the difficulty of training recurrent neural networks (2013) Proc. 30th Int. Conf. Mach. Learn. (ICML), pp. 2347-2355. , http://arxiv.org/abs/1211.5063, Nov., [Online]; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780. , Dec; Yeon, K., Min, K., Shin, J., Sunwoo, M., Han, M., Ego-vehicle speed prediction using a long short-term memory based recurrent neural network (2019) Int. J. Automot. Technol., 20 (4), pp. 713-722. , Aug; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with LSTM (2000) Neural Comput., 12 (10), pp. 2451-2471. , Oct; Jozefowicz, R., Zaremba, W., Sutskever, I., An empirical exploration of recurrent network architectures (2015) Proc. 32nd Int. Conf. Mach. Learn. (ICML), 3, pp. 2332-2340. , Jul; Cho, K., Van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014) Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1724-1734. , https://www.aclweb.org/anthology/D14-1179, [Online]; Ilievski, I., Akhtar, T., Feng, J., Shoemaker, C.A., Efficient hyperparameter optimization of deep learning algorithms using deterministic RBF surrogates (2017) Proc. 31st Aaai Conf. Artif. Intell, pp. 822-829. , Feb","Han, M.; Department of Mechanical and Automotive Engineering, South Korea; email: mbhan2002@kmu.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85100793877
"Geng X.","57221911254;","Research on athlete's action recognition based on acceleration sensor and deep learning",2021,"Journal of Intelligent and Fuzzy Systems","40","2",,"2229","2240",,3,"10.3233/JIFS-189221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100544457&doi=10.3233%2fJIFS-189221&partnerID=40&md5=bfe94e07cdf7a7b1da26a88b49791750","Department of Physical Education, Chang'An University, Xi'an, Shaanxi, China","Geng, X., Department of Physical Education, Chang'An University, Xi'an, Shaanxi, China","Due to the difficulty of athletes' motion recognition, there are few studies on athletes' specific motion recognition. Based on this, this study uses the acceleration sensor as the carrier, and uses human-computer interaction to transform the action of the athlete into a machine-identifiable action unit. At the same time, this paper combines the actual situation of human body motion to construct a human body motion model and builds a corresponding computer hardware and software platform. Moreover, this paper designs a classification recognition algorithm that can recognize the movement of athletes and builds SVM model based on machine learning for classification and recognition. In addition, in this study, the effectiveness of the algorithm was studied through experimental comparison. Finally, the simulation analysis was carried out to obtain the corresponding research results, and the results were analyzed by combing statistics. The research shows that the proposed algorithm can classify and recognize the collected motion data, and it has certain effects on the theoretical analysis of athletes' motion recognition. Moreover, the algorithm can perform motion quality analysis and provide theoretical reference for subsequent related research. © 2021-IOS Press. All rights reserved.","Acceleration sensor; machine learning; motion recognition; SVM model","Biomechanics; Computer hardware; Deep learning; Human computer interaction; Quality control; Sports; Support vector machines; Turing machines; Acceleration sensors; Action recognition; Classification and recognition; Experimental comparison; Hardware and software; Motion recognition; Recognition algorithm; Simulation analysis; Motion estimation",,,,,,,,,,,,,,,,"Lun, R., Zhao, W., A survey of applications and human motion recognition with microsoft kinect (2015) International Journal of Pattern Recognition and Artificial Intelligence, 29 (5), p. 1555008; Park, R.C., Jung, H., Shin, D.K., M2M-based smart health service for human UI/UX using motion recognition (2015) Cluster Computing, 18 (1), pp. 221-232; Theusner, S., De, L.M., Lappe, M., Action recognition by motion detection in posture space (2014) Journal of Neuroscience the Official Journal of the Society for Neuroscience, 34 (3), pp. 909-921; Fang, Y., Liu, H., Li, G., A Multichannel Surface EMG System for Hand Motion Recognition (2015) International Journal of Humanoid Robotics, 12 (2), p. 1550011; Mane, S.M., Kambli, R.A., Kazi, F.S., Hand motion recognition from single channel surface emg using wavelet & artificial neural network (2015) Procedia Computer Science, 49 (5), pp. 58-65; Hu, F., Hao, Q., Sun, Q., Cyberphysical System with Virtual Reality for Intelligent Motion Recognition and Training (2016) IEEE Transactions on Systems, Man, and Cybernetics: Systems, 45 (12), pp. 1-17; Narang, S., Best, A., Feng, A., Motion recognition of self and others on realistic 3D avatars (2017) Computer Animation & Virtual Worlds, 28 (34), pp. 78-83; Xiang, J., Liang, R., Motion recognition and synthesis based on 3D sparse representation (2015) Signal Processing, 110, pp. 82-93; Choi, C.H., Joo, H.J., Motion recognition technology based remote Taekwondo Poomsae evaluation system (2016) Multimedia Tools & Applications, 75 (21), pp. 13135-13148; Yingzhou, H., Yalu, C., Jingjing, Z., A Self-Powered Insole for Human Motion Recognition (2016) Sensors, 16 (9), pp. 1502-1511; Yang, D., Gu, Y., Liu, R., Dexterous motion recognition for myoelectric control of multifunctional transradial prostheses (2014) Advanced Robotics, 28 (22), pp. 11-14; Hachaj, T., Ogiela, M.R., The adaptation of GDL motion recognition system to sport and rehabilitation techniques analysis (2016) Journal of Medical Systems, 40 (6), pp. 137-145; Kim, J., Jung, H., Kang, M., 3D Human-Gesture Interface for Fighting Games Using Motion Recognition Sensor (2016) Wireless Personal Communications, 89 (3), pp. 927-940; Oh, B.H., Kim, J.H., Chung, K.W., Multiuser motion recognition system using smartphone LED luminescence (2015) Electronics Letters, 51 (5), pp. 388-390; Yuting, Y., Dingna, D., Huan, Z., Motion Recognition Based on Hidden Markov Model with Improved Brain Storm Optimization (2015) Space Medicine & Medical Engineering, 48 (7), pp. 1274-1287; Cai, M., Zou, B., Gao, H., Motion recognition for 3D human motion capture data using support vector machines with rejection determination (2014) Multimedia Tools & Applications, 70 (2), pp. 1333-1362; Cheng, X., Jie, H., Xiaotong, Z., Recurrent Transformation of Prior Knowledge Based Model for Human Motion Recognition (2018) Computational Intelligence and Neuroscience, 20 (8), pp. 1-12; Wu, Q., Shao, J., Wu, X., Upper Limb Motion Recognition Based on LLE-ELM Method of sEMG (2017) International Journal of Pattern Recognition and Artificial Intelligence, 31 (6), p. 1750018; Chiang, H., Lai, C., Lai, Y., A sensor-based feet motion recognition of graphical user interface controls (2016) Multimedia Tools and Applications, 75 (22), pp. 14125-14141; Kim, J., Chung, D., Ko, I., A climbing motion recognition method using anatomical information for screen climbing games (2017) Human-centric Computing and Information Sciences, 7 (1), pp. 25-32; Guo, Y., Li, Y., Shao, Z., RRV: A Spatiotemporal Descriptor for Rigid Body Motion Recognition (2018) IEEE Transactions on Cybernetics, 48 (5), pp. 1513-1525; Maolin, L., Huaiyu, L., Yuan, W., Double-Windows-Based Motion Recognition in Multi-Floor Buildings Assisted by a Built-In Barometer (2018) Sensors, 18 (4), pp. 1061-1074; Tariq, M.I., An Analysis of the Application of Fuzzy Logic in Cloud Computing (2020) Journal of Intelligent & Fuzzy Systems, 38 (5), pp. 5933-5947; Zhou, H., You, M., Liu, L., Sequential data feature selection for human motion recognition via Markov blanket (2017) Pattern Recognition Letters, 86, pp. 18-25; Xu, H.C., The Image Segmentation Algorithm of Colorimetric Sensor Array Based on Fuzzy C-means Clustering (2020) Journal of Intelligent & Fuzzy Systems, 38 (4), pp. 3605-3613; Yu, J., Sun, J., Liu, S., Multi-Activity 3D human motion recognition and tracking in composite motion model with synthesized transition bridges (2017) Multimedia Tools and Applications, 23 (8), pp. 55-62; Yang, X., Sun, X., Zhou, D., Towards Wearable Amode Ultrasound Sensing for Real-Time Finger Motion Recognition (2018) IEEE Transactions on Neural Systems and Rehabilitation Engineering, 44 (12), pp. 12-21","Geng, X.; Department of Physical Education, China; email: tendenr@126.com",,,"IOS Press BV",,,,,10641246,,,,"English","J. Intelligent Fuzzy Syst.",Article,"Final","",Scopus,2-s2.0-85100544457
"Goel A., Aghajanzadeh S., Tung C., Chen S.-H., Thiruvathukal G.K., Lu Y.-H.","57235031500;57202979240;57208723935;56739498200;6601955304;7405476074;","Modular Neural Networks for Low-Power Image Classification on Embedded Devices",2021,"ACM Transactions on Design Automation of Electronic Systems","26","1","1","","",,,"10.1145/3408062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099081379&doi=10.1145%2f3408062&partnerID=40&md5=3cbd29ceab4979561d4299d4af09f472","Purdue University, United States; National Taipei University of Technology, China; Loyola University Chicago, Chicago, United States","Goel, A., Purdue University, United States; Aghajanzadeh, S., Loyola University Chicago, Chicago, United States; Tung, C., Purdue University, United States; Chen, S.-H., National Taipei University of Technology, China; Thiruvathukal, G.K., Purdue University, United States; Lu, Y.-H., Purdue University, United States","Embedded devices are generally small, battery-powered computers with limited hardware resources. It is difficult to run deep neural networks (DNNs) on these devices, because DNNs perform millions of operations and consume significant amounts of energy. Prior research has shown that a considerable number of a DNN's memory accesses and computation are redundant when performing tasks like image classification. To reduce this redundancy and thereby reduce the energy consumption of DNNs, we introduce the Modular Neural Network Tree architecture. Instead of using one large DNN for the classifier, this architecture uses multiple smaller DNNs (called modules) to progressively classify images into groups of categories based on a novel visual similarity metric. Once a group of categories is selected by a module, another module then continues to distinguish among the similar categories within the selected group. This process is repeated over multiple modules until we are left with a single category. The computation needed to distinguish dissimilar groups is avoided, thus reducing redundant operations, memory accesses, and energy. Experimental results using several image datasets reveal the effectiveness of our proposed solution to reduce memory requirements by 50% to 99%, inference time by 55% to 95%, energy consumption by 52% to 94%, and the number of operations by 15% to 99% when compared with existing DNN architectures, running on two different embedded systems: Raspberry Pi 3 and Raspberry Pi Zero. © 2020 ACM.","image classification; Low-power","Deep neural networks; Embedded systems; Energy utilization; Image classification; Low power electronics; Memory architecture; Network architecture; Battery powered; Embedded device; Hardware resources; Image datasets; Memory access; Memory requirements; Modular neural networks; Visual similarity; Neural networks",,,,,"National Science Foundation, NSF: CNS-1925713, OAC-1535108, OAC-1747694; Intel Corporation; Argonne National Laboratory, ANL; Google","This project was supported in part by NSF OAC-1747694, OAC-1535108, CNS-1925713, Google, Facebook, Intel, and Argonne National Laboratory. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors. Authors’ addresses: A. Goel, S. Aghajanzadeh, C. Tung, and Y.-H. Lu, Purdue University, MSEE 222, School of Electrical and Computer Engineering, Materials and Electrical Engineering Building, 501 Northwestern Ave., West Lafayette, Indiana 47907-2035; emails: {goel39, saghajan, tung3, yunglu}@purdue.edu; S.-H. Chen, Department of Computer Science and Information Engineering, National Taipei University of Technology, Room 331, Technology Building, 1, Sec. 3, Chung-Hsiao E. Rd., Taipei 106, Taiwan, Republic of China; email: qoolili@iis.sinica.edu.tw; G. K. Thiruvathukal, Loyola University Chicago, Doyle 301, Doyle Center, Lake Shore Campus, 1052 W Loyola Ave, Chicago, IL 60626; email: gkt@cs.luc.edu. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2020 Association for Computing Machinery. 1084-4309/2020/10-ART1 $15.00 https://doi.org/10.1145/3408062",,,,,,,,,,"Mohan, A., Internet of video things in 2030: A world with many cameras (2017) Proceedings of Ieee Iscas 2017, pp. 1-4; Han, S., Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding (2015) ArXiv 1510.00149 [Cs]; Zhao, H., Thermal-sensor-based occupancy detection for smart buildings using machine-learning methods (2018) Acm Transactions on Design Automation of Electronic Systems, 23 (4). , 2018 Article 54 21; Huang, H., Distributed machine learning on smart-gateway network toward real-Time smart-grid energy management with behavior cognition (2018) Acm Transactions on Design Automation of Electronic Systems, 23 (5), pp. 1-26. , 2018; Aghajanzadeh, S., Camera placement meeting restrictions of computer vision (2020) Proceedings of Ieee Icip 2020; Lu, Y., Low-power image recognition. Nature Machine Intelligence (2019), 1 (4), p. 199. , 2019; He, K., Deep residual learning for image recognition (2016) Proceedings of Ieee Cvpr 2016, pp. 770-778; Amir, M., Switching predictive control using reconfigurable state-basedmodel (2018) ACMTransactions on Design Automation of Electronic Systems, 24 (1), p. 21. , 2018, Article 2; Fallahzadeh, R., Trading off power consumption and prediction performance in wearable motion sensors: An optimal and real-Time approach (2018) Acm Transactions on Design Automation of Electronic Systems, 23 (5), p. 23. , 2018), Article 67; Anup, S., Visual positioning system for automated indoor/outdoor navigation (2017) Proceedings of Ieee Tencon 2017; Alyamkin, S., Low-power computer vision: Status, challenges, and opportunities (2019) Ieee Journal on Emerging and Selected Topics in Circuits and Systems, 9 (2), pp. 411-421. , 2019; Gauen, K., Three years of low-power image recognition challenge (2018) Proceedings of Ieee Date 2018; Simonyan, K., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , ArXiv 1409.1556 [cs]; Cheng, Y., An exploration of parameter redundancy in deep networks with circulant projections (2015) Proceedings of Ieee Iccv 2015; Goel, A., (2019) Modular Neural Networks, , https://github.com/abhinavgoel95/Modular_Neural_Networks, Retrieved August 8, 2020; Ghodgaonkar, I., (2020) Observing Responses to the COVID-19 Pandemic Using Worldwide Network Cameras, , ArXiv 2005 09091; Szegedy, C., Deep neural networks for object detection (2013) Proceedings of Advances in NeurIPS, 2013, pp. 2553-2561; Quinlan, J.R., Induction of decision trees (1986) Machine Learning, 1 (1), pp. 81-106. , 1986; Cover, T., Nearest neighbor pattern classification (1967) Ieee Transactions on Information Theory, 13 (1), pp. 21-27. , 1967; Friedman, N., Bayesian network classifiers (1997) Machine Learning, 29, pp. 131-163. , 1997; Kaski, S., Dimensionality reduction by random mapping: Fast similarity computation for clustering (1998) Proceedings of Ieee Ijcnn 1998 and Ieee WCCI1998, 1, pp. 413-418; Huang, G., Condensenet: An efficient densenet using learned group convolutions (2018) Proceedings of Ieee Cvpr 2018; Bianco, S., Benchmark analysis of representative deep neural network architectures (2018) Ieee Access, 6, pp. 64270-64277. , 2018; Goel, A., A survey of methods for low-power deep learning and computer vision (2020) Proceedings of Ieee WF-IoT 2020; Rastegari, M., XNOR-Net: ImageNet classification using binary convolutional neural networks (2016) Proceedings of Eccv, 2016, pp. 525-542; Albalawi, H., Training fixed-point classifiers for on-chip low-power implementation (2017) Acm Transactions on Design Automation of Electronic Systems, 4 (22), pp. 691-6918. , 2017; Li, H., (2016) Pruning Filters for Efficient ConvNets, , ArXiv 1608.08710; Goel, A., CompactNet: High accuracy deep neural network optimized for on-chip implementation (2018) Proceedings of Ieee Big Data2018; Jiang, L., Energy-efficient and quality-Assured approximate computing framework using a co-Training method (2019) Acm Transactions on Design Automation of Electronic Systems, 24 (6), p. 25. , 2019, Article 59; Iandola, F.N., (2016) SqueezeNet: AlexNet-level Accuracy with 50x Fewer Parameters and 0.5 Mb Model Size, , ArXiv 1602.07360; Sandler, M., MobileNetV2: Inverted residuals and linear bottlenecks (2018) Proceedings of Ieee Cvpr 2018, pp. 4510-4520; Szegedy, C., Inception-v4, Inception-ResNet and the impact of residual connections on learning (2017) Proceedings of Acm Aaai 2017, pp. 4278-4284; Sironi, A., Learning separable filters (2015) Ieee Transactions on Pattern Analysis and Machine Intelligence, 37, pp. 94-106. , 2015; Denton, E., Exploiting linear structurewithin convolutional networks for efficient evaluation (2014) Proceedings of Advances in NeurIPS, 2014, pp. 1269-1277; Jaderberg, M., (2014) Speeding up Convolutional Neural Networks with Low Rank Expansions, , ArXiv 1405.3866; Zhong, G., Synergy: An HW/SW framework for high throughput CNNs on embedded heterogeneous SoC (2019) Acm Transactions on Embedded Computing Systems, 18 (2), p. 23. , 2019, Article 13; Li, J., SynergyFlow: An elastic accelerator architecture supporting batch processing of large-scale deep neural networks (2018) Acm Transactions on Design Automation of Electronic Systems, 24 (1), pp. 1-27. , 2018; Cheng, Y., (2017) A Survey of Model Compression and Acceleration for Deep Neural Networks, , ArXiv 1710.09282; Hinton, G., (2015) Distilling the Knowledge in a Neural Network, , ArXiv 1503.02531 [cs, stat]; Ba, J., Do deep nets really need to be deep? (2014) Proceedings of Advances in NeurIPS, 2014, pp. 2654-2662; Guerin, J., (2017) Cnn Features Are Also Great at Unsupervised Classification, , ArXiv 1707.01700; Di Gesu, V., Distance-based functions for image comparison (1999) Pattern Recognition Letters, 20, pp. 207-214. , 1999; Zhang, R., Bit-scalable deep hashing with regularized similarity learning for image retrieval and person re-identification (2015) Ieee Transactions on Image Processing, 24 (12), pp. 4766-4779. , 2015; Zhu, H., Deep hashing network for efficient similarity retrieval (2016) Proceedings of Aaai, 2016, pp. 2415-2421; Griffin, G., Learning and using taxonomies for fast visual categorization (2008) Proceedings of Ieee Cvpr 2008, pp. 1-8; Deng, J., Fast and balanced: Efficient label tree learning for large scale object recognition (2011) Proceedings of Advances in NeurIPS, 2011; Beygelzimer, A., Conditional probability tree estimation analysis and algorithms (2009) Proceedings of Acm Uai 2009, pp. 51-58; Yuan, X., Automatic video genre categorization using hierarchical SVM (2006) Proceedings of Icip, 2006, pp. 2905-2908; Rastegari, M., Attribute discovery via predictable discriminative binary codes (2012) Proceedings of Eccv, 2012, pp. 876-889; Panda, P., FALCON: Feature driven selective classification for energy-efficient image recognition (2017) Ieee Transactions on Computer-Aided Design of Integrated Circuits and Systems, 36 (12), pp. 2017-2029. , 2017; Torralba, A., 80 million tiny images: A large data set for nonparametric object and scene recognition (2008) Ieee Transactions on Pattern Analysis and Machine Intelligence, 30, pp. 1958-1970. , 2008; Redmon, J., (2016) YOLO9000: Better, Faster, Stronger, , ArXiv 1612.08242; Zweig, A., Exploiting object hierarchy: Combining models from different category levels (2007) Proceedings of Ieee Iccv 2007; Peluso, V., Scalable-effort ConvNets for multilevel classification (2018) Proceedings of IEEE/ACM Iccad 2018, pp. 1-8; Chen, S., Discriminative hierarchical k-means tree for large-scale image classification (2015) Ieee Transactions on Neural Networks and Learning Systems, 26 (9), pp. 2200-2205. , 2015; Marszalek, M., Constructing category hierarchies for visual recognition (2008) Proceedings of Eccv 2008, 5305, pp. 479-491; Lukic, Y., Speaker identification and clustering using convolutional neural networks (2016) Proceedings of Ieee Mlsp 2016. IEEE, Los Alamitos, Ca, pp. 1-6; Jain, A.K., Object detection using Gabor filters (1997) Pattern Recognition, 30, pp. 295-309. , 1997; Levkowitz, H., GLHS: A generalized lightness, hue, and saturation color model (1993) CVGIP: Graphical Models and Image Processing, 55, pp. 271-285. , 1993; Qu, Y., Joint hierarchical category structure learning and large-scale image classification (2017) Ieee Transactions on Image Processing, 26 (9), pp. 4331-4346. , 2017; Miller, G.A., WordNet: A lexical database for English (1995) Communications of the Acm, 1995 (38), pp. 39-41; Xia, R., Supervised hashing for image retrieval via image representation learning (2014) Proceedings of Aaai, 2014, pp. 2156-2162; Shen, F., Unsupervised deep hashing with similarity-Adaptive and discrete optimization (2018) Ieee Transactions on Pattern Analysis and Machine Intelligence, 40 (12), pp. 3034-3044. , 2018; Wang, J., Semi-supervised hashing for scalable image retrieval (2010) Proceedings of Ieee Cvpr, 2010, pp. 3424-3431; Wang, Z., Learning fine-grained features via a CNN tree for large-scale classification (2018) Neurocomputing, 275, pp. 1231-1240. , 2018; Roy, D., (2018) Tree-CNN: A Hierarchical Deep Convolutional Neural Network for Incremental Learning, , ArXiv 1802 05800; Sun, M., Find the best path: An efficient and accurate classifier for image hierarchies (2013) Proceedings of Ieee Iccv, 2013, pp. 265-272; Guo, Y., Dynamic network surgery for efficient DNNs (2016) Proceedings of Advances in of NeurIPS, 2016, pp. 1379-1387; Zadeh, L.A., Fuzzy sets (1965) Information and Control, 8 (3), pp. 338-353. , 1965; Singpurwalla, N.D., Membership functions and probability measures of fuzzy sets (2004) Journal of the American Statistical Association, 99, pp. 867-889. , 2004; Tan, M., EfficientNet: Rethinking model scaling for convolutional neural networks (2019) Proceedings of Icml, pp. 6105-6114; Kontschieder, P., Deep neural decision forests (2015) Proceedings of Iccv, 2015, pp. 1467-1475; Roy, A., Monocular depth estimation using neural regression forest (2016) Proceedings of Ieee Cvpr, 2016, pp. 5506-5514; Huang, G., Densely connected convolutional networks (2017) Proceedings of Ieee Cvpr, 2017; Krizhevsky, A., Learning multiple layers of features from tiny images (2009) Technical Report TR-2009, , University of Toronto; Netzer, Y., Reading digits in natural images with unsupervised feature learning (2011) Proceedings of the NeurIPS 2011 Workshop on Deep Learning and Unsupervised Feature Learning; Cohen, G., (2017) EMNIST: An Extension of Mnist to Handwritten Letters, , ArXiv 1702.05373; Deng, J., ImageNet: A large-scale hierarchical image database (2009) Proceedings of Ieee Cvpr, 2009, pp. 248-255; Griffin, G., (2007) Caltech-256 Object Category Dataset, , http://authors.library.caltech.edu/7694, Technical Report; (2017) WT310E/TW310EH/WT332E/WT333E Digital Power Meter: User?s Manual, , https://cdn.tmi.yokogawa.com/IMWT310E-01EN.pdf, Retrieved August 9, 2020 from Yokogawa; (2019) Torch.utils.data, , https://pytorch.org/docs/stable/data.html, PyTorch. Retrieved August 9, 2020 from; Canziani, A., (2016) An Analysis of Deep Neural Network Models for Practical Applications, , ArXiv 1605.07678; Chen, B., (2018) Introducing the Cvpr 2018 On-Device Visual Intelligence Challenge, , http://ai.googleblog.com/2018/04/introducing-cvpr-2018-on-device-visual.html, Google AI Blog. Retrieved August 9, 2020 from; Mordvintsev, A., (2013) Getting Started with Videos: OpenCV-Python Documentation, , https://opencv-python-Tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html, Retrieved August 9, 2020 from; Kingma, D.P., (2014) Adam: A Method for Stochastic Optimization, , ArXiv 1412.6980; Goel, A., (2019) Image Classification with the Modular Neural Network Tree, , https://youtu.be/gdae-v-ZyVs, Retrieved August 9, 2020 from; Zagoruyko, S., (2016) Wide Residual Networks, , ArXiv 1605.07146; Dufourq, E., EDEN: Evolutionary deep networks for efficient machine learning (2017) Proceedings of PRASARobMech, 2017; Hastie, T., (2001) The Elements of Statistical Learning, , Springer; Jiang, J.J., Semantic similarity based on corpus statistics and lexical taxonomy (1997) Proceedings of Rocling, 1997, pp. 19-33; Selvaraju, R.R., Grad-CAM: Visual explanations from deep networks via gradient-based localization (2016) ArXiv 1610.02391; Krizhevsky, A., ImageNet classification with deep convolutional neural networks (2012) Proceedings of NeurIPS, 2012; Gondimalla, A., SparTen: A sparse tensor accelerator for convolutional neural networks (2019) Proceedings of ACM/ Ieee Micro, 2019, pp. 151-165; Albericio, J., Cnvlutin: Ineffectual-neuron-free deep neural network computing (2016) Proceedings of ACM/ Ieee Isca, 2016; Parashar, A., SCNN: An accelerator for compressed-sparse convolutional neural networks (2017) Proceedings of Acm Isca, 2017",,,,"Association for Computing Machinery",,,,,10844309,,,,"English","ACM Trans. Design Autom. Electron. Syst.",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85099081379
"Sun Y., Amano H.","57213516676;7201933332;","FiC-RNN: A multi-FPGA acceleration framework for deep recurrent neural networks",2020,"IEICE Transactions on Information and Systems","E103D","12",,"2457","2462",,8,"10.1587/transinf.2020PAP0003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097863878&doi=10.1587%2ftransinf.2020PAP0003&partnerID=40&md5=0b36367b58d457d48768b4020884cff8","Dept. of Information and Computer Science, Keio University, Yokohama-shi, 223-8522, Japan","Sun, Y., Dept. of Information and Computer Science, Keio University, Yokohama-shi, 223-8522, Japan; Amano, H., Dept. of Information and Computer Science, Keio University, Yokohama-shi, 223-8522, Japan","Recurrent neural networks (RNNs) have been proven effective for sequence-based tasks thanks to their capability to process temporal information. In real-world systems, deep RNNs are more widely used to solve complicated tasks such as large-scale speech recognition and machine translation. However, the implementation of deep RNNs on traditional hardware platforms is inefficient due to long-range temporal dependence and irregular computation patterns within RNNs. This inefficiency manifests itself in the proportional increase in the latency of RNN inference with respect to the number of layers of deep RNNs on CPUs and GPUs. Previous work has focused mostly on optimizing and accelerating individual RNN cells. To make deep RNN inference fast and efficient, we propose an accelerator based on a multi-FPGA platform called Flow-in-Cloud (FiC). In this work, we show that the parallelism provided by the multi-FPGA system can be taken advantage of to scale up the inference of deep RNNs, by partitioning a large model onto several FPGAs, so that the latency stays close to constant with respect to increasing number of RNN layers. For single-layer and four-layer RNNs, our implementation achieves 31x and 61x speedup compared with an Intel CPU. Copyright © 2020 The Institute of Electronics, Information and Communication Engineers","LSTM; Multi-FPGA; Recurrent neural networks","Computer aided language translation; Deep neural networks; Field programmable gate arrays (FPGA); Program processors; Speech recognition; Speech transmission; Hardware platform; Irregular computations; Machine translations; Multi-FPGA system; Real-world system; Recurrent neural network (RNNs); Temporal dependence; Temporal information; Recurrent neural networks",,,,,"JP-MJCR19k1","This work was supported by JST CREST Grant Number JP-MJCR19k1, Japan.",,,,,,,,,,"Elman, J.L., Finding structure in time (1990) COGNITIVE SCIENCE, 14 (2), pp. 179-211; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780. , Nov; Chung, J., Gülçehre, Ç., Cho, K., Bengio, Y., Empirical evaluation of gated recurrent neural networks on sequence modeling (2014) CoRR, , vol.abs/1412.3555; Umuroglu, Y., Fraser, N.J., Gambardella, G., Blott, M., Leong, P., Jahre, M., Vissers, K., Finn: A framework for fast, scalable binarized neural network inference (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, FPGA'17, pp. 65-74; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing fpga-based accelerator design for deep convolutional neural networks (2015) Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, FPGA'15, pp. 161-170; Abdelouahab, K., Pelcat, M., Sérot, J., Berry, F., Accelerating CNN inference on fpgas: A survey (2018) CoRR, , vol.abs/1806.01683; Han, S., Wang, Y., Yang, H., Dally, B.J., Kang, J., Mao, H., Hu, Y., Yao, S., Ese: Efficient speech recognition engine with sparse lstm on fpga (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, FPGA'17, pp. 75-84. , W.(and; Wang, S., Li, Z., Ding, C., Yuan, B., Qiu, Q., Wang, Y., Liang, Y., C-lstm: Enabling efficient lstm using structured compression techniques on fpgas (2018) Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, FPGA'18, pp. 11-20; Gao, C., Neil, D., Ceolini, E., Liu, S.-C., Delbruck, T., Deltarnn: A power-efficient recurrent neural network accelerator (2018) Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, FPGA'18, pp. 21-30; Li, Z., Ding, C., Wang, S., Wen, W., Zhuo, Y., Liu, C., Qiu, Q., Wang, Y., E-rnn: Design optimization for efficient recurrent neural networks in fpgas (2019) 2019 IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 69-80; Sak, H., Senior, A.W., Beaufays, F., Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition (2014) CoRR, , vol.abs/1402.1128; Hannun, A., Deep speech: Scaling up end-to-end speech recognition (2014) CoRR, , vol.abs/1412.5567; Zhang, C., Wu, D., Sun, J., Sun, G., Luo, G., Cong, J., Energy-efficient CNN implementation on a deeply pipelined FPGA cluster (2016) Proceedings of the 2016 International Symposium on Low Power Electronics and Design, ISLPED 2016, pp. 326-331. , San Francisco Airport, CA, USA, Aug. 08 10; Zhang, W., Zhang, J., Shen, M., Luo, G., Xiao, N., An efficient mapping approach to large-scale dnns on multi-fpga architectures (2019) 2019 Design, Automation Test in Europe Conference Exhibition (DATE), pp. 1241-1244; Chung, E., Fowers, J., Accelerating persistent neural networks at datacenter scale (2017) Hot Chips, 29. , Session 6; Musha, K., Kudoh, T., Amano, H., Deep learning on high performance FPGA switching boards: Flow-in-cloud (2018) Applied Reconfigurable Computing. Architectures, Tools, and Applications - 14th International Symposium, , ARC; Sun, Y., Ben Ahmed, A., Amano, H., Acceleration of deep recurrent neural networks with an fpga cluster (2019) Proceedings of the 10th International Symposium on Highly-Efficient Accelerators and Reconfigurable Technologies, HEART, pp. 1-4; Pascanu, R., Gulcehre, C., Cho, K., Bengio, Y., How to construct deep recurrent neural networks (2014) Proceedings of the Second International Conference on Learning Representations (ICLR 2014), , arXiv:1312.6026; Hermans, M., Schrauwen, B., Training and analysing deep recurrent neural networks Advances in Neural Information Processing Systems, 26. , ed. C.J.C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger; Putnam, A., Caulfield, A.M., Chung, E.S., Chiou, D., Constantinides, K., Demme, J., Esmaeilzadeh, H., Burger, D., A reconfigurable fabric for accelerating large-scale datacenter services (2014) Proceeding of the 41st Annual International Symposium on Computer Architecuture, ISCA'14, pp. 13-24; Yamakura, M., Hironaka, K., Azegami, K., Musha, K., Amano, H., The evaluation of partial reconfiguration for a multi-board FPGA system ficsw (2019) Proceedings of the 10th International Symposium on Highly-Efficient Accelerators and Reconfigurable Technologies, HEART, pp. 1-4; Warden, P., Speech commands: A dataset for limited-vocabulary speech recognition (2018) CoRR, , vol.abs/1804.03209; (2018) Vivado Design Suite User Guide High-Level Synthesis, , Xilinx, ug902, Feb; Abadi, M., Tensorflow: A system for large-scale machine learning (2016) 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16); Ito, K., Iizuka, K., Hironaka, K., Hu, Y., Koibuchi, M., Amano, H., Implementing a Multi-ejection Switch and Making the Use of Multiple Lanes in a Circuit switched Multi-FPGA System (2020) CANDAR Workshop","Sun, Y.; Dept. of Information and Computer Science, Japan; email: hikari@am.ics.keio.ac.jp",,,"Institute of Electronics, Information and Communication, Engineers, IEICE",,,,,09168532,,ITISE,,"English","IEICE Trans Inf Syst",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85097863878
"Pham M.T., Kim J.-M., Kim C.H.","57219268800;55850196800;57223773862;","Deep learning-based bearing fault diagnosis method for embedded systems",2020,"Sensors (Switzerland)","20","23","6886","1","15",,13,"10.3390/s20236886","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097271568&doi=10.3390%2fs20236886&partnerID=40&md5=0ee73c28f26329c4d4b1b0681b21b794","School of Electronics and Computer Engineering, Chonnam National University, Gwangju, 61186, South Korea; School of IT Convergence, University of Ulsan, Ulsan, 44610, South Korea; School of Computer Science and Engineering, Soongsil University, Seoul, 06978, South Korea","Pham, M.T., School of Electronics and Computer Engineering, Chonnam National University, Gwangju, 61186, South Korea; Kim, J.-M., School of IT Convergence, University of Ulsan, Ulsan, 44610, South Korea; Kim, C.H., School of Computer Science and Engineering, Soongsil University, Seoul, 06978, South Korea","Bearing elements are vital in induction motors; therefore, early fault detection of rolling-element bearings is essential in machine health monitoring. With the advantage of fault feature representation techniques of time–frequency domain for nonstationary signals and the advent of convolutional neural networks (CNNs), bearing fault diagnosis has achieved high accuracy, even at variable rotational speeds. However, the required computation and memory resources of CNN-based fault diagnosis methods render it difficult to be compatible with embedded systems, which are essential in real industrial platforms because of their portability and low costs. This paper proposes a novel approach for establishing a CNN-based process for bearing fault diagnosis on embedded devices using acoustic emission signals, which reduces the computation costs significantly in classifying the bearing faults. A light state-of-the-art CNN model, MobileNet-v2, is established via pruning to optimize the required system resources. The input image size, which significantly affects the consumption of system resources, is decreased by our proposed signal representation method based on the constant-Q nonstationary Gabor transform and signal decomposition adopting ensemble empirical mode decomposition with a CNN-based method for selecting intrinsic mode functions. According to our experimental results, our proposed method can provide the accuracy for bearing faults classification by up to 99.58% with less computation overhead compared to previous deep learning-based fault diagnosis methods. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Acoustic emission signals; Bearing fault; Convolutional neural network; Embedded systems; Fault diagnosis; Machine health monitoring; Signal decomposition","Acoustic emission testing; Computer aided diagnosis; Convolutional neural networks; Costs; Deep learning; Embedded systems; Failure analysis; Frequency domain analysis; Induction motors; Learning systems; Roller bearings; Signal processing; Structures (built objects); Acoustic emission signal; Bearing fault diagnosis; Ensemble empirical mode decomposition; Intrinsic Mode functions; Machine health monitoring; Nonstationary Gabor transforms; Rolling Element Bearing; Signal representations; Fault detection; article; convolutional neural network; deep learning; empirical mode decomposition; Gabor transform; human; intrinsic mode function",,,,,"National Research Foundation of Korea, NRF; Ministry of Science and ICT, South Korea, MSIT","Funding: This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (NRF-2018R1A2B6005740).",,,,,,,,,,"Khan, S.A., Kim, J.-M., Automated Bearing Fault Diagnosis Using 2D Analysis of Vibration Acceleration Signals under Variable Speed Conditions (2016) Shock Vib, 2016, pp. 1-11. , [CrossRef]; Thorsen, O.V., Dalva, M., Failure identification and analysis for high-voltage induction motors in the petrochemical industry (1999) IEEE Trans. Ind. Appl, 35, pp. 810-818. , [CrossRef]; Zhang, R., Peng, Z., Wu, L., Yao, B., Guan, Y., Fault Diagnosis from Raw Sensor Data Using Deep Neural Networks Considering Temporal Coherence (2017) Sensors, 17, p. 549. , [CrossRef] [PubMed]; Sohaib, M., Kim, C.-H., Kim, J.-M., A Hybrid Feature Model and Deep-Learning-Based Bearing Fault Diagnosis (2017) Sensors, 17, p. 2876. , [CrossRef] [PubMed]; Tra, V., Kim, J., Khan, S.A., Kim, J.-M., Incipient fault diagnosis in bearings under variable speed conditions using multiresolution analysis and a weighted committee machine (2017) J. Acoust. Soc. Am, 142, pp. EL35-EL41. , [CrossRef]; Eftekharnejad, B., Carrasco, M.R., Charnley, B., Mba, D., The application of spectral kurtosis on Acoustic Emission and vibrations from a defective bearing (2011) Mech. Syst. Signal Process, 25, pp. 266-284. , [CrossRef]; Widodo, A., Kim, E.Y., Son, J.D., Yang, B.S., Tan, A.C., Gu, D.S., Choi, B.K., Mathew, J., Fault diagnosis of low speed bearing based on relevance vector machine and support vector machine (2009) Expert Syst. Appl, 36, pp. 7252-7261. , [CrossRef]; Pandya, D.H., Upadhyay, S.H., Harsha, S.P., Fault diagnosis of rolling element bearing with intrinsic mode function of acoustic emission data using APF-KNN (2013) Expert Syst. Appl, 40, pp. 4137-4145. , [CrossRef]; Glowacz, A., Glowacz, W., Glowacz, Z., Kozik, J., Early fault diagnosis of bearing and stator faults of the single-phase induction motor using acoustic signals (2018) Measurement, 113, pp. 1-9. , [CrossRef]; Glowacz, A., Fault diagnosis of single-phase induction motor based on acoustic signals (2019) Mech. Syst. Signal Process, 117, pp. 65-80. , [CrossRef]; Tuan, P.M., Kim, J., Kim, C.H., Accurate Bearing Fault Diagnosis under Variable Shaft Speed using Convolutional Neural Networks and Vibration Spectrogram (2020) Appl. Sci, 10, p. 6385; Frosini, L., Bassi, E., Stator Current and Motor Efficiency as Indicators for Different Types of Bearing Faults in Induction Motors (2010) IEEE Trans. Ind. Electron, 57, pp. 244-251. , [CrossRef]; Lau, E.C.C., Ngan, H.W., Detection of Motor Bearing Outer Raceway Defect by Wavelet Packet Transformed Motor Current Signature Analysis (2010) IEEE Trans. Instrum. Meas, 59, pp. 2683-2690. , [CrossRef]; Cipollini, F., Oneto, L., Coraddu, A., Savio, S., Unsupervised Deep Learning for Induction Motor Bearings Monitoring (2019) Data-Enabled Discov. Appl, 3, p. 1. , [CrossRef]; Nguyen, P., Kang, M., Kim, J.-M., Ahn, B.-H., Ha, J.-M., Choi, B.-K., Robust condition monitoring of rolling element bearings using de-noising and envelope analysis with signal decomposition techniques (2015) Expert Syst. Appl, 42, pp. 9024-9032. , [CrossRef]; Kang, M., Kim, J., Kim, J., High-Performance and Energy-Efficient Fault Diagnosis Using Effective Envelope Analysis and Denoising on a General-Purpose Graphics Processing Unit (2015) IEEE Trans. Power Electron, 30, pp. 2763-2776. , [CrossRef]; Zhang, W., Li, C., Peng, G., Chen, Y., Zhang, Z., A deep convolutional neural network with new training methods for bearing fault diagnosis under noisy environment and different working load (2018) Mech. Syst. Signal Process, 100, pp. 439-453. , [CrossRef]; Hasan, M.J., Islam, M.M., Kim, J.M., Acoustic spectral imaging and transfer learning for reliable bearing fault diagnosis under variable speed conditions (2019) Meas. J. Int. Meas. Confed, 138, pp. 620-631. , [CrossRef]; Lecun, Y., Bottou, L., Bengio, Y., Ha, P., LeNet (1998) Proc. IEEE, pp. 1-46. , [CrossRef]; Tra, V., Kim, J., Kim, J.M., (2019) Fault Diagnosis of Bearings with Variable Rotational Speeds Using Convolutional Neural Networks, 759. , Springer: Singapore; Tra, V., Khan, S., Kim, J., Diagnosis of bearing defects under variable speed conditions using energy distribution maps of acoustic emission spectra and convolutional neural networks (2018) J. Acoust. Soc. Am, 144, pp. EL322-EL327. , [CrossRef]; Tan, M., Le, Q.V., EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, , http://arxiv.org/abs/1905.11946, (accessed on 1 May 2019); Zimroz, R., Bartelmus, W., Barszcz, T., Urbanek, J., Wind Turbine Main Bearing Diagnosis—A Proposal of Data Processing and Decision Making Procedure under Non Stationary Load Condition (2012) Key Eng. Mater, 518, pp. 437-444. , [CrossRef]; Wu, Z., Huang, N.E., Ensemble empirical mode decomposition: A noise-assisted data analysis method (2009) Adv. Adapt. Data Anal, 1, pp. 1-41. , [CrossRef]; Velasco, G.A., Holighaus, N., Doerfler, M., Grill, T., Constructing an Invertible Constant-Q Transform with Nonstationary Gabor Frames (2011) Proceedings of the 14th International Conference on Digital Audio Effects (DAFx 11), , Paris, France, 19–23 September; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., MobileNetV2: Inverted Residuals and Linear Bottlenecks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018, , Salt Lake City, UT, USA, 18–23 June; Graney, B., Starry, K., Rolling Element Bearing Analysis (2012) Mater. Eval, 70, pp. 78-85; Gabor, D., Theory of communication. Part 1: The analysis of information (1946) J. Inst. Electr. Eng. Part III Radio Commun. Eng, 93, pp. 429-441. , [CrossRef]; Feichtinger, H., Zimmermann, G., (1998) Gabor Analysis and Algorithms, pp. 123-170. , Birkhäuser: Boston, MA, USA; Holighaus, N., Dörfler, M., Velasco, G.A., Grill, T., A Framework for Invertible, Real-Time Constant-Q Transforms (2013) IEEE Trans. Audio. Speech. Lang. Process, 21, pp. 775-785. , [CrossRef]; Zeiler, A., Faltermeier, R., Keck, I.R., Tome, A.M., Puntonet, C.G., Lang, E.W., Empirical Mode Decomposition—An introduction Proceedings of the 2010 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , Barcelona, Spain, 18–23 July 2010; Fang, K., Zhang, H., Qi, H., Dai, Y., Comparison of EMD and EEMD in rolling bearing fault signal analysis Proceedings of the 2018 IEEE International Instrumentation and Measurement Technology Conference (I2MTC), pp. 1-5. , Houston, TX, USA, 14–17 May 2018; Wu, Z., Huang, N.E., Chen, X., The multi-dimensional ensemble empirical mode decomposition method (2009) Adv. Adapt. Data Anal, 1, pp. 339-372. , [CrossRef]; Choudhary, T., Mishra, V., Goswami, A., Sarangapani, J., A comprehensive survey on model compression and acceleration (2020) Artif. Intell. Rev, 53, pp. 5113-5155. , [CrossRef]; Liu, N., Ma, X., Xu, Z., Wang, Y., Tang, J., Ye, J., AutoCompress: An Automatic DNN Structured Pruning Framework for Ultra-High Compression Rates, , http://arxiv.org/abs/1907.03141, (accessed on 1 July 2019); Yong, H., Huang, J., Hua, X., Zhang, L., Gradient Centralization: A New Optimization Technique for Deep Neural Networks, , http://arxiv.org/abs/2004.01461, (accessed on 1 April 2020); Li, Q., Haque, S., Anil, C., Lucas, J., Grosse, R., Jacobsen, J.-H., Preventing Gradient Attenuation in Lipschitz Constrained Convolutional Networks, , http://arxiv.org/abs/1911.00937, (accessed on 1 November 2019); Pham, M.T., Kim, J.-M., Kim, C.H., Intelligent Fault Diagnosis Method Using Acoustic Emission Signals for Bearings under Complex Working Conditions (2020) Appl. Sci, 10, p. 7068. , [CrossRef]; Kang, M., Islam, M.R., Kim, J., Kim, J., Pecht, M., A Hybrid Feature Selection Scheme for Reducing Diagnostic Performance Deterioration Caused by Outliers in Data-Driven Diagnostics (2016) IEEE Trans. Ind. Electron, 63, pp. 3299-3310. , [CrossRef]; Tra, V., Kim, J., Khan, S.A., Kim, J.M., Bearing fault diagnosis under variable speed using convolutional neural networks and the stochastic diagonal levenberg-marquardt algorithm (2017) Sensors, 17, p. 2834. , [CrossRef]; Raspberry pi 3 Model b, , https://www.raspberrypi.org/products/raspberry-pi-3-model-b/, (accessed on 10 September 2020)","Kim, C.H.; School of Computer Science and Engineering, South Korea; email: cheolhong@ssu.ac.kr",,,"MDPI AG",,,,,14248220,,,"33276483","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85097271568
"Dong S., Zhao P., Lin X., Kaeli D.","57193710077;57201580783;57205018638;7003340827;","Exploring GPU acceleration of Deep Neural Networks using Block Circulant Matrices",2020,"Parallel Computing","100",,"102701","","",,2,"10.1016/j.parco.2020.102701","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094556483&doi=10.1016%2fj.parco.2020.102701&partnerID=40&md5=07ec9b90fa90bcdb53ac1b6045519b92","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA  02115, United States","Dong, S., Department of Electrical and Computer Engineering, Northeastern University, Boston, MA  02115, United States; Zhao, P., Department of Electrical and Computer Engineering, Northeastern University, Boston, MA  02115, United States; Lin, X., Department of Electrical and Computer Engineering, Northeastern University, Boston, MA  02115, United States; Kaeli, D., Department of Electrical and Computer Engineering, Northeastern University, Boston, MA  02115, United States","Training a Deep Neural Network (DNN) is a significant computing task since it places high demands on computing resources and memory bandwidth. Many approaches have been proposed to compress the network, while maintaining high model accuracy, reducing the computational demands associated with large-scale DNN training. One attractive approach is to leverage Block Circulant Matrices (BCM), compressing the linear transformation layers, e.g., convolutional and fully-connected layers, that heavily rely on performing General Matrix Multiplications (GEMM). By using BCMs, we can reduce the weight storage for a linear transformation layer from O(N2) to O(N). BCMs are also more efficient in terms of computational complexity, improving algorithmic complexity from O(N2) to O(Nlog(N)). Previous work has only evaluated DNNs using BCMs targeting FPGAs for inference. There has been little prior work that considers the potential benefits of using BCMs for accelerating DNN training on GPUs. In this paper, we explore acceleration of DNNs using BCM on a state-of-the-art GPU. First, we identify the challenges posed by using BCMs. Next, we perform both general and GPU-specific optimizations that impact: (i) the decomposition and interaction of individual operations, and (ii) the overall GPU kernel design. We modify the algorithmic steps to remove redundant computations, while maintaining mathematical integrity. We also leverage multiple GPU kernel optimizations, considering performance factors, such as occupancy, data sharing/reuse patterns, and memory coalescing. We evaluate the performance of DNN training on an NVIDIA Tesla V100, providing insights into the benefits of our proposed kernel optimizations on a state-of-the-art GPU. Based on our results, we can achieve average speedups of 1.31× and 2.79× for the convolutional layers and fully-connected layers, respectively for AlexNet. We can also achieve average speedups of 1.33× and 3.66× for the convolutional layers and fully-connected layers, respectively for VGGNet-16. © 2020 Elsevier B.V.","Block Circulant Matrix; Deep Neural Network; GPU","Complex networks; Computational complexity; Convolution; Data Sharing; Deep neural networks; Digital storage; Flocculation; Graphics processing unit; Linear transformations; Mathematical transformations; Matrix algebra; Parallel processing systems; Program processors; Algorithmic complexity; Block-circulant matrices; Computational demands; Kernel optimizations; MAtrix multiplication; Performance factors; Potential benefits; Redundant computation; Neural networks",,,,,"1733701; National Science Foundation, NSF","This work was supported by the National Science Foundation, USA [NSF CCF AiF #1733701].",,,,,,,,,,"Goodfellow, I., Bengio, Y., Courville, A., Deep Learning (2016), MIT Press; Guizzo, E., How google's self-driving car works (2016); Siri Team, E., Deep learning for siri's voice: On-device deep mixture density networks for hybrid unit selection synthesis (2017); Reagen, B., Adolf, R., Whatmough, P., Deep Learning for Computer Architects (2017), Morgan & Claypool Publishers; Dong, S., Kaeli, D., DNNMark: A deep neural network benchmark suite for GPUs (2017) Proceedings of the General Purpose GPUs, GPGPU-10, pp. 63-72. , ACM New York, NY, USA; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015), International Conference on Learning Representations; Szegedy, C., (2015), pp. 1-9. , Wei Liu,. Yangqing Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions, in: 2015 IEEE Conference on Computer Vision and Pattern Recognition, CVPR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016), pp. 770-778. , 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR; Liao, S., Li, Z., Lin, X., Qiu, Q., Wang, Y., Yuan, B., Energy-efficient, high-performance, highly-compressed deep neural network design using block-circulant matrices (2017) Proceedings of the 36th International Conference on Computer-Aided Design, pp. 458-465. , IEEE Press; Ding, C., Liao, S., Wang, Y., Li, Z., Liu, N., Zhuo, Y., Wang, C., Lin, X., C ir CNN: accelerating and compressing deep neural networks using block-circulant weight matrices (2017) Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture, pp. 395-408. , ACM; Zhao, R., Song, W., Zhang, W., Xing, T., Lin, J.-H., Srivastava, M., Gupta, R., Zhang, Z., Accelerating binarized convolutional neural networks with software-programmable FPGAs (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, FPGA ’17, pp. 15-24. , ACM New York, NY, USA; Alemdar, H., Caldwell, N., Leroy, V., Prost-Boucle, A., Pétrot, F., Ternary neural networks for resource-efficient AI applications (2016); Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) CVPR09; Mojumder, S.A., Louis, M.S., Sun, Y., Ziabari, A.K., Abellán, J.L., Kim, J., Kaeli, D., Joshi, A., Profiling DNN workloads on a volta-based DGX-1 system (2018), pp. 122-133. , 2018 IEEE International Symposium on Workload Characterization, IISWC; Cheng, Y., Yu, F.X., Feris, R.S., Kumar, S., Choudhary, A., Chang, S.-F., An exploration of parameter redundancy in deep networks with circulant projections (2015), pp. 2857-2865. , Proceedings of the IEEE International Conference on Computer Vision; Wang, Y., Ding, C., Li, Z., Yuan, G., Liao, S., Ma, X., Yuan, B., Lin, X., Towards ultra-high performance and energy efficiency of deep learning systems: an algorithm-hardware co-optimization framework (2018), Proceedings of the 32nd AAAI Conference on Artificial Intelligence, AAAI; Rosenblatt, F., The perceptron: A probabilistic model for information storage and organization in the brain (1958), pp. 65-386; NVIDIA, F., cuDNN: GPU accelerated deep learning (2016); Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Zhao, L., Liao, S., Wang, Y., Li, Z., Tang, J., Yuan, B., Theoretical properties for neural networks with weight matrices of low displacement rank (2017), pp. 4082-4090. , International Conference on Machine Learning; Sindhwani, V., Sainath, T., Kumar, S., Structured transforms for small-footprint deep learning (2015) Advances in Neural Information Processing Systems, pp. 3088-3096; Pan, V.Y., Structured Matrices and Polynomials: Unified Superfast Algorithms (2012), Springer Science & Business Media; Bini, D., Pan, V., Eberly, W., Polynomial and matrix computations volume 1: Fundamental algorithms (1996) SIAM Rev., 38 (1), pp. 161-164; NVIDIA, D., CUDA CUFFT library (2016); NVIDIA, D., CUDA toolkit documentation (2016); Rao, K.R., Kim, D.N., Hwang, J.-J., Fast Fourier Transform - Algorithms and Applications (2010), first ed. Springer Publishing Company, Incorporated; Intel, K.R., Intel(R) Xeon(R) Processor E5-2630 v3 (2014); NVIDIA, K.R., NVIDIA TESLA V100 GPU architecture (2017); Garofolo, J., Lamel, L., Fisher, W., Fiscus, J., Pallett, D., Dahlgren, N., Zue, V., TIMIT Acoustic-phonetic continuous speech corpus (1992) Linguist. Data Consortium; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012), pp. 1097-1105. , Pereira F. Burges C.J.C. Bottou L. Weinberger K.Q. Curran Associates, Inc; Michalek, J., Vanek, J., A survey of recent DNN architectures on the TIMIT phone recognition task; NVIDIA, A., cuBLAS: Dense linear algebra on GPUs (2016); Krizhevsky, A., Nair, V., Hinton, G., CIFAR-10 (Canadian Institute for Advanced Research); LeCun, Y., Cortes, C., MNIST handwritten digit database (2010); Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y., Reading digits in natural images with unsupervised feature learning (2011), NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011; Awan, A.A., Hamidouche, K., Hashmi, J.M., Panda, D.K., S-caffe: Co-designing MPI runtimes and caffe for scalable deep learning on modern GPU clusters (2017) Proceedings of the 22Nd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPoPP ’17, pp. 193-205. , ACM New York, NY, USA; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014); Jouppi, N., Google supercharges machine learning tasks with TPU custom chip (2016); Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Yoon, D.H., In-datacenter performance analysis of a tensor processing unit (2017); Merolla, P.A., Arthur, J.V., Alvarez-Icaza, R., Cassidy, A.S., Sawada, J., Akopyan, F., Jackson, B.L., Modha, D.S., A million spiking-neuron integrated circuit with a scalable communication network and interface (2014) Science, 345 (6197), pp. 668-673; Esser, S.K., Appuswamy, R., Merolla, P., Arthur, J.V., Modha, D.S., Backpropagation for energy-efficient neuromorphic computing (2015) NIPS, pp. 1117-1125; Esser, S.K., Merolla, P.A., Arthur, J.V., Cassidy, A.S., Appuswamy, R., Andreopoulos, A., Berg, D.J., Modha, D.S., Convolutional networks for fast, energy-efficient neuromorphic computing (2016), pp. 11441-11446. , National Acad Sciences; Chen, T., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., Temam, O., Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning (2014) ACM Sigplan Notices, 49 (4), pp. 269-284; Qiu, J., Wang, J., Yao, S., Guo, K., Li, B., Zhou, E., Yu, J., Yang, H., Going deeper with embedded FPGA platform for convolutional neural network (2016) FPGA, pp. 26-35. , ACM; Chen, T., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., Temam, O., Dadiannao: A machine-learning supercomputer (2014) MICRO, pp. 609-622. , IEEE Computer Society; Chen, Y.H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2017) IEEE J. Solid-State Circuits, 52 (1), pp. 127-138; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: efficient inference engine on compressed deep neural network (2016) ISCA, pp. 243-254. , IEEE Press; Judd, P., Albericio, J., Moshovos, A., Stripes: Bit-serial deep neural network computing (2016) MICRO, pp. 1-12. , IEEE; Lin, D., Talathi, S., Annapureddy, S., Fixed point quantization of deep convolutional networks (2016) ICML, pp. 2849-2858; Wu, J., Leng, C., Wang, Y., Hu, Q., Cheng, J., Quantized convolutional neural networks for mobile devices (2016) CVPR; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2015); Han, S., Pool, J., Tran, J., Dally, W.J., Learning both weights and connections for efficient neural network (2015) NIPS, pp. 1135-1143; Jaderberg, M., Vedaldi, A., Zisserman, A., Speeding up convolutional neural networks with low rank expansions (2014); Tai, C., Xiao, T., Wang, X., E., W., Convolutional neural networks with low-rank regularization (2015); Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., (2016), pp. 265-283. , Tensorflow: A system for large-scale machine learning, in: 12th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI} 16; Seide, F., Agarwal, A., CNTK: Microsoft's Open-Source Deep-Learning Toolkit, ACM, pp. 2135–2135,; Eliuk, S., Upright, C., Skjellum, A., Dmath: A scalable linear algebra and math library for heterogeneous GP-GPU architectures (2016); Dong, S., Gong, X., Sun, Y., Baruah, T., Kaeli, D., Characterizing the microarchitectural implications of a convolutional neural network (CNN) execution on GPUs (2018) Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering, ICPE ’18, pp. 96-106. , ACM New York, NY, USA; Gautier, T., (2013), J.V. Ferreira Lima, N. Maillard, B. Raffin, Locality-aware work stealing on multi-CPU and multi-GPU architectures, in: 6th Workshop on Programmability Issues for Heterogeneous Multicores, MULTIPROG, Berlin, Germany; Deng, C., Liao, S., Xie, Y., Parhi, K.K., Qian, X., Yuan, B., Permdnn: Efficient compressed DNN architecture with permuted diagonal matrices (2018) 2018 51st Annual IEEE/ACM International Symposium on Microarchitecture, MICRO, pp. 189-202","Kaeli, D.; 409 Dana Research Center, United States; email: kaeli@ece.neu.edu",,,"Elsevier B.V.",,,,,01678191,,PACOE,,"English","Parallel Comput",Article,"Final","",Scopus,2-s2.0-85094556483
"Mas J., Panadero T., Botella G., Del Barrio A.A., García C.","57219223385;57219230075;16174458100;24758151800;55328676100;","CNN Inference acceleration using low-power devices for human monitoring and security scenarios",2020,"Computers and Electrical Engineering","88",,"106859","","",,3,"10.1016/j.compeleceng.2020.106859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091736034&doi=10.1016%2fj.compeleceng.2020.106859&partnerID=40&md5=b28740e0715dd134c6d7122e467a5aa8","Department of Computer Architecture and Automation, Facultad de Informática, Complutense University of Madrid, Spain; ING Direct, Las Rozas, Madrid, Spain; Instituto de Tecnología del Conocimiento-Universidad Complutense de Madrid, Spain","Mas, J., Department of Computer Architecture and Automation, Facultad de Informática, Complutense University of Madrid, Spain; Panadero, T., ING Direct, Las Rozas, Madrid, Spain; Botella, G., Department of Computer Architecture and Automation, Facultad de Informática, Complutense University of Madrid, Spain, Instituto de Tecnología del Conocimiento-Universidad Complutense de Madrid, Spain; Del Barrio, A.A., Department of Computer Architecture and Automation, Facultad de Informática, Complutense University of Madrid, Spain; García, C., Department of Computer Architecture and Automation, Facultad de Informática, Complutense University of Madrid, Spain, Instituto de Tecnología del Conocimiento-Universidad Complutense de Madrid, Spain","Security is currently one of the top concerns in our society. From governmental installations to private companies and medical institutions, they all have to address directly with security issues as: access to restricted information quarantine control, or criminal tracking. As an example, identifying patients is critical in hospitals or geriatrics in order to isolate infected people, which has proven to be a non- trivial issue with the COVID-19 pandemic that is currently affecting all countries, or to locate fled patients. Face recognition is then a non-intrusive alternative for performing these tasks. Although FaceNet from Google has proved to be almost perfect, in a multi-face scenario its performance decays rapidly. In order to mitigate this loss of performance, in this paper a cluster based on the Neural Computer Stick version 2 and OpenVINO by Intel is proposed. A detailed power and runtime study is shown for two programming models, namely: multithreading and multiprocessing. Furthermore, 3 different hosts have been considered. In the most efficient configuration, an average of 6 frames per second has been achieved using the Raspberry Pi 4 as host and with a power consumption of just 11.2W, increasing by a factor of 3.3X the energy efficiency with respect to a PC-based solution in a multi-face scenario. © 2020","Cluster; Convolutional neural network; Inference; Neural compute stick 2; OpenVINO","Energy efficiency; Multitasking; Frames per seconds; Loss of performance; Low-power devices; Medical institutions; Neural computers; Performance decay; Private companies; Programming models; Face recognition",,,,,"European Commission, EC; Ministerio de Economía y Competitividad, MINECO: PR26- 16/20B-1, RTI2018-093684-B-I00, S2018/TCS-4423, TIN 2015-65277-R; European Regional Development Fund, FEDER","This paper has been supported by the EU (FEDER) and the Spanish MINECO and CM under grants S2018/TCS-4423 , RTI2018-093684-B-I00 and TIN 2015-65277-R , as well as the UCM-Banco Santander Grant PR26- 16/20B-1. Besides, UCM - Innova docentia competitive Projects: 2018–2019 (Project 315, acronym Reconnet) and 2019–2020 (Project 205, acronym Transform) have supported this paper as well.",,,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proceedings of the 25th international conference on neural information processing systems, 1, pp. 1097-1105; LeCun, Y., Bengio, Y., Hinton, G.E., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Deng, Y., Deep learning on mobile devices: a review (2019) Mobile multimedia/image processing, security, and applications 2019, 10993, pp. 52-66. , International society for optics and photonics, SPIE; Heath, K., Guibas, L., FaceNet: tracking people and acquiring canonical face images in a wireless camera sensor network (2007) 2007 First ACM/IEEE international conference on distributed smart cameras, pp. 117-124; Wang, M., Deng, W., Deep face recognition: a survey (2018) ArXiv; Turk, M., Pentland, A., Eigenfaces for recognition (1991) Journal of Cognitive Neuroscience, 3 (1), pp. 71-86. , PMID: 23964806; Corpas, A., Costero, L., Botella, G., Igual, F.D., García, C., Rodríguez, M., Acceleration and energy consumption optimization in cascading classifiers for face detection on low-cost arm big. Little asymmetric architectures (2018) Int J Circuit Theory Appl, 46 (9), pp. 1756-1776; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: a unified embedding for face recognition and clustering (2015) CoRR; Kim, M.S., Barrio, A.A.D., Oliveira, L.T., Hermida, R., Bagherzadeh, N., Efficient Mitchell's approximate log multipliers for convolutional neural networks (2019) IEEE Trans Comput, 68 (5), pp. 660-675; Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E., Labeled faces in the wild: a database for studying face recognition in unconstrained environments (2007) Tech. Rep. 07–49, , University of Massachusetts, Amherst; Fernández, D.G., Barrio, A.A.D., Juan, G.B., García, C., Prieto, M., Hermida, R., Complexity reduction in the HEVC/H265 standard based on smooth region classification (2018) Digit Signal Process, 73, pp. 24-39; Fernández, D.G., Botella, G., Del Barrio, A.A., García, C., Prieto-Matías, M., Grecos, C., HEVC Optimization based on human perception for real-time environments (2018) Multimed Tools Appl; Ding, R., Liu, Z., Blanton, R.D.S., Marculescu, D., Lightening the load with highly accurate storage- and energy-efficient lightnns (2018) ACM Trans Reconfigurable Technol Syst, 11 (3). , 17:1–17:24; Kim, M.S., Barrio, A.A.D., Hermida, R., Bagherzadeh, N., Low-power implementation of Mitchell's approximate logarithmic multiplication for convolutional neural networks (2018) 23rd Asia and South pacific design automation conference, ASP-DAC 2018, Jeju, Korea (South), January 22–25, 2018, pp. 617-622; https://software.intel.com/en-us/neural-compute-stick, Intel® neural compute stick 2.; Accessed: 29-08-2019; https://software.intel.com/en-us/openvino-toolkit, Intel® distribution of Openvino™Toolkit.; Accessed: 19-09-2019; https://www.tensorflow.org/, LLC G. Tensorflow: an end-to-end open source machine learning platform.; Accessed: 19-09-2019; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Going deeper with convolutions (2015) 2015 IEEE Conference on computer vision and pattern recognition (CVPR), pp. 1-9; Szegedy, C., Ioffe, S., Vanhoucke, V., Inception-v4, inception-resnet and the impact of residual connections on learning (2016) CoRR; Shi, W., Cao, J., Zhang, Q., Li, Y., Xu, L., Edge computing: vision and challenges (2016) IEEE Internet Things J, 3 (5), pp. 637-646; https://movidius.github.io/ncsdk/ncs.html, Intel® movidius™neural compute stick.; Accessed: 29-08-2019; (2019), https://software.intel.com/en-us/neural-compute-stick, Corporation I. Intel® movidius™neural compute stick. [Online; accessed 25-October-2019];; (2019), https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/, Nvidia. Embedded systems for next-generation autonomous machines. [Online; accessed 25-October-2019];; (2019), https://coral.withgoogle.com/, LLC G. Coral. [Online; accessed 25-October-2019];; Almeida, M., Laskaridis, S., Leontiadis, I., Venieris, S.I., Lane, N.D., EmBench: quantifying performance variations of deep neural networks across modern commodity devices (2019) The 3rd international workshop on deep learning for mobile systems and applications, pp. 1-6; Kristiani, E., Yang, C.-T., Huang, C.-Y., iSEC: an optimized deep learning model for image classification on edge computing (2020) IEEE Access, 8, pp. 27267-27276; Othman, N.A., Aydin, I., A new deep learning application based on movidius NCS for embedded object detection and recognition (2018) 2018 2nd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT), pp. 1-5; Mathew, G., Sindhu Ramachandran, S., Suchithra, V.S., Lung nodule detection from low dose CT scan using optimization on intel xeon and core processors with intel distribution of openvino toolkit (2019) TENCON 2019 - 2019 IEEE region 10 conference (TENCON), pp. 1783-1788; Dinelli, G., Meoni, G., Rapuano, E., Benelli, G., Fanucci, L., An FPGA-based hardware accelerator for CNNs using on-chip memories only: design and benchmarking with intel movidius neural compute stick (2019) Int J Reconfigurable Comput., 2019; Lin, Z., Yih, M., Ota, J.M., Owens, J.D., Muyan-Ozelik, P., Benchmarking deep learning frameworks and investigating FPGA deployment for traffic sign classification and detection (2019) IEEE Trans Intell Veh, 4 (3), pp. 385-395; Corporation, N., Technical brief. NVIDIA Jetson TK1 development Kit (2014) Tech. Rep., , NVidia Corporation; Amos, B., Ludwiczuk, B., Satyanarayanan, M., OpenFace: a general-purpose face recognition library with mobile applications (2016) Tech. Rep., , CMU-CS-16-118, CMU School of Computer Science; Jose, E., M, G., T. P., M.H., M. H., S., Face recognition based surveillance system using FaceNet and MTCNN on Jetson TX2 (2019) 2019 5th International conference on advanced computing communication systems (ICACCS), pp. 608-613; Zhang, K., Zhang, Z., Li, Z., Qiao, Y., Joint face detection and alignment using multitask cascaded convolutional networks (2016) IEEE Signal Process Lett, 23 (10), pp. 1499-1503; Mohamed Salah Salhi, H.A., Alaaeddine Sarraj, A., Implementation of an evolutionary facial recognition algorithm on Jetson TK 1 (2019) J Multimed Process Technol, 10 (1); https://www.nvidia.com/en-us/autonomous-machines/jetson-store/, Jetson store.; Accessed: 15-10-2019; Wang, Z., Cheng, Z., Huang, H., Zhou, X., Liu, Y., Design and implementation of vehicle unlocking system based on face recognition (2019) 2019 34rd Youth academic annual conference of chinese association of automation (YAC), pp. 121-126; Boka, A., Morris, B., Person recognition for access logging (2019) 2019 IEEE 9th annual computing and communication workshop and conference (CCWC), pp. 0933-0936; https://movidius.github.io/ncsdk/, Intel® movidius™neural compute sdk.; Accessed: 15-10-2019; Xie, Y., Ding, L., Zhou, A., Chen, G., An optimized face recognition for edge computing (2019) 2019 IEEE 13th international conference on ASIC (ASICON), pp. 1-4; (2019), https://software.intel.com/en-us/articles/transitioning-from-intel-movidius-neural-compute-sdk-to-openvino-toolkit, Smith N. Transitioning from intel® movidius™neural compute sdk to intel© distribution of openvino™toolkit. Accessed: 24-09-2019;; Barrio, A.A.D., Bagherzadeh, N., Hermida, R., Ultra-low-power adder stage design for exascale floating point units (2014) ACM Trans Embedded Comput Syst, 13 (3s). , 105:1–105:24; (2018), https://github.com/davidsandberg/facenet, Sandberg D. facenet. Accessed: 14-11-2019; Yang, S., Luo, P., Loy, C.C., Tang, X., Wider face: a face detection benchmark (2016) IEEE Conference on computer vision and pattern recognition (CVPR); https://docs.python.org/3/c-api/init.html#thread-state-and-the-global-interpreter-lock, Thread state and the global interpreter lock.; Accessed: 15-10-2019; https://drive.google.com/open?id=1cWwSCtgch9g1m5C7IJ6Jv5PASoOp1fDq, Video repository.; Accessed: 15-11-2019; (2019), https://benchmarks.ul.com/legacy-benchmarks, https://benchmarks.ul.com/legacy-benchmarks Accessed: 14-11-2019;; (2013), https://www.notebookcheck.net/Review-Lenovo-IdeaPad-Z510-Notebook.105627.0.html, Review lenovo ideapad z510 notebook. Accessed: 14-11-2019;","García, C.; Fac. Informática, Spain; email: garsanca@ucm.es",,,"Elsevier Ltd",,,,,00457906,,CPEEB,,"English","Comput Electr Eng",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85091736034
"Cavallaro L., Bagdasar O., De Meo P., Fiumara G., Liotta A.","57215417954;55939520000;6507520114;22034070100;13408852200;","Artificial neural networks training acceleration through network science strategies",2020,"Soft Computing","24","23",,"17787","17795",,4,"10.1007/s00500-020-05302-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090930825&doi=10.1007%2fs00500-020-05302-y&partnerID=40&md5=0e98ec958a2ec49a889ea9238ff128d6","University of Derby, Kedleston Road, Derby, DE22 1GB, United Kingdom; University of Messina, Polo Universitario Annunziata, Messina, 98122, Italy; MIFT Department, University of Messina, Messina, 98166, Italy; Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy","Cavallaro, L., University of Derby, Kedleston Road, Derby, DE22 1GB, United Kingdom; Bagdasar, O., University of Derby, Kedleston Road, Derby, DE22 1GB, United Kingdom; De Meo, P., University of Messina, Polo Universitario Annunziata, Messina, 98122, Italy; Fiumara, G., MIFT Department, University of Messina, Messina, 98166, Italy; Liotta, A., Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy","The development of deep learning has led to a dramatic increase in the number of applications of artificial intelligence. However, the training of deeper neural networks for stable and accurate models translates into artificial neural networks (ANNs) that become unmanageable as the number of features increases. This work extends our earlier study where we explored the acceleration effects obtained by enforcing, in turn, scale freeness, small worldness, and sparsity during the ANN training process. The efficiency of that approach was confirmed by recent studies (conducted independently) where a million-node ANN was trained on non-specialized laptops. Encouraged by those results, our study is now focused on some tunable parameters, to pursue a further acceleration effect. We show that, although optimal parameter tuning is unfeasible, due to the high non-linearity of ANN problems, we can actually come up with a set of useful guidelines that lead to speed-ups in practical cases. We find that significant reductions in execution time can generally be achieved by setting the revised fraction parameter (ζ) to relatively low values. © 2020, The Author(s).","Artificial neural networks; Multilayer perceptron; Network science; Revise phase","Deep learning; Acceleration effects; Fraction parameters; Network science; Neural networks trainings; Optimal parameter; Scale-freeness; Small-worldness; Tunable parameter; Neural networks",,,,,,,,,,,,,,,,"Barabási, A.-L., Pósfai, M., (2016) Network science, , Cambridge University Press, Cambridge UK; (2018) Deep Rewiring: Training Very Sparse Deep Networks. Arxiv Preprint Arxiv, 1711, p. 05136; Berman, D.S., Buczak, A.L., Chavis, J.S., Corbett, C.L., A survey of deep learning methods for cyber security (2019) Information, 4, p. 122; Bourely, A., Boueri, J.P., Choromonski, K., (2017) Sparse Neural Networks Topologies; Cai, D., He, X., Han, J., Huang, T.S., Graph regularized non-negative matrix factorization for data representation (2011) PAMI, 33 (8), pp. 1548-1560; Cai, D., He, X., Han, J., Speed up kernel discriminant analysis (2011) VLDB J, 20, pp. 21-33; Cao, C., Liu, F., Tan, H., Song, D., Shu, W., Li, W., Zhou, Y., Xie, Z., Deep learning and its applications in biomedicine (2018) Genom Proteomics Bioinform, 16 (1), pp. 17-32; Cavallaro, L., Bagdasar, O., Meo, P., Fiumara, G., Liotta, A., Artificial neural networks training acceleration through network science strategies. In: Sergeyev YD, Kvasov DE (eds) Numerical computations: Theory and algorithms, NUMTA 2019 (2020) Lecture Notes in Computer Science, Springer, Cham, 11974, pp. 330-336. , https://doi.org/10.1007/978-3-030-40616-5_27; Chen, H., Engkvist, O., Wang, Y., Olivecrona, M., Blaschke, T., The rise of deep learning in drug discovery (2018) Drug Discov Today, 23 (6), pp. 1241-1250; Dong, Y., Li, D., Deep learning and its applications to signal and information processing [exploratory DSP] (2011) IEEE Signal Process Mag, 1, p. 145; Erdős, P., Rényi, A., On random graphs i (1959) Publ Math-Debr, 6, pp. 290-297; Frankle, J., Carbin, M., The Lottery Ticket Hypothesis: Finding Sparse (2018) Trainable Neural Networks. Arxiv Preprint Arxiv, 1803, p. 03635; Gale, T., (1902) Elsen E, Hooker S (2019) the State of Sparsity in Deep Neural Networks. Arxiv Preprint Arxiv, p. 09574; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep learning, , MIT Press, Cambridge US; Haslinger, C., Schweifer, N., Stilgenbauer, S., Döhner, H., Lichter, P., Kraut, N., Stratowa, C., Abseher, R., Microarray gene expression profiling of B-cell chronic lymphocytic leukemia subgroups defined by genomic aberrations and VH mutation status (2004) J Clin Oncol, 22 (19), pp. 3937-3949; Hestness, J., Narang, S., Ardalani, N., Diamos, G.F., Jun, H., Kianinejad, H., Patwary, M.M.A., Zhou, Y., (2017) Deep Learning Scaling is Predictable, Empirically. Arxiv Preprint Arxiv, 1712, p. 00409; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, pp. 770-778. , Las Vegas USA; Hilgetag, C.C., Goulas, A., Is the brain really a small-world network? (2016) Brain Struct Funct, 221 (4), pp. 2361-2366; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A., Jaitly, N., Senior, A., Kingsbury, B., Deep neural networks for acoustic modeling in speech recognition (2012) IEEE Signal Process Mag, 29, pp. 82-97; Kalchbrenner, N., Elsen, E., Simonyan, K., Noury, S., Casagrande, N., Lockhart, E., Stimberg, F., Kavukcuoglu, K., Efficient neural audio synthesis (2018) ICML 2018, Stockholm, pp. 2415-2424; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2017) Commun ACM, 60 (6), pp. 84-90; Latora, V., Nicosia, V., Russo, G., (2017) Complex networks: principles, methods and applications, , Cambridge University Press, Cambridge UK; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Liu, S., Mocanu, D.C., Matavalam, A.R.R., Pei, Y., Pechenizkiy, M., Sparse evolutionary Deep Learning with over one million artificial neurons on commodity hardware (2019) Arxiv, Arxiv, 1901; Louizos, C., Welling, M., Kingma, D.P., (2017) Learning Sparse Neural Networks through L 0 Regularization., , arXiv preprint arXiv:1712.01312; Mocanu, D.C., Mocanu, E., Stone, P., Nguyen, P.H., Gibescu, M., Liotta, A., Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science (2018) Nat Commun, 9, p. 2383; Ruano-Ordás, D., Yevseyeva, I., Fernandes, V.B., Méndez, J.R., Emmerich, M.T.M., Improving the drug discovery process by using multiple classifier systems (2019) Expert Syst Appl, 121, pp. 292-303; Srinivas, S., Subramanya, A., Babu, R.V., Training sparse neural networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, Honolulu, pp. 455-462. , https://doi.org/10.1109/CVPRW.2017.61; Stier, J., Granitzer, M., Structural analysis of sparse neural networks (2019) Procedia Comput Sci, 159, pp. 107-116; Ullrich, K., Meeds, E., Welling, M., (2017) Soft Weight-Sharing for Neural Network Compression., , arXiv preprint arXiv:1702.04008; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., Attention is all you need (2017) Proceedings of the Annual Conference on Neural Information Processing Systems, pp. 6000-6010. , Long Beach, USA; Watts, D.J., Strogatz, S.H., Collective dynamics of ‘small-world’ networks (1998) Nature, 393, pp. 440-442","Cavallaro, L.; University of Derby, Kedleston Road, United Kingdom; email: l.cavallaro@derby.ac.uk",,,"Springer Science and Business Media Deutschland GmbH",,,,,14327643,,,,"English","Soft Comput.",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85090930825
"Gulgec N.S., Takáč M., Pakzad S.N.","57189243964;57203176046;18038101800;","Structural sensing with deep learning: Strain estimation from acceleration data for fatigue assessment",2020,"Computer-Aided Civil and Infrastructure Engineering","35","12",,"1349","1364",,21,"10.1111/mice.12565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085010123&doi=10.1111%2fmice.12565&partnerID=40&md5=ce318c22072fcc49695a9cc19b725f4c","Department of Civil and Environmental Engineering, Lehigh University, Bethlehem, PA, United States; Department of Industrial and Systems Engineering, Lehigh University, Bethlehem, PA, United States","Gulgec, N.S., Department of Civil and Environmental Engineering, Lehigh University, Bethlehem, PA, United States; Takáč, M., Department of Industrial and Systems Engineering, Lehigh University, Bethlehem, PA, United States; Pakzad, S.N., Department of Civil and Environmental Engineering, Lehigh University, Bethlehem, PA, United States","Many of the civil structures experience significant vibrations and repeated stress cycles during their life span. These conditions are the bases for fatigue analysis to accurately establish the remaining fatigue life of the structures that ideally requires a full-field strain assessment of the structures over years of data collection. Traditional inspection methods collect strain measurements by using strain gauges for a short time span and extrapolate the measurements in time; nevertheless, large-scale deployment of strain gauges is expensive and laborious as more spatial information is desired. This paper introduces a deep learning-based approach to replace this high cost by employing inexpensive data coming from acceleration sensors. The proposed approach utilizes collected acceleration responses as inputs to a multistage deep neural network based on long short-term memory and fully connected layers to estimate the strain responses. The memory requirement of training long acceleration sequences is reduced by proposing a novel training strategy. In the evaluation of the method, a laboratory-scale horizontally curved girder subjected to various loading scenarios is tested. © 2020 Computer-Aided Civil and Infrastructure Engineering",,"Deep neural networks; Fatigue of materials; Multilayer neural networks; Strain gages; Acceleration response; Acceleration sensors; Horizontally curved girders; Large-scale deployment; Learning-based approach; Remaining fatigue life; Repeated stress cycle; Spatial informations; Deep learning; acceleration; artificial neural network; estimation method; fatigue; learning; strain analysis",,,,,"National Science Foundation, NSF: CCF‐1618717, CCF‐1740796, CMMI‐1351537; U.S. Department of Transportation, DOT","Research funding is partially provided by a grant from the U.S. Department of Transportation's University Transportation Centers Program, and National Science Foundation through Grants CMMI‐1351537, CCF‐1618717, and CCF‐1740796, and by a grant from the Commonwealth of Pennsylvania, Department of Community and Economic Development, through the Pennsylvania Infrastructure Technology Alliance (PITA). The authors would like to thank Gabriela Vinson who helped with the experimental study.",,,,,,,,,,"Aenlle, M.L., Hermanns, L., Fernandez, P., Fraile, A., Cunha, A., Ramos, L., o, P., Stress estimation in a scale model of a symmetric two story building (2013) Proceedings of 5th International Operational Modal Analysis Conference, , … Lourenç, Guimaraes, Portugal; Arms, S., Townsend, C., Galbreath, J., Newhard, A., Wireless strain sensing networks (2004) Proceedings of the 2nd European Workshop on Structural Health Monitoring, pp. 7-9. , Stanford, CA; Avitabile, P., Pingle, P., Prediction of full field dynamic strain from limited sets of measured data (2012) Shock and Vibration, 19 (5), pp. 765-785; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 157-166; Chang, M., Pakzad, S.N., Observer kalman filter identification for output-only systems using interactive structural modal identification toolsuite (2013) Journal of Bridge Engineering, 19 (5); Chen, S., Cai, C., Equivalent wheel load approach for slender cable-stayed bridge fatigue assessment under traffic and wind: Feasibility study (2007) Journal of Bridge Engineering, 12 (6), pp. 755-764; Childers, B.A., Froggatt, M.E., Allison, S.G., Moore, S.T.C., Hare, D.A., Batten, C.F., Jegley, D.C., Use of 3000 Bragg grating strain sensors distributed on four 8-m optical fibers during static load tests of a composite structure (2001) Smart structures and materials 2001: Industrial and commercial applications of smart structures technologies, 4332, pp. 133-142. , Bellingham, WA, International Society for Optics and Photonics; Cho, S., Sim, S.-H., Park, J.-W., Lee, J., Extension of indirect displacement estimation method using acceleration and strain to various types of beam structures (2014) Smart Structures and Systems, 14 (4), pp. 699-718; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical evaluation of gated recurrent neural networks on sequence modeling, , Preprint; Dharap, P., Li, Z., Nagarajaiah, S., Barrera, E., Nanotube film based on single-wall carbon nanotubes for strain sensing (2004) Nanotechnology, 15 (3). , 379; Dong, J., (2008) Analytical study of horizontally curved hollow tubular flange girders, , Bethlehem, PA, Lehigh University; Downing, S.D., Socie, D., Simple rainflow counting algorithms (1982) International Journal of Fatigue, 4 (1), pp. 31-40; Elman, J.L., Finding structure in time (1990) Cognitive Science, 14 (2), pp. 179-211; Eshkevari, S.S., Pakzad, S.N., Signal reconstruction from mobile sensors network using matrix completion approach (2020) Topics in Modal Analysis & Testing, 8, pp. 61-75; Fatemi, A., Yang, L., Cumulative fatigue damage and life prediction theories: A survey of the state of the art for homogeneous materials (1998) International Journal of Fatigue, 20 (1), pp. 9-34; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with LSTM (2000) Neural Computation, 12 (10), pp. 2451-2471; Gindy, M., Vaccaro, R., Nassif, H., Velde, J., A state-space approach for deriving bridge displacement from acceleration (2008) Computer-Aided Civil and Infrastructure Engineering, 23 (4), pp. 281-290; Giraldo, D.F., Dyke, S.J., Caicedo, J.M., Damage detection accommodating varying environmental conditions (2006) Structural Health Monitoring, 5 (2), pp. 155-172; Graf, W., Freitag, S., Kaliske, M., Sickert, J., Recurrent neural networks for uncertain time-dependent structural behavior (2010) Computer-Aided Civil and Infrastructure Engineering, 25 (5), pp. 322-323. , -U; Graves, A., Mohamed, A.-R., Hinton, G., (2013) Speech recognition with deep recurrent neural networks, pp. 6645-6649. , 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),), Vancouver, BC; Gulgec, N.S., Takáč, M., Pakzad, S.N., Structural damage detection using convolutional neural networks (2017) Model validation and uncertainty quantification, 3, pp. 331-337. , R. Barthorpe, R. Platz, I. Lopez, B. Moaveni, C. Papadimitriou, (Eds.),, Conference Proceedings of the Society for Experimental Mechanics Series, Cham, Springer; Gulgec, N.S., Takáč, M., Pakzad, S.N., Convolutional neural network approach for robust structural damage detection and localization (2019) Journal of Computing in Civil Engineering, 33 (3); Gulgec, N.S., Takáč, M., Pakzad, S.N., Innovative sensing by using deep learning framework (2019) Dynamics of Civil Structures: Vol. 2. Conference Proceedings of the Society for Experimental Mechanics Series, pp. 293-300. , S. Pakzad, (Ed.),, Cham, Springer; Hild, F., Roux, S., (2012) Digital image correlation, , Weinheim, Wiley-VCH; Hill, K.O., Meltz, G., Fiber Bragg grating technology fundamentals and overview (1997) Journal of Lightwave Technology, 15 (8), pp. 1263-1276; Hjelm, H.P., Brincker, R., Graugaard-Jensen, J., Munch, K., Determination of stress histories in structures by natural input modal analysis (2005) Proceedings of 23rd Conference and Exposition on Structural Dynamics (IMACXXIII), , Orlando, FL; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Iliopoulos, A., Weijtjens, W., Van Hemelrijck, D., Devriendt, C., Fatigue assessment of offshore wind turbines on monopile foundations using multi-band modal expansion (2017) Wind Energy, 20 (8), pp. 1463-1479; Jo, H., Spencer, B., Multi-metric model-based structural health monitoring (2014) Sensors and Smart Structures Technologies for Civil, Mechanical, and Aerospace Systems 2014, 9061. , (, p, Bellingham, WA, International Society for Optics and Photonics; Kim, S., Pakzad, S., Culler, D., Demmel, J., Fenves, G., Glaser, S., Turon, M., Health monitoring of civil infrastructures using wireless sensor networks (2007) Proceedings of the 6th International Conference on Information Processing in Sensor Networks, pp. 254-263. , New York, ACM; Kingma, D., Ba, J., (2014) Adam: A method for stochastic optimization, , Preprint; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Lee, H., Yun, H.-B., Maclean, B., Development and field testing of a prototype hybrid uniaxial strain transducer (2002) NDT & E International, 35 (2), pp. 125-134; Lee, H.S., Hong, Y.H., Park, H.W., Design of an fir filter for the displacement reconstruction using measured acceleration in low-frequency dominant structures (2010) International Journal for Numerical Methods in Engineering, 82 (4), pp. 403-434; Liang, X., Image-based post-disaster inspection of reinforced concrete bridge systems using deep learning with Bayesian optimization (2019) Computer-Aided Civil and Infrastructure Engineering, 34 (5), pp. 415-430; Lipton, Z.C., Berkowitz, J., Elkan, C., (2015) A critical review of recurrent neural networks for sequence learning, , Preprint; Maeda, H., Sekimoto, Y., Seto, T., Kashiyama, T., Omata, H., Road damage detection and classification using deep neural networks with smartphone images (2018) Computer-Aided Civil and Infrastructure Engineering, 33 (12), pp. 1127-1141; Maes, K., Iliopoulos, A., Weijtjens, W., Devriendt, C., Lombaert, G., Dynamic strain estimation for fatigue assessment of an offshore monopile wind turbine using filtering and modal expansion algorithms (2016) Mechanical Systems and Signal Processing, 76, pp. 592-611; Matarazzo, T.J., Pakzad, S.N., Truncated physical model for dynamic sensor networks with applications in high-resolution mobile sensing and bigdata (2016) Journal of Engineering Mechanics, 142 (5); Miner, M., Cumulative damage in fatigue (1945) Applied Mechanics Transactions (ASME), 12 (3), pp. 159-164; Nabian, M.A., Meidani, H., Deep learning for accelerated seismic reliability analysis of transportation networks (2018) Computer-Aided Civil and Infrastructure Engineering, 33 (6), pp. 443-458; Nguyen, T., Kashani, A., Ngo, T., Bordas, S., Deep neural network with high-order neuron for the prediction of foamed concrete strength (2019) Computer-Aided Civil and Infrastructure Engineering, 34 (4), pp. 316-332; Pakzad, S.N., Fenves, G.L., Kim, S., Culler, D.E., Design and implementation of scalable wireless sensor network for structural monitoring (2008) Journal of Infrastructure Systems, 14 (1), pp. 89-101; Palanisamy, R., Cho, S., Kim, H., Sim, S.-H., Experimental validation of Kalman filter-based strain estimation in structures subjected to non-zero mean input (2015) Smart Structures and Systems, 15 (2), pp. 489-503; Papadimitriou, C., Fritzen, C.-P., Kraemer, P., Ntotsios, E., Fatigue predictions in entire body of metallic structures from a limited number of vibration sensors using Kalman filtering (2011) Structural Control and Health Monitoring, 18 (5), pp. 554-573; Park, J.-W., Sim, S.-H., Jung, H.-J., Displacement estimation using multimetric data fusion (2013) IEEE/ASME Transactions on Mechatronics, 18 (6), pp. 1675-1682; Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Desmaison, A., PyTorch: An imperative style, high-performance deep learning library (2019) Advances in Neural Information Processing Systems, pp. 8024-8035. , http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf, . Curran Associates, Inc; Pelayo, F., Skafte, A., Aenlle, M.L., Brincker, R., Modal analysis based stress estimation for structural elements subjected to operational dynamic loadings (2015) Experimental Mechanics, 55 (9), pp. 1791-1802; Putnam, E., (2010) Design, experimental, and analytical study of a horizontally curved tubular flange girder, , Bethlehem, PA, Lehigh University; Rafiei, M.H., Adeli, H., A novel unsupervised deep learning model for global and local health condition assessment of structures (2018) Engineering Structures, 156, pp. 598-607; Rafiei, M.H., Khushefati, W.H., Demirboga, R., Adeli, H., Supervised deep restricted Boltzmann machine for estimation of concrete (2017) ACI Materials Journal, 114 (2), pp. 237-244; Rapp, S., Kang, L.-H., Han, J.-H., Mueller, U.C., Baier, H., Displacement field estimation for a two-dimensional structure using fiber Bragg grating sensors (2009) Smart Materials and Structures, 18 (2); Sekiya, H., Kimura, K., Miki, C., Technique for determining bridge displacement response using MEMS accelerometers (2016) Sensors, 16 (2), p. 257. , https://doi.org/10.3390/s16020257; Male, P., Lourens, E.-M., Estimation of accumulated fatigue damage in lattice support structures from operational vibrations (2015) Proceedings of EWEA Offshore 2015: European Offshore Wind Energy Conference and Exhibition, , Van der, Copenhagen, Denmark; Wu, Y., Yuan, M., Dong, S., Lin, L., Liu, Y., Remaining useful life estimation of engineered systems using vanilla LSTM neural networks (2018) Neurocomputing, 275, pp. 167-179; Yang, Y., Sun, P., Nagarajaiah, S., Bachilo, S.M., Weisman, R.B., Full-field, high-spatial-resolution detection of local structural damage from low-resolution random strain field measurements (2017) Journal of Sound and Vibration, 399, pp. 75-85; Yehia, S., Abudayyeh, O., Abdel-Qader, I., Zalt, A., Meganathan, V., Evaluation of sensor performance for concrete applications (2008) Transportation Research Record, 2050 (1), pp. 101-110; Yoneyama, S., Kitagawa, A., Iwata, S., Tani, K., Kikuta, H., Bridge deflection measurement using digital image correlation (2007) Experimental Techniques, 31 (1), pp. 34-40; Zhang, Y., Song, X., Load prediction of space deployable structure based on FBG and LSTM (2019) IEEE Access, 7, pp. 13715-13722; Zheng, S., Ristovski, K., Farahat, A., Gupta, C., (2017) Long short-term memory network for remaining useful life estimation, pp. 88-95. , 2017 IEEE International Conference on Prognostics and Health Management (ICPHM), Dallas, TX","Takáč, M.; Department of Industrial and Systems Engineering, United States; email: mat614@lehigh.edu",,,"Blackwell Publishing Inc.",,,,,10939687,,CCIEF,,"English","Comput.-Aided Civ. Infrastruct. Eng.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85085010123
"Djedidi O., Djeziri M.A.","57195620798;15839204800;","Power profiling and monitoring in embedded systems: A comparative study and a novel methodology based on NARX neural networks",2020,"Journal of Systems Architecture","111",,"101805","","",,3,"10.1016/j.sysarc.2020.101805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084937178&doi=10.1016%2fj.sysarc.2020.101805&partnerID=40&md5=b57434164b08116e671da90ce852941f","Aix-Marseille University, Universitéde Toulon, CNRS, LIS, Marseille, France","Djedidi, O., Aix-Marseille University, Universitéde Toulon, CNRS, LIS, Marseille, France; Djeziri, M.A., Aix-Marseille University, Universitéde Toulon, CNRS, LIS, Marseille, France","Power consumption in electronic systems is an essential feature for the management of energy autonomy, performance analysis, and the aging monitoring of components. Thus, several research studies have been devoted to the development of power models and profilers for embedded systems. Each of these models is designed to fit a specific usage context. This paper is a part of a series of works dedicated to modeling and monitoring embedded systems in airborne equipment. The objective of this paper is twofold. Firstly, it presents an overview of the most used models in the literature. Then, it offers a comparative analysis of these models according to a set of criteria, such as the modeling assumptions, the necessary instrumentation necessary, the accuracy, and the complexity of implementation. Secondly, we introduce a new power estimator for ARM-Based embedded systems, with component-level granularity. The estimator is based on NARX neural networks and used to monitor power for diagnosis purposes. The obtained experimental results highlight the advantages and limitations of the models presented in the literature and demonstrate the effectiveness of the proposed NARX, having obtained the best results in its class for a smartphone (An online Mean Absolute Percentage Error = 2.2%). © 2020","Data fitting; Embedded systems; Machine learning; Modeling; NARX; Neural networks; Power consumption; Power profiling; Smartphone","Monitoring; Airborne equipments; Comparative analysis; Comparative studies; Electronic systems; Essential features; Mean absolute percentage error; NARX neural network; Performance analysis; Embedded systems",,,,,,,,,,,,,,,,"Hoque, M.A., Siekkinen, M., Khan, K.N., Xiao, Y., Tarkoma, S., Modeling, profiling, and debugging the energy consumption of mobile devices (2015) ACM Comput. Surv., 48 (3), pp. 1-40; Kang, J.-M., Park, C.-K., Seo, S.-S., Choi, M.-J., Hong, J.W.-K., User-Centric Prediction for Battery Lifetime of Mobile Devices (2008) Challenges for Next Generation Network Operations and Service Management, Proceedings, 5297, pp. 531-534. , Springer, Berlin, Heidelberg; Kim, D., Chon, Y., Jung, W., Kim, Y., Cha, H., Accurate prediction of available battery time for mobile applications (2016) ACM Trans. Embedded Comput. Syst., 15 (3), pp. 1-17; Kanduri, A., Haghbayan, M.H., Rahmani, A.M., Liljeberg, P., Jantsch, A., Tenhunen, H., Dutt, N., Accuracy-Aware power management for many-core systems running error-Resilient applications (2017) IEEE Trans. Very Large Scale Integr. VLSI Syst., 25 (10), pp. 2749-2762; Martinez, B., Montón, M., Vilajosana, I., Prades, J.D., The power of models: modeling power consumption for IoT devices (2015) IEEE Sens. J., 15 (10), pp. 5777-5789; Bokhari, M.A., Alexander, B., Wagner, M., In-vivo and offline optimisation of energy use in the presence of small energy signals (2018) Proceedings of the 15th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services - MobiQuitous ’18, pp. 207-215. , ACM Press New York, New York, USA; Demirbilek, E., Grgoire, J.-C., Vakili, A., Reyero, L., Modelling and improving the battery performance of a mobile phone application: A methodology (2015) 5th International Conference on Energy Aware Computing Systems and Applications, ICEAC 2015, pp. 1-4. , IEEE; Kim, J.M., Kim, Y.G., Chung, S.W., Stabilizing CPU frequency and voltage for temperature-aware DVFS in mobile devices (2015) IEEE Trans. Comput., 64 (1), pp. 286-292; Park, J.G., Hsieh, C.Y., Dutt, N., Lim, S.S., Quality-aware mobile graphics workload characterization for energy-efficient DVFS design (2014) 2014 IEEE 12th Symposium on Embedded Systems for Real-Time Multimedia, ESTIMedia 2014, pp. 70-79. , IEEE; Li, S., Mishra, S., Optimizing power consumption in multicore smartphones (2015) J. Parallel Distrib. Comput., 95, pp. 124-137; Linares-Vásquez, M., Bavota, G., Cárdenas, C.E.B., Oliveto, R., Di Penta, M., Poshyvanyk, D., Optimizing energy consumption of GUIs in Android apps: a multi-objective approach (2015) Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering - ESEC/FSE 2015, pp. 143-154. , ACM Press New York, New York, USA; Guo, Y., Wang, C., Chen, X., Understanding application-battery interactions on smartphones: a large-scale empirical study (2017) IEEE Access, 5, pp. 13387-13400; Abbasi, A.M., Al-tekreeti, M., Ali, Y., Naik, K., Nayak, A., Goel, N., Plourde, B., A framework for detecting energy bugs in smartphones (2015) 2015 6th International Conference on the Network of the Future (NOF), pp. 1-3. , IEEE; Koo, J., Lee, K., Lee, W., Park, Y., Choi, S., BattTracker: enabling energy awareness for smartphone using Li-ion battery characteristics (2016) Proceedings - IEEE INFOCOM, 2016-July, pp. 1-9. , IEEE; Caviglione, L., Gaggero, M., Lalande, J.F., Mazurczyk, W., Urbański, M., Seeing the unseen: revealing mobile malware hidden communications via energy consumption and artificial intelligence (2016) IEEE Trans. Inf. Forensics Secur., 11 (4), pp. 799-810; Merlo, A., Migliardi, M., Fontanelli, P., Measuring and estimating power consumption in android to support energy-based intrusion detection (2015) J. Comput. Secur., 23 (5), pp. 611-637; Suarez-Tangil, G., Tapiador, J.E., Peris-Lopez, P., Pastrana, S., Power-aware anomaly detection in smartphones: an analysis of on-platform versus externalized operation (2015) Pervasive Mob. Comput., 18, pp. 137-151; Djedidi, O., Djeziri, M.A., M'Sirdi, N.K., Data-Driven approach for feature drift detection in embedded electronic devices (2018) IFAC-PapersOnLine, 51 (24), pp. 1024-1029; Djedidi, O., Djeziri, M.A., M'Sirdi, N.K., Naamane, A., Modular modelling of an embedded mobile CPU-GPU chip for feature estimation (2017) Proceedings of the 14th International Conference on Informatics in Control, Automation and Robotics, 1, pp. 338-345. , SciTePress Mardrid, Spain; Shukla, N.K., Pila, R., Rawat, S., Utilization-based power consumption profiling in smartphones (2016) Proceedings of the 2016 2nd International Conference on Contemporary Computing and Informatics, IC3I 2016, pp. 881-886. , IEEE; Rattagan, E., Chu, E.T., Lin, Y.D., Lai, Y.C., Semi-online power estimation for smartphone hardware components (2015) 2015 10th IEEE International Symposium on Industrial Embedded Systems, SIES 2015 - Proceedings, pp. 174-177. , IEEE; Mittal, R., Kansal, A., Chandra, R., Empowering developers to estimate app energy consumption (2012) Proceedings of the 18th annual international conference on Mobile computing and networking - Mobicom ’12, p. 317. , ACM Press New York, New York, USA; Huang, J., Li, R., An, J., Ntalasha, D., Yang, F., Li, K., Energy-Efficient resource utilization for heterogeneous embedded computing systems (2017) IEEE Trans. Comput., 66 (9), pp. 1518-1531; Niu, L., Zhu, D., Reliability-aware scheduling for reducing system-wide energy consumption for weakly hard real-time systems (2017) J. Syst. Archit., 78, pp. 30-54; Ahmad, R.W., Gani, A., Hamid, S.H.A., Xia, F., Shiraz, M., A review on mobile application energy profiling: taxonomy, state-of-the-art, and open research issues (2015) J. Network Comput. Appl., 58, pp. 42-59; Benkhelifa, E., Welsh, T., Tawalbeh, L., Jararweh, Y., Basalamah, A., Energy optimisation for mobile device power consumption: A Survey and a unified view of modelling for a comprehensive network simulation (2016) Mob. Networks Appl., 21 (4), pp. 575-588; (2019), I. Qualcomm Innovation Center, Trepn Profiler - Android Apps on Google Play; Zhang, L., Tiwana, B., Qian, Z., Wang, Z., Dick, R.P., Mao, Z.M., Yang, L., Accurate online power estimation and automatic battery behavior based power model generation for smartphones (2010) Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis - CODES/ISSS ’10, p. 105. , ACM Press New York, New York, USA; Dong, M., Zhong, L., Self-constructive high-rate system energy modeling for battery-powered mobile systems (2011) MobiSys, p. 335. , ACM Press New York, New York, USA; Ardito, L., Procaccianti, G., Torchiano, M., Migliore, G., Profiling power consumption on mobile devices (2013) Proceedings of The Third International Conference on Smart Grids, Green Communications and IT Energy-aware Technologies, pp. 101-106. , IARIA Lisbon; Yoon, C., Lee, S., Choi, Y., Ha, R., Cha, H., Accurate power modeling of modern mobile application processors (2017) J. Syst. Archit., 81, pp. 17-31; Kim, Y.G., Kim, M., Kim, J.M., Sung, M., Chung, S.W., A novel GPU power model for accurate smartphone power breakdown (2015) ETRI J., 37 (1), pp. 157-164; Di Nucci, D., Palomba, F., Prota, A., Panichella, A., Zaidman, A., De Lucia, A., PETrA: a software-based tool for estimating the energy profile of android applications (2017) 2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C), pp. 3-6. , IEEE; Chowdhury, S.A., Hindle, A., GreenOracle: estimating software energy consumption with energy measurement corpora (2016) Proceedings of the 13th International Workshop on Mining Software Repositories - MSR ’16, pp. 49-60. , ACM Press New York, New York, USA; Walker, M.J., Diestelhorst, S., Hansson, A., Das, A.K., Yang, S., Al-Hashimi, B.M., Merrett, G.V., Accurate and stable run-Time power modeling for mobile and embedded CPUs (2017) IEEE Trans. Comput. Aided Des. Integr. Circuits Syst., 36 (1), pp. 106-119; Kim, K., Shin, D., Xie, Q., Wang, Y., Pedram, M., Chang, N., FEPMA: fine-grained event-driven power meter for android smartphones based on device driver layer event monitoring (2014) Design, Automation I& Test in Europe Conference and Exhibition (DATE), pp. 1-6. , IEEE Conference Publications New Jersey; Dzhagaryan, A., Milenković, A., Milosevic, M., Jovanov, E., An environment for automated measuring of energy consumed by android mobile devices (2016) PECCS 2016 - Proceedings of the 6th International Joint Conference on Pervasive and Embedded Computing and Communication Systems, pp. 28-39. , SCITEPRESS - Science and Technology Publications Lisbon, Portugal; Sun, L., Sheshadri, R.K., Zheng, W., Koutsonikolas, D., Modeling WiFi active power/energy consumption in smartphones (2014) Proceedings - International Conference on Distributed Computing Systems, pp. 41-51. , IEEE; Djedidi, O., Djeziri, M.A., M'Sirdi, N.K., Naamane, A., A novel easy-to-construct power model for embedded and mobile systems using recursive neural nets to estimate power consumption of arm-based embedded systems and mobile devices (2018) Proceedings of the 15th International Conference on Informatics in Control, Automation and Robotics (ICINCO 2018), volume 1, INSTICC, pp. 541-545. , SciTePress Porto, Portugal; Ahmad, R.W., Gani, A., Ab Hamid, S.H., Naveed, A., Kwangman, K.O., Rodrigues, J.J., A case and framework for code analysis-based smartphone application energy estimation (2017) Int. J. Commun. Syst., 30 (10), p. e3235; Di Nucci, D., Palomba, F., Prota, A., Panichella, A., Zaidman, A., De Lucia, A., Software-based energy profiling of Android apps: Simple, efficient and reliable? (2017) SANER 2017 - 24th IEEE International Conference on Software Analysis, Evolution, and Reengineering, 15, pp. 103-114. , IEEE; Pathak, A., Hu, Y.C., Zhang, M., Where is the energy spent inside my app?: Fine grained energy accounting on smartphones with Eprof (2012) Proceedings of the 7th ACM European Conference on Computer Systems, EuroSys ’12, pp. 29-42. , ACM New York, NY, USA; Holleis, P., Luther, M., Broll, G., Souville, B., A DIY power monitor to compare mobile energy consumption in situ (2013) Proceedings of the 15th International Conference on Human-Computer Interaction with Mobile Devices and Services, ACM, pp. 416-421; Altamimi, M.L., Naik, K., A computing profiling procedure for mobile developers to estimate energy cost (2015) Proceedings of the 18th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems - MSWiM ’15, pp. 301-305. , ACM Press New York, New York, USA; Pathak, A., Hu, Y.C., Zhang, M., Bahl, P., Wang, Y.-M., Fine-grained power modeling for smartphones using system call tracing (2011) Proceedings of the sixth conference on Computer systems EuroSys 11, p. 153; Dousti, M.J., Ghasemi-Gol, M., Nazemi, M., Pedram, M., ThermTap: an online power analyzer and thermal simulator for Android devices (2015) Proceedings of the International Symposium on Low Power Electronics and Design, 2015-Septe, pp. 341-346. , IEEE; Fu, Y., Li, L., Wang, K., Zhang, C., Kalman predictor-Based proactive dynamic thermal management for 3-D NoC systems with noisy thermal sensors (2017) IEEE Trans. Comput.-Aided Des.Integr. Circuits Syst., 36 (11), pp. 1869-1882; Zhang, N., Ramanathan, P., Kim, K.-H., Banerjee, S., PowerVisor: a battery virtualization scheme for smartphones (2012) Proceedings of the Third ACM Workshop on Mobile Cloud Computing and Services - MCS ’12, p. 37. , ACM Press New York, New York, USA; Bornholt, J., Mytkowicz, T., McKinley, K.S., The model is not enough: understanding energy consumption in mobile devices (2012) 2012 IEEE Hot Chips 24 Symposium (HCS), pp. 1-3. , IEEE; Djedidi, O., Djeziri, M.A., M'Sirdi, N.K., Naamane, A., Constructing an accurate and a high-performance power profiler for embedded systems and smartphones (2018) Proceedings of the 21st ACM International Conference on Modelling, Analysis and Simulation of Wireless and Mobile Systems (MSWIM ’18), 18, pp. 79-82. , ACM Press Montréal, Canada; Alawnah, S., Sagahyroon, A., Modeling of smartphones’ power using neural networks (2017) Eurasip J. Embedded Syst., 2017 (1), p. 22; Kamiyama, T., Inamura, H., Ohta, K., A model-based energy profiler using online logging for Android applications (2014) 2014 7th International Conference on Mobile Computing and Ubiquitous Networking, ICMU 2014, pp. 7-13. , IEEE; Chen, X., Chen, Y., Dong, M., Zhang, C., Demystifying energy usage in smartphones (2014) Design Automation Conference (DAC), pp. 1-5; Romansky, S., Borle, N.C., Chowdhury, S., Hindle, A., Greiner, R., Deep Green: modelling time-series of software energy consumption (2017) 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 273-283. , IEEE; Xu, F., Liu, Y., Li, Q., Zhang, Y., V-edge: fast self-constructive power modeling of smartphones based on battery voltage dynamics (2013) nsdi’13 Proceedings of the 10th USENIX conference on Networked Systems Design and Implementation, pp. 43-55. , USENIX Lombard, IL; Shin, D., Kim, K., Chang, N., Lee, W., Wang, Y., Xie, Q., Pedram, M., Online estimation of the remaining energy capacity in mobile systems considering system-wide power consumption and battery characteristics (2013) Proceedings of the Asia and South Pacific Design Automation Conference, ASP-DAC, pp. 59-64. , IEEE; Jung, W., Kang, C., Yoon, C., Kim, D.D., Cha, H., DevScope: a nonintrusive and online power analysis tool for smartphone hardware components (2012) Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis - CODES+ISSS ’12, p. 353; (2019), Qualcomm Technologies Inc, Snapdragon Profiler - Qualcomm Developer Network; Cornillon, P.-A., Matzner-Løber, E., Régression: Théorie et applications (2007) Statistique et probabilités appliquées, , Springer; F.J.M., Jr., The kolmogorov-smirnov test for goodness of fit (1951) J. Am. Stat. Assoc., 46 (253), pp. 68-78; Engle, R.F., Autoregressive conditional heteroscedasticity with estimates of the variance of united kingdom inflation (1982) Econometrica, 50 (4), pp. 987-1007; (2019), Qualcomm Inc, Trepn Power Profiler - FAQs - Qualcomm Developer Network; Bokhari, M.A., Bruce, B.R., Alexander, B., Wagner, M., Deep parameter optimisation on Android smartphones for energy minimisation (2017) Proceedings of the Genetic and Evolutionary Computation Conference Companion on - GECCO ’17, pp. 1501-1508. , ACM Press New York, New York, USA; Hindle, A., Wilson, A., Rasmussen, K., Barlow, E.J., Campbell, J.C., Romansky, S., GreenMiner: a hardware based mining software repositories software energy consumption framework (2014) Proceedings of the 11th Working Conference on Mining Software Repositories - MSR 2014, pp. 12-21. , ACM Press Hyderabad, India; Bokhari, M., Wagner, M., Optimising energy consumption heuristically on android mobile phones (2016) Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion - GECCO ’16 Companion, pp. 1139-1140. , ACM Press New York, New York, USA; Carvalho, S.A., Cunha, D.C., Silva-Filho, A.G., On the use of nonlinear methods for low-power CPU frequency prediction based on Android context variables (2016) Proceedings - 2016 IEEE 15th International Symposium on Network Computing and Applications, NCA 2016, pp. 250-253. , IEEE; Yoon, C., Kim, D., Jung, W., Kang, C., Cha, H., Appscope: application energy metering framework for android smartphone using kernel activity monitoring (2012) Presented as Part of the 2012 USENIX Annual Technical Conference (USENIX ATC 12), pp. 387-400; Lu, Z., Cao, C., Tao, X., Improving screen power usage model on android smartphones (2016) Proceedings - Asia-Pacific Software Engineering Conference, APSEC, 2016-May, pp. 167-173. , IEEE; Gordon, M., Zhang, L., Tiwana, B., (2011), PowerTutor; Li, J., Xiao, J., Hong, J.W.K., Boutaba, R., FSM-based Wi-Fi power estimation method for smart devices (2015) Proceedings of the 2015 IFIP/IEEE International Symposium on Integrated Network Management, IM 2015, pp. 147-155. , IEEE; Li, D., Hao, S., Gui, J., Halfond, W.G., An empirical study of the energy consumption of android applications (2014) 2014 IEEE International Conference on Software Maintenance and Evolution, pp. 121-130. , IEEE; Jin, T., He, S., Liu, Y., Towards accurate GPU power modeling for smartphones (2015) Proceedings of the 2nd Workshop on Mobile Gaming - MobiGames ’15, pp. 7-11. , ACM Press New York, New York, USA; Lee, J., Joe, H., Kim, H., Automated power model generation method for smartphones (2014) IEEE Trans. Consum. Electron., 60 (2), pp. 190-197; Jaymin, L., Hyunwoo, J., Hyungshin, K., Smart phone power model generation using use pattern analysis (2012) 2012 IEEE International Conference on Consumer Electronics (ICCE), pp. 412-413. , IEEE; Arpinen, T., Salminen, E., Hämäläinen, T.D., Hännikäinen, M., MARTE profile extension for modeling dynamic power management of embedded systems (2012) J. Syst. Archit., 58 (5), pp. 209-219; König, I., Memon, A., David, K., Energy consumption of the sensors of Smartphones (2013) 10th International Symposium on Wireless Communications Systems (ISWCS), pp. 723-727; Hao, S., Li, D., Halfond, W.G.J., Govindan, R., Estimating mobile application energy consumption using program analysis (2013) Proceedings of the 2013 International Conference on Software Engineering, ICSE ’13, pp. 92-101. , IEEE Press Piscataway, NJ, USA; Nacci, A.A., Trovò, F., Maggi, F., Ferroni, M., Cazzola, A., Sciuto, D., Santambrogio, M.D., Adaptive and flexible smartphone power modeling (2013) Mob. Networks Appl., 18 (5), pp. 600-609; Kim, M., Chung, S.W., Accurate GPU power estimation for mobile device power profiling (2013) Digest of Technical Papers - IEEE International Conference on Consumer Electronics, pp. 183-184; Kim, M., Kong, J., Chung, S.W., Enhancing online power estimation accuracy for smartphones (2012) IEEE Trans. Consum. Electron., 58 (2), pp. 333-339; Murmuria, R., Medsger, J., Stavrou, A., Voas, J.M., Mobile application and device power usage measurements (2012) Proceedings of the 2012 IEEE 6th International Conference on Software Security and Reliability, SERE 2012, pp. 147-156. , IEEE; Kim, M., Kong, J., Chung, S.W., An online power estimation technique for multi-core smartphones with advanced display components (2012) 2012 IEEE International Conference on Consumer Electronics (ICCE), pp. 666-667. , IEEE; Yusuke, K., Okuhira, T., Tohru, I., Kenji, H., Takeshi, K., Masaji, K., A run-time power analysis method using OS-observable parameters for mobile terminals (2010) Proc. of International Conference on Embedded Systems and Intelligent Technology(ICESIT), 2010, pp. 1-6; Gurun, S., Krintz, C., A run-time, feedback-based energy estimation model For embedded devices (2006) Proceedings of the 4th International Conference on Hardware/Software Codesign and System Synthesis - CODES+ISSS ’06, p. 28. , ACM Press New York, New York, USA; Arena, G.S.M., (2016), Samsung Galaxy S8+ - Full phone specifications; (2019), NXP Inc., i.MX 6SoloX Applications Processors | Arm® Cortex®-A9, Cortex-M4 |NXP; (2019), Pcmag, GPU Definition from PC Magazine Encyclopedia; Ciman, M., Gaggi, O., An empirical analysis of energy consumption of cross-platform frameworks for mobile development (2017) Pervasive Mob. Comput., 39, pp. 214-230; Lin, Y.D., Rattagan, E., Lai, Y.C., Chang, L.P., Yo, Y.C., Ho, C.Y., Chang, S.L., Calibrating parameters and formulas for process-level energy consumption profiling in smartphones (2014) J. Network Comput. Appl., 44, pp. 106-119; (2019), Samsung, Samsung Opensource Release Center; Samsung, I., (2017), Exynos 9 Series 8895 Processor: Specs, Features | Samsung Exynos; Almusalli, F.A., Zaman, N., Rasool, R., Energy efficient middleware: Design and development for mobile applications (2017) 2017 19th International Conference on Advanced Communication Technology (ICACT), pp. 541-549. , IEEE; Xie, H., Tang, H., Liao, Y.H., Time series prediction based on narx neural networks: an advanced approach (2009) Proceedings of the 2009 International Conference on Machine Learning and Cybernetics, 3, pp. 1275-1279. , IEEE; (2019), AnTuTu, AnTuTu Benchmark - Android Apps on Google Play; (2019), Primate Labs Inc., Geekbench 4 - Android Apps on Google Play; Futuremark Oy, PCMark for Android Benchmark - Android Apps on Google Play, 2019a; Futuremark Oy, 3DMark - The Gamer's Benchmark - Android Apps on Google Play, 2019b","Djedidi, O.; Aix-Marseille University, France; email: oussama.djedidi@lis-lab.fr",,,"Elsevier B.V.",,,,,13837621,,JSARF,,"English","J Syst Archit",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85084937178
"Wang H., Luo Y., An W., Sun Q., Xu J., Zhang L.","56516241700;57220124176;57195987607;57204813965;57193740884;55115873800;","PID Controller-Based Stochastic Optimization Acceleration for Deep Neural Networks",2020,"IEEE Transactions on Neural Networks and Learning Systems","31","12","8972933","5079","5091",,17,"10.1109/TNNLS.2019.2963066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082399171&doi=10.1109%2fTNNLS.2019.2963066&partnerID=40&md5=25ad260feac650cdb454f5cb5656aa00","Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China; Department of Mathematics, Stanford University, Stanford, CA  94305, United States; College of Computer Science, Nankai University, Tianjin, 300071, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong, Hong Kong","Wang, H., Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China; Luo, Y., Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China; An, W., Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China; Sun, Q., Department of Mathematics, Stanford University, Stanford, CA  94305, United States; Xu, J., College of Computer Science, Nankai University, Tianjin, 300071, China; Zhang, L., Department of Computing, Hong Kong Polytechnic University, Hong Kong, Hong Kong","Deep neural networks (DNNs) are widely used and demonstrated their power in many applications, such as computer vision and pattern recognition. However, the training of these networks can be time consuming. Such a problem could be alleviated by using efficient optimizers. As one of the most commonly used optimizers, stochastic gradient descent-momentum (SGD-M) uses past and present gradients for parameter updates. However, in the process of network training, SGD-M may encounter some drawbacks, such as the overshoot phenomenon. This problem would slow the training convergence. To alleviate this problem and accelerate the convergence of DNN optimization, we propose a proportional-integral-derivative (PID) approach. Specifically, we investigate the intrinsic relationships between the PID-based controller and SGD-M first. We further propose a PID-based optimization algorithm to update the network parameters, where the past, current, and change of gradients are exploited. Consequently, our proposed PID-based optimization alleviates the overshoot problem suffered by SGD-M. When tested on popular DNN architectures, it also obtains up to 50% acceleration with competitive accuracy. Extensive experiments about computer vision and natural language processing demonstrate the effectiveness of our method on benchmark data sets, including CIFAR10, CIFAR100, Tiny-ImageNet, and PTB. © 2012 IEEE.","Deep neural network (DNN); optimization; proportional-integral-derivative (PID) control; stochastic gradient descent (SGD)-momentum","Acceleration control; Computer vision; Deep neural networks; Gradient methods; Natural language processing systems; Optimization; Proportional control systems; Three term control systems; Two term control systems; NAtural language processing; Network parameters; Optimization algorithms; Overshoot phenomena; Overshoot problem; Proportional integral derivatives; Stochastic gradient descent; Stochastic optimizations; Neural networks; algorithm; factual database; Markov chain; natural language processing; visual prosthesis; Algorithms; Databases, Factual; Deep Learning; Natural Language Processing; Neural Networks, Computer; Stochastic Processes; Visual Prosthesis",,,,,"Office of Defense Nuclear Nonproliferation, DNN; National Natural Science Foundation of China, NSFC: 61531014, 61571259, 61831014, GGFW2017040714161462; Science and Technology Planning Project of Shenzhen Municipality: JCYJ20170817161916238, JCYJ20180508152042002","optimizer is also a key point of a model. Even with the same data set and architecture, different optimizers could result in I. INTRODUCTION very different training effects, due to different directions of the B ENEFITTING from the availability of a great number gradient descent, different optimizers may reach completely of data (e.g., ImageNet [1]) and the fast-growing power different local minimum [9]. The learning rate is another principal hyperparameter for December5,2019;acceptedDecember25,2019.Date ofpublicationManuscriptreceivedApril 1,2019;revisedSeptember20,2019 and DNN training [10]. Based on different strategies of choos-January 28, 2020; date of current version December 1, 2020. This work ing learning rates, DNN optimizers can be categorized into was supported in part by the National Natural Science Foundation of two groups: 1) Hand-tuned learning rate optimizers, such 61531014,andinpartbytheShenzhenScienceandTechnologyProjectunderChina (NSFC)fundunderGrant 61571259,Grant61831014,and Grant as stochastic gradient descent (SGD) [11], SGD-momentum GrantJCYJ20170817161916238,GrantJCYJ20180508152042002,andGrant (SGD-M) [12], Nesterov′s momentum [12], and so on, GGFW2017040714161462. (Corresponding author: Haoqian Wang.) and 2. Auto learning rate optimizers, such as AdaGrad [13], ShenzhenInternationalGraduateSchool,TsinghuaUniversity, ShenzhenHaoqianWang, Yi Luo,and WangpengAnarewiththeTsinghua RMSProp [14], Adam [15], and so on. 518055, China, andalsowiththeShenzhen Institute ofFutureMedia Tech- The SGD-M method puts past and current gradients nology, Shenzhen 518055, China (e-mail: wanghaoqian@tsinghua.edu.cn; into consideration and then updates the network parame-QingyunSuniswiththeDepartmentofMathematics, StanfordUniversity,vast2stars@gmail.com; anwangpeng@gmail.com). ters. Although SGD-M performs well in most cases, it may Stanford,CA94305USA(e-mail:qysun@stanford.edu). encounter an overshoot phenomenon [16], which indicates Jun Xu is with the College of Computer Science, Nankai the case where the weight exceeds its target value too much Lei Zhang iswiththeDepartmentof Computing,TheHong KongTianjin300071,China(e-mail:nankaimathxujun@gmail.com). and fails to correct its update direction. Such an overshoot Polytechnic University, Hong Kong, and also with the Artificial Intelli- problem costs more resources (e.g., time and GPUs) to gence Center, Alibaba DAMO Academy, Hangzhou 311121, China (e-mail: train a DNN and also hampers the convergence of SGD-Color versionsof oneormore ofcslzhang@comp.polyu.edu.hk). M. Therefore, a more efficient DNN optimizer is eagerly onlineathttps://ieeexplore.ieee.org. desired to alleviate the overshoot problem and achieve better Digital Object Identifier 10.1109/TNNLS.2019.2963066 convergence. 2162-237X © 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.","This work was supported in part by the National Natural Science Foundation of China (NSFC) fund under Grant 61571259, Grant 61831014, and Grant 61531014, and in part by the Shenzhen Science and Technology Project under Grant JCYJ20170817161916238, Grant JCYJ20180508152042002, and Grant GGFW2017040714161462.",,,,,,,,,"Russakovsky, O., Imagenet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252. , Dec; Bottou, L., Large-scale machine learning with stochastic gradient descent (2010) Proc. 19th Int. Conf. Comput. Statist., pp. 177-186. , Paris, France, Aug; Zhang, J., (2019) Gradient Descent Based Optimization Algorithms for Deep Learning Models Training, , https://arxiv.org/abs/1903.03614, Mar; Denton, E.L., Zaremba, W., Bruna, J., LeCun, Y., Fergus, R., Exploiting linear structure within convolutional networks for efficient evaluation (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 1269-1277; Jaderberg, M., Vedaldi, A., Zisserman, A., (2014) Speeding up Convolutional Neural Networks with Low Rank Expansions, , https://arxiv.org/abs/1405.3866, Mayy; Zhang, X., Zou, J., He, K., Sun, J., Accelerating very deep convolutional networks for classification and detection (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (10), pp. 1943-1955. , Oct; Vasilache, N., Johnson, J., Mathieu, M., Chintala, S., Piantino, S., LeCun, Y., (2014) Fast Convolutional Nets with Fbfft: A GPU Performance Evaluation, , https://arxiv.org/abs/1412.7580, Dec; Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y., Fitnets: Hints for thin deep nets (2015) Proc. Int. Conf. Learn. Representations; Im, D.J., Tao, M., Branson, K., An empirical analysis of the optimization of deep network loss surfaces (2017) Proc. Int. Conf. Learn. Representations (ICLR); Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning. Cambridge, , MA, USA: MIT Press; Bottou, L., Online learning and stochastic approximations (1998) Online Learning in Neural Networks, pp. 9-42. , http://dl.acm.org/citation.cfm?id=304710.304720, D. Saad, Ed., Cambridge, U.K.: Cambridge Univ. Press; Sutskever, I., Martens, J., Dahl, G., Hinton, G., On the importance of initialization and momentum in deep learning (2013) Proc. Int. Conf. Mach. Learn.; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) J. Mach. Learn. Res., 12, pp. 2121-2159. , Feb; Hinton, G., Srivastava, N., Swersky, K., (2012) Neural Networks for Machine Learning Lecture 6a Overview of Mini-batch Gradient Descent, , https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf, Univ. Toronto, Toronto, ON, Canada; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2014) Proc. Int. Conf. Learn. Represent. (ICLR); Ogata, K., (1995) Discrete-Time Control Systems. Upper Saddle River, 2. , NJ, USA: Prentice-Hall; Lessard, L., Recht, B., Packard, A., Analysis and design of optimization algorithms via integral quadratic constraints (2016) Siam J. Optim., 26 (1), pp. 57-95. , Jan; Wang, L., Cluett, W., Barnes, T., New frequency-domain design method for PID controllers (1995) Iee Proc. Control Theory Appl., 142 (4), pp. 265-271. , Jul; Heong Ang, K., Chong, G., Li, Y., PID control system analysis, design, and technology (2005) IEEE Trans. Control Syst. Technol., 13 (4), pp. 559-576. , Jul; Salih, A.L., Moghavvemi, M., Mohamed, H.A.F., Gaeid, K.S., Modelling and PID controller design for a quadrotor unmanned air vehicle (2010) Proc. IEEE Int. Conf. Autom., Qual. Test., Robot. (AQTR), 1, pp. 1-5. , May; Rocco, P., Stability of PID control for industrial robot arms (1996) IEEE Trans. Robot. Autom., 12 (4), pp. 606-614; Zhao, P., Chen, J., Song, Y., Tao, X., Xu, T., Mei, T., Design of a control system for an autonomous vehicle based on adaptive-PID (2012) Int. J. Adv. Robot. Syst., 9 (2), p. 44. , https://doi.org/10.5772/51314, Aug; Laplace, P.S., (1820) Theorie Analytique des Probabilites. Roubaix, , France: Courcier; An, W., Wang, H., Sun, Q., Xu, J., Dai, Q., Zhang, L., A PID controller approach for stochastic optimization of deep networks (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., , Jun; Polyak, B., Some methods of speeding up the convergence of iteration methods (1964) Ussr Comput. Math. Math. Phys., 4 (5), pp. 1-17. , Jan; Wei, Y., HCP: A flexible CNN framework for multi-label image classification (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (9), pp. 1901-1907. , Sep; Girshick, R., Donahue, J., Darrell, T., Malik, J., Region-based convolutional networks for accurate object detection and segmentation (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (1), pp. 142-158. , Jan; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (6), pp. 1137-1149. , Jun; Ouyang, W., DeepID-Net: Object detection with deformable part based convolutional neural networks (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (7), pp. 1320-1334. , Jul; Farabet, C., Couprie, C., Najman, L., Lecun, Y., Learning hierarchical features for scene labeling (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (8), pp. 1915-1929. , Aug; Goodfellow, I., Generative adversarial nets (2014) Proc. Nips; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780. , https://doi.org/10.1162/neco.1997.9.8.1735; Arjovsky, M., Shah, A., Bengio, Y., Unitary evolution recurrent neural networks (2016) Proc. 33nd Int. Conf. Mach. Learn. (ICML). New York, pp. 1120-1128. , http://jmlr.org/proceedings/papers/v48/arjovsky16.html, NY, USA, Jun; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding (2015) Proc. Int. Conf. Learn. Represent. (ICLR); Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C., Learning efficient convolutional networks through network slimming (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 2736-2744. , Oct; He, Y., Liu, P., Wang, Z., Hu, Z., Yang, Y., Filter pruning via geometric median for deep convolutional neural networks acceleration (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 4340-4349. , Jun; Dai, X., Yin, H., Jha, N.K., NeST: A neural network synthesis tool based on a grow-and-prune paradigm (2019) IEEE Trans. Comput., 68 (10), pp. 1487-1497. , Oct; Du, X., Li, Z., Cao, Y., (2019) Cgap: Continuous Growth and Pruning for Efficient Deep Learning, , https://arxiv.org/abs/1905.11533, May; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Quantized neural networks: Training neural networks with low precision weights and activations (2017) J. Mach. Learn. Res., 18 (1), pp. 6869-6898; Kidambi, R., Netrapalli, P., Jain, P., Kakade, S., On the insufficiency of existing momentum schemes for stochastic optimization (2018) Proc. Inf. Theory Appl. Workshop (ITA), , Feb; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., (2016) Pruning Filters for Efficient Convnets, , https://arxiv.org/abs/1608.08710, Aug; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), , Jun; Huang, G., Liu, Z., Maaten, L.V.D., Weinberger, K.Q., Densely connected convolutional networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), , Jul; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) Proc. IEEE Eur. Conf. Comput. Vis. (ECCV), pp. 630-645. , Oct; Zagoruyko, S., Komodakis, N., Wide residual networks (2016) Proc. Brit. Mach. Vis. Conf.; Nesterov, Y., A method of solving a convex programming problem with convergence rate o (1/k2) (1983) Sov. Math. Doklady, 269 (3), pp. 543-547; Maxwell, J.C., On governors (1867) Proc. Roy. Soc. London, 16, pp. 270-283. , Dec; Minorsky, N., Directional stability of automatically steered bodies (2010) J. Amer. Soc. Nav. Eng., 34 (2), pp. 280-309. , Aug; Qian, N., On the momentum term in gradient descent learning algorithms (1999) Neural Netw., 12 (1), pp. 145-151. , Jan; Spiegel, M.R., (1991) Advanced Mathematics. New York, , NY, USA: McGraw-Hill; De Jong, K., An analysis of the behavior of a class of genetic adaptive systems (1975) Ph.D. Dissertation, Dept. Comput. Commun. Sci., Univ. Michigan, , Ann Arbor, MI, USA; Ziegler, J.G., Nichols, N.B., Optimum settings for automatic controllers (1942) Trans. Asme, 64 (11), pp. 759-765; Robert, G.E., Kaufman, H., (1966) Table Laplace Transforms. Philadelphia, , PA, USA: Saunders; Khalil, H.K., (1996) Nonlinear Systems. Upper Saddle River, , NJ, USA: Prentice-Hall; Li, F.F., Tiny imagenet visual recognition challenge (2015) Sandford Artif. Intell. Lab., , https://tiny-imagenet.herokuapp.com/, Stanford Univ., Stanford, CA, USA; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. Ieee, 86 (11), pp. 2278-2324. , Nov; Krizhevsky, A., Learning multiple layers of features from tiny images (2009) M.S. Thesis, Univ. Toronto, , Toronto, ON, Canada; Xie, S., Girshick, R., Dollár, P., Tu, Z., He, K., Aggregated residual transformations for deep neural networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), , Jul; Cooijmans, T., Ballas, N., Laurent, C., Gülçehre, Ç., Courville, A., (2016) Recurrent Batch Normalization, , https://arxiv.org/abs/1603.09025; Laurent, C., Pereyra, G., Brakel, P., Zhang, Y., Bengio, Y., Batch normalized recurrent neural networks (2016) Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), pp. 2657-2661. , Mar; Gal, Y., Ghahramani, Z., A theoretically grounded application of dropout in recurrent neural networks (2016) Proc. Adv. Neural Inf. Process. Syst. 29thAnnu. Conf. Neural Inf. Process. Syst. Barcelona, pp. 1019-1027. , Spain, Dec","Wang, H.; Tsinghua Shenzhen International Graduate School, China; email: wanghaoqian@tsinghua.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,2162237X,,,"32011265","English","IEEE Trans. Neural Networks Learn. Sys.",Article,"Final","",Scopus,2-s2.0-85082399171
"Wang D., Xu K., Guo J., Ghiasi S.","56918742900;57203777751;57214099449;57204259395;","DSP-Efficient Hardware Acceleration of Convolutional Neural Network Inference on FPGAs",2020,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","39","12","8963678","4867","4880",,8,"10.1109/TCAD.2020.2968023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078147486&doi=10.1109%2fTCAD.2020.2968023&partnerID=40&md5=8a899702262790c211abcc742d779ba7","School of Computer and Information Technology, Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA, United States","Wang, D., School of Computer and Information Technology, Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing, China; Xu, K., Institute of Information Science, Beijing Jiaotong University, Beijing, China; Guo, J., Institute of Information Science, Beijing Jiaotong University, Beijing, China; Ghiasi, S., Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA, United States","Field-programmable gate array (FPGA)-based accelerators for convolutional neural network (CNN) inference have received significant attention in recent years. The reported designs tend to adopt a similar underlying approach based on multiplier-accumulator (MAC) arrays, which yields strong demand for the available on-chip DSP blocks, while leaving FPGA logic and memory resources underutilized. The practical outcome is that the computational roof of the accelerator is bound by the number of DSP blocks offered by the target FPGA. In addition, integrating the CNN accelerator with other functional units that may also need DSP blocks would degrade the inference performance. Leveraging the robustness of inference accuracy to limited arithmetic precision, we propose a transformation to the convolution computation, which leads to transformation of the accelerator design space and relaxes the pressure on the required DSP resources. Through analytical and empirical evaluations, we demonstrate that our approach enables us to strike a favorable balance between utilization of the FPGA on-chip memory, logic, and DSP resources, due to which, our accelerator considerably outperforms state of the art. We report the effectiveness of our approach on a variety of FPGA devices, including Cyclone-V, Stratix-V, and Arria-10, which are used in large number of applications, ranging from embedded settings to high performance computing. Our proposed technique yields 1.5× throughput improvement and 4× DSP resource reduction compared to the best frequency domain convolution-based accelerator, and 2.5× boost in raw arithmetic performance and 8.4× saving in DSPs compared to a state-of-the-art sparse convolution-based accelerator. © 1982-2012 IEEE.","Accelerator architectures; application specific integrated circuits; artificial neural networks; neural network hardware; reconfigurable architectures","Acceleration; Computation theory; Computer circuits; Convolution; Digital signal processing; Field programmable gate arrays (FPGA); Frequency domain analysis; Latexes; Microprocessor chips; Paper; Storms; Convolution computations; High performance computing; IEEE; IEEEtran; journal; Multiplier-accumulators; template; Throughput improvement; Convolutional neural networks",,,,,"DJHL-20190202-006; 2018ZTE05-01; National Natural Science Foundation of China, NSFC: 61574013; China Scholarship Council, CSC: 201807095007; Natural Science Foundation of Beijing Municipality: 4202063","Manuscript received August 1, 2019; revised October 21, 2019; accepted December 28, 2019. Date of publication January 20, 2020; date of current version November 20, 2020. This work was supported in part by the NNSF of China under Grant 61574013, in part by the CSC Scholarship under Grant 201807095007, in part by the BJTU-Kuaishou under Research Grant DJHL-20190202-006, in part by the BJTU-ZTE under Research Grant 2018ZTE05-01, and in part by the Beijing Natural Science Foundation under Grant 4202063. This article was recommended by Associate Editor L. Benini. (Corresponding author: Dong Wang.) Dong Wang is with the School of Computer and Information Technology, Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing 100044, China (e-mail: wangdong@bjtu.edu.cn).",,,,,,,,,,"Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. ICLR, San Diego, CA, USA, pp. 1-14; Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. Ieee, 105 (12), pp. 2295-2329. , Dec; Yang, T.-J., Chen, Y.-H., Sze, V., Designing energy-efficient convolutional neural networks using energy-aware pruning (2017) Proc. IEEE Conf. Comput. Vision Pattern Recognit. (CVPR), Honolulu, HI, USA, pp. 6071-6079; Fowers, J., A configurable cloud-scale DNN processor for realtime AI (2018) Proc. ACM/IEEE 45th Annu. Int. Symp. Comput. Architect. (ISCA), Los Angeles, CA, USA, pp. 1-14; Guo, K.Y., Angel-eye: A complete design flow for mapping CNN onto embedded FPGA (2018) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 37 (1), pp. 35-47. , Jan; Shi, X., HERO: Accelerating autonomous robotic tasks with FPGA (2018) Proc. IROS, Madrid, Spain, pp. 7766-7772; Cameron, J.A.D., Savoie, P., Kaye, M.E., Scheme, E.J., Design considerations for the processing system of a CNN-based automated surveillance system (2019) Expert Syst. Appl., 136, pp. 105-114. , Dec; Du, S., Huang, T., Hou, J., Song, S., Song, Y., FPGA based acceleration of game theory algorithm in edge computing for autonomous driving (2019) J. Syst. Architect., 93, pp. 33-39. , Feb; Suda, N., Throughput-optimized OpenCL-based FPGA accelerator for large-scale convolutional neural networks (2016) Proc. ACM/SIGDA Int. Symp. Field Program. Gate Arrays (FPGA), pp. 16-25. , New York, NY, USA; Ma, Y.F., Suda, N., Cao, Y., Seo, J.-S., Vrudhula, S., Scalable and modularized RTL compilation of convolutional neural networks onto FPGA (2016) Proc. 26th Int. Conf. Field Program. Logic Appl. (FPL), pp. 1-8. , Lausanne, Switzerland; Wang, D., Xu, K., Jiang, D., PipeCNN: An OpenCL-based opensource FPGA accelerator for convolution neural networks (2017) Proc. Int. Conf. Field Program. Technol. (ICFPT), pp. 279-282. , Melbourne, VIC, Australia; Ma, Y.F., Cao, Y., Vrudhula, S., Seo, J.-S., An automatic RTL compiler for high-throughput FPGA implementation of diverse deep convolutional neural networks (2017) Proc. 27th Int. Conf. Field Program. Logic Appl. (FPL), pp. 1-8. , Ghent, Belgium; Ma, Y.F., Cao, Y., Vrudhula, S., Seo, J.-S., Optimizing loop operation and dataflow in FPGA acceleration of deep convolutional neural networks (2017) Proc. ACM/SIGDA Int. Symp. Field Program. Gate Arrays (FPGA), pp. 45-54. , New York, NY, USA; Wei, X.C., Automated systolic array architecture synthesis for high throughput CNN inference on FPGAS (2017) Proc. 54th ACM/EDAC/IEEE Design Autom. Conf. (DAC), pp. 1-6. , Austin, TX, USA; Guo, K.Y., From model to FPGA: Software-hardware co-design for efficient neural network acceleration (2016) Proc. IEEE Hot Chips 28th Symp. (HCS), pp. 1-27. , Cupertino, CA, USA; Aydonat, U., O'Connell, S., Capalija, D., Ling, A.C., Chiu, G.R., An OpenCL deep learning accelerator on Arria 10 (2017) Proc. ACM/SIGDA Int. Symp. Field Program. Gate Arrays (FPGA), pp. 55-64. , New York, NY, USA; Yu, J.C., Instruction driven cross-layer CNN accelerator with winograd transformation on FPGA (2017) Proc. Int. Conf. Field Program. Technol. (ICFPT), pp. 227-230. , Melbourne, VIC, Australia; Zeng, H., Zhang, C., Prasanna, V., Fast generation of high throughput customized deep learning accelerators on FPGAS (2017) Proc. Int. Conf. ReConFigurable Comput. FPGAS (ReConFig), pp. 1-8. , Cancun, Mexico; Zeng, H., Chen, R., Zhang, C., Prasanna, V., A framework for generating high throughput CNN implementations on FPGAS (2018) Proc. ACM/SIGDA Int. Symp. Field Program. Gate Arrays (FPGA), pp. 117-126. , New York, NY, USA; Page, A., Jafari, A., Shea, C., Mohsenin, T., SPARCNet: A hardware accelerator for efficient deployment of sparse convolutional networks (2017) J. Emerg. Technol. Comput. Syst, 13 (3), pp. 1-31. , May; Li, B., Wen, W., Mao, J., Li, S., Chen, Y., Li, H.H., Running sparse and low-precision neural network: When algorithm meets hardware (2018) Proc. 23rd Asia South Pac. Design Autom. Conf. (ASP-DAC), pp. 534-539. , Jeju, South Korea; Li, S., Wen, W., Wang, Y., Han, S., Chen, Y., Li, H., An FPGA design framework for CNN sparsification and acceleration (2017) Proc. IEEE 25th Annu. Int. Symp. Field Program. Custom Comput. Mach. (FCCM), p. 28. , Napa, CA, USA; Lu, L.Q., Xie, J., Huang, R., Zhang, J., Lin, W., Liang, Y., An efficient hardware accelerator for sparse convolutional neural networks on FPGAS (2019) Proc. IEEE 25th Annu. Int. Symp. Field Program. Custom Comput. Mach. (FCCM), pp. 17-25. , San Diego, CA, USA; Wang, D., Xu, K., Jia, Q., Ghiasi, S., ABM-SpConv: A novel approach to FPGA-based acceleration of convolutional neural network inference (2019) Proc. 56th ACM/IEEE Design Autom. Conf. (DAC), pp. 1-6. , Las Vegas, NV, USA; Fang, S., Real-time object detection and semantic segmentation hardware system with deep learning networks (2018) Proc. Int. Conf. Field Program. Technol. (FPT), pp. 389-392. , Naha, Japan; Gysel, P., Pimentel, J., Motamedi, M., Ghiasi, S., Ristretto: A framework for empirical study of resource-efficient inference in convolutional neural networks (2018) IEEE Trans. Neural Netw. Learn. Syst., 29 (11), pp. 5784-5789. , Nov; Gao, Y., Liu, Z., Wang, D., Error models of finite word length arithmetic in CNN accelerator design (2016) Proc. Visual Commun. Image Process. (VCIP), pp. 1-4. , Chengdu, China; Han, S., Mao, H.Z., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman codings (2016) Proc. ICLR, San Juan, Puerto Rico, pp. 1-14; Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J., Pruning convolutional neural networks for resource efficient inference (2017) Proc. ICLR, Toulon, France, pp. 1-17; Jacob, B., Quantization and training of neural networks for efficient integer-arithmetic-only inference (2018) Proc. IEEE Conf. Comput. Vision Pattern Recognit. (CVPR), pp. 2704-2713. , Salt Lake City, UT, USA; Anwar, S., Hwang, K., Sung, W., Structured pruning of deep convolutional neural networks (2017) J. Emerg. Technol. Comput. Syst., 13 (32), pp. 1-18; (2018), https://www.intel.com/, Intel FPGA SDK for OpenCL Pro Edition Programming Guide V18.1, Intel Company, Santa Clara, CA, USA","Wang, D.; School of Computer and Information Technology, China; email: wangdong@bjtu.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Final","",Scopus,2-s2.0-85078147486
"Kim T.H., Choi A., Heo H.M., Kim H., Mun J.H.","57210850598;12753511000;56589597700;55766538600;7005674984;","Acceleration magnitude at impact following loss of balance can be estimated using deep learning model",2020,"Sensors (Switzerland)","20","21","6126","1","17",,1,"10.3390/s20216126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094573370&doi=10.3390%2fs20216126&partnerID=40&md5=211634e90839f8d0cb07e038b46b16df","Department of Biomechatronic Engineering, College of Biotechnology and Bioengineering, Sungkyunkwan University, Suwon, 440-746, South Korea; Department of Biomedical Engineering, College of Medical Convergence, Catholic Kwandong University, 24 Beomilro 579 Beongil, Gangneung, Gangwon  25601, South Korea","Kim, T.H., Department of Biomechatronic Engineering, College of Biotechnology and Bioengineering, Sungkyunkwan University, Suwon, 440-746, South Korea; Choi, A., Department of Biomechatronic Engineering, College of Biotechnology and Bioengineering, Sungkyunkwan University, Suwon, 440-746, South Korea, Department of Biomedical Engineering, College of Medical Convergence, Catholic Kwandong University, 24 Beomilro 579 Beongil, Gangneung, Gangwon  25601, South Korea; Heo, H.M., Department of Biomechatronic Engineering, College of Biotechnology and Bioengineering, Sungkyunkwan University, Suwon, 440-746, South Korea; Kim, H., Department of Biomechatronic Engineering, College of Biotechnology and Bioengineering, Sungkyunkwan University, Suwon, 440-746, South Korea; Mun, J.H., Department of Biomechatronic Engineering, College of Biotechnology and Bioengineering, Sungkyunkwan University, Suwon, 440-746, South Korea","Pre-impact fall detection can detect a fall before a body segment hits the ground. When it is integrated with a protective system, it can directly prevent an injury due to hitting the ground. An impact acceleration peak magnitude is one of key measurement factors that can affect the severity of an injury. It can be used as a design parameter for wearable protective devices to prevent injuries. In our study, a novel method is proposed to predict an impact acceleration magnitude after loss of balance using a single inertial measurement unit (IMU) sensor and a sequential-based deep learning model. Twenty-four healthy participants participated in this study for fall experiments. Each participant worn a single IMU sensor on the waist to collect tri-axial accelerometer and angular velocity data. A deep learning method, bi-directional long short-term memory (LSTM) regression, is applied to predict a fall’s impact acceleration magnitude prior to fall impact (a fall in five directions). To improve prediction performance, a data augmentation technique with increment of dataset is applied. Our proposed model showed a mean absolute percentage error (MAPE) of 6.69 ± 0.33% with r value of 0.93 when all three different types of data augmentation techniques are applied. Additionally, there was a significant reduction of MAPE by 45.2% when the number of training datasets was increased by 4-fold. These results show that impact acceleration magnitude can be used as an activation parameter for fall prevention such as in a wearable airbag system by optimizing deployment process to minimize fall injury in real time. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Data augmentation; Deep learning; Falling; Peak impact acceleration magnitude; Pre-impact fall detection; Wearable fall protective device","Acceleration; Accident prevention; Forecasting; Learning systems; Long short-term memory; Wearable technology; Acceleration magnitude; Activation parameter; Inertial measurement unit; Mean absolute percentage error; Pre-impact fall-detection; Prediction performance; Protective systems; Triaxial accelerometer; Deep learning; acceleration; electronic device; falling; human; prevention and control; Acceleration; Accidental Falls; Deep Learning; Humans; Wearable Electronic Devices",,,,,"National Research Foundation of Korea, NRF; Ministry of Science and ICT, South Korea, MSIT","Funding: This research was supported by a grant (No. 2019M3E5D1A01068999) of the Bio & Medical Technology Development Program of the National Research Foundation (NRF) funded by the Korean government (MSIT).","This research was supported by a grant (No. 2019M3E5D1A01068999) of the Bio & Medical Technology Development Program of the National Research Foundation (NRF) funded by the Korean government (MSIT).",,,,,,,,,"Choi, A., Kang, T.G., Mun, J.H., Biomechanical Evaluation of Dynamic Balance Control Ability During Golf Swing (2016) J. Med. Biol. Eng, 36, pp. 430-439. , [CrossRef]; Choi, A., Sim, T., Mun, J.H., Improved determination of dynamic balance using the centre of mass and centre of pressure inclination variables in a complete golf swing cycle (2015) J. Sports Sci, 34, pp. 906-914. , [CrossRef] [PubMed]; Hrysomallis, C., Relationship Between Balance Ability, Training and Sports Injury Risk (2007) Sports Med, 37, pp. 547-556. , [CrossRef] [PubMed]; Zecevic, A.A., Salmoni, A., Speechley, M., Vandervoort, A.A., Defining a Fall and Reasons for Falling: Comparisons Among the Views of Seniors, Health Care Providers, and the Research Literature (2006) Gerontologist, 46, pp. 367-376. , [CrossRef] [PubMed]; De La Concepción, M.A.A., Morillo, L.M.S., Álvarez-García, J.A., González-Abril, L., Mobile activity recognition and fall detection system for elderly people using Ameva algorithm (2017) Pervasive Mob. Comput, 34, pp. 3-13. , [CrossRef]; Luque, R., Casilari, E., Morón, M.-J., Redondo, G., Comparison and Characterization of Android-Based Fall Detection Systems (2014) Sensors, 14, pp. 18543-18574. , [CrossRef] [PubMed]; Rubenstein, L.Z., Falls in older people: Epidemiology, risk factors and strategies for prevention (2006) Age Ageing, 35. , [CrossRef]; Prince, F., Corriveau, H., Hébert, R., Winter, D.A., Gait in the elderly (1997) Gait Posture, 5, pp. 128-135. , [CrossRef]; De Backere, F., Ongenae, F., Abeele, F.V.D., Nelis, J., Bonte, P., Clément, E., Philpott, M., Ackaert, A., Towards a social and context-aware multi-sensor fall detection and risk assessment platform (2015) Comput. Biol. Med, 64, pp. 307-320. , [CrossRef]; Choi, A., Jung, H., Mun, J.H., Single Inertial Sensor-Based Neural Networks to Estimate COM-COP Inclination Angle During Walking (2019) Sensors, 19, p. 2974. , [CrossRef]; Hu, X., Qu, X., Pre-impact fall detection (2016) Biomed. Eng. Online, 15, pp. 1-16. , [CrossRef]; Özdemir, A.T., Barshan, B., Detecting Falls with Wearable Sensors Using Machine Learning Techniques (2014) Sensors, 14, pp. 10691-10708. , [CrossRef]; Yu, X., Qiu, H., Xiong, S., A Novel Hybrid Deep Neural Network to Predict Pre-impact Fall for Older People Based on Wearable Inertial Sensors (2020) Front. Bioeng. Biotechnol, 8, p. 8. , [CrossRef]; Mubashir, M., Shao, L., Seed, L., A survey on fall detection: Principles and approaches (2013) Neurocomputing, 100, pp. 144-152. , [CrossRef]; Wu, Y., Su, Y., Feng, R., Yu, N., Zang, X., Wearable-sensor-based pre-impact fall detection system with a hierarchical classifier (2019) Measurement, 140, pp. 283-292. , [CrossRef]; Noury, N., Fleury, A., Rumeau, P., Bourke, A.K., Laighin, G.O., Rialle, V., Lundy, J.E., Fall detection-principles and methods Proceedings of the 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pp. 1663-1666. , Lyon, France, 22–26 August 2007; Arena, S.L., Davis, J.L., Grant, J.W., Madigan, M.L., Tripping Elicits Earlier and Larger Deviations in Linear Head Acceleration Compared to Slipping (2016) PLoS ONE, 11, p. e0165670. , [CrossRef] [PubMed]; Groen, B.E., Weerdesteyn, V., Duysens, J., The relation between hip impact velocity and hip impact force differs between sideways fall techniques (2008) J. Electromyogr. Kinesiol, 18, pp. 228-234. , [CrossRef]; Hajiaghamemar, M., Seidi, M., Ferguson, J.R., Caccese, V., Measurement of Head Impact Due to Standing Fall in Adults Using Anthropomorphic Test Dummies (2015) Ann. Biomed. Eng, 43, pp. 2143-2152. , [CrossRef]; Choi, W.J., Wakeling, J., Robinovitch, S.N., Kinematic analysis of video-captured falls experienced by older adults in long-term care (2015) J. Biomech, 48, pp. 911-920. , [CrossRef] [PubMed]; Kurt, M., Laksari, K., Kuo, C., Grant, G.A., Camarillo, D.B., Modeling and Optimization of Airbag Helmets for Preventing Head Injuries in Bicycling (2016) Ann. Biomed. Eng, 45, pp. 1148-1160. , [CrossRef]; Marconi, E., Gatto, F., Massaro, M., Investigation on Wearable Airbags for Motorcyclists Through Simulations and Experimental Tests (2018) The World Congress on Engineering, pp. 87-100. , Springer: Singapore; Lee, J.K., Robinovitch, S.N., Park, E.J., Inertial Sensing-Based Pre-Impact Detection of Falls Involving Near-Fall Scenarios (2014) IEEE Trans. Neural Syst. Rehabil. Eng, 23, pp. 258-266. , [CrossRef] [PubMed]; Serpen, G., Khan, R.H., Real-time Detection of Human Falls in Progress: Machine Learning Approach (2018) Procedia Comput. Sci, 140, pp. 238-247. , [CrossRef]; Emmatpour, M., Ferrero, R., Montrucchio, B., Rebaudengo, M., A Review on Fall Prediction and Prevention System for Personal Devices: Evaluation and Experimental Results (2019) Adv. Hum. Comput. Interact, , [CrossRef]; Lapierre, N., Neubauer, N., Miguel-Cruz, A., Rincón, A.M.R., Liu, L., Rousseau, J., The state of knowledge on technologies and their use for fall detection: A scoping review (2018) Int. J. Med. Inform, 111, pp. 58-71. , [CrossRef]; Xu, T., Zhou, Y., Zhu, J., New Advances and Challenges of Fall Detection Systems: A Survey (2018) Appl. Sci, 8, p. 418. , [CrossRef]; Liu, J., Lockhart, T.E., Development and evaluation of a prior-to-impact fall event detection algorithm (2014) IEEE Trans. Biomed. Eng, 61, pp. 2135-2140. , [CrossRef]; Tamura, T., Yoshimura, T., Sekine, M., Uchida, M., Tanaka, O., A wearable airbag to prevent fall injuries (2009) IEEE Trans. Inf. Technol. Biomed, 13, pp. 910-914. , [CrossRef]; Casilari-Pérez, E., García-Lagos, F., A comprehensive study on the use of artificial neural networks in wearable fall detection systems (2019) Expert Syst. Appl, 138, p. 112811. , [CrossRef]; Sabatini, A.M., Ligorio, G., Mannini, A., Genovese, V., Pinna, L., Prior-to-and Post-Impact Fall Detection Using Inertial and Barometric Altimeter Measurements (2015) IEEE Trans. Neural Syst. Rehabil. Eng, 24, pp. 774-783. , [CrossRef]; Aziz, O., Russell, C.M., Park, E.J., Robinovitch, S.N., The effect of window size and lead time on pre-impact fall detection accuracy using support vector machine analysis of waist mounted inertial sensor data Proceedings of the 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pp. 30-33. , Chicago, IL, USA, 26–30 August 2014; Kim, T.H., Choi, A., Heo, H.M., Kim, K., Lee, K., Mun, J.H., Machine Learning-Based Pre-Impact Fall Detection Model to Discriminate Various Types of Fall (2019) J. Biomech. Eng, 141, p. 081010. , [CrossRef]; Kangas, M., Vikman, I., Wiklander, J., Lindgren, P., Nyberg, L., Jämsä, T., Sensitivity and specificity of fall detection in people aged 40 years and over (2009) Gait Posture, 29, pp. 571-574. , [CrossRef] [PubMed]; Pierleoni, P., Belli, A., Palma, L., Pellegrini, M., Pernini, L., Valenti, S., A High Reliability Wearable Device for Elderly Fall Detection (2015) IEEE Sens. J, 15, pp. 4544-4553. , [CrossRef]; Choi, A., Jung, H., Kim, H., Mun, J.H., Predicting Center of Gravity Displacement During Walking Using a Single Inertial Sensor and Deep Learning Technique (2020) J. Med. Imaging Health Inform, 10, pp. 1436-1443. , [CrossRef]; Nweke, H.F., Teh, Y.W., Al-Garadi, M.A., Alo, U.R., Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: State of the art and research challenges (2018) Expert Syst. Appl, 105, pp. 233-261. , [CrossRef]; Kamycki, K., Kapuscinski, T., Oszust, M., Data Augmentation with Suboptimal Warping for Time-Series Classification (2019) Sensors, 20, p. 98. , [CrossRef]; Wen, Q., Sun, L., Song, X., Gao, J., Wang, X., Xu, H., Time Series Data Augmentation for Deep Learning: A Survey 2020, , arXiv 2020, arXiv:2002.12478; Zhou, H., Zhong, Z., Hu, M., Design and Occupant-Protection Performance Analysis of a New Tubular Driver Airbag (2018) Engineering, 4, pp. 291-297. , [CrossRef]; Shi, G., Chan, C.S., Li, W.J., Leung, K.-S., Zou, Y., Jin, Y., Mobile Human Airbag System for Fall Protection Using MEMS Sensors and Embedded SVM Classifier (2009) IEEE Sens. J, 9, pp. 495-503. , [CrossRef]; Choi, A., Jung, H., Lee, K.Y., Lee, S., Mun, J.H., Machine learning approach to predict center of pressure trajectories in a complete gait cycle: A feedforward neural network vs. LSTM network (2019) Med. Biol. Eng. Comput, 57, pp. 2693-2703. , [CrossRef]; Eyobu, O.S., Han, D.S., Feature Representation and Data Augmentation for Human Activity Classification Based on Wearable IMU Sensor Data Using a Deep LSTM Neural Network (2018) Sensors, 18, p. 2892. , [CrossRef]; Ronao, C.A., Cho, S.-B., Human activity recognition with smartphone sensors using deep learning neural networks (2016) Expert Syst. Appl, 59, pp. 235-244. , [CrossRef]; Pascanu, P., Mikolov, T., Bengio, Y., On the difficulty of training recurrent neural networks Proceedings of the 30th International Conference on Machine Learning, pp. 1310-1318. , Atlanta, GA, USA, 16–21 June 2013; Sagheer, A., Kotb, M., Time series forecasting of petroleum production using deep LSTM recurrent networks (2019) Neurocomputing, 323, pp. 203-213. , [CrossRef]; Li, X., Peng, L., Hu, Y., Shao, J., Chi, T., Deep learning architecture for air quality predictions (2016) Environ. Sci. Pollut. Res, 23, pp. 22408-22417. , [CrossRef]; Fukaya, K., Uchida, M., Protection against impact with the ground using wearable airbags (2008) Ind. Health, 46, pp. 59-65. , [CrossRef]; Sarvi, M.N., Luo, Y., Sideways fall-induced impact force and its effect on hip fracture risk: A review (2017) Osteoporos. Int, 28, pp. 2759-2780. , [CrossRef] [PubMed]; Taylor, L., Nitschke, G., (2017) Improving deep learning using generic data augmentation, , arXiv arXiv:170806020; Rashid, K.M., Louis, J., Times-series data augmentation and deep learning for construction equipment activity recognition (2019) Adv. Eng. Inform, 42, p. 100944. , [CrossRef]; Hsieh, C.-Y., Liu, K.-C., Huang, C.-N., Chu, W.-C., Chan, C.-T., Novel Hierarchical Fall Detection Algorithm Using a Multiphase Fall Model (2017) Sensors, 17, p. 307. , [CrossRef]; Liu, C., Jiang, Z., Su, X., Benzoni, S., Maxwell, A., Detection of Human Fall Using Floor Vibration and Multi-Features Semi-Supervised SVM (2019) Sensors, 19, p. 3720. , [CrossRef]; Anglin, J.M., Sugiyama, T., Liew, S.-L., Visuomotor adaptation in head-mounted virtual reality versus conventional training (2017) Sci. Rep, 7, p. 45469. , [CrossRef]","Kim, H.; Department of Biomechatronic Engineering, South Korea; email: hkim.bme@skku.edu
Mun, J.H.; Department of Biomechatronic Engineering, South Korea; email: jmun@skku.edu",,,"MDPI AG",,,,,14248220,,,"33126491","English","Sensors",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85094573370
"Zhou J.","57216994423;","Real-time task scheduling and network device security for complex embedded systems based on deep learning networks",2020,"Microprocessors and Microsystems","79",,"103282","","",,26,"10.1016/j.micpro.2020.103282","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091597415&doi=10.1016%2fj.micpro.2020.103282&partnerID=40&md5=2703a014612ce98b8131112a182702b5","School of Mathematics and Computer Science, Xinlian College of Henan Normal University, Xinxiang, Henan  453007, China","Zhou, J., School of Mathematics and Computer Science, Xinlian College of Henan Normal University, Xinxiang, Henan  453007, China","As a hotspot of machine learning research, deep learning is applied in many fields. Embedded systems are becoming more and more complex and networked, so the real-time performance of embedded systems and the security of network embedded devices face severe challenges. Based on this, this paper studies the real-time task scheduling problem for complex embedded systems and the security of embedded network devices. For real-time, this paper proposes a comprehensive task scheduling algorithm. Based on the task classification in the embedded system, different scheduling methods are adopted for different tasks, and the scheduling mode is flexibly changed as the system load changes. A dynamic integrity measurement model is established based on the star trust chain structure, and the hardware implementation mechanism of constructing dynamic trust chain in embedded system is studied. The dynamic reconfigurable hardware design method based on FPGA is applied to the construction of dynamic trust chain, and a verification system is designed to verify the dynamic measurement mechanism. This can solve the security problem of deep network embedded devices to a certain extent. © 2020 Elsevier B.V.","Complex embedded systems; Deep learning; Real-time; Security","Complex networks; Computer hardware; Deep learning; Dynamics; Embedded systems; Hardware security; Learning systems; Multitasking; Real time systems; Reconfigurable hardware; Scheduling; Dynamic measurement; Hardware implementations; Machine learning research; Real time performance; Scheduling methods; Task classification; Task-scheduling algorithms; Verification systems; Network security",,,,,,,,,,,,,,,,"Magno, M., Ibrahim, A., Pullini, A., An energy efficient E-skin embedded system for real-time tactile data decoding (2018) J. Low Power Electron., 14 (1), pp. 101-109; Zheng, W., Wu, H., Nie, C., Integrating task scheduling and cache locking for multicore real-time embedded systems (2017) ACM Sigplan Notices, 52 (4), pp. 71-80; Cervero, T.G., Caba, J., López, S., A scalable and dynamically reconfigurable FPGA-based embedded system for real-time hyperspectral unmixing (2017) IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens., 8 (6), pp. 2894-2911; Ahmad, A., Anisetti, M., Damiani, E., Special issue on real-time image and video processing in mobile embedded systems (2017) J. Real-Time Image Proc., 16 (1), pp. 1-4; Wang, Z., Gu, Z., Shao, Z., Optimizated allocation of data variables to PCM/DRAM-based hybrid main memory for real-time embedded systems (2017) IEEE Embed. Syst. Lett., 6 (3), pp. 61-64; Mao, H., Song, Y., Tang, T., Towards real-time object detection on embedded systems (2018) IEEE Trans. Emerg. Top. Comput., 6 (3), p. 1; Niu, L., Han, Q., Wang, T., Reliability-aware energy management for embedded real-time systems with (m, k)-hard timing constraint (2018) J. Signal Process. Syst., 90 (4), pp. 515-536; Lucia, S., Navarro, D., Lucía, Ó., Optimized FPGA implementation of model predictive control for embedded systems using high-level synthesis tool (2018) IEEE Trans. Ind. Inf., 14 (1), pp. 137-145; Jr, E.F.F., Salgado, R.M., Ohishi, T., Analysis of two-phase flow pattern identification methodologies for embedded systems (2018) IEEE Lat. Am. Trans., 16 (3), pp. 718-727; Ansari, M., Safari, S., Khaksar, A.Y., Peak power management to meet thermal design power in fault-tolerant embedded systems (2019) IEEE Trans. Parallel Distrib. Syst., 30 (1), p. 1; Bertozzi, M., Bo, C., Zingaretti, P., Introduction to the special issue on applications of mechatronic and embedded systems (MESA) in ITS (2018) IEEE Trans. Intell. Transp. Syst., 19 (2), pp. 530-532; Ebert, C., Dubey, A., Convergence of enterprise IT and embedded systems (2019) IEEE Softw., 36 (3), pp. 92-97; Liu, J., Chen, L., Rival, X., Automatic verification of embedded system code manipulating dynamic structures stored in contiguous regions (2018) IEEE Trans. Comput. Aided Des. Integr. Circuits Syst., 37 (11), pp. 2311-2322; Markevicius, V., Navikas, D., Idzkowski, A., Practical methods for vehicle speed estimation using a microprocessor-embedded system with AMR sensors (2018) Sensors, 18 (7), p. 2225; Amaya-Cruz, E., Gutierrez-Frias, O., Luviano-Juarez, A., Design and construction of a robotic platform for 3D reconstruction through an embedded processing system (2018) IEEE Lat. Am. Trans., 16 (1), pp. 19-24; Yamashita, T., Furusato, T., Asari, N., Design of solid/gas composite insulation system with embedded electrode (2019) IEEE Trans. Dielectr. Electr. Insul., 26 (1), pp. 56-63; Olshanskii, M.A., Yushutin, V., A penalty finite element method for a fluid system posed on embedded surface (2019) J. Math. Fluid Mech., 21 (1), p. 14; Zamoramartinez, F., Castrobleda, M.J., Efficient embedded decoding of neural network language models in a machine translation system (2018) Int. J. Neural. Syst., 28 (7); Luo, B., Ma, M., Zhang, M.A., Composite glass-silicon substrates embedded with microcomponents for MEMS system integration (2019) IEEE Trans. Compon. Packag. Manuf. Technol., 9 (2), pp. 201-208; Huang, X., Su, Z., Zhang, Z., Vibration transmission suppression for propeller-shaft system by hub-embedded damping ring under broadband propeller force (2018) Nonlinear Dyn., 91 (1), pp. 1-16; Khiarak, M.N., Martianova, E., Bories, C., A Wireless fiber photometry system based on a high-precision CMOS biosensor with embedded continuous-time modulation (2018) IEEE Trans. Biomed. Circuits Syst., 12 (3), pp. 495-509; Chen, M., Lu, S., Liu, Q., Uniform regularity for a Keller-Segel-Navier-Stokes system (2020) Appl. Math. Lett., 107",,,,"Elsevier B.V.",,,,,01419331,,MIMID,,"English","Microprocessors Microsyst",Article,"Final","",Scopus,2-s2.0-85091597415
"Sanchez J., Sawant A., Neff C., Tabkhi H.","57202575233;57204543509;57215927747;26768309300;","AWARE-CNN: Automated Workflow for Application-Aware Real-Time Edge Acceleration of CNNs",2020,"IEEE Internet of Things Journal","7","10","9078049","9318","9329",,3,"10.1109/JIOT.2020.2990215","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092707587&doi=10.1109%2fJIOT.2020.2990215&partnerID=40&md5=47ce49234c2c24f91561914604876a3c","Electrical and Computer Engineering Department, University of North Carolina at Charlotte, Charlotte, NC  28223, United States; Qualcomm Research and Development Center, San Diego, CA  28223, United States","Sanchez, J., Electrical and Computer Engineering Department, University of North Carolina at Charlotte, Charlotte, NC  28223, United States; Sawant, A., Qualcomm Research and Development Center, San Diego, CA  28223, United States; Neff, C., Electrical and Computer Engineering Department, University of North Carolina at Charlotte, Charlotte, NC  28223, United States; Tabkhi, H., Electrical and Computer Engineering Department, University of North Carolina at Charlotte, Charlotte, NC  28223, United States","This article presents the application-aware real-time edge acceleration of CNNs (AWARE-CNNs) accelerators, which is a novel architecture design methodology for real-time execution of deep learning algorithms on IoT devices. AWARE leverages the reconfigurability of field-programmable gate arrays (FPGAs) to create application-specific architectures customized to match the inherent dataflow of targeted deep neural networks and user-specified real-time requirements. The customized datapath is combined with a customized memory path to guarantee deterministic latency-aware execution over streaming data. For results and evaluation, we have developed a Chisel-based implementation of AWARE-CNN with a full integrative framework for application-specific architecture generation and synthesis (AWARE-CNN architecture compiler). Our results demonstrate the ability to execute Tiny DarkNet and shallow MobileNet inference at 120 frames/s (FPS) and 75 FPS, using only 2.8 and 3.4 W, respectively, on a Xilinx XCZU9EG FPGA. In addition, AWARE-CNN framework's flexibility with respect to the targeted convolutional neural networks and user constraints is validated by targeting additional design points for AlexNet (as a baseline network) and Tiny YOLOv2. © 2014 IEEE.","Convolutional neural networks (CNNs); deep learning accelerators; field-programmable gate arrays (FPGAs); low-power devices; real-time architecture","Deep learning; Deep neural networks; Field programmable gate arrays (FPGA); Integrated circuit design; Learning algorithms; Network architecture; Application-specific architectures; Automated workflow; Customized memory; Integrative framework; Novel architecture; Real time execution; Real time requirement; Reconfigurability; Convolutional neural networks",,,,,"National Science Foundation, NSF: 1932524","Manuscript received December 15, 2019; revised March 28, 2020; accepted April 13, 2020. Date of publication April 24, 2020; date of current version October 9, 2020. This work was supported by the National Science Foundation under Award 1932524. (Corresponding author: Christopher Neff.) Justin Sanchez, Christopher Neff, and Hamed Tabkhi are with the Electrical and Computer Engineering Department, University of North Carolina at Charlotte, Charlotte, NC 28223 USA (e-mail: jsanch19@uncc.edu; cneff1@uncc.edu; htabkhiv@uncc.edu).",,,,,,,,,,"Li, D., Salonidis, T., Desai, N.V., Chuah, M.C., DeepCham: Collaborative edge-mediated adaptive deep learning for mobile object recognition (2016) Proc. IEEE/ACM Symp. Edge Comput. (SEC), pp. 64-76. , Washington, DC, USA, Oct; Sun, Y., Liang, D., Wang, X., Tang, X., (2015) Deepid3: Face Recognition with Very Deep Neural Networks, , http://arxiv.org/abs/1502.00873, [Online]; Ng, J.Y.-H., Hausknecht, M., Vijayanarasimhan, S., Vinyals, O., Monga, R., Toderici, G., Beyond short snippets: Deep networks for video classification (2015) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 4694-4702; Canziani, A., Paszke, A., Culurciello, E., (2016) An Analysis of Deep Neural Network Models for Practical Applications, , [Online]; Strigl, D., Kofler, K., Podlipnig, S., Performance and scalability of GPU-based convolutional neural networks (2010) Proc. 18th Euromicro Int. Conf. Parallel Distrib. Netw. Based Process. (PDP), pp. 317-324. , Pisa, Italy; Potluri, S., Fasih, A., Vutukuru, L.K., Al MacHot, F., Kyamakya, K., CNN based high performance computing for real time image processing on GPU (2011) Proc. Joint 3rd Int. Workshop Nonlinear Dyn. Synchronization (INDS) 16th Int. Symp. Theor. Elect. Eng. (ISTET), pp. 1-7. , Klagenfurt, Austria; Nasse, F., Thurau, C., Fink, G.A., Face detection using GPU-based convolutional neural networks (2009) Proc. Int. Conf. Comput. Anal. Images Patterns, pp. 83-90; Oskouei, S.S.L., Golestani, H., Hashemi, M., Ghiasi, S., CNNdroid: GPU-Accelerated execution of trained deep convolutional neural networks on android (2016) Proc. Acm 24th Int. Conf. Multimedia, pp. 1201-1205; Jouppi, N.P., In-datacenter performance analysis of a tensor processing unit (2017) Proc. 44th Annu. Int. Symp. Comput. Architect., pp. 1-12; (2019) Chai-DNN, , https://github.com/Xilinx/chaidnn, Aug., [Online]; Sharma, H., From high-level deep neural models to FPGAS (2016) Proc. 49th Annu. IEEE/ACM Int. Symp. Microarchitect. (MICRO), pp. 1-12. , Taipei, Taiwan; Qadeer, W., Hameed, R., Shacham, O., Venkatesan, P., Kozyrakis, C., Horowitz, M., Convolution engine: Balancing efficiency and flexibility in specialized computing (2015) Commun. Acm, 58 (4), pp. 85-93. , http://doi.acm.org/10.1145/2735841, Mar.. [Online]; Savich, A., Areibi, S., A low-power scalable stream compute accelerator for general matrix multiply (GEMM) (2014) VLSI Design, 2014, p. 2. , Jan; Chen, Y.-H., Emer, J., Sze, V., (2018) Eyeriss v2: A Flexible and Highperformance Accelerator for Emerging Deep Neural Networks, , [Online]; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., XNOR-Net: Imagenet classification using binary convolutional neural networks (2016) Proc. Eur. Conf. Comput. Vis., pp. 525-542; Kim, H., Sim, J., Choi, Y., Kim, L.-S., A kernel decomposition architecture for binary-weight convolutional neural networks (2017) Proc. 54th Annu. Design Autom. Conf, pp. 1-6. , Austin, TX, USA; Colangelo, P., Nasiri, N., Nurvitadhi, E., Mishra, A., Margala, M., Nealis, K., Exploration of low numeric precision deep learning inference using intel?o FPGAS (2018) Proc. Ieee 26th Annu. Int. Symp. Field Program. Custom Comput. Mach. (FCCM), pp. 73-80. , Boulder, CO, USA, Apr; Ghasemzadeh, M., Samragh, M., Koushanfar, F., ReBNet: Residual binarized neural network (2018) Proc. Ieee 26th Annu. Int. Symp. Field Program. Custom Comput. Mach. (FCCM), pp. 57-64. , Boulder, CO, USA, Apr; Guo, P., Ma, H., Chen, R., Li, P., Xie, S., Wang, D., FBNA: A fully binarized neural network accelerator (2018) Proc. 28th Int. Conf. Field Program. Logic Appl. (FPL), pp. 51-513. , Dublin, Ireland; Shimoda, M., Sato, S., Nakahara, H., Demonstration of object detection for event-driven cameras on FPGAS and GPUs (2018) Proc. 28th Int. Conf. Field Program. Logic Appl. (FPL), pp. 461-4611. , Dublin, Ireland; Vogel, S., Liang, M., Guntoro, A., Stechele, W., Ascheid, G., Efficient hardware acceleration of CNNs using logarithmic data representation with arbitrary log-base (2018) Proc. Int. Conf. Comput.-Aided Design, pp. 1-8; Miyashita, D., Lee, E.H., Murmann, B., (2016) Convolutional Neural Networks Using Logarithmic Data Representation, , [Online]; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: Efficient inference engine on compressed deep neural network (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Architect. (ISCA), pp. 243-254; Jafri, S.M.A.H., Hemani, A., Paul, K., Abbas, N., MOCHA: Morphable locality and compression aware architecture for convolutional neural networks (2017) Proc. Ieee Int. Parallel Distrib. Process. Symp. (IPDPS), pp. 276-286. , Orlando, FL, USA; Du, Z., ShiDianNao: Shifting vision processing closer to the sensor (2015) Acm Sigarch Comput. Architect. News, 43 (3), pp. 92-104; Shen, Y., Ferdman, M., Milder, P., Escher: A CNN accelerator with flexible buffering to minimize off-chip transfer (2017) Proc. Ieee 25th Annu. Int. Symp. Field Program. Custom Comput. Mach. (FCCM), pp. 93-100. , Napa, CA, USA; Aimar, A., (2017) NullHop: A Flexible Convolutional Neural Network Accelerator Based on Sparse Representations of Feature Maps, , [Online]; Gong, L., Wang, C., Li, X., Chen, H., Zhou, X., MALOC: A fully pipelined FPGA accelerator for convolutional neural networks with all layers mapped on chip (2018) Ieee Trans. Comput.-Aided Design Integr. Circuits Syst., 37 (11), pp. 2601-2612. , Nov; Blott, M., FINN-R: An end-To-end deep-learning framework for fast exploration of quantized neural networks (2018) Acm Trans. Reconfigurable Technol. Syst. (TRETS), 11 (3), p. 16; Zhang, X., DNNBuilder: An automated tool for building high-performance DNN hardware accelerators for FPGAS (2018) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design, pp. 1-8. , San Diego, CA, USA; Venieris, S.I., Bouganis, C.-S., F-CNNx: A toolflow for mapping multiple convolutional neural networks on FPGAS (2018) Proc. 28th Int. Conf. Field Program. Logic Appl. (FPL), pp. 381-3817. , Dublin, Ireland; Alwani, M., Chen, H., Ferdman, M., Milder, P., Fused-layer CNN accelerators (2016) Proc. 49th Annu. IEEE/ACM Int. Symp. Microarchitect. (MICRO), pp. 1-12. , Taipei, Taiwan; Shen, Y., Ferdman, M., Milder, P., Maximizing CNN accelerator efficiency through resource partitioning (2017) Sigarch Comput. Architect. News, 45 (2), pp. 535-547. , http://doi.acm.org/10.1145/3140659.3080221, Jun., [Online]; Putic, M., Buyuktosunoglu, A., Venkataramani, S., Bose, P., Eldridge, S., Stan, M., DyHard-DNN: Even more DNN acceleration with dynamic hardware reconfiguration (2018) Proc. 55th ACM/ESDA/IEEE Design Autom. Conf. (DAC), pp. 1-6. , San Francisco, CA, USA; Tabkhi, H., Bushey, R., Schirner, G., Function-level processor (FLP): A novel processor class for efficient processing of streaming applications (2016) J. Signal Process. Syst., 85 (3), pp. 287-306; Capodieci, N., Cavicchiolo, R., Vogel, P., Marongiu, A., Scordino, C., Gai, P., (2017) Hercules, , https://hercules2020.eu/wpcontent/uploads/2017/03/D2.2-Detailed-Characterization-of-Platforms.pdf, Jun., [Online]; Redmon, J., (2018) Tiny Darknet, , https://pjreddie.com/darknet/tiny-darknet/, Accessed: Aug. 23, [Online]; Krizhevsky, A., Nair, V., Hinton, G., (2009) CIFAR-10 and CIFAR-100 Datasets, , https://www.cs.toronto.edu/kriz/cifar.html, [Online]; Howard, A.G., (2017) MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , [Online]; Ditty, M., Karandikar, A., Reed, D., (2018) NVIDIA Xavier Soc, , https://www.hotchips.org/hc30/1conf/1.12-Nvidia-XavierHotchips2018Final-814.pdf, Aug., [Online]; Baharani, R., (2019) Tegra Xavier Ina Power Monitors, , https://github.com/mbaharan, [Online]; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; Moreau, T., (2018) A Hardware-software Blueprint for Flexible Deep Learning Specialization, , http://arxiv.org/abs/1807.04188, [Online]; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , http://arxiv.org/abs/1512.03385, [Online]; Redmon, J., Farhadi, A., (2016) YOLO9000: Better, Faster, Stronger, , http://arxiv.org/abs/1612.08242, [Online]; GmbH, T.E., (2019) Te08xx-Zynq Ultrascale, , https://shop.trenz-electronic.de/en/Products/Trenz-Electronic/TE08XX-Zynq-UltraScale/, Accessed: Jul. 25, [Online]; Chen, T., TVM: An automated end-To-end optimizing compiler for deep learning (2018) Proc. 12th Usenix Symp. Oper. Syst. Design Implement. (OSDi18), pp. 578-594","Neff, C.; Electrical and Computer Engineering Department, United States; email: cneff1@uncc.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,23274662,,,,"English","IEEE Internet Things J.",Article,"Final","",Scopus,2-s2.0-85092707587
"Xu Z., Cheung R.C.C.","57195259131;10044976000;","Binary convolutional neural network acceleration framework for rapid system prototyping",2020,"Journal of Systems Architecture","109",,"101762","","",,10,"10.1016/j.sysarc.2020.101762","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082566267&doi=10.1016%2fj.sysarc.2020.101762&partnerID=40&md5=2d5f55da435acc2e4c8421e3d34450f9","Department of Electrical Engineering, City University of Hong Kong, Hong Kong, Hong Kong","Xu, Z., Department of Electrical Engineering, City University of Hong Kong, Hong Kong, Hong Kong; Cheung, R.C.C., Department of Electrical Engineering, City University of Hong Kong, Hong Kong, Hong Kong","The huge model size and high computational complexity make emerging convolutional neural network (CNN) models unsuitable to deploy on current embedded or edge computing devices. Recently the binary neural network (BNN) is explored to help reduce network model size and avoid complex multiplication. In this paper, a binary network acceleration framework for rapid system prototyping is proposed to promote the deployment of CNNs on embedded devices. Firstly trainable scaling factors are adopted in binary network training to improve network accuracy performance. The hardware/software co-design framework supports various compact network structures such as residual block, 1 × 1 squeeze convolution layer, and depthwise separable convolution. With flexible network binarization and efficient hardware architecture optimization, the acceleration system is able to achieve over 2 TOPS throughput performance comparable to modern desktop GPU with much higher power efficiency. © 2020 Elsevier B.V.","Binarization; Convolutional neural network; FPGA; Hardware acceleration; Rapid system prototyping","Complex networks; Convolution; Field programmable gate arrays (FPGA); Hardware-software codesign; Acceleration systems; Binarizations; Binary neural networks; Complex multiplication; Hardware acceleration; Hardware architecture optimizations; Rapid system prototyping; Throughput performance; Convolutional neural networks",,,,,,,,,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, pp. 1097-1105; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International conference on learning representations (ICLR); He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pp. 770-778; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pp. 580-587; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pp. 779-788; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., Berg, A.C., Ssd: Single shot multibox detector (2016) European conference on computer vision (ECCV), pp. 21-37. , Springer; Gatys, L.A., Ecker, A.S., Bethge, M., Image style transfer using convolutional neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2414-2423; Chen, D., Yuan, L., Liao, J., Yu, N., Hua, G., Stylebank: An explicit representation for neural image style transfer (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1897-1906; Zhang, H., Kyaw, Z., Chang, S.-F., Chua, T.-S., Visual translation embedding network for visual relation detection (2017) Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pp. 5532-5540; Zhang, H., Kyaw, Z., Yu, J., Chang, S.-F., Ppr-fcn: weakly supervised visual relation detection via parallel pairwise r-fcn (2017) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 4233-4241; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., Squeezenet: Alexnet-level accuracy with 50x fewer parameters and< 0.5 mb model size (2016) arXiv preprint arXiv:1602.07360; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., Mobilenets: Efficient convolutional neural networks for mobile vision applications (2017) arXiv preprint arXiv:1704.04861; Zhang, X., Zhou, X., Lin, M., Sun, J., Shufflenet: An extremely efficient convolutional neural network for mobile devices (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6848-6856; Lin, Z., Courbariaux, M., Memisevic, R., Bengio, Y., Neural networks with few multiplications (2016) International conference on learning representations (ICLR); Dong, Y., Ni, R., Li, J., Chen, Y., Zhu, J., Su, H., Learning accurate low-bit deep neural networks with stochastic quantization (2017) British machine vision conference (BMVC); Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Advances in neural information processing systems, pp. 1135-1143; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing fpga-based accelerator design for deep convolutional neural networks (2015) Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 161-170. , ACM; Suda, N., Chandra, V., Dasika, G., Mohanty, A., Ma, Y., Vrudhula, S., Seo, J.-S., Cao, Y., Throughput-optimized opencl-based fpga accelerator for large-scale convolutional neural networks (2016) Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 16-25. , ACM; Courbariaux, M., Bengio, Y., David, J.-P., Binaryconnect: Training deep neural networks with binary weights during propagations (2015) Advances in neural information processing systems, pp. 3123-3131; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Binarized neural networks (2016) Advances in neural information processing systems, pp. 4107-4115; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., Xnor-net: Imagenet classification using binary convolutional neural networks (2016) European Conference on Computer Vision (ECCV), pp. 525-542. , Springer; Zhou, S., Wu, Y., Ni, Z., Zhou, X., Wen, H., Zou, Y., Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients (2016) arXiv preprint arXiv:1606.06160; Tang, W., Hua, G., Wang, L., How to train a compact binary neural network with high accuracy? (2017) Thirty-First AAAI Conference on Artificial Intelligence (AAAI); Cai, Z., He, X., Sun, J., Vasconcelos, N., Deep learning with low precision by half-wave gaussian quantization (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5918-5926; Wang, P., Hu, Q., Zhang, Y., Zhang, C., Liu, Y., Cheng, J., Two-step quantization for low-bit neural networks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4376-4384; Lin, X., Zhao, C., Pan, W., Towards accurate binary convolutional neural network (2017) Advances in Neural Information Processing Systems, pp. 345-353; Liu, Z., Wu, B., Luo, W., Yang, X., Liu, W., Cheng, K.-T., Bi-real net: Enhancing the performance of 1-bit cnns with improved representational capability and advanced training algorithm (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 722-737; Li, H., Fan, X., Jiao, L., Cao, W., Zhou, X., Wang, L., A high performance fpga-based accelerator for large-scale convolutional neural networks (2016) 2016 26th International Conference on Field Programmable Logic and Applications (FPL), pp. 1-9. , IEEE; Wang, D., Xu, K., Jiang, D., Pipecnn: An opencl-based open-source fpga accelerator for convolution neural networks (2017) 2017 International Conference on Field Programmable Technology (ICFPT), pp. 279-282. , IEEE; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., Optimizing loop operation and dataflow in fpga acceleration of deep convolutional neural networks (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 45-54. , ACM; Su, J., Faraone, J., Liu, J., Zhao, Y., Thomas, D.B., Leong, P.H., Cheung, P.Y., Redundancy-reduced mobilenet acceleration on reconfigurable logic for imagenet classification (2018) International Symposium on Applied Reconfigurable Computing, pp. 16-28. , Springer; Ding, W., Huang, Z., Huang, Z., Tian, L., Wang, H., Feng, S., Designing efficient accelerator of depthwise separable convolutional neural network on fpga (2019) Journal of Systems Architecture, 97, pp. 278-286; Umuroglu, Y., Fraser, N.J., Gambardella, G., Blott, M., Leong, P., Jahre, M., Vissers, K., Finn: A framework for fast, scalable binarized neural network inference (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 65-74. , ACM; Zhao, R., Song, W., Zhang, W., Xing, T., Lin, J.-H., Srivastava, M., Gupta, R., Zhang, Z., Accelerating binarized convolutional neural networks with software-programmable fpgas (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 15-24. , ACM; Chellapilla, K., Puri, S., Simard, P., High performance convolutional neural networks for document processing (2006) Tenth International Workshop on Frontiers in Handwriting Recognition; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1-9; Lin, M., Chen, Q., Yan, S., Network in network (2014) International conference on learning representations (ICLR)","Cheung, R.C.C.; Department of Electrical Engineering, Hong Kong; email: r.cheung@cityu.edu.hk",,,"Elsevier B.V.",,,,,13837621,,JSARF,,"English","J Syst Archit",Article,"Final","",Scopus,2-s2.0-85082566267
"Liu R., Chen X., Liu D., Ling Y., Wang W., Tan Y., Xiao C., Yang C., Zhang R., Liang L.","57203526902;56373575400;55538903700;57196352700;57219048998;36572444500;56393706400;57194854473;57195976715;50262158200;","Separable binary convolutional neural network on embedded systems",2020,"IEEE Transactions on Computers","69","10","9000571","1474","1486",,,"10.1109/TC.2020.2973974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079639044&doi=10.1109%2fTC.2020.2973974&partnerID=40&md5=93f1eb1f4d0225e8a7f6e898ac97b3ae","Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Shapingba, Chongqing, China","Liu, R., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; Chen, X., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; Liu, D., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; Ling, Y., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; Wang, W., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; Tan, Y., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; Xiao, C., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; Yang, C., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; Zhang, R., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education and College of Computer Science, Chongqing University, Chongqing, China; Liang, L., School of Microelectronics and Communication Engineering, Chongqing University, Shapingba, Chongqing, China","We have witnessed the tremendous success of deep neural networks. However, this success comes with the considerable memory and computational costs which make it difficult to deploy these networks directly on resource-constrained embedded systems. To address this problem, we propose TaijiNet, a separable binary network, to reduce the storage and computational overhead while maintaining a comparable accuracy. Furthermore, we also introduce a strategy called partial binarized convolution which binarizes only unimportant kernels to efficiently balance network performance and accuracy. Our approach is evaluated on the CIFAR-10 and ImageNet datasets. The experimental results show that with the proposed TaijiNet, the separable binary versions of AlexNet and ResNet-18 can achieve 26× and 6.4× compression rates with comparable accuracy when comparing with the full-precision versions respectively. In addition, by adjusting the PCA threshold, the xnor version of Taiji-AlexNet improves accuracy by 4-8 percent comparing with other state-of-The-Art methods. © 1968-2012 IEEE.","binarization; Convolutional neural network; embedded systems","Convolution; Deep neural networks; Embedded systems; Binarizations; Compression rates; Computational costs; Computational overheads; Resource-constrained embedded systems; State-of-the-art methods; Convolutional neural networks",,,,,"cstc2019jscx-mbdx0063; National Natural Science Foundation of China, NSFC: 61601067, 61672116, 61802038; China Postdoctoral Science Foundation: 2017M620412; Fundamental Research Funds for the Central Universities: 02140 05207005, 2019CDJGFJSJ001; Huxiang Youth Talent Support Program","We would like to thank the anonymous reviewers for their valuable feedback and improvements to this paper. This work was supported in part by the National Natural Science Foundation of China under Grants 61672116, 61601067, and 61802038, in part by the Chongqing High-Tech Research Key Program (cstc2019jscx-mbdx0063), in part by the Fundamental Research Funds for the Central Universities under Grants 02140 05207005 and 2019CDJGFJSJ001, in part by the Chongqing Youth Talent Support Program, and in part by the China Postdoctoral Science Foundation (2017M620412). A preliminary version of this paper was presented at the IEEE 2018 Computer Society Annual Symposium on VLSI (ISVLSI 2018) [1].",,,,,,,,,,"Ling, Y., TaiJiNet: Towards partial binarized convolutional neural network for embedded systems (2018) Proc Ieee Comput. Soc. Annu. Symp. Vlsi, pp. 136-141; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 1097-1105; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. Int. Conf. Learn. Representations; Szegedy, C., Going deeper with convolutions (2015) Proc Ieee Conf. Comput. Vis. Pattern Recognit, pp. 1-9; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc Ieee Conf. Comput. Vis. Pattern Recognit, pp. 770-778; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc Ieee Conf. Comput. Vis. Pattern Recognit, pp. 580-587; Girshick, R., Fast R-CNN (2015) Proc Ieee Int. Conf. Comput. Vis, pp. 1440-1448; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-Time object detection with region proposal networks (2015) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 91-99; He, K., Gkioxari, G., Dollar, P., Girshick, R., Mask R-CNN (2017) Proc Ieee Int. Conf. Comput. Vis, pp. 2961-2969; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., XNORNet: ImageNet classification using binary convolutional neural networks (2016) Proc. Eur. Conf. Comput. Vis, pp. 525-542; Courbariaux, M., Bengio, Y., David, J.-P., BinaryConnect: Training deep neural networkswith binaryweights during propagations (2015) Proc. Int. Conf.Neural Inf. Process. Syst, pp. 3123-3131; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1 (2016) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 4107-4115; Jia, Y., Caffe: Convolutional architecture for fast feature embedding (2014) Proc Acm Int. Conf. Multimedia, pp. 675-678; Lin, M., Chen, Q., Yan, S., Network in network (2013) ArXiv 1312.4400; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2016) Proc. Int. Conf. Learn. Representations, pp. 4107-4115; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 1135-1143; Denton, E.L., Zaremba, W., Bruna, J., LeCun, Y., Fergus, R., Exploiting linear structure within convolutional networks for efficient evaluation (2014) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 1269-1277; Gong, Y., Liu, L., Yang, M., Bourdev, L., Compressing deep convolutional networks using vector quantization (2014) ArXiv 1412.6115; Li, F., Zhang, B., Liu, B., Ternary weight networks (2016) Proc. Efficient Methods Deep Neural Netw; Zhu, C., Han, S., Mao, H., Dally, W.J., Trained ternary quantization (2017) Proc. Int. Conf. Learn. Representations; Howard, A.G., MobileNets: Efficient convolutional neural networks for mobile vision applications (2017) ArXiv 1704.04861; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016) SqueezeNet: AlexNet-level Accuracy with 50x Fewer Parameters and 0.5 Mb Model Size, , https://arxiv.org/abs/1602.07360; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2014) Proc. Int. Conf. Learn. Representations; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proc. Int. Conf. Artif. Intell. Statist, pp. 249-256; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, Y., Bengio, R., Quantized neural networks: Training neural networks with low precision weights and activations (2017) J. Mach. Learn. Res, 18 (1), pp. 6869-6898; Russakovskyetal, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis, 115 (3), pp. 211-252; The CIFAR-10 Dataset, , https://www.cs.toronto.edu/~kriz/cifar.html; Cun, Y.L., Denker, J.S., Solla, S.A., Optimal brain damage (1989) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 598-605; Hassibi, B., Stork, D.G., Second order derivatives for network pruning: Optimal brain surgeon (1993) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 164-171; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning filters for efficient convnets (2016) Proc. Int. Conf. Learn. Representations; Lin, S., Ji, R., Li, Y., Wu, Y., Huang, F., Zhang, B., Accelerating convolutional networks via global & dynamic filter pruning (2018) Proc. Int. Joint Conf. Artif. Intell, pp. 2425-2432; Yu, R., NISP: Pruning networks using neuron importance score propagation (2018) Proc Ieee Conf. Comput. Vis. Pattern Recognit, pp. 9194-9203; Roffo, G., Melzi, S., Cristani, M., Infinite feature selection (2015) Proc Ieee Int. Conf. Comput. Vis, pp. 4202-4210; Zhou, S., Wu, Y., Ni, Z., Zhou, X., Wen, H., Zou, Y., DoReFa-Net: Training low bitwidth convolutional neural networks with low bitwidth gradients (2016) ArXiv 1606.06160; Mishra, A., Nurvitadhi, E., Cook, J.J., Marr, D., WRPN: Wide reduced-precision networks (2017) ArXiv 1709.01134; Yazdanbakhsh, A., Elthakeb, A.T., Pilligundla, P., Mireshghallah, F., Esmaeilzadeh, H., ReLeQ: An automatic reinforcement learning approach for deep quantization of neural networks (2018) ArXiv 1811 01704; Gong, R., Differentiable soft quantization: Bridging full-precision and low-bit neural networks (2019) Proc Ieee Int. Conf. Comput. Vis, pp. 4852-4861; Hinton, G., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) ArXiv 1503.02531","Chen, X.; Key Laboratory of Dependable Service Computing in Cyber Physical Society, China; email: xzchen@cqu.edu.cn
Liu, D.; Key Laboratory of Dependable Service Computing in Cyber Physical Society, China; email: liuduo@cqu.edu.cn",,,"IEEE Computer Society",,,,,00189340,,ITCOB,,"English","IEEE Trans Comput",Article,"Final","",Scopus,2-s2.0-85079639044
"Chen C., Li Z., Zhang Y., Zhang S., Hou J., Zhang H.","57212536422;24921695300;57207478362;57207331117;57214786571;55685653600;","Low-power fpga implementation of convolution neural network accelerator for pulse waveform classification",2020,"Algorithms","13","9","213","","",,,"10.3390/a13090213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098177715&doi=10.3390%2fa13090213&partnerID=40&md5=50b04e9d90a72f1f393b10d0aa5d732d","Institute of Microelectronics of Chinese Academy of Sciences, Beijing, 100029, China; School of Electronics, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China; Beijing Key Laboratory for Next Generation RF Communication Chip Technology, Beijing, 100029, China","Chen, C., Institute of Microelectronics of Chinese Academy of Sciences, Beijing, 100029, China, School of Electronics, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China, Beijing Key Laboratory for Next Generation RF Communication Chip Technology, Beijing, 100029, China; Li, Z., Institute of Microelectronics of Chinese Academy of Sciences, Beijing, 100029, China, School of Electronics, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China, Beijing Key Laboratory for Next Generation RF Communication Chip Technology, Beijing, 100029, China; Zhang, Y., Institute of Microelectronics of Chinese Academy of Sciences, Beijing, 100029, China, Beijing Key Laboratory for Next Generation RF Communication Chip Technology, Beijing, 100029, China; Zhang, S., Institute of Microelectronics of Chinese Academy of Sciences, Beijing, 100029, China, Beijing Key Laboratory for Next Generation RF Communication Chip Technology, Beijing, 100029, China; Hou, J., Institute of Microelectronics of Chinese Academy of Sciences, Beijing, 100029, China, School of Electronics, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China, Beijing Key Laboratory for Next Generation RF Communication Chip Technology, Beijing, 100029, China; Zhang, H., Institute of Microelectronics of Chinese Academy of Sciences, Beijing, 100029, China, School of Electronics, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China, Beijing Key Laboratory for Next Generation RF Communication Chip Technology, Beijing, 100029, China","In pulse waveform classification, the convolution neural network (CNN) shows excellent performance. However, due to its numerous parameters and intensive computation, it is challenging to deploy a CNN model to low-power devices. To solve this problem, we implement a CNN accelerator based on a field-programmable gate array (FPGA), which can accurately and quickly infer the waveform category. By designing the structure of CNN, we significantly reduce its parameters on the premise of high accuracy. Then the CNN is realized on FPGA and optimized by a variety of memory access optimization methods. Experimental results show that our customized CNN has high accuracy and fewer parameters, and the accelerator costs only 0.714 W under a working frequency of 100 MHz, which proves that our proposed solution is feasible. Furthermore, the accelerator classifies the pulse waveform in real time, which could help doctors make the diagnosis. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution neural network (CNN); Field-programmable gate array (FPGA); Pulse waveform classification; Traditional Chinese medicine (TCM)","Convolution; Field programmable gate arrays (FPGA); Low power electronics; Convolution neural network; High-accuracy; Low-power devices; Low-power FPGAs; Memory access optimization; Pulse waveform classification; Pulse waveforms; Working frequency; Neural networks",,,,,"National Science and Technology Major Project: 2018ZX01031-201, 2018ZX09201011","Funding: This research was funded by the National Major Science and Technology Project (No. 2018ZX01031-201, 2018ZX09201011).",,,,,,,,,,"Wang, N., Yu, Y., Huang, D., Xu, B., Liu, J., Li, T., Xue, L., Wang, J., Pulse diagnosis signals analysis of fatty liver disease and cirrhosis patients by using machine learning (2015) Sci. World J, 2015. , [CrossRef] [PubMed]; Charbonnier, S., Galichet, S., Mauris, G., Siché, J.P., Statistical and fuzzy models of ambulatory systolic blood pressure for hypertension diagnosis (2000) IEEE Trans. Instrum. Meas, 49, pp. 998-1003. , [CrossRef]; He, D., Wang, L., Fan, X., Yao, Y., Geng, N., Sun, Y., Xu, L., Qian, W., A new mathematical model of wrist pulse waveforms characterizes patients with cardiovascular disease—A pilot study (2017) Med. Eng. Phys, 48, pp. 142-149. , [CrossRef] [PubMed]; Gomes Ribeiro Moura, N., Sá Ferreira, A., Pulse waveform analysis of chinese pulse images and its association with disability in hypertension (2016) JAMS J. Acupunct. Meridian Stud, 9, pp. 93-98. , [CrossRef] [PubMed]; Zhang, Z., Zhang, Y., Yao, L., Song, H., Kos, A., A sensor-based wrist pulse signal processing and lung cancer recognition (2018) J. Biomed. Inform, 79, pp. 107-116. , [CrossRef] [PubMed]; Fei, Z., (2003) Contemporary Sphygmology in Traditional Chinese Medicine, , People’s Medical Publishing House: Beijing, China; Hu, X., Zhu, H., Xu, J., Xu, D., Dong, J., Wrist pulse signals analysis based on Deep Convolutional Neural Networks Proceedings of the 2014 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB 2014), , Honolulu, HI, USA, 21–24 May 2014. [CrossRef]; Wang, Y.-Y.L., Hsu, T.-L., Jan, M.-Y., Wang, W.-K., Theory and applications of the harmonic analysis of arterial pressure pulse wave (2010) J. Med. Biol. Eng, 30, pp. 125-131. , [CrossRef]; Lu, G., Jiang, Z., Ye, L., Huang, Y., Pulse feature extraction based on improved gaussian model Proceedings of the Proceedings—2014 International Conference on Medical Biometrics, ICMB 2014, pp. 90-94. , Shenzhen, China, 30 May–1 June 2014; Tang, A.C.Y., Chung, J.W.Y., Wong, T.K.S., Digitalizing traditional chinese medicine pulse diagnosis with artificial neural network (2012) Telemed. e-Health, 18, pp. 446-453. , [CrossRef] [PubMed]; Xu, L.S., Meng, M.Q.H., Wang, K.Q., Pulse image recognition using fuzzy neural network (2007) Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, 36, pp. 3148-3151. , Lyon, France, 22–26 August [CrossRef]; Chen, Y., Zhang, L., Zhang, D., Zhang, D., Wrist pulse signal diagnosis using modified Gaussian models and Fuzzy C-Means classification (2009) Med. Eng. Phys, 31, pp. 1283-1289. , [CrossRef] [PubMed]; Shu, J.J., Sun, Y., Developing classification indices for Chinese pulse diagnosis (2007) Complement. Ther. Med, 15, pp. 190-198. , [CrossRef] [PubMed]; Liu, Y.H., Yang, Q.H., Shi, H.F., Pulse feature analysis and extraction based on pulse mechanism analysis Proceedings of the 2009 WRI World Congress on Computer Science and Information Engineering, CSIE 2009, 7, pp. 53-56. , Los Angeles, CA, USA, 31 March–2 April 2009; [CrossRef]; Hudoba, G., Vascular health diagnosis by pulse wave analysis Proceedings of the SAMI 2010—8th International Symposium on Applied Machine Intelligence and Informatics, pp. 89-91. , Herlany, Slovakia, 28–30 January 2010; [CrossRef]; Sareen, M., Abhinav, A., Prakash, P., Anand, S., Wavelet decomposition and feature extraction from pulse signals of the radial artery Proceedings of the 2008 International Conference on Advanced Computer Theory and Engineering, pp. 551-555. , Phuket, Thailand, 20–22 December 2008; [CrossRef]; Zhang, P.Y., Wang, H.Y., A framework for automatic time-domain characteristic parameters extraction of human pulse signals (2008) EURASIP J. Adv. Signal Process, 2008. , [CrossRef]; Joshi, A., Chandran, S., Jayaraman, V.K., Kulkarni, B.D., Arterial pulse system modern methods for traditional indian Proceedings of the 2007 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pp. 608-611. , Lyon, France, 22–26 August 2007; [CrossRef]; Li, J., Cao, Y., Liu, Q., Jiao, Q., Determination of urinary L-citrulline by enzymatic method (2006) Chin. J. Anal. Chem, 34, pp. 379-381. , [CrossRef]; Wang, K., Wang, L., Wang, D., Xu, L., SVM classification for discriminating cardiovascular disease patients from non-cardiovascular disease controls using pulse waveform variability analysis (2005) Lect. Notes Comput. Sci, pp. 109-119. , [CrossRef]; Wang, H., Cheng, Y., A quantitative system for pulse diagnosis in traditional Chinese medicine (2006) Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, 7, pp. 5676-5679. , Shanghai, China, 17–18 January [CrossRef]; Qiu, J., Wang, J., Yao, S., Guo, K., Li, B., Going deeper with embedded FPGA Platform for Convolutional Neural Network Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 26-35. , Monterey, CA, USA, 21 February 2016; [CrossRef]; Ma, Y., Suda, N., Cao, Y., Seo, J.S., Vrudhula, S., Scalable and modularized RTL compilation of Convolutional Neural Networks onto FPGA Proceedings of the FPL 2016—26th International Conference on Field-Programmable Logic and Applications, , Lausanne, Switzerland, 29 August–2 September 2016. [CrossRef]; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.S., Optimizing loop operation and dataflow in FPGA acceleration of deep convolutional neural networks Proceedings of the FPGA 2017—The 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 45-54. , Monterey, CA, USA, 22–24 February 2017; [CrossRef]; Zhang, C., Optimizing FPGA-based accelerator design for deep convolutional neural networks Proceedings of the FPGA 2015—The 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 161-170. , Monterey, CA, USA, 22–24 February 2015; [CrossRef]; Li, S., Sun, K., Luo, Y., Yadav, N., Choi, K., Novel CNN-based AP2D-net accelerator: An area and power efficient solution for real-time applications on mobile FPGA (2020) Electron, 9, p. 832. , [CrossRef]; Gong, L., Wang, C., Li, X., Chen, H., Zhou, X., MALOC: A fully pipelined FPGA accelerator for convolutional neural networks with all layers mapped on chip (2018) IEEE Trans. Comput. Des. Integr. Circuits Syst, 37, pp. 2601-2612. , [CrossRef]; Zhang, C., Wu, D., Sun, J., Sun, G., Luo, G., Cong, J., Energy-efficient CNN implementation on a deeply pipelined FPGA cluster Proceedings of the 2016 International Symposium on Low Power Electronics and Design, ISLPED 2016, pp. 326-331. , San Francisco, CA, USA, 8–10 August 2016; [CrossRef]; Di Cecco, R., Lacey, G., Vasiljevic, J., Chow, P., Taylor, G., Areibi, S., Caffeinated FPGAs: FPGA framework for convolutional neural networks Proceedings of the 2016 International Conference on Field-Programmable Technology, FPT 2016, pp. 265-268. , Xi’an, China, 7–9 December 2016; [CrossRef]; Guo, K., Sui, L., Qiu, J., Yu, J., Wang, J., Yao, S., Han, S., Yang, H., Angel-Eye: A complete design flow for mapping CNN onto embedded FPGA (2018) IEEE Trans. Comput. Des. Integr. Circuits Syst, 37, pp. 35-47. , [CrossRef]; Geng, T., Wang, T., Sanaullah, A., Yang, C., Patel, R., Herbordt, M., A framework for acceleration of CNN training on deeply-pipelined FPGA clusters with work and weight load balancing Proceedings of the 28th International Conference on Field Programmable Logic and Applications (FPL), pp. 394-398. , Dublin, Ireland, 27–31 August 2018; [CrossRef]; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., (2016) Binarized neural networks: Training deep neural networks with weights and activations constrained to +1 or-1, , arXiv arXiv:1602.02830; Chen, C., Li, Z., Zhang, Y., Zhang, S., Hou, J., Zhang, H., A 3D wrist pulse signal acquisition system for width information of pulse wave (2020) Sensors, 20, p. 11. , [CrossRef] [PubMed]","Li, Z.; Institute of Microelectronics of Chinese Academy of SciencesChina; email: lizhiqiang@ime.ac.cn
Li, Z.; School of Electronics, China; email: lizhiqiang@ime.ac.cn
Li, Z.; Beijing Key Laboratory for Next Generation RF Communication Chip TechnologyChina; email: lizhiqiang@ime.ac.cn",,,"MDPI AG",,,,,19994893,,,,"English","Algorithms",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85098177715
"Saha S., Duwe H., Zambreno J.","57211079735;55279914300;20437056300;","CyNAPSE: A Low-power Reconfigurable Neural Inference Accelerator for Spiking Neural Networks",2020,"Journal of Signal Processing Systems","92","9",,"907","929",,1,"10.1007/s11265-020-01546-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086704721&doi=10.1007%2fs11265-020-01546-x&partnerID=40&md5=c9e9f9e2fa7b0ab7a6a028d5d68218d8","Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, United States","Saha, S., Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, United States; Duwe, H., Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, United States; Zambreno, J., Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, United States","While neural network models keep scaling in depth and computational requirements, biologically accurate models are becoming more interesting for low-cost inference. Coupled with the need to bring more computation to the edge in resource-constrained embedded and IoT devices, specialized ultra-low power accelerators for spiking neural networks are being developed. Having a large variance in the models employed in these networks, these accelerators need to be flexible, user-configurable, performant and energy efficient. In this paper, we describe CyNAPSE, a fully digital accelerator designed to emulate neural dynamics of diverse spiking networks. Since the use case of our implementation is primarily concerned with energy efficiency, we take a closer look at the factors that could improve its energy consumption. We observe that while majority of its dynamic power consumption can be credited to memory traffic, its on-chip components suffer greatly from static leakage. Given that the event-driven spike processing algorithm is naturally memory-intensive and has a large number of idle processing elements, it makes sense to tackle each of these problems towards a more efficient hardware implementation. With a diverse set of network benchmarks, we incorporate a detailed study of memory patterns that ultimately informs our choice of an application-specific network-adaptive memory management strategy to reduce dynamic power consumption of the chip. Subsequently, we also propose and evaluate a leakage mitigation strategy for runtime control of idle power. Using both the RTL implementation and a software simulation of CyNAPSE, we measure the relative benefits of these undertakings. Results show that our adaptive memory management policy results in up to 22% more reduction in dynamic power consumption compared to conventional policies. The runtime leakage mitigation techniques show that up to 99.92% and at least 14% savings in leakage energy consumption is achievable in CyNAPSE hardware modules. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Accelerator; Caching; Energy efficiency; Leakage; Memory; Neuromorphic; Reconfigurable; Spiking neural networks","Benchmarking; Computer hardware; Computer software; Electric power utilization; Energy efficiency; Energy utilization; Neural networks; Application-specific network; Computational requirements; Digital accelerators; Dynamic power consumption; Hardware implementations; Neural network model; Processing algorithms; Spiking neural networks; Low power electronics",,,,,"National Science Foundation, NSF;US NSF;USA NSF: CCF-1149539",,,,,,,,,,,"Akopyan, F., Sawada, J., Cassidy, A., Alvarez-Icaza, R., Arthur, J., Merolla, P., Imam, N., Nam, G.J., Truenorth: Design and tool flow of a 65 mw 1 million neuron programmable neurosynaptic chip (2015) IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 34 (10), pp. 1537-1557; Allu, B., Zhang, W., Static next sub-bank prediction for drowsy instruction cache (2004) Proceedings of the 2004 International Conference on Compilers, Architecture, and Synthesis for Embedded Systems, pp. 124-131. , ACM; Attwell, D., Laughlin, S.B., An energy budget for signaling in the grey matter of the brain (2001) Journal of Cerebral Blood Flow & Metabolism, 21 (10), pp. 1133-1145; Bauer, J., Bershteyn, M., Kaplan, I., Vyedin, P., A reconfigurable logic machine for fast event-driven simulation (1998) Proceedings 1998 Design and Automation Conference. 35Th Dac.(Cat. No. 98CH36175), pp. 668-671. , IEEE; Belady, L.A., A study of replacement algorithms for a virtual-storage computer (1966) IBM Systems Journal, 5 (2), pp. 78-101; Bellosa, F., The benefits of event: Driven energy accounting in power-sensitive systems (2000) Proceedings of the 9Th Workshop on ACM SIGOPS European Workshop: Beyond the PC: New Challenges for the Operating System, pp. 37-42. , ACM; Bi, G., Poo, M., Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type (1998) Journal of Neuroscience, 18 (24), pp. 10464-10472; Boahen, K., A neuromorph’s prospectus (2017) Computing in Science & Engineering, 19, pp. 14-28; Brette, R., Gerstner, W., Adaptive exponential integrate-and-fire model as an effective description of neuronal activity (2005) Journal of Neurophysiology, 94 (5), pp. 3637-3642; Cassidy, A., Andreou, A.G., Georgiou, J., Design of a one million neuron single fpga neuromorphic system for real-time multimodal scene analysis (2011) 2011 45Th Annual Conference on Information Sciences and Systems, pp. 1-6. , IEEE; Chandrasekar, K., Weis, C., Li, Y., Akesson, B., Wehn, N., Goossens, K., (2012) Drampower: Open-Source Dram Power & Energy Estimation Tool, p. 22. , http://www.drampower.info; Chen, Y.H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: an energy-efficient reconfigurable accelerator for deep convolutional neural networks (2016) IEEE Journal of Solid-State Circuits, 52 (1), pp. 127-138; Davies, M., Srinivasa, N., Lin, T.H., Chinya, G., Cao, Y., Choday, S.H., Dimou, G., Jain, S., Loihi: a neuromorphic manycore processor with on-chip learning (2018) IEEE Micro, 38 (1), pp. 82-99; Delbruck, T., Neuromorophic vision sensing and processing (2016) 2016 46Th European Solid-State Device Research Conference (ESSDERC), pp. 7-14. , IEEE; Diehl, P.U., Cook, M., Unsupervised learning of digit recognition using spike-timing-dependent plasticity (2015) Frontiers in Computational Neuroscience, 9, p. 99; Diehl, P.U., Neil, D., Binas, J., Cook, M., Liu, S.C., Pfeiffer, M., Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing (2015) 2015 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , IEEE; Duong, N., Zhao, D., Kim, T., Cammarota, R., Valero, M., Veidenbaum, A.V., Improving cache management policies using dynamic reuse distances (2012) 2012 45Th Annual IEEE/ACM International Symposium on Microarchitecture, pp. 389-400. , IEEE; Flautner, K., Kim, N.S., Martin, S., Blaauw, D., Mudge, T., Drowsy caches: Simple techniques for reducing leakage power (2002) ACM SIGARCH Computer Architecture News, 30, pp. 148-157. , EEE computer society; Gerstner, W., Kistler, W.M., (2002) Spiking Neuron Models: Single Neurons, Populations, Plasticity, , Cambridge, Cambridge University Press; Gerstner, W., Naud, R., How good are neuron models? (2009) Science, 326 (5951), pp. 379-380; Goodman, D.F., Brette, R., The brian simulator (2009) Frontiers in Neuroscience, 3, p. 26; Han, S., Mao, H., Dally, W.J., (2015) Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding coRR; Hinton, G.E., Osindero, S., Teh, Y.W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554; Hinton, G.E., Sejnowski, T.J., Poggio, T.A., (1999) Unsupervised Learning: Foundations of Neural Computation, , Cambrdige, MIT press; Hodgkin, A.L., Huxley, A.F., A quantitative description of membrane current and its application to conduction and excitation in nerve (1952) The Journal of Physiology, 117 (4), pp. 500-544; Hodgkin, A.L., Huxley, A.F., Katz, B., Measurement of current-voltage relations in the membrane of the giant axon of loligo (1952) The Journal of Physiology, 116 (4), pp. 424-448; Hopfield, J.J., Hopfield network (2007) Scholarpedia, 2 (5), p. 1977; Hu, Z., Buyuktosunoglu, A., Srinivasan, V., Zyuban, V., Jacobson, H., Bose, P., Microarchitectural techniques for power gating of execution units (2004) Proceedings of the 2004 International Symposium on Low Power Electronics and Design, pp. 32-37. , ACM; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Quantized neural networks: Training neural networks with low precision weights and activations (2017) The Journal of Machine Learning Research, 18 (1), pp. 6869-6898; Izhikevich, E.M., Which model to use for cortical spiking neurons? (2004) IEEE Transactions on Neural networks, 15 (5), pp. 1063-1070; Jiang, H., Marek-Sadowska, M., Nassif, S.R., Benefits and costs of power-gating technique (2005) 2005 International Conference on Computer Design, pp. 559-566. , IEEE; Jiang, S., Zhang, X., Lirs: an efficient low inter-reference recency set replacement policy to improve buffer cache performance (2002) ACM SIGMETRICS Performance Evaluation Review, 30 (1), pp. 31-42; Jolivet, R., Lewis, T.J., Gerstner, W., Generalized integrate-and-fire models of neuronal activity approximate spike trains of a detailed model to a high degree of accuracy (2004) Journal of Neurophysiology, 92 (2), pp. 959-976; Jolivet, R., Rauch, A., Lüscher, H.R., Gerstner, W., Integrate-and-fire models with adaptation are good enough (2006) Advances in Neural Information Processing Systems, pp. 595-602; Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Borchers, A., In-datacenter performance analysis of a tensor processing unit (2017) 2017 ACM/IEEE 44Th Annual International Symposium on Computer Architecture (ISCA), pp. 1-12. , IEEE; Jug, F., (2012) On Competition and Learning in Cortical Structures, , Ph.D. thesis, ETH Zurich; Kaxiras, S., Hu, Z., Martonosi, M., Cache decay: Exploiting generational behavior to reduce cache leakage power (2001) Proceedings 28Th Annual International Symposium on Computer Architecture, pp. 240-251. , IEEE; Khan, S.M., Tian, Y., Jimenez, D.A., Sampling dead block prediction for last-level caches (2010) Proceedings of the 2010 43Rd Annual IEEE/ACM International Symposium on Microarchitecture, pp. 175-186. , IEEE Computer Society; Kim, Y., Yang, W., Mutlu, O., Ramulator: a fast and extensible dram simulator (2015) IEEE Computer Architecture Letters, 15 (1), pp. 45-49; Kim, Y., Zhang, Y., Li, P., A reconfigurable digital neuromorphic processor with memristive synaptic crossbar for cognitive computing (2015) ACM Journal on Emerging Technologies in Computing Systems (JETC), 11 (4), p. 38; Koch, C., Segev, I., (1998) Methods in Neuronal Modeling: From Ions to Networks, , Cambridge, MIT press; Lecun, Y., Cortes, C., Burges, C., (2010) Mnist Handwritten Digit Database at&t Labs; Li, S., Chen, K., Ahn, J.H., Brockman, J.B., Jouppi, N.P., Cacti-p: Architecture-level modeling for sram-based structures with advanced leakage reduction techniques (2011) Proceedings of the International Conference on Computer-Aided Design, pp. 694-701. , IEEE Press; Li, Y., Pedram, A., Caterpillar: Coarse grain reconfigurable architecture for accelerating the training of deep neural networks (2017) 2017 IEEE 28Th International Conference on Application-Specific Systems, Architectures and Processors (ASAP), pp. 1-10. , IEEE; Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y., Alsaadi, F.E., A survey of deep neural network architectures and their applications (2017) Neurocomputing, 234, pp. 11-26; Mahowald, M.A., Mead, C., The silicon retina (1991) Scientific American, 264, pp. 76-82; Mead, C., Neuromorphic electronic systems (1990) Proceedings of the IEEE, 78 (10), pp. 1629-1636; Moerland, P., Fiesler, E., Hardware-friendly learning algorithms for neural networks: An overview (1996) Proceedings of Fifth International Conference on Microelectronics for Neural Networks, pp. 117-124. , IEEE; Neckar, A., Fok, S., Benjamin, B.V., Stewart, T.C., Oza, N.N., Voelker, A.R., Eliasmith, C., Boahen, K., Braindrop: a mixed-signal neuromorphic architecture with a dynamical systems-based programming model (2019) Proceedings of the IEEE, 107 (1), pp. 144-164; Neil, D., Liu, S.C., Minitaur, an event-driven fpga-based spiking network accelerator (2014) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 22 (12), pp. 2621-2628; O’Connor, P., Neil, D., Liu, S.C., Delbruck, T., Pfeiffer, M., Real-time classification and sensor fusion with a spiking deep belief network (2013) Frontiers in Neuroscience, 7, p. 178; Podili, A., Zhang, C., Prasanna, V., Fast and efficient implementation of convolutional neural networks on fpga (2017) 2017 IEEE 28Th International Conference on Application-Specific Systems, Architectures and Processors (ASAP), pp. 11-18. , IEEE; Powell, M., Yang, S.H., Falsafi, B., Roy, K., Vijaykumar, T., Gated-v dd: A circuit technique to reduce leakage in deep-submicron cache memories (2000) Proceedings of the 2000 International Symposium on Low Power Electronics and Design, pp. 90-95. , ACM; Qiao, N., Mostafa, H., Corradi, F., Osswald, M., Stefanini, F., Sumislawska, D., Indiveri, G., A reconfigurable on-line learning spiking neuromorphic processor comprising 256 neurons and 128k synapses (2015) Frontiers in Neuroscience, 9, p. 141; Qureshi, M.K., Jaleel, A., Patt, Y.N., Steely, S.C., Emer, J., Adaptive insertion policies for high performance caching (2007) ACM SIGARCH Computer Architecture News, 35 (2), pp. 381-391; Rumelhart, D.E., Hinton, G.E., Williams, R.J., (1985) Learning Internal Representations by Error Propagation, , Technical report. California Univ San Diego La Jolla Inst for Cognitive Science; Schuman, C.D., Potok, T.E., Patton, R.M., Birdwell, J.D., Dean, M.E., Rose, G.S., Plank, J.S., (2017) A Survey of Neuromorphic Computing and Neural Networks in Hardware; Shepherd, G.M., (2003) The Synaptic Organization of the Brain, , Oxford, Oxford University Press; Wen, B., Boahen, K., A silicon cochlea with active coupling (2009) IEEE Transactions on Biomedical Circuits and Systems, 3 (6), pp. 444-455; Wijeratne, S., Jayaweera, S., Dananjaya, M., Pasqual, A., Reconfigurable co-processor architecture with limited numerical precision to accelerate deep convolutiosnal neural networks (2018) 2018 IEEE 29Th International Conference on Application-Specific Systems, Architectures and Processors (ASAP), pp. 1-7. , IEEE; Yu, T., Park, J., Joshi, S., Maier, C., Cauwenberghs, g.: 65k-neuron integrate-and-fire array transceiver with address-event reconfigurable synaptic routing (2012) 2012 IEEE Biomedical Circuits and Systems Conference (Biocas), pp. 21-24. , IEEE; Zhao, R., Liu, S., Ng, H.C., Wang, E., Davis, J.J., Niu, X., Wang, X., Cheung, P.Y., Hardware compilation of deep neural networks: An overview (2018) 2018 IEEE 29Th International Conference on Application-Specific Systems, Architectures and Processors (ASAP), pp. 1-8. , IEEE; Zhao, W., Fu, H., Luk, W., Yu, T., Wang, S., Feng, B., Ma, Y., Yang, G., F-cnn: An fpga-based framework for training convolutional neural networks (2016) 2016 IEEE 27Th International Conference on Application-Specific Systems, Architectures and Processors (ASAP), pp. 107-114; Zhou, H., Toburen, M.C., Rotenberg, E., Conte, T.M., Adaptive mode control: a static-power-efficient cache design (2003) ACM Transactions on Embedded Computing Systems (TECS), 2 (3), pp. 347-372","Saha, S.; Department of Electrical and Computer Engineering, United States; email: saha@iastate.edu",,,"Springer",,,,,19398018,,,,"English","J. Signal Process Syst.",Article,"Final","",Scopus,2-s2.0-85086704721
"Zu Y.","57215409655;","Deep learning parallel computing and evaluation for embedded system clustering architecture processor",2020,"Design Automation for Embedded Systems","24","3",,"145","159",,,"10.1007/s10617-020-09235-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080958098&doi=10.1007%2fs10617-020-09235-5&partnerID=40&md5=84dfe21f21c8f6fba47c0a42d9fc9e6a","Department of Human Resources Office, Jilin Institute of Chemical Technology, Jilin, 132022, China","Zu, Y., Department of Human Resources Office, Jilin Institute of Chemical Technology, Jilin, 132022, China","In the era of intelligence, the processing of a large amount of information and various intelligent applications need to rely on embedded devices. This trend has made machine learning algorithms play an increasingly important role. High-performance embedded computing is an effective means to solve the lack of computing power of embedded devices. Aiming at the problem that the calculation amount of new intelligent embedded applications based on machine learning technology is higher, the computing power of traditional embedded systems is difficult to meet their needs, this paper studies the parallel optimization and implementation techniques of convolutional neural networks in Parallella platform. The parallel optimization strategy of convolutional neural network on the clustering architecture processor of heterogeneous multi-core system is given. Then the high-performance implementation of convolutional neural network on Parallella platform is studied, and the function of convolutional neural network system is implemented. A set of performance evaluation methods for embedded parallel processors is proposed. From the application point of S698P, the eCos operating system is selected as the platform. The single-core mode and multi-core mode are compared on the simulator GRSIM, and the parallel performance evaluation is given. Experiments have shown that the efficiency of deep learning tasks is significantly improved compared to traditional parallel methods. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Clustered architecture processor; Deep learning; Parallel computing; Performance evaluation","Convolution; Convolutional neural networks; Embedded systems; Learning algorithms; Learning systems; Network architecture; Parallel architectures; Parallel processing systems; Clustered architectures; Clustering architecture; Heterogeneous multi-core systems; High performance implementations; Implementation techniques; Intelligent applications; Parallel optimization; Performance evaluation; Deep learning",,,,,,,,,,,,,,,,"Mai, T.N.T., Kim, S., Parallel implementation of color-based particle filter for object tracking in embedded systems (2017) Hum Cent Comput Inf Sci, 7 (1), p. 2; Gao, F., Huang, Z., Wang, S., Optimized parallel implementation of face detection based on embedded heterogeneous many-core architecture (2017) Int J Pattern Recognit Artif Intell, 31 (7), p. 1756011; Chen, W.H., Ji-Yao, A.N., Ren-Fa, L.I., Review on deep-learning-based cognitive computing (2017) Acta Autom Sin, 43 (11), pp. 1886-1897; Niu, J., Huang, C., Li, J., Parallel computing techniques for concept-cognitive learning based on granular computing (2018) Int J Mach Learn Cybernet, 9 (3), pp. 1-21; Zeng, G., Liu, W., An iso-time scaling method for big data tasks executing on parallel computing systems (2017) J Supercomput, 73 (10), pp. 4493-4516; Yin, S., Peng, O., Tang, S., A high energy efficient reconfigurable hybrid neural network processor for deep learning applications (2018) IEEE J Solid State Circuits, 53 (4), pp. 968-982; Wen, S., Wei, H., Zeng, Z., Memristive fully convolutional network: an accurate hardware image-segmentor in deep learning (2018) IEEE Trans Emerg Top Comput Intell, 2 (5), pp. 324-334; Gu, X., Angelov, P.P., Zhang, C., A massively parallel deep rule-based ensemble classifier for remote sensing scenes (2018) IEEE Geosci Remote Sens Lett, 15 (3), pp. 345-349; Wang, C., Shen, Y., Jia, J., SingleCaffe: an efficient framework for deep learning on a single node (2018) IEEE Access, 6 (99), pp. 69660-69671; Chung, I., Sainath, T.N., Ramabhadran, B., Parallel deep neural network training for Big Data on Blue Gene/Q (2017) IEEE Trans Parallel Distrib Syst, 28 (6), pp. 1703-1714; Sugie, T., Akamatsu, T., Nishitsuji, T., High-performance parallel computing for next-generation holographic imaging (2018) Nat Electron, 1 (4), pp. 254-259; Xia, C., Yan, L., Xin, Z., A novel DVR-ESS-embedded wind-energy conversion system (2018) IEEE Trans Sustain Energy, 9 (3), p. 1; Cai, B., Ye, W., Zhao, J., A dynamic texture based segmentation method for ultrasound images with Surfacelet, HMT and parallel computing (2018) Multimed Tools Appl, 78 (1), pp. 5381-5401; Cunha, M.A.P., Matoussi, O., Pétrot, F., Detecting software cache coherence violations in MPSoC using traces captured on virtual platforms (2018) ACM Trans Embed Comput Syst, 16 (2), pp. 1-21; Dou, W., Li, Y., A fault-tolerant computing method for Xdraw parallel algorithm (2018) J Supercomput, 74 (3), pp. 1-25; Thoman, P., Dichev, K., Heller, T., A taxonomy of task-based parallel programming technologies for high-performance computing (2018) J Supercomput, 74 (4), pp. 1422-1434; Yu, L., Nina-Paravecino, F., Kaeli, D., Scalable and massively parallel Monte Carlo photon transport simulations for heterogeneous computing platforms (2018) J Biomed Opt, 23 (1), pp. 1-4; Zhu, G., Chen, W., Wang, D., Study on high-density integration resistive random access memory array from multiphysics perspective by parallel computing (2019) IEEE Trans Electron Devices, 66 (4), pp. 1747-1753; Mo, Z.Y., Extreme-scale parallel computing: bottlenecks and strategies (2018) Front Inf Technol Electron Eng, 19 (10), pp. 1251-1260; Grubov, V.V., Nedaivozov, V.O., Stream processing of multichannel EEG data using parallel computing technology with NVIDIA CUDA graphics processors (2018) Tech Phys Lett, 44 (5), pp. 453-455; Chen, Y., Zhao, Q., Hu, X., Multi-resolution parallel magnetic resonance image reconstruction in mobile computing-based IoT (2019) IEEE Access, 7 (99), pp. 15623-15633","Zu, Y.; Department of Human Resources Office, China; email: zzzzy1934@163.com",,,"Springer",,,,,09295585,,DAESF,,"English","Des Autom Embedded Syst",Article,"Final","",Scopus,2-s2.0-85080958098
"Kim Y., Lee J., Kim J.-S., Jei H., Roh H.","57203516427;56460888100;9733544500;57205882759;26421289000;","Comprehensive techniques of multi-GPU memory optimization for deep learning acceleration",2020,"Cluster Computing","23","3",,"2193","2204",,6,"10.1007/s10586-019-02974-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071525758&doi=10.1007%2fs10586-019-02974-6&partnerID=40&md5=53920d8706f87ec4a76409e111253b90","Korea Aerospace University, Goyang-si, South Korea; Myongji University, Yongin-si, South Korea; SK Telecom ML Infra Lab, Seongnam-si, South Korea","Kim, Y., Korea Aerospace University, Goyang-si, South Korea; Lee, J., Korea Aerospace University, Goyang-si, South Korea; Kim, J.-S., Myongji University, Yongin-si, South Korea; Jei, H., SK Telecom ML Infra Lab, Seongnam-si, South Korea; Roh, H., SK Telecom ML Infra Lab, Seongnam-si, South Korea","This paper presents a comprehensive suite of techniques for optimized memory management in multi-GPU systems to accelerate deep learning application execution. We employ a hybrid utilization of GPU and CPU memories in a multi-GPU environment by effectively addressing contention issues in the shared interconnect (e.g., PCIe, NVLink). In addition, we designed and implemented an intelligent prefetching algorithm (from CPU memory to GPU) that achieves the highest processing throughput while sustaining a large mini-batch size. We successfully implemented our optimization techniques on TensorFlow, and performed extensive experiments in various multi-GPU environments including traditional PCIe and the latest high-bandwidth interconnect, NVLink. Evaluation results show that our proposed scheme actually improves computing performance by decreasing the I/O bottleneck, and effectively increasing the mini-batch size without sacrificing overall training throughput. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Convolutional neural network; GPGPU; Mini-batch; Multi-GPU","Computer aided instruction; Graphics processing unit; Neural networks; Program processors; Computing performance; Convolutional neural network; GPGPU; High-bandwidth interconnect; Mini-batch; Multi-gpu; Optimization techniques; Prefetching algorithm; Deep learning",,,,,"GRRC-KAU-2018-B01; Ministry of Trade, Industry and Energy, MOTIE; Ministry of Science, ICT and Future Planning, MSIP; Korea Evaluation Institute of Industrial Technology, KEIT: 10076476; National Research Foundation of Korea, NRF","This research was supported by Basic Science Research Program (NRF-2019R1H1A2039658), and Next-Generation Information Computing Development Program (NRF-2015M3C4A7065646) through the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT, and partly supported by the GRRC program of Gyeonggi province (No. GRRC-KAU-2018-B01, ?Study on the Video and Space Convergence Platform for 360VR Services?) and IT R&D program of MOTIE/KEIT (10076476, Scalable Machine Learning Acceleration Hardware Technology for Big-Data Servers).","This research was supported by Basic Science Research Program (NRF-2019R1H1A2039658), and Next-Generation Information Computing Development Program (NRF-2015M3C4A7065646) through the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT, and partly supported by the GRRC program of Gyeonggi province (No. GRRC-KAU-2018-B01, “Study on the Video and Space Convergence Platform for 360VR Services”) and IT R&D program of MOTIE/KEIT (10076476, Scalable Machine Learning Acceleration Hardware Technology for Big-Data Servers).",,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, 25, pp. 1097-1105. , Pereira F, Burges CJC, Bottou L, Weinberger KQ, (eds), Curran Associates Inc., Red Hook; Rhu, M., Gimelshein, N., Clemons, J., Zulfiqar, A., Keckler, S.W., Vdnn: Virtualized deep neural networks for scalable, memory-efficient neural network design (2016) 2016 49Th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO); Simonyan, K., Zisserman, A., (2015) Very Deep Convolutional Networks for Large-Scale Image Recognition, , Proceedings of the International Conference on Learning Representations; Efficient multi-GPU memory management for deep learning acceleration (2018) 6Th International Workshop on Autonomic Management of High Performance Grid and Cloud Computing (AMGCC’18); He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , arxiv.org; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , In; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, , In; DGX-1 system architecture White Paper, NVIDIA; Duc, T.L., Ibmcaffe: The harmony of CPU and GPU in training deep neural networks IBM Research, Technical Reports; Krizhevsky, A., One weird trick for parallelizing convolutional neural networks (2014) Arxiv.Org; Goyal, P., Dollár, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., He, K., Accurate, large minibatch SGD: Training imagenet in 1 hour (2018) Arxiv.Org; NVIDIA: Unified Memory in Cuda 6; (2019), https://www.tensorflow.org/performance/xla; (2019), https://github.com/dmlc/nnvm-fusion; (2019) MXNet’s Optimizing Memory Consumption in Deep Learning, , http://mxnet.incubator.apache.org/architecture/note-memory.html; Chen, T., Xu, B., Zhang, C., Guestrin, C., Training deep nets with sublinear memory cost (2016) Arxiv.Org; Kehne, J., Metter, J., Bellosa, F., Gpuswap: Enabling oversubscription of GPU memory through transparent swapping Proceedings of the 11Th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments, pp. 65-77; Lin, Y., Han, S., Mao, H., Wang, Y., Dally, W., Deep gradient compression: Reducing the communication bandwidth for distributed training (2018) Sixth International Conference on Learning Representations (ICLR)","Lee, J.; Korea Aerospace UniversitySouth Korea; email: jlee@kau.ac.kr",,,"Springer",,,,,13867857,,,,"English","Cluster Comput.",Article,"Final","",Scopus,2-s2.0-85071525758
"Bahamon-Blanco S., Rapp S., Zhang Y., Liu J., Martin U.","57211625319;57188974108;57214255566;57211623032;7102008474;","Recognition of track defects through measured acceleration using a recurrent neural network",2020,"International Journal of Computational Methods and Experimental Measurements","8","3",,"270","280",,,"10.2495/CMEM-V8-N3-270-280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091999486&doi=10.2495%2fCMEM-V8-N3-270-280&partnerID=40&md5=7378924a3588bd2141c859f99175fcc0","Institute of Railway and Transportation Engineering, University of Stuttgart, Germany","Bahamon-Blanco, S., Institute of Railway and Transportation Engineering, University of Stuttgart, Germany; Rapp, S., Institute of Railway and Transportation Engineering, University of Stuttgart, Germany; Zhang, Y., Institute of Railway and Transportation Engineering, University of Stuttgart, Germany; Liu, J., Institute of Railway and Transportation Engineering, University of Stuttgart, Germany; Martin, U., Institute of Railway and Transportation Engineering, University of Stuttgart, Germany","As part of an optimized maintenance strategy, track monitoring should provide information to predict track faults at an early stage. This is possible by continuously measuring the axle box accelerations and using artificial intelligence, which can detect short wave defects on the railway track with high accuracy. Such short wave defects include rail breaks, cracks, and local irregularities (mud spots). These types of faults can reduce the track quality in a short period of time. Different track irregularities were simulated in a track-vehicle scale model to generate acceleration data for typical track defects. The main focus of the current research is on recognition of local irregularities in the track-vehicle scale model. To implement the artificial intelligence, a Recurrent Neural Network is used to show the procedure and the results of recognition of track defects. The architecture and components of the neural network used are described in detail in this article. At the end of the article, a table summarizing the results of the different models trained for detecting the local irregularities in the track-vehicle scale model is presented. © 2020 WIT Press.","Artificial intelligence; Deep learning; Detection; Local instability; Maintenance; Railway",,,,,,"Deutsche Forschungsgemeinschaft, DFG","FUNDING The research described in this paper is part of the EPIB project which is financed by the DFG (German Research Foundation).",,,,,,,,,,"Martin, R.S., Strähle, U.M., Scheffbuch, M., Track-vehicle scale model for evaluating local track defects detection methods (2019) Transportation Geotechnics, 19, pp. 9-19. , https://doi.org/10.1016/j.trgeo.2019.01.001; Rapp, B.S., Rupp, S., Liu, J.C., Martin, U., Recognition of track defects through measured acceleration P1 & P2 (2019) 7th International Conference of EACEF (European Asian Civil Engineering Forum), 615; Rapp, S., Martin, U., (2018) Erkennung von Punktuellen Unstetigkeitsstellen Am Fahrweg Am Beispiel Eines Fahrzeug-Fahrwegmodells - Ansatz Zur Modellbildung (EPIB 1.1)., , Auftaktworkshop EPIB; Bahamon, S., (2018) Detection of Local Instabilities on A Scale Vehicle-track Model through Measured Accelerations of the Vehicle, , Master Thesis, Institute of Railway and Transportation Engineering of the University of Stuttgart; Sander, K., (2019) Anwendung Beschleunigungssensormodul Version 3.Kurzform; Zaccone, G., Karim, R., Menshawy, A., (2017) Deep Learning with TensorFlow: Explore Neural Networks with Python., p. 72. , Packt Publishing; Aggarwal, C., (2018) Neural Networks and Deep Learning., p. 38. , Springer international publishing AG; Deep Learning: Long Short-Term Memory Networks (LSTMs), , https://www.youtube.com/watch?v=5dMXyiWddYs, Accessed on: 4 May 2020; Hopkins, B., (2012) A Wavelet-Based Rail Surface Defect Prediction and Detection Algorithm, pp. 74-82. , Virginia Polytechnic Institute and State University; How to Reduce Overfitting with Dropout Regularization in Keras, , https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularizationin-keras, Accessed on: 10 May. 2020; Zhang, Y., (2019) Work Summary Deep Learning., , Institute of Railway and Transportation Engineering of the University of Stuttgart; (2018) Deep Learning. Mitp Verlags GmbH & Co, p. 6. , Goodfellow I; NN-SVG Publication-ready NN-architecture Schematics, , http://alexlenail.me/NN-SVG/index.html, Accessed on: 4 May 2020; Yang, B., (2018) Class of Deep Learning Chapter 5: Advanced Optimizaion Thechniques, , Institute of signal processing and system theory. of the University of Stuttgart; Srivastava, N., Dropout: A Simple Way to Prevent Neural Networks from Overfitting (2014) Journal of Machine Learning Research, 15, pp. 1929-1958; What Is the Role of the Activation Function in A Neural Network? How Does This Function in A Human Neural Network System?, , https://www.quora.com/What-is-the-roleof-the-activation-function-in-a-neural-network-How-does-this-function-in-a-humanneural-network-system2018, Accessed on: 4 May 2020",,,,"Wit Press",,,,,20460546,,,,"English","Int. J. Comput. Methods Experiment. Meas.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85091999486
"Guo J., Wang J., Wen C.-K., Jin S., Li G.Y.","56161255400;57218847393;7201367144;55243233900;57211345986;","Compression and Acceleration of Neural Networks for Communications",2020,"IEEE Wireless Communications","27","4","9136588","110","117",,21,"10.1109/MWC.001.1900473","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090426499&doi=10.1109%2fMWC.001.1900473&partnerID=40&md5=5c1806de3632089d1f50ccdda4f5fa8a","Information and Communications Engineering, Southeast University, China; Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Georgia Institute of Technology, United States","Guo, J., Information and Communications Engineering, Southeast University, China; Wang, J., Information and Communications Engineering, Southeast University, China; Wen, C.-K., Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Jin, S., Information and Communications Engineering, Southeast University, China; Li, G.Y., Georgia Institute of Technology, United States","DL has achieved great success in signal processing and communications and has become a promising technology for future wireless communications. Existing works mainly focus on exploiting DL to improve the performance of communication systems. However, the high memory requirement and computational complexity constitute a major hurdle for the practical deployment of DL-based communications. In this article, we investigate how to compress and accelerate the neural networks (NNs) in communication systems. After introducing the deployment challenges for DL-based communication algorithms, we discuss some representative NN compression and acceleration techniques. Afterwards, two case studies for multiple-input-multiple- output (MIMO) communications, including DL-based channel state information feedback and signal detection, are presented to show the feasibility and potential of these techniques. We finally identify some challenges on NN compression and acceleration in DL-based communications and provide a guideline for subsequent research. © 2002-2012 IEEE.",,"Channel state information; MIMO systems; Acceleration technique; Case-studies; Channel state information feedbacks; Communication algorithms; Memory requirements; Neural networks (NNS); Wireless communications; Neural networks",,,,,"National Natural Science Foundation of China, NSFC: 61625106, 61941104; Ministry of Science and Technology of the People's Republic of China, MOST: 108-2628-E-110-001-MY3; Ministry of Science and Technology, Taiwan, MOST; National Key Research and Development Program of China, NKRDPC: 2018YFA0701602","AcKnowledGment This work was supported in part by the National Key Research and Development Program 2018YFA0701602; the National Science Foundation of China (NSFC) for Distinguished Young Scholars with Grant 61625106; and the NSFC under Grant 61941104. The work of C.-K. Wen was supported in part by the Ministry of Science and Technology of Taiwan under grant MOST 108-2628-E-110-001-MY3.",,,,,,,,,,"Wang, T., Deep learning for wireless physical layer: Opportunities and challenges (2017) China Commun., 14 (11), pp. 92-111. , Nov; Qin, Z., Deep learning in physical layer communications (2019) Ieee Wireless Commun., 26 (2), pp. 93-99. , Apr; He, H., Model-driven deep learning for physical layer communications (2019) Ieee Wireless Commun., 26 (5), pp. 77-83. , Oct; Wang, T., Deep learning-based csi feedback approach for time-varying massive MIMO channels (2019) Ieee Wireless Commun. Lett., 8 (2), pp. 416-419. , Apr; Guo, J., Convolutional neural network based multiple-rate compressive sensing for massive MIMO csi feedback: Design, simulation, and analysis (2020) Ieee Trans. Wireless Commun., 19 (4), pp. 2827-2840. , Apr; Wen, C.-K., Shih, W.-T., Jin, S., Deep learning for massive MIMO csi feedback (2018) Ieee Wireless Commun. Lett., 7 (5), pp. 748-751. , Oct; Samuel, N., Diskin, T., Wiesel, A., Learning to detect (2019) Ieee Trans. Signal Process., 67 (10), pp. 2554-2564. , May; Shea, T.O.'., Hoydis, J., An introduction to deep learning for the physical layer (2017) Ieee Trans. On Cogn. Commun. Netw., 3 (4), pp. 563-575. , Dec; De Carvalho, E., Non-stationarities in extra-large scale massive MIMO (2019) ArXiv Preprint; Bucilua, C., Caruana, R., Niculescu-Mizil, A., Model compression (2006) Proc. Acm Sigkdd, pp. 535-541. , Aug; Lin, M., Chen, Q., Yan, S., Network in network (2013) ArXiv Preprint; Liang, F., Shen, C., Wu, F., An iterative bp-cnn architecture for channel decoding (2018) Ieee J. Sel. Topics Signal Process., 12 (1), pp. 144-159. , Feb; Iandola, F.N., Squeezenet: Alexnet-level accuracy with 50x fewer parameters and 0.5 mb model size (2016) ArXiv Preprint; Shih, W.-T., Study on Massive MIMO Csi Feedback Based on Deep Learning, , https://hdl.handle.net/11296/pvuea3, accessed on 25 May 2020, National Sun Yat-sen University; Wang, G., Acquisition of channel state information in heterogeneous cloud radio access networks: Challenges and research directions (2015) Ieee Wireless Commun., 22 (3), pp. 100-107. , June","Jin, S.; Information and Communications Engineering, China",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,15361284,,IWCEA,,"English","IEEE Wirel. Commun.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85090426499
"Wang T., Geng T., Li A., Jin X., Herbordt M.","56430084400;57192157725;56654631300;36611788700;6603686731;","FPDeep: Scalable Acceleration of CNN Training on Deeply-Pipelined FPGA Clusters",2020,"IEEE Transactions on Computers","69","8","9110747","1143","1158",,14,"10.1109/TC.2020.3000118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086709521&doi=10.1109%2fTC.2020.3000118&partnerID=40&md5=0b3b152edc0787cec589979a7b407338","Department of Physics, University of Science and Technology of China, Hefei, 230026, China; Department of Electrical and Computer Engineering, Boston University, Boston, MA  02215, United States; PCSD, Pacific Northwest National Laboratory, Richland, WA  99354, United States","Wang, T., Department of Physics, University of Science and Technology of China, Hefei, 230026, China; Geng, T., Department of Electrical and Computer Engineering, Boston University, Boston, MA  02215, United States; Li, A., PCSD, Pacific Northwest National Laboratory, Richland, WA  99354, United States; Jin, X., Department of Physics, University of Science and Technology of China, Hefei, 230026, China; Herbordt, M., Department of Electrical and Computer Engineering, Boston University, Boston, MA  02215, United States","Deep convolutional Neural Networks (CNNs) have revolutionized numerous applications, but the demand for ever more performance remains unabated. Scaling CNN computations to larger clusters is generally done by distributing tasks in batch mode using methods such as distributed synchronous SGD. Among the issues with this approach is that, to make the distributed cluster work with high utilization, the workload distributed to each node must be large; this implies nontrivial growth in the SGD mini-batch size. In this article we propose a framework, called FPDeep, which uses a hybrid of model and layer parallelism to configure distributed reconfigurable clusters to train CNNs. This approach has numerous benefits. First, the design does not suffer from performance loss due to batch size growth. Second, work and storage are balanced among nodes through novel workload and weight partitioning schemes. Part of the mechanism is the surprising finding that it is preferable to store excess weights in neighboring devices rather than in local off-chip memory. Third, the entire system is a fine-grained pipeline. This leads to high parallelism and utilization and also minimizes the time that features need to be cached while waiting for back-propagation. As a result, storage demand is reduced to the point where only on-chip memory is used for the convolution layers. And fourth, we find that the simplest topology, a 1D array, is preferred for interconnecting the FPGAs thus enabling widespread applicability. We evaluate FPDeep with the Alexnet, VGG-16, and VGG-19 benchmarks. Results show that FPDeep has good scalability to a large number of FPGAs, with the limiting factor being the FPGA-to-FPGA bandwidth. But with 250 Gb/s bidirectional bandwidth per FPGA, which is easily supported by current generation FPGAs, FPDeep performance shows linearity up to 100 FPGAs. Energy efficiency is evaluated with respect to GOPs/J. FPDeep provides, on average, 6.4× higher energy efficiency than comparable GPU servers. © 1968-2012 IEEE.","Convolution neural network training; parallel and distributed systems; reconfigurable computing","Bandwidth; Energy efficiency; Green computing; Pipelines; Batch modes; Bi-directional bandwidth; Distributed clusters; Entire system; Fine grained; High utilizations; On chip memory; Partition methods; Field programmable gate arrays (FPGA)",,,,,"National Science Foundation, NSF: 1405695, CCF-1618303/7960, CNS-1405695; National Institutes of Health, NIH: 1R41GM128533; U.S. Department of Energy, USDOE: DE-AC05-76RL01830; Intel Corporation: FPL 2018; Microsoft; Advanced Scientific Computing Research, ASCR: 66150; Pacific Northwest National Laboratory, PNNL","This research was supported in part by the DMC-CFA project and DS-HPC project under PNNL’s Laboratory Directed Research and Development Program. It was also supported in part by the U.S. DOE Office of Science, Office of Advanced Scientific Computing Research, under award 66150: ”CENATE - Center for Advanced Architecture Evaluation”. The Pacific Northwest National Laboratory is operated by Battelle for the U.S. Department of Energy under contract DE-AC05-76RL01830. This work was also supported, in part, by the NSF through Awards CNS-1405695 and CCF-1618303/7960; in part by the NIH through Award 1R41GM128533; in part by grants from Microsoft and Red Hat; and in part by Intel through donated FPGAs, tools, and IP. Preliminary versions of parts of this work appeared in FCCM 2018 [11] and FPL 2018 [10]. Tianqi Wang and Tong Geng contributed equally to this work.","This research was supported in part by the DMC-CFA project and DS-HPC project under PNNL?s Laboratory Directed Research and Development Program. It was also supported in part by the U.S. DOE Office of Science, Office of Advanced Scientific Computing Research, under award 66150: ?CENATE - Center for Advanced Architecture Evaluation?. The Pacific Northwest National Laboratory is operated by Battelle for the U.S. Department of Energy under contract DE-AC05-76RL01830. This work was also supported, in part, by the NSF through Awards CNS-1405695 and CCF-1618303/7960; in part by the NIH through Award 1R41GM128533; in part by grants from Microsoft and Red Hat; and in part by Intel through donated FPGAs, tools, and IP. Preliminary versions of parts of this work appeared in FCCM 2018 [11] and FPL 2018 [10]. Tianqi Wang and Tong Geng contributed equally to this work.",,,,,,,,,"Abadi, M., (2016) TensorFlow: Large-scale Machine Learning on Heterogeneous Distributed Systems; Ben-Nun, T., Hoefler, T., (2018) Demystifying Parallel and Distributed Deep Learning: An In-depth Concurrency Analysis; Blott, M., Scaling neural network performance through customized hardware architectures on reconfigurable logic (2017) Proc. Ieee Int. Conf. Comput. Des., pp. 419-422; Caulfield, A.M., A cloud-scale acceleration architecture (2016) Proc. 49th Annu. IEEE/ACM Int. Symp. Microarchit., pp. 1-13; Chen, J., Pan, X., Monga, R., Bengio, S., Jozefowicz, R., (2016) Revisiting Distributed Synchronous Sgd; Chen, T., (2015) MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems; Chung, E., Serving DNNs in real time at datacenter scale with project brainwave (2018) Ieee Micro, 38 (2), pp. 8-20. , Mar./Apr; Cong, J., Sarkar, V., Reinman, G., Bui, A., Customizable domain-specific computing (2011) Ieee Design Test Comput., 28 (2), pp. 6-15. , Mar./Apr; Fowers, J., A configurable cloud-scale DNN processor for real-time AI (2018) Proc. 45th Annu. Int. Symp. Comput. Archit., pp. 1-14; Geng, T., Wang, T., Sanaullah, A., Yang, C., Patel, R., Herbordt, M., A framework for acceleration ofCNNtraining on deeply-pipelined FPGA clusters with work and weight load balancing (2018) Proc. 28th Int. Conf. Field Programmable Logic Appl., pp. 394-3944; Geng, T., FPDeep: Acceleration and load balancing of CNN training on FPGA clusters (2018) Proc. Ieee 26th Annu. Int. Symp. Field-Programmable Custom Comput. Machines, pp. 81-84; Geng, T., LP-BNN: Ultra-low-latency BNN inference with layer parallelism (2019) Proc. Ieee 30th Int. Conf. Appl.-Specific Syst. Architectures Processors, 2160, pp. 9-16; Geng, T., O3BNN: An out-of-order architecture for highperformance binarized neural network inference with fine-grained pruning (2019) Proc. ACMInt. Conf. Supercomputing, pp. 461-472; George, A.D., Herbordt, M.C., Lam, H., Lawande, A.G., Sheng, J., Yang, C., Novo-G#: Large-scale reconfigurable computing with direct and programmable interconnects (2016) Proc. Ieee High Perform. Extreme Comput. Conf., pp. 1-7; Goyal, P., (2017) Accurate, Large Minibatch SGD: Training Image-Net in 1 Hour; Guan, Y., FP-DNN: An automated framework for mapping deep neural networks onto FPGAS with RTL-HLS hybrid templates (2017) Proc. Ieee 25th Annu. Int. Symp. Field-Programmable Custom Comput. Machines, pp. 152-159; Hegde, G., Kapre, N., CaffePresso: Accelerating convolutional networks on embedded SoCs (2017) Acm Trans. Embedded Comput. Syst., 17 (1), pp. 1-26; Huang, Y., GPipe: Efficient training of giant neural networks using pipeline parallelism (2019) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 103-112; Huo, Z., Gu, B., Huang, H., Training neural networks using features replay (2018) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 6660-6669; Huo, Z., Gu, B., Yang, Q., Huang, H., (2018) Decoupled Parallel Backpropagationwith Convergence Guarantee; Jia, Y., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. 22nd Acm Int. Conf. Multimedia, pp. 675-678; Jia, Z., Lin, S., Qi, C.R., Aiken, A., (2018) Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks; Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tang, P.T.P., (2016) On Large-batch Training for Deep Learning: Generalization Gap and Sharp Minima; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 1097-1105; http://www.leadergpu.com/articles/428-tensorflow-alexnet-benchmark, LeaderGPU TensorFlow AlexNet benchmark 2018. Accessed: Jul. 19, 2018; http://www.leadergpu.com/articles/430-tensorflow-vgg16-benchmark, LeaderGPU TensorFlow VGG-16 benchmark 2018. Accessed: Jul. 19, 2018; Li, A., Geng, T., Wang, T., Herbordt, M., Song, S.L., Barker, K., BSTC: A novel binarized-soft-tensor-core design for accelerating bit-based approximated neural nets (2019) Proc. Int. Conf. High Perform. Comput. Netw. Storage Anal., pp. 1-30; Li, M., Scaling distributed machine learning with the parameter server (2014) Proc. 11th Usenix Symp. Operating Syst. Des. Implementation, pp. 583-598; Lian, R.L., (2016) A Framework for FPGA-based Acceleration of Neural Network Inference with Limited Numerical Precision Via High-level Synthesis with Streaming Functionality, , PhD thesis, Dept. Electr. Comput. Eng., Univ. Toronto, Toronto, Canada; Lian, X., Zhang, C., Zhang, H., Hsieh, C.-J., Zhang, W., Liu, J., Can decentralized algorithms outperform centralized algorithms? A case study for decentralized parallel stochastic gradient descent (2017) Proc. Int. Conf.Neural Inf. Process. Syst., pp. 5330-5340; Lu, L., Liang, Y., Xiao, Q., Yan, S., Evaluating fast algorithms for convolutional neural networks on FPGAS (2017) Proc. Ieee 25th Annu. Int. Symp. Field-Programmable Custom Comput. Machines, pp. 101-108; Mirhoseini, A., Device placement optimization with reinforcement learning (2017) Proc. 34th Int. Conf. Mach. Learn., pp. 2430-2439; Moss, D.J.M., High performance binary neural networks on the xeon+ FPGATM platform (2017) Proc. 27th Int. Conf. Field Programmable Logic Appl., pp. 1-4; Narayanan, D., PipeDream: Generalized pipeline parallelism for DNN training (2019) Proc. 27th Acm Symp. Operating Syst. Princ., pp. 1-15; Ovtcharov, K., Ruwase, O., Kim, J.-Y., Fowers, J., Strauss, K., Chung, E.S., Accelerating deep convolutional neural networks using specialized hardware (2015) Microsoft Research Whitepaper, 2 (11); Sanaullah, A., Yang, C., Alexeev, Y., Yoshii, K., Herbordt, M.C., Application aware tuning of reconfigurable multi-layer perceptron architectures (2018) Proc. Ieee High Perform. Extreme Comput. Conf., pp. 1-9; Sheng, J., Yang, C., Herbordt, M.C., High performance communication on reconfigurable clusters (2018) Proc. 28th Int. Conf. Field Programmable Logic Appl., pp. 219-2194; Sun, X., Xu, Z., Meng, N., Lam, E.Y., So, H.K.-H., Data-driven light field depth estimation using deep convolutional neural networks (2016) Proc. Int. Joint Conf. Neural Netw., pp. 367-374; Venkataramanietal, S., ScaleDeep: A scalable compute architecture for learning and evaluating deep networks (2017) Sigarch Comput. Architecture News, 45 (2), pp. 13-26; Wei, X., Automated systolic array architecture synthesis for high throughput CNN inference on FPGAS (2017) Proc. 54th Annu. Des. Autom. Conf.; Wu, Y., (2016) Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation; Yang, C., Fully integrated FPGA molecular dynamics simulations (2019) Proc. Int. Conf. High Perform. Comput. Netw. Storage Anal., pp. 1-31; Zhang, C., Wu, D., Sun, J., Sun, G., Luo, G., Cong, J., Energyefficient CNNimplementation on a deeply pipelined FPGAcluster (2016) Proc. Int. Symp. Low Power Electron. Des., pp. 326-331; Zhao, R., Niu, X., Wu, Y., Luk, W., Liu, Q., Optimizing CNNbased object detection algorithms on embedded FPGA platforms (2017) Proc. Int. Symp. Appl. Reconfigurable Comput., pp. 255-267; Zhao, W., F-CNN: An FPGA-based framework for training convolutional neural networks (2016) Proc. Ieee 27th Int. Conf. Appl.-Specific Syst. Architectures Processors, pp. 107-114","Wang, T.; Department of Physics, China; email: tqwang@mail.ustc.edu.cn",,,"IEEE Computer Society",,,,,00189340,,ITCOB,,"English","IEEE Trans Comput",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85086709521
"Sanchez-Iborra R., Skarmeta A.F.","55933950900;7004419066;","TinyML-Enabled Frugal Smart Objects: Challenges and Opportunities",2020,"IEEE Circuits and Systems Magazine","20","3","9166461","4","18",,53,"10.1109/MCAS.2020.3005467","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089941646&doi=10.1109%2fMCAS.2020.3005467&partnerID=40&md5=d5e8d48f2b6b731d2d47ab8a4d567771","University of Murcia, Murcia, Spain","Sanchez-Iborra, R., University of Murcia, Murcia, Spain; Skarmeta, A.F., University of Murcia, Murcia, Spain","The TinyML paradigm proposes to integrate Machine Learning (ML)-based mechanisms within small objects powered by Microcontroller Units (MCUs). This paves the way for the development of novel applications and services that do not need the omnipresent processing support from the cloud, which is power consuming and involves data security and privacy risks. In this work, a comprehensive review of the novel TinyML ecosystem is provided. The related challenges and opportunities are identified and the potential services that will be enabled by the development of truly smart frugal objects are discussed. As a main contribution of this paper, a detailed survey of the available TinyML frameworks for integrating ML algorithms within MCUs is provided. Besides, aiming at illustrating the given discussion, a real case study is presented. Concretely, we propose a multi-Radio Access Network (RAT) architecture for smart frugal objects. The issue of selecting the most adequate communication interface for sending sporadic messages considering both the status of the device and the characteristics of the data to be sent is addressed. To this end, several TinyML frameworks are evaluated and the performances of a number of ML algorithms embedded in an Arduino Uno board are analyzed. The attained results reveal the validity of the TinyML approach, which successfully enables the integration of techniques such as Neural Networks (NNs), Support Vector Machine (SVM), decision trees, or Random Forest (RF) in frugal objects with constrained hardware resources. The outcomes also show promising results in terms of algorithm's accuracy and computation performance. © 2001-2012 IEEE.",,"Decision trees; Microcontrollers; Security of data; Support vector machines; Communication interface; Computation performance; Data security and privacy; Hardware resources; Microcontroller unit; Multi-radio access; Neural networks (NNS); Novel applications; Radio access networks",,,,,"Ministerio de Ciencia, Innovación y Universidades, MCIU: TIN2017-86885-R; European Commission, EC: 779852, 814918, 830929; European Regional Development Fund, FEDER","This work has been supported by the European Commission, under the projects IoTCrawler (Grant No. 779852), CyberSec4Europe (Grant No. 830929) and Fed4IoT (Grant No. 814918), and by the Spanish Ministry of Science, Innovation and Universities, under the project PERSEIDES (Grant No. TIN2017-86885-R with ERDF funds).",,,,,,,,,,"Columbus, L., (2018) 10 Charts That Will Change Your Perspective of Big Data's Growth, , https://softwarestrategiesblog.com/2018/06/02/10-charts-that-will-change-your-perspective-of-big-datas-growth, Tech. Rep, [Online]; Sun, Y., Peng, M., Zhou, Y., Huang, Y., Mao, S., Application of machine learning in wireless networks: Key techniques and open issues (2019) Ieee Commun. Surveys Tut., 21 (4), pp. 3072-3108. , https://ieeexplore.ieee.org/document/8743390, [Online]; Baltrusaitis, T., Ahuja, C., Morency, L.-P., Multimodal machine learning: A survey and taxonomy (2019) Ieee Trans. Pattern Anal. Mach. Intell., 41 (2), pp. 423-443. , https://ieeexplore.ieee.org/document/8269806, Feb, [Online]; Chen, Q., A survey on an emerging area: Deep learning for smart city data (2019) Ieee Trans. Emerg. Topics Comput. Intell., 3 (5), pp. 392-410. , https://ieeexplore.ieee.org/document/8704334, Oct, [Online]; Li, G., Gomez, R., Nakamura, K., He, B., Human-centered reinforcement learning: A survey (2019) Ieee Trans. Human-Mach. Syst., 49 (4), pp. 337-349. , https://ieeexplore.ieee.org/document/8708686, Aug, [Online]; Luo, T., DaDianNao: A neural network supercomputer (2017) Ieee Trans. Comput., 66 (1), pp. 73-88. , http://ieeexplore.ieee.org/document/7480791, JaN, [Online]; Garbinato, B., Guerraoui, R., Hulaas, J., Monod, M., Spring, J.H., Pervasive computing with frugal objects (2007) Proc. Ieee 21st Int. Conf. Advanced Information Networking and Applications Workshops (AINAW'07), pp. 13-18. , http://ieeexplore.ieee.org/document/4224076, [Online]; Bormann, C., Ersue, M., Keranen, A., (2014) Terminology for Constrained-Node Networks, , IETF RFC 7228; Hadj Sassi, M.S., Jedidi, F.G., Fourati, L.C., A new architecture for cognitive internet of things and big data (2019) Proc. Comput. Sci., 159, pp. 534-543. , https://linkinghub.elsevier.com/retrieve/pii/S1877050919313924, [Online]; Roman, R., Lopez, J., Mambo, M., Mobile edge computing Fog et al.: A survey and analysis of security threats and challenges"" (2018) Future Gener. Comput. Syst., 78, pp. 680-698. , https://linkinghub.elsevier.com/retrieve/pii/S0167739X16305635, Jan, [Online]; Martinez, B., Monton, M., Vilajosana, I., Prades, J.D., The power of models: Modeling power consumption for IoT devices (2015) Ieee Sensors J., 15 (10), pp. 5777-5789. , http://ieeexplore.ieee.org/document/7122861, Oct, [Online]; (2020) TinyML, , https://www.tinyml.org, [Online]; MacGillivray, C., Torchia, M., (2019) Internet of Things: Spending Trends and Outlook, , https://www.idc.com/getdoc.jsp?containerId=US45161419, Tech. Rep, [Online]; Doyu, H., (2019) TinyML As a Service and the Challenges of Machine Learning at the Edge, , https://www.ericsson.com/en/blog/2019/12/tinyml-as-a-service, Ericsson, Tech. Rep, [Online]; Pham, H.-T., Nguyen, M.-A., Sun, C.-C., AIoT solution survey and comparison in machine learning on low-cost microcontroller (2019) Proc. Ieee Int. Symp. Intelligent Signal Processing and Communication Systems (ISPACS), pp. 1-2. , https://ieeexplore.ieee.org/document/8986357, Dec, [Online]; Falbo, V., Apicella, T., Aurioso, D., Danese, L., Bellotti, F., Berta, R., De Gloria, A., Analyzing machine learning on mainstream microcontrollers Proc. Int. Conf. Applications Electronics Pervading Industry, Environment and Society, 2020, pp. 103-108. , https://link.springer.com/chapter/10.1007/978-3-030-37277-4-12, [Online]; Costa, R., The internet of moving things [industry view] (2018) Ieee Technol. Soc. Mag., 37 (1), pp. 13-14. , http://ieeexplore.ieee.org/document/8307131, MaR, [Online]; Quigley, M., Burke, M., Low-cost Internet of Things digital technology adoption in SMEs (2013) Int. J. Manage. Pract., 6 (2), p. 153. , http://www.inderscience.com/link.php?id=55828, [Online]; Sanchez-Iborra, R., Cano, M.-D., State of the art in LP-WAN solutions for industrial IoT services (2016) Sensors, 16 (5), p. 708; Niu, W., PatDNN: Achieving real-time DNN execution on mobile devices with pattern-based weight pruning (2020) Proc. 25th Int. Conf. Architectural Support Programming Languages and Operating Systems, pp. 907-922. , https://dl.acm.org/doi/10.1145/3373376.3378534, New York, Mar, [Online]; Banbury, C.R., Benchmarking TinyML systems: Challenges and direction (2020) Proc. 1st Int. Work Shop Ben Chmarking Machine Learning Workloads Emerging Hardware-3rd Conf. Machine Learning and Systems (MLSys), , https://arxiv.org/pdf/2003.04821.pdf, [Online]; Liberis, E., Lane, N.D., (2019) Neural Networks on Microcontrollers: Saving Memory at Inference Via Operator Reordering; Randhawa, P., Shanthagiri, V., Kumar, A., A review on applied machine learning in wearable technology and its applications (2017) Proc. Ieee Int. Conf. Intelligent Sustainable Systems (ICISS), pp. 347-354. , https://ieeexplore.ieee.org/document/8389428, Dec, [Online]; Ahmed, E., Yaqoob, I., Gani, A., Imran, M., Guizani, M., Internet-of-things-based smart environments: State of the art, taxonomy, and open research challenges (2016) Ieee Wireless Commun., 23 (5), pp. 10-16. , http://ieeexplore.ieee.org/document/7721736, Oct, [Online]; Rizzardi, A., Miorandi, D., Sicari, S., Cappiello, C., Coen-Porisini, A., Networked smart objects: Moving data processing closer to the source (2016) Lecture Notes Institute Computer Sciences, Social Informatics and Telecommunications Engineering), pp. 28-35. , https://linkspringer.com/chapter/10.1007/978-3-319-47075-7-4, [Online]; Roy, A., Zalzala, A.M., Kumar, A., Disruption of things: A model to facilitate adoption of IoT-based innovations by the urban poor (2016) Proc. Eng., 159, pp. 199-209. , https://linkinghub, [Online]. Available, elsevier.com/retrieve/pii/S1877705816323074; Santa, J., Ferná Ndez, P.J., Seamless IPv6 connectivity for two-wheelers (2017) Pervas. Mobile Comput., 42, pp. 526-541. , https://www.sciencedirect.com/science/article/pii/S1574119217300652, Dec, [Online]; Wollschlaeger, M., Sauter, T., Jasperneite, J., The future of industrial communication: Automation networks in the era of the Internet of Things and industry 4.0 (2017) Ieee Ind. Electron. Mag., 11 (1), pp. 17-27. , http://ieeexplore.ieee.org/document/7883994, MaR, [Online]; Deshmukh, S., Shah, R., Computation offloading frameworks in mobile cloud computing: A survey (2016) Proc. Ieee Int. Conf. Current Trends Advanced Computing (ICCTAC), pp. 1-5. , http://ieeexplore.ieee.org/document/7567332, Mar, [Online]; Jayaraman, P., Yavari, A., Georgakopoulos, D., Morshed, A., Zaslavsky, A., Internet of Things platform for smart farming: Experiences and lessons learnt (2016) Sensors, 16 (11), p. 1884. , http://www.mdpi.com/1424-8220/16/11/1884, NoV, [Online]; Warden, P., Situnayake, D., (2019) Tinyml: Machine Learning with Ten-sorflow Lite on Arduino and Ultra-Low-Power Microcontrollers, , O'Reilly UK; (2020) TensorFlow, , https://www.tensorflow.org, [Online]; (2020) Scikitlearn, , https://scikit-learn.org, [Online]; (2020) PyTorcH, , https://pytorch.org, [Online]; (2020) TensorFlow Lite, , https://www.tensorflow.org/lite, [Online]; (2020) TinyGo, , https://tinygo.org, [Online]; (2020) Embedded Learning Library, , https://microsoft.github.io/ELL, [Online]; (2020) The Microsoft Cognitive Toolkit, , https://docs.microsoft.com/en-us/cognitive-toolkit, [Online]; (2020) Darknet: Convolutional Neural Networks, , https://github.com/pjreddie/darknet, [Online]; Open Neural Network Exchange., p. 2020. , https://onnx.ai, [Online]; (2020) ARM-NN, , https://github.com/ARM-software/armnn, [Online]; (2020) CMSIS-NN, , https://arm-software.github.io/CMSIS-5/NN/html, [Online]; (2020) STM32Cube.AI, , https://www.st.com/en/embedded-software/x-cube-ai.html, [Online]; (2020) AIfES, , https://www.ims.fraunhofer.de/en/Business-Units-and-Core-Competencies/Electronic-Assistance-Systems/Technologies/Artificial-Intelligence-for-Embedded-Systems-AIfES.html, [Online]; (2020) NanoEdge Ai Studio, , https://cartesiam.ai, [Online]; (2020) MicroML, , https://github.com/eloquentarduino/micromlgen, [Online]; Morawiec, D., (2020) Sklearn-Porter, , https://github.com/nok/sklearn-porter, [Online]; (2020) M2cgen, , https://github.com/BayesWitnesses/m2cgen, [Online]; (2020) Weka-Porter, , https://github.com/nok/weka-porter, [Online]; Tsutsui Da Silva, L., Souza, V.M.A., Batista, G.E.A.P.A., EmbML Tool: Supporting the use of supervised learning algorithms in low-cost embedded systems,"" in Proc (2019) Ieee 31st Int. Conf. Tools Artificial Intelligence (ICTAI), pp. 1633-1637. , https://ieeexplore.ieee.org/document/8995408, Nov, [Online]; Nordby, J., (2019) Emlearn: Machine Learning Inference Engine for Microcontrollers and Embedded Devices, , https://doi.org/10.5281/zenodo.2589394, Mar, [Online]; (2020) UTensor, , https://github.com/uTensor/uTensor, [Online]; (2020) TinyMLgen, , https://github.com/eloquentarduino/tinymlgen, [Online]; Capotondi, A., Rusci, M., Fariselli, M., Benini, L., CMix-NN: Mixed low-precision CNN library for memory-constrained edge devices Ieee Trans. Circuits Syst. II, Express Briefs, , https://ieeexplore.ieee.org/document/9049084, to be published, [Online]; Wang, X., Magno, M., Cavigelli, L., Benini, L., FA NN-on-MCU: A n open-source toolkit for energy-efficient neural network inference at the edge of the Internet of Things Ieee Internet Things J, , https://ieeexplore.ieee.org/document/9016202, to be published, [Online]; (2020) Linaro, , https://www.linaro.org, [Online]; (2020) Caffe, , https://caffe.berkeleyvision.org, [Online]; (2020) Keras, , https://keras.io, [Online]; Holmes, G., Donkin, A., Witten, I., WEKA: A machine learning workbench (1994) Proc. Ieee Anziis '94-Australian New Zealnd Intelligent Information Systems Conf, pp. 357-361. , http://ieeexplore.ieee.org/document/396988, [Online]; (2020) TeensY, , https://www.pjrc.com/teensy, [Online]; (2020) Mbed Platforms, , https://os.mbed.com/platforms, [Online]; Howard, A.G., (2017) MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , http://arxiv.org/abs/1704.04861, ApR, [Online]; (2020) Fast Artificial Neural Network Library (FANN), , http://leenissen.dk/fann/wp, [Online]; Rossi, D., PULP: A parallel ultra low power platform for next generation IoT applications (2015) Proc. Ieee Hot Chips 27 Symp. (HCS), pp. 1-39. , http://ieeexplore.ieee.org/document/7477325, Aug, [Online]; Wang, Y., Luo, Z., Qiu, G., Zhou, G., Design of Smart Watch system based on E-paper (2015) Proc. 10th Ieee Int. Conf. Nano/Micro Engineered and Molecular Systems, pp. 327-330. , http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7147437, ApR. [Online]",,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,1531636X,,,,"English","IEEE Circuits Syst. Mag.",Article,"Final","",Scopus,2-s2.0-85089941646
"Cui S., Joe I.","57218489138;56212559100;","Collision prediction for a low power wide area network using deep learning methods",2020,"Journal of Communications and Networks","22","3","9143572","205","214",,8,"10.1109/JCN.2020.000017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089303742&doi=10.1109%2fJCN.2020.000017&partnerID=40&md5=98b753ede192876c8701cff0b11ad04c","Department of Computer Science, Hanyang University, South Korea","Cui, S., Department of Computer Science, Hanyang University, South Korea; Joe, I., Department of Computer Science, Hanyang University, South Korea","A low power wide area network (LPWAN) is becoming a popular technology since more and more industrial Internet of things (IoT) applications rely on it. It is able to provide long distance wireless communication with great power saving. Given the fact that an LPWAN covers a wide area where all end nodes communicate directly to a few gateways, a large number of devices have to share the gateway. In this situation, chances are many collisions could occur, leading to waste of limited wireless resources. However, many factors affecting the number of collisions that cannot be solved by traditional time series analysis algorithms. Therefore, deep learning methods can be applied here to predict collisions by analyzing these factors in an LPWAN system. In this paper, we propose long short-term memory extended Kalman filter (LSTMEKF) model for collision prediction in the LPWAN in terms of the temporal correlation which can improve the LSTM performance. The efficacies of our models are demonstrated on the data set simulated by LoRaSim. © 2011 KICS.","Deep Learning; extended Kalman filter; Internet of things; LoRa; LSTM","Forecasting; Gateways (computer networks); Industrial internet of things (IIoT); Kalman filters; Learning systems; Long short-term memory; Low power electronics; Time series analysis; Wide area networks; Collision prediction; Data set; Learning methods; Long-distance wireless; Low Power; Power savings; Temporal correlations; Wireless resources; Deep learning",,,,,"Hanyang University, HYU; National Research Foundation of Korea, NRF; Ministry of Science and ICT, South Korea, MSIT","Manuscript received October 22, 2019; revised May 29, 2020; approved for publication by Yansha Deng, Guest Editor, May 31, 2020. This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No.NRF-2019R1A2C1009894) S. Cui and I. Joe are with the Department of Computer Science, Hanyang University, email: {shengmincui, iwjoe}@hanyang.ac.kr. I. Joe is the corresponding author. Digital Object Identifier: 10.1109/JCN.2020.000017",,,,,,,,,,"Al-Fuqaha, A., Internet of things: A survey on enabling technologies, protocols, and applications (2015) IEEE Commun. Surveys Tuts., 17 (4), pp. 2347-2376. , June; Da Xu, L., He, W., Li, S., Internet of things in industries: A survey (2014) IEEE Trans. Ind. Informat., 10 (4), pp. 2233-2243. , Jan; Zanella, A., Internet of things for smart cities (2014) IEEE Internet Things J., 1 (1), pp. 22-32. , Feb; Tong, F., A Tractable Analysis of Positioning Fundamentals in Low-Power Wide Area Internet of Things (2019) IEEE Trans. Veh. Technol., 68 (7), pp. 7024-7034. , July; Raza, U., Kulkarni, P., Sooriyabandara, M., Low power wide area networks: An overview (2017) IEEE Commun. Surveys Tuts., 19 (2), pp. 855-873. , Jan; Xiong, X., Low power wide area machine-to-machine networks: Key techniques and prototype (2015) IEEE Commun. Mag., 53 (9), pp. 64-71. , Sept; Petajajarvi, J., On the coverage of LPWANs: Range evaluation and channel attenuation model for LoRa technology (2015) Proc. ITST, , Dec; Georgiou, O., Raza, U., Low power wide area network analysis: Can LoRa scale? (2017) IEEE Wireless Commun. Lett., 6 (2), pp. 162-165. , Apr; (2017) LoRaWAN Specification., LoRa Alliance., CA; Voigt, T., Mitigating inter-network interference in LoRa networks (2016) J. ArXiv Preprint arXiv:1611.00688; Box, G.E.P., (2015) Time Series Analysis: Forecasting and Ontrol, John Wiley & Sons; Stathopoulos, A., Karlaftis, M.G., A multivariate state space approach for urban traffic flow modeling and prediction (2003) Transportation Research Part C: Emerging Technol., 11 (1), pp. 121-135. , Apr; Dong, C., A spatial-temporal-based state space approach for freeway network traffic flow modelling and prediction (2015) Transportmetrica A: Transport Science, vol.9935, pp. 547-560. , Apr; Sebe, N., (2005) Machine Learning in Computer Vision, Springer; Schuler, C.J., A machine learning approach for non-blind image deconvolution (2013) Proc. IEEE CVPR, pp. 1067-1074; Ganapathiraju, A., Hamaker, J., Picone, J., Hybrid SVM/HMM architectures for speech recognition (2000) Proc. ICSLP, pp. 504-507; Deng, L., Li, X., Machine learning paradigms for speech recognition: An overview (2013) IEEE Trans. Audio, Speech, Language Process., 21 (5). , May; Wernick, M.N., Machine learning in medical imaging (2010) IEEE Signal Process. Mag., 27 (4), pp. 25-38. , July; Kourou, K., Machine learning applications in cancer prognosis and prediction (2015) Computational Structural Biotechnology J., 13, pp. 8-17; Kaelbling, L.P., Littman, L.M., Moore, A.W., Reinforcement learning: A survey (1996) J. Artificial Intell. Research, 4, pp. 237-285. , May; Wang, M., Machine learning for networking: Workflow, advances and opportunities (2017) IEEE Network, 32 (2), pp. 92-99. , Nov; Mao, B., An intelligent route computation approach based on realtime deep learning strategy for software defined communication systems (2019) IEEE Trans. Emerg. Topics Comput., p. 1. , Feb; Zhou, T., A deep-learning-based radio resource assignment technique for 5G ultra dense networks (2018) IEEE Network, 32 (6), pp. 28-34. , Nov; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) J. Neural Comput., 9 (8), pp. 1735-1780. , Nov; Chung, J., Empirical evaluation of gated recurrent neural networks on sequence modeling (2014) ArXiv Preprint arXiv:1412.3555; Kostas M, T., A long short-term memory deep learning network for the prediction of epileptic seizures using EEG signals (2018) J. Comput. Biology Medicine, 99, pp. 24-37. , Aug; Ma, X., Long short-term memory neural network for traffic speed prediction using remote microwave sensor data (2015) Transportation Research Part C: Emerging Technologies, 54, pp. 187-197. , May; Chemali, E., Long short-term memory networks for accurate stateof-charge estimation of li-ion batteries (2018) IEEE Trans. Ind. Electron., 65 (8), pp. 6730-6739. , Aug; Haxhibeqiri, J., LoRa Scalability: A Simulation Model Based on Interference Measurements (2017) J. Sensors, 17 (6), p. 1193. , May; Mahmood, A., Scalability analysis of a LoRa network under imperfect orthogonality (2019) IEEE Trans. Ind. Informat., 15 (3), pp. 1425-1436. , Mar; Bor, M., Do LoRa low-power wide-area networks scale? (2016) Proc. ACM MSWiM, pp. 59-67; Qin, Z., Performance analysis of clustered LoRa networks (2019) IEEE Trans. Veh. Technol., 68 (8), pp. 7616-7629. , Aug; Kawamoto, Y., (2019) Multilayer Virtual Cell-Based Resource Allocation in Low-Power Wide-Area Networks, 6 (6), pp. 10665-10674. , Dec; Reynders, B., Improving Reliability and Scalability of LoRaWANs through Lightweight Scheduling (2018) IEEE Internet Things J., 5 (3), pp. 1830-1842. , June; Bengio, Y., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Trans. Neural Netw., 5 (2), pp. 157-166. , Mar; Werbos, P.J., Backpropagation through time: What it is and how to do it (1990) Proc. IEEE, 78 (10), pp. 1550-1560. , Oct; Jaeger, H., (2002) Tutorial on Training Recurrent Neural Networks, Covering BPPT, RTRL, EKF and The"" Echo State Network"" Approach, Bonn: GMDForschungszentrum Informationstechnik; Pérez-Ortiz, J.A., Kalman filters improve LSTM network performance in problems unsolvable by traditional recurrent nets (2013) J. Neural Netw., 16 (2), pp. 241-250. , Mar; Gers, F.A., DEKF-LSTM (2002) Proc. ESANN, pp. 369-376; Anderson, B.D., Moore, J.B., (2012) Optimal Filtering, Courier Corporation; Meurer, A., SymPy: Symbolic computing in Python (2017) J. PeerJ Computer Science 3, 3, p. e103","Cui, S.; Department of Computer Science, South Korea; email: shengmincui@hanyang.ac.kr.",,,"Korean Institute of Communication Sciences",,,,,12292370,,,,"English","J. Commun. Netw.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85089303742
"Jain A., Goel P., Aggarwal S., Fell A., Anand S.","57211049251;57531016300;57218705925;24780574600;14036950100;","Symmetric k-Means for Deep Neural Network Compression and Hardware Acceleration on FPGAs",2020,"IEEE Journal on Selected Topics in Signal Processing","14","4","8966322","737","749",,2,"10.1109/JSTSP.2020.2968810","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090113466&doi=10.1109%2fJSTSP.2020.2968810&partnerID=40&md5=071f0471bdfe97711b7300b01cd66d71","Indraprastha Institute of Information Technology, New Delhi, 110020, India","Jain, A., Indraprastha Institute of Information Technology, New Delhi, 110020, India; Goel, P., Indraprastha Institute of Information Technology, New Delhi, 110020, India; Aggarwal, S., Indraprastha Institute of Information Technology, New Delhi, 110020, India; Fell, A., Indraprastha Institute of Information Technology, New Delhi, 110020, India; Anand, S., Indraprastha Institute of Information Technology, New Delhi, 110020, India","Convolutional Neural Networks (CNNs) are popular models that have been successfully applied to diverse domains like vision, speech, and text. To reduce inference-time latency, it is common to employ hardware accelerators, which often require a model compression step. Contrary to most compression algorithms that are agnostic of the underlying hardware acceleration strategy, this paper introduces a novel Symmetric k-means based compression algorithm that is specifically designed to support a new FPGA-based hardware acceleration scheme by reducing the number of inference-time multiply-accumulate (MAC) operations by up to 98%. First, a simple k-means based training approach is presented and then as an extension, Symmetric k-means is proposed which yields twice the reduction in MAC operations for the same bit-depth as the simple k-means approach. A comparative analysis is conducted on popular CNN architectures for tasks including classification, object detection and end-to-end stereo matching on various datasets. For all tasks, the model compression down to 3 bits is presented, while no loss is observed in accuracy for the 5-bits quantization. © 2007-2012 IEEE.","Convolutional neural network (CNN); deep learning; FPGA; k-means; model compression; object detection; quantization; stereo","Classification (of information); Convolutional neural networks; Deep neural networks; Field programmable gate arrays (FPGA); Inference engines; Object detection; Comparative analysis; Compression algorithms; Diverse domains; Hardware acceleration; Hardware accelerators; Model compression; Multiply-accumulate operation; Stereo matching; K-means clustering",,,,,"Microsoft Research","Manuscript received June 1, 2019; revised November 19, 2019 and January 15, 2020; accepted January 16, 2020. Date of publication January 22, 2020; date of current version August 10, 2020. This work was supported in part by Infosys Center for AI at IIIT-Delhi and Microsoft Research, India. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Diana Marculescu. (Corresponding author: Akshay Jain.) The authors are with the Indraprastha Institute of Information Technology, New Delhi 110020, India (e-mail: akshayj@iiitd.ac.in; pulkit15158@iiitd.ac.in; shivam16195@iiitd.ac.in; alex@iiitd.ac.in; anands@iiitd.ac.in). Digital Object Identifier 10.1109/JSTSP.2020.2968810",,,,,,,,,,"LeCun, Y., Bengio, Y., Hinton, G., Deep Learning (2015) Nature, 521 (7553); Alyamkin, S., Low-power computer vision: Status, challenges, and opportunities (2019) Ieee J. Emerg. Sel. Topics Circuits Syst., 9 (2), pp. 411-421. , Jun; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding (2016) Proc. Int. Conf. Learn. Representations; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 1135-1143; Chen, W., Wilson, J., Tyree, S., Weinberger, K., Chen, Y., Compressing neural networks with the hashing trick (2015) Proc. Int. Conf. Mach. Learn., pp. 2285-2294; Zhou, A., Yao, A., Guo, Y., Xu, L., Chen, Y., Incremental network quantization: Towards lossless cnns with low-precision weights (2017) Proc. Int. Conf. Learn. Representations; Du, Z., ShiDianNao: Shifting vision processing closer to the sensor (2015) Proc. 42nd Annu. Int. Symp. Comput. Archit., New York, NY, Usa, pp. 92-104. , http://doi.acm.org/10.1145/2749469.2750389, [Online]; Han, S., EIE: Efficient inference engine on compressed deep neural network (2016) Proc. 43rd Int. Symp. Comput. Archit., Piscataway, NJ, Usa, pp. 243-254. , https://doi.org/10.1109/ISCA.2016.30, [Online]; Chen, Y., Emer, J., Sze, V., Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit., Jun., pp. 367-379; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., Optimizing loop operation and dataflow in FPGA acceleration of deep convolutional neural networks (2017) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays, Ser. FPGA'17, , http://doi.acm.org/10.1145/3020078.3021736, New York, NY, USA: ACM, [Online]; Motamedi, M., Gysel, P., Akella, V., Ghiasi, S., Design space exploration of fpga-based deep convolutional neural networks (2016) Proc. 21st Asia South Pacific Des. Autom. Conf., pp. 575-580; Qiu, J., Going deeper with embedded FPGA platform for convolu-tional neural network (2016) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays, pp. 26-35; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays, pp. 161-170; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems 25, pp. 1106-1114. , http://papers.nips.cc/book/advances-in-neural-information-processing-systems-25-2012, P. L. Bartlett, F. C. N. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds., [Online]; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. Int. Conf. Learn. Representations; Neklyudov, K., Molchanov, D., Ashukha, A., Vetrov, D.P., Structured bayesian pruning via log-normal multiplicative noise (2017) Proc. Adv. Neural Inf. Process. Syst., pp. 6775-6784; Zhu, M., Gupta, S., To prune, or not to prune: Exploring the efficacy of pruning for model compression (2018) Proc. 6th Int. Conf. Learn. Representations, Workshop Track Proceedings; Gong, Y., Liu, L., Yang, M., Bourdev, L., (2014) Compressing Deep Convolu-tional Networks Using Vector Quantization; Kuchaiev, O., Ginsburg, B., Factorization tricks for lstm networks (2017) Proc. Workshop, Int. Conf. Learn. Representations; Thakker, U., Beu, J.G., Gope, D., Dasika, G., Mattina, M., Run-time efficient RNN compression for inference on edge devices (2019) 4th Edition Workshop Energy Efficient Machine Learn. Cognitive Comput. Embedded Appl. Int. Symposium Comput. Architecture, Phoenix, Arizona; Choi, Y., El-Khamy, M., Lee, J., Towards the limit of network quantization (2017) Proc. Int. Conf. Learn. Representations; Ding, C., C ir cnn: Accelerating and compressing deep neural networks using block-circulant weight matrices (2017) Proc. 50th Annu. IEEE/ACM Int. Symp. Microarchitecture, pp. 395-408; Wang, S., C-LSTM: Enabling efficient lstm using structured compression techniques on FPGAs (2018) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 11-20; Thakker, U., (2019) Compressing RNNs for IoT Devices by 15-38x Using Kronecker Products; Gupta, S., Agrawal, A., Gopalakrishnan, K., Narayanan, P., Deep learning with limited numerical precision (2015) Proc. Int. Conf. Mach. Learn., pp. 1737-1746; Lin, D., Talathi, S., Annapureddy, S., Fixed point quantization of deep convolutional networks (2016) Proc. Int. Conf. Mach. Learn., pp. 2849-2858; Courbariaux, M., Bengio, Y., David, J.-P., BinaryConnect: Training Deep Neural Networks with binary weights during propagations (2015) Advances in Neural Information Processing Systems 28, pp. 3123-3131. , C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, Eds. Curran Associates, Inc; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Bina-rized neural networks (2016) Advances in Neural Information Processing Systems 29, pp. 4107-4115. , http://papers.nips.cc/paper/6573-binarized-neural-networks.pdf, D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, Eds. Curran Associates, Inc., [Online]; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., XNOR-Net: ImageNet classification using binary convolutional neural networks (2016) Proc. Eur. Conf. Comput. Vision, pp. 525-542. , Springer; Li, F., Zhang, B., Liu, B., Ternary weight networks (2016) 1st Int. Workshop Efficient Methods for Deep Neural Networks, Nips; Zhu, C., Han, S., Mao, H., Dally, W.J., Trained ternary quantization (2016) Int. Conf. Learn. Representations; Tschannen, M., Khanna, A., Anandkumar, A., StrassenNets: Deep learning with a multiplication budget (2018) Proc. Int. Conf. Mach. Learn., pp. 4992-5001; Gope, D., Dasika, G., Mattina, M., Ternary hybrid neural-tree networks for highly constrained IoT applications (2019) Proc. 2nd Conf. Systems Machine Learn.; Gope, D., Beu, J., Thakker, U., Mattina, M., (2019) Ternary Mobilenets Via Per-layer Hybrid Filter Banks; Howard, A.G., (2017) Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications; Hinton, G., Vinyals, O., Dean, J., (2014) Distilling the Knowledge in a Neural Network, , NIPS Deep Learning Workshop; Kumar, A., Goyal, S., Varma, M., Resource-efficient machine learning in 2 kb ram for the internet of things (2017) Proc. 34th Int. Conf. Mach. Learn., 70, pp. 1935-1944. , JMLR. org; He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., Han, S., AMC: AutoML for model compression and acceleration on mobile devices (2018) Proc. Eur. Conf. Comput. Vision, pp. 815-832. , Sep; Rahman, A., Oh, S., Lee, J., Choi, K., Design space exploration of FPGA accelerators for convolutional neural networks (2017) Proc. Conf. Des., Autom. Test Eur. European Design and Automation Association, pp. 1147-1152; Suda, N., Throughput-Optimized OpenCL-based FPGA accelerator for large-scale convolutional neural networks (2016) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, New York, NY, Usa, pp. 16-25. , http://doi.acm.org/10.1145/2847263.2847276, [Online]; Tann, H., Hashemi, S., Bahar, R.I., Reda, S., Hardware-software codesign of accurate, multiplier-free Deep Neural Networks (2017) Proc. 54th ACM/EDAC/IEEE Des. Autom. Conf., Jun., pp. 1-6; Ji, S., Xu, W., Yang, M., Yu, K., 3D Convolutional neural networks for human action recognition (2013) Ieee Trans. Pattern Anal. Mach. Intell., 35 (1), pp. 221-231. , Jan; Paszke, A., PyTorch: An imperative style, high-performance deep learning library (2019) Advances in Neural Information Processing Systems 32, pp. 8024-8035. , H. Wallach, H. Larochelle, A. Beygelzimer, F. Alch'e-Buc, E. Fox and R. Garnett, Eds. Curran Associates, Inc; Krizhevsky, A., Hinton, G., Learning multiple layers of features from tiny images (2009) Citeseer, Tech. Rep.; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A Large-Scale Hierarchical Image Database (2009) Proc. Ieee Conf. Com-put. Vision Pattern Recognit., pp. 248-255; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Proc. Ieee Conf. Comput. Vision Pattern Recognit., pp. 779-788; Redmon, J., Farhadi, A., YOLO9000: Better, Faster, Stronger (2016) Proc. IEEE/CVF Conf. Comput. Vision Pattern Recognit., Jun., pp. 6517-6525; Chang, J., Chen, Y., Pyramid Stereo Matching Network (2018) Proc. IEEE/CVF Conf. Comput. Vision Pattern Recognit., Jun., pp. 5410-5418; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. Ieee, pp. 2278-2324; Darabi, S., Belbahri, M., Courbariaux, M., Nia, V.P., (2018) Bnn+: Improved Binary Network Training; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. Ieee Conf. Comput. Vision Pattern Recognit., Jun., pp. 770-778; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L., Mo-bilenetv2: Inverted residuals and linear bottlenecks (2018) Proc. IEEE/CVF Conf. Comput. Vision Pattern Recognit., Jun., pp. 4510-4520; Zhang, X., Zhou, X., Lin, M., Sun, J., Shufflenet: An extremely efficient convolutional neural network for mobile devices (2018) Proc. Ieee Conf. Comput. Vision Pattern Recognit., pp. 6848-6856; Everingham, M., Eslami, S.A., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The Pascal visual object classes challenge: A retrospective (2015) Int. J. Comput. Vision, 111 (1), pp. 98-136; Scharstein, D., Szeliski, R., A taxonomy and evaluation of dense Two-Frame stereo correspondence algorithms (2002) Int. J. Comput. Vision, 47 (1-3), pp. 7-42. , https://doi.org/10.1023/A:1014573219977, [Online]; Mayer, N., A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation (2016) Proc. Ieee Conf. Comput. Vision Pattern Recognit., Jun., pp. 4040-4048; Menze, M., Geiger, A., Object scene flow for autonomous vehicles (2015) Proc. Conf. Comput. Vision Pattern Recognit., pp. 3061-3070","Jain, A.; Indraprastha Institute of Information TechnologyIndia; email: akshayj@iiitd.ac.in",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,19324553,,,,"English","IEEE J. Sel. Top. Sign. Proces.",Article,"Final","",Scopus,2-s2.0-85090113466
"Singh P., Verma V.K., Rai P., Namboodiri V.P.","57208015691;56001533700;36768797700;8724086000;","Acceleration of Deep Convolutional Neural Networks Using Adaptive Filter Pruning",2020,"IEEE Journal on Selected Topics in Signal Processing","14","4","9086749","838","847",,4,"10.1109/JSTSP.2020.2992390","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089953123&doi=10.1109%2fJSTSP.2020.2992390&partnerID=40&md5=5ce691f52790f2c22a35cc607f97cfd6","Department of Computer Science and Engineering, IIT Kanpur, Kanpur, 208016, India","Singh, P., Department of Computer Science and Engineering, IIT Kanpur, Kanpur, 208016, India; Verma, V.K., Department of Computer Science and Engineering, IIT Kanpur, Kanpur, 208016, India; Rai, P., Department of Computer Science and Engineering, IIT Kanpur, Kanpur, 208016, India; Namboodiri, V.P., Department of Computer Science and Engineering, IIT Kanpur, Kanpur, 208016, India","While convolutional neural networks (CNNs) have achieved remarkable performance on various supervised and unsupervised learning tasks, they typically consist of a massive number of parameters. This results in significant memory requirements as well as a computational burden. Consequently, there is a growing need for filter-level pruning approaches for compressing CNN based models that not only reduce the total number of parameters but reduce the overall computation as well. We present a new min-max framework for the filter-level pruning of CNNs. Our framework jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance. Our framework consists of two modules: (1) An adaptive filter pruning (AFP) module, which minimizes the number of filters in the model; and (2) A pruning rate controller (PRC) module, which maximizes the accuracy during pruning. In addition, we also introduce orthogonality regularization in training of CNNs to reduce redundancy across filters of a particular layer. In the proposed approach, we prune the least important filters and, at the same time, reduce the redundancy level in the model by using orthogonality constraints during training. Moreover, unlike most previous approaches, our approach allows directly specifying the desired error tolerance instead of the pruning level. We perform extensive experiments for object classification (LeNet, VGG, MobileNet, and ResNet) and object detection (SSD, and Faster-RCNN) over benchmarked datasets such as MNIST, CIFAR, GTSDB, ImageNet, and MS-COCO. We also present several ablation studies to validate the proposed approach. Our compressed models can be deployed at run-time, without requiring any special libraries or hardware. Our approach reduces the number of parameters of VGG-16 by an impressive factor of 17.5X, and the number of FLOPS by 6.43X, with no loss of accuracy, significantly outperforming other state-of-the-art filter pruning methods. © 2007-2012 IEEE.","Deep convolutional neural network acceleration; efficient computation; model compression; pruning","Adaptive filtering; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Libraries; Object detection; Redundancy; Computational burden; Loss of accuracy; Memory requirements; Object classification; Orthogonality constraints; Predictive performance; Special libraries; Supervised and unsupervised learning; Adaptive filters",,,,,,,,,,,,,,,,"Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. 3rd Int. Conf. Learn. Representations, , San Diego, CA, USA, May 7-9; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 770-778; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., XNOR-Nets: Imagenet classification using binary convolutional neural networks (2016) European Conference on Computer Vision. Berlin, Germany: Springer, pp. 525-542; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2015) Proc. Int. Conf. Learn. Representations; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Proc. Advances Neural Inf. Process. Syst., pp. 1135-1143; Alvarez, J.M., Salzmann, M., Learning the number of neurons in deep networks (2016) Proc. Advances Neural Inf. Process. Syst., pp. 2270-2278; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning structured sparsity in deep neural networks (2016) Proc. Advances Neural Inf. Process. Syst., pp. 2074-2082; Luo, J.-H., Wu, J., Lin, W., ThiNet: A filter level pruning method for deep neural network compression (2017) Proc. IEEE Int. Conf. Comput. Vision, pp. 5058-5066; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning filters for efficient convnets (2017) Proc. 5th Int. Conf. Learn. Representations, , https://openreview.net/pdf?id=rJqFGTslg, Toulon, France, Apr. 24-26; He, Y., Zhang, X., Sun, J., Channel pruning for accelerating very deep neural networks (2017) Proc. IEEE Int. Conf. Comput. Vision, pp. 1389-1397; Singh, P., Verma, V.K., Rai, P., Namboodiri, V.P., Play and prune: Adaptive filter pruning for deep model compression (2019) Proc. 28th Int. Joint Conf. Artif. Intell., pp. 3460-3466; Hinton, G.E., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) CoRR; Ba, J., Caruana, R., Do deep nets really need to be deep? (2014) Proc. Advances Neural Inf. Process. Syst, pp. 2654-2662; Zhou, H., Alvarez, J.M., Porikli, F., Less is more: Towards compact CNNs (2016) Proc. Eur. Conf. Comput. Vision, pp. 662-677; Castellano, G., Fanelli, A.M., Pelillo, M., An iterative pruning algorithm for feedforward neural networks (1997) IEEE Trans, Neural Netw., 8 (3), pp. 519-531. , May; Huang, Z., Wang, N., Data-driven sparse structure selection for deep neural networks (2018) Proc. Eur. Conf. Comput. Vision, pp. 304-320; Wang, T., Fan, L., Wang, H., Simultaneously learning architectures and features of deep neural networks (2019) Proc. Int. Conf. Artif. Neural Netw., pp. 275-287; Bansal, N., Chen, X., Wang, Z., Can we gain more from orthogonality regularizations in training deep networks? (2018) Proc. Advances Neural Inf. Process. Syst., pp. 4261-4271; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning structured sparsity in deep neural networks (2016) Proc. Advances Neural Inf. Process. Syst., pp. 2074-2082; Neklyudov, K., Molchanov, D., Ashukha, A., Vetrov, D.P., Structured Bayesian pruning via log-normal multiplicative noise (2017) Proc. Advances Neural Inf. Process. Syst., pp. 6778-6787; Molchanov, D., Ashukha, A., Vetrov, D., Variational dropout sparsifies deep neural networks (2017) Proc. 34th Int.Conf.Mach. Learn., 70, pp. 2498-2507; Hu, H., Peng, R., Tai, Y.-W., Tang, C.-K., Network trimming: A data-driven neuron pruning approach towards efficient deep architectures (2016) CoRR; Ding, X., Ding, G., Han, J., Tang, S., Auto-balanced filter pruning for efficient convolutional neural networks (2018) Proc. 32nd Aaai Conf. Artif. Intell., pp. 6797-6804. , New Orleans, LA, USA, Feb. 2-7; Lin, S., Ji, R., Yan, C., Zhang, B., Cao, L., Ye, Q., Huang, F., Doermann, D., Towards optimal structured cnn pruning via generative adversarial learning (2019) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 2790-2799; Zhao, C., Ni, B., Zhang, J., Zhao, Q., Zhang, W., Tian, Q., Variational convolutional neural network pruning (2019) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 2780-2789; He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., Han, S., AMC: AutoML for model compression and acceleration on mobile devices (2018) Proc. Eur. Conf. Comput. Vision, pp. 784-800; Kim, H., Khan, M.U.K., Kyung, C.-M., Efficient neural network compression (2019) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 12569-12577; Minnehan, B., Savakis, A., Cascaded projection: End-to-end network compression and acceleration (2019) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 10715-10724; Lin, S., Ji, R., Li, Y., Wu, Y., Huang, F., Zhang, B., Accelerating convolutional networks via global &dynamic filter pruning (2018) Proc. Int. Joint Conf. Artif. Intell., pp. 2425-2432; Luo, J.-H., Zhang, H., Zhou, H.-Y., Xie, C.-W., Wu, J., Lin, W., ThiNet: Pruning CNN filters for a thinner net (2018) IEEE Trans. Pattern Anal. Mach. Intell., 41 (10), pp. 2525-2538. , Oct; Luo, J.-H., Wu, J., An entropy-based pruning method for CNN compression (2017) CoRR; Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J., Pruning convolutional neural networks for resource efficient inference (2017) Proc. Int. Conf. Learn. Representations; Lin, J., Rao, Y., Lu, J., Zhou, J., Runtime neural pruning (2017) Proc. Advances Neural Inf. Process. Syst., pp. 2181-2191; He, Y., Kang, G., Dong, X., Fu, Y., Yang, Y., Soft filter pruning for accelerating deep convolutional neural networks (2018) Proc. Int. Joint Conf. Artif. Intell., pp. 2234-2240; Yu, R., NISP: Pruning networks using neuron importance score propagation (2018) Proc. IEEE Conf.Comput. Vision Pattern Recognit., pp. 9194-9203; Houben, S., Stallkamp, J., Salmen, J., Schlipsing, M., Igel, C., Detection of traffic signs in real-world images: The German traffic sign detection benchmark (2013) Proc. Int. Joint Conf. Neural Netw, pp. 1-8; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vision, 115 (3), pp. 211-252; Lin, T.-Y., Microsoft COCO: Common objects in context (2014) Proc. Eur. Conf. Comput. Vision, pp. 740-755; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. Ieee, 86 (11), pp. 2278-2324. , Nov; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., MobileNetv2: Inverted residuals and linear bottlenecks (2018) Proc. IEEE Conference Comput. Vision Pattern Recognit., pp. 4510-4520; Liu, W., SSD: Single shot multibox detector (2016) Proc. Eur. Conf. Comput. Vision, pp. 21-37; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detectionwith region proposal networks (2015) Proc. Advances Neural Inf. Process. Syst., pp. 91-99; Howard, A.G., MobileNets: Efficient convolutional neural networks for mobile vision applications (2017) CoRR; Lin, T.-Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie, S., Feature pyramid networks for object detection (2017) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 2117-2125","Singh, P.; Department of Computer Science and Engineering, India; email: psingh@cse.iitk.ac.in",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,19324553,,,,"English","IEEE J. Sel. Top. Sign. Proces.",Article,"Final","",Scopus,2-s2.0-85089953123
"Xue T., Wang Z.-W., Zhang T., Bai O., Zhang M., Han B.","57615916300;57190881030;55547106760;57205912472;57208209572;54788899500;","Fixed-time constrained acceleration reconstruction scheme for robotic exoskeleton via neural networks",2020,"Frontiers of Information Technology and Electronic Engineering","21","5",,"705","722",,2,"10.1631/FITEE.1900418","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085182866&doi=10.1631%2fFITEE.1900418&partnerID=40&md5=d8474092a0a7dddcc82bfe3761ce725d","Department of Automation, Tsinghua University, Beijing, 100084, China; Department of Electrical and Computer Engineering, Florida International University, Miami, 33174, United States; Move Robotics Technology Co., Ltd., Shanghai, 201306, China; School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China","Xue, T., Department of Automation, Tsinghua University, Beijing, 100084, China; Wang, Z.-W., Department of Automation, Tsinghua University, Beijing, 100084, China; Zhang, T., Department of Automation, Tsinghua University, Beijing, 100084, China; Bai, O., Department of Electrical and Computer Engineering, Florida International University, Miami, 33174, United States; Zhang, M., Department of Automation, Tsinghua University, Beijing, 100084, China, Move Robotics Technology Co., Ltd., Shanghai, 201306, China; Han, B., School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China","Accurate acceleration acquisition is a critical issue in the robotic exoskeleton system, but it is difficult to directly obtain the acceleration via the existing sensing systems. The existing algorithm-based acceleration acquisition methods put more attention on finite-time convergence and disturbance suppression but ignore the error constraint and initial state irrelevant techniques. To this end, a novel radical bias function neural network (RBFNN) based fixed-time reconstruction scheme with error constraints is designed to realize high-performance acceleration estimation. In this scheme, a novel exponential-type barrier Lyapunov function is proposed to handle the error constraints. It also provides a unified and concise Lyapunov stability-proof template for constrained and non-constrained systems. Moreover, a fractional power sliding mode control law is designed to realize fixed-time convergence, where the convergence time is irrelevant to initial states or external disturbance, and depends only on the chosen parameters. To further enhance observer robustness, an RBFNN with the adaptive weight matrix is proposed to approximate and attenuate the completely unknown disturbances. Numerical simulation and human subject experimental results validate the unique properties and practical robustness. © 2020, Zhejiang University and Springer-Verlag GmbH Germany, part of Springer Nature.","Acceleration reconstruction; Barrier Lyapunov function; Constrained control; Fixed-time convergence; Initial state irrelevant technique; Robotic exoskeleton; TP242","Acceleration; Errors; Lyapunov functions; Sliding mode control; Disturbance suppression; Error constraints; External disturbances; Finite-time convergence; Lyapunov stability; Performance acceleration; Robotic exoskeletons; Unknown disturbance; Exoskeleton (Robotics)",,,,,"National Natural Science Foundation of China, NSFC: 51705163","Project supported by the Move Robotics Technology Co., Ltd. and the National Natural Science Foundation of China (No. 51705163)",,,,,,,,,,"Abooee, A., Moravej Khorasani, M., Haeri, M., Finite time control of robotic manipulators with position output feedback (2017) Int J Robust Nonl Contr, 27 (16), pp. 2982-2999; Aguirre-Ollinger, G., Colgate, J.E., Peshkin, M.A., Active-impedance control of a lower-limb assistive exoskeleton (2007) 10th Int Conf on Rehabilitation Robotics, pp. 188-195. , https://doi.org/10.1109/icorr.2007.4428426; Chen, Q., Cheng, H., Yue, C., Dynamic balance gait for walking assistance exoskeleton (2018) Appl Bion Biomech, 2018, p. 7847014; Chen, S., Chen, Z., Yao, B., Adaptive robust cascade force control of 1-DOF hydraulic exoskeleton for human performance augmentation (2017) IEEE/ASME Trans Mech, 22 (2), pp. 589-600; Dong, T.Y., Zhang, X.L., Liu, T., Artificial muscles for wearable assistance and rehabilitation (2018) Front Inform Technol Electron Eng, 19 (11), pp. 1303-1315; Fei, J., Ding, H., Adaptive sliding mode control of dynamic system using RBF neural network (2012) Nonl Dynam, 70 (2), pp. 1563-1573; He, S., Lin, D., Reliable spacecraft rendezvous without velocity measurement (2018) Acta Astron, 144, pp. 52-60; He, Y., Li, N., Wang, C., Development of a novel autonomous lower extremity exoskeleton robot for walking assistance (2019) Front Inform Technol Electron Eng, 20 (3), pp. 318-329; Hua, C.C., Yang, Y., Guan, X., Neural network-based adaptive position tracking control for bilateral teleoperation under constant time delay (2013) Neurocomputing, 113, pp. 204-212; Huo, W.G., Mohammed, S., Amirat, Y., Active impedance control of a lower limb exoskeleton to assist sit-to-stand movement (2016) Proc IEEE Int Conf on Robotics and Automation, pp. 3530-3536. , https://doi.org/10.1109/ICRA.2016.7487534; Kang, I., Hsu, H., Young, A., The effect of hip assistance levels on human energetic cost using robotic hip exoskeletons (2019) IEEE Robot Autom Lett, 4 (2), pp. 430-437; Kazerooni, H., Racine, J., Huang, L.H., On the control of the Berkeley lower extremity exoskeleton (BLEEX) (2005) Proc IEEE Int Conf on Robotics and Automation, P, pp. 4353-4360. , https://doi.org/10.1109/ROBOT.2005.1570790; Kim, H., Shin, Y.J., Kim, J., Design and locomotion control of a hydraulic lower extremity exoskeleton for mobility augmentation (2017) Mechatronics, 46, pp. 32-45; Kim, J., Heimgartner, R., Lee, G., Autonomous and portable soft exosuit for hip extension assistance with online walking and running detection algorithm (2018) Proc IEEE Int Con on Robotics and Automation, P, pp. 5473-5480. , https://doi.org/10.1109/ICRA.2018.8460474; Kim, J., Lee, G., Heimgartner, R., Reducing the metabolic rate of walking and running with a versatile, portable exosuit (2019) Science, 365 (6454), pp. 668-672; Kuo, C.H., Yudha, A.P., Mohapatra, S.K., Force sensorless compliance control of a lower-limb exoskeleton robot (2018) Int J Autom Smart Technol, 8 (1), pp. 51-60; Li, S., Yang, J., Chen, W.H., Generalized extended state observer based control for systems with mismatched uncertainties (2011) IEEE Trans Ind Electron, 59 (12), pp. 4792-4802; Long, Y., Du, Z.J., Wang, W.D., Physical humanrobot interaction estimation based control scheme for a hydraulically actuated exoskeleton designed for power amplification (2018) Front Inform Technol Electron Eng, 19 (9), pp. 1076-1085; Luenberger, D., Observers for multivariable systems (1966) IEEE Trans Autom Contr, 11 (2), pp. 190-197; Nagarajan, U., Aguirre-Ollinger, G., Goswami, A., Integral admittance shaping: a unified framework for active exoskeleton control (2016) Robot Auton Syst, 75, pp. 310-324; Polyakov, A., Nonlinear feedback design for fixed-time stabilization of linear control systems (2011) IEEE Trans Autom Contr, 57 (8), pp. 2106-2110; Seo, K., Kim, K., Park, Y.J., Adaptive oscillator-based control for active lower-limb exoskeleton and its metabolic impact (2018) Proc IEEE Int Conf on Robotics and Automation, pp. 6752-6758. , https://doi.org/10.1109/ICRA.2018.8460841; Shtessel, Y., Edwards, C., Fridman, L., (2014) Sliding Mode Control and Observation, , Springer, Berlin, Germany; Tan, C.P., Yu, X., Man, Z., Terminal sliding mode observers for a class of nonlinear systems (2010) Automatica, 46 (8), pp. 1401-1404; Tanghe, K., Aertbeliën, E., Vantilt, J., Realtime delayless estimation of derivatives of noisy sensor signals for quasi-cyclic motions with application to joint acceleration estimation on an exoskeleton (2018) IEEE Robot Autom Lett, 3 (3), pp. 1647-1654; Wang, Z.W., Liang, B., Wang, X.Q., Chattering-free fixed-time control for bilateral teleoperation system with jittering time delays and state constraints (2018) IFAC, 51 (32), pp. 588-593; Wang, Z.W., Chen, Z., Zhang, Y.M., Adaptive finite-time control for bilateral teleoperation systems with jittering time delays (2019) Int J Robust Nonl Contr, 29 (4), pp. 1007-1030; Wang, Z.W., Chen, Z., Liang, B., Fixed-time velocity reconstruction scheme for space teleoperation systems: exp barrier Lyapunov function approach (2019) Acta Astron, 157, pp. 92-101; Xiao, B., Yin, S., Velocity-free fault-tolerant and uncertainty attenuation control for a class of nonlinear systems (2016) IEEE Trans Ind Electr, 63 (7), pp. 4400-4411; Xue, T., Wang, Z., Zhang, T., The control system for flexible hip assistive exoskeleton (2018) Proc IEEE Int Conf on Robotics and Biomimetics, P, pp. 697-702. , https://doi.org/10.1109/ROBIO.2018.8665203; Xue, T., Wang, Z., Zhang, T., Adaptive oscillator-based robust control for flexible hip assistive exoskeleton (2019) IEEE Robot Autom Lett, 4 (4), pp. 3318-3323; Yang, Y., Hua, C.C., Li, J.P., Finite-time outputfeedback synchronization control for bilateral teleoperation system via neural networks (2017) Inform Sci, 406, pp. 216-233; Yang, Z.Y., Gu, W.J., Zhang, J., (2017) Force Control Theory and Method of Human Load Carrying Exoskeleton Suit, , Springer, Berlin, Germany; Zhang, T., Tran, M., Huang, H., Admittance shaping-based assistive control of SEA-driven robotic hip exoskeleton (2019) IEEE/ASME Trans Mech, 24 (4), pp. 1508-1519; Zhu, Z., Xia, Y., Fu, M., Attitude stabilization of rigid spacecraft with finite-time convergence (2011) Int J Robust Nonl Contr, 21 (6), pp. 686-702; Zoss, A.B., Kazerooni, H., Chu, A., Biomechanical design of the Berkeley lower extremity exoskeleton (BLEEX) (2006) IEEE/ASME Trans Mech, 11 (2), pp. 128-138","Zhang, T.; Department of Automation, China; email: taozhang@tsinghua.edu.cn",,,"Zhejiang University",,,,,20959184,,,,"English","Front. Inf. Technol. Electr. Eng.",Article,"Final","",Scopus,2-s2.0-85085182866
"Taspinar Y.S., Selek M.","57219157067;24438288600;","Object recognition with hybrid deep learning methods and testing on embedded systems",2020,"International Journal of Intelligent Systems and Applications in Engineering","8","2",,"71","77",,3,"10.18201/ijisae.2020261587","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091510582&doi=10.18201%2fijisae.2020261587&partnerID=40&md5=3215770bfc50d75ba13db3a522e717d9","Doganhisar Vocational School, Selcuk University, Turkey; Vocational School of Technical Sciences, Konya Technical University, Turkey","Taspinar, Y.S., Doganhisar Vocational School, Selcuk University, Turkey; Selek, M., Vocational School of Technical Sciences, Konya Technical University, Turkey","Object recognition applications can be made with deep neural networks. However, this process may require intensive processing load. For this purpose, hybrid object recognition algorithms that can be created for the recognition of an object in the image and the comparison of the working time of these algorithms on various embedded systems are emphasized. While Haar Cascade, Local Binary Pattern (LBP) and Histogram Oriented Gradients (HOG) algorithms are used for object detection, Convolutional Neural Network (CNN) and Deep Neural Network (DNN) algorithms are used for classification. As a result, six hybrid structures such as Haar Cascade+CNN, LBP+CNN, HOG+CNN and Haar Cascade+DNN, LBP+DNN, HOG+DNN are developed. In this study, these 6 hybrid algorithms were analyzed in terms of success percentage and time, then compared with each other. Microsoft COCO dataset was used to train and test all these hybrid algorithms. Object recognition success of CNN was 76.33%. Object recognition success of Haar Cascade+CNN, one of the hybrid methods we recommend, with a success rate of 78.6% is higher than CNN and other hybrid methods. LBP+CNN method recognized objects in 0.487 seconds which is faster than any other hybrid methods. In our study, Nvidia Jetson TX2, Asus TinkerBoard, Raspbbery Pi 3 B+ were used as embedded systems. As a result of these tests, Haar Cascade+CNN method on Nvidia Jetson TX2 was detected in 0.1303 seconds, LBP+DNN and Haar Cascade+DNN methods on Asus Tinker Board were detected in 0.2459 seconds, and HOG+DNN method on Raspberry Pi 3 B+ was detected in 0.7153 seconds.. © 2020, Ismail Saritas. All rights reserved.","Deep learning; Hybrid methods; Image classification; Object detection",,,,,,"17101015","This work was supported by Selcuk University Scientific Research Programs Coordination project number 17101015.",,,,,,,,,,"Viola, P., Jones, M., Rapid object detection using a boosted cascade of simple features (2001) Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on, 1, p. I. , I). IEEE; Cevikalp, H., Triggs, B., Visual object detection using cascades of binary and one-class classifiers (2017) International Journal of Computer Vision, 123 (3), pp. 334-349; Dehghani, A., Moloney, D., Speed improvement of object recognition using boundary-bitmap of histogram of oriented gradients (2016) Image, Vision and Computing (ICIVC), International Conference on, pp. 51-56. , (August) IEEE; Reschke, J., Sehr, A., (2017) Face Recognition with Machine Learning in OpenCV_ Fusion of the results with the Localization Data of an Acoustic Camera for Speaker Identification, , arXiv preprint arXiv:1707.00835; Utaminingrum, F., Praetya, R. P., Sari, Y. A., Image Processing for Rapidly Eye Detection based on Robust Haar Sliding Window (2017) International Journal of Electrical and Computer Engineering (IJECE), 7 (2), pp. 823-830; Yadav, Y., Walavalkar, R., Yedurkar, A., Suchak, S., Gharat, S., (2017) Street Light Intensity Controller Using Density Mapping Mechanism; Lee, D., Kim, D., Lee, J., Lee, S., Hwang, H., Mariappan, V., Cha, J., Design of Low Cost Real-Time Audience Adaptive Digital Signage using Haar Cascade Facial Measures (2017) International Journal of Advanced Culture Technology (IJACT), 5 (1), pp. 51-57; Kim, J., Yu, S., Kim, D., Toh, K. A., Lee, S., An adaptive local binary pattern for 3D hand tracking (2017) Pattern Recognition, 61, pp. 139-152; Karczmarek, P., Kiersztyn, A., Pedrycz, W., Dolecki, M., An application of chain code-based local descriptor and its extension to face recognition (2017) Pattern Recognition, 65, pp. 26-34; Wasim, M., Aziz, A., Ali, S. F., Siddiqui, A. A., Ahmed, L., Saeed, F., Object‘s Shape Recognition using Local Binary Patterns (2017) INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS, 8 (8), pp. 258-262; Liu, L., Lao, S., Fieguth, P. W., Guo, Y., Wang, X., Pietikäinen, M., Median robust extended local binary pattern for texture classification (2016) IEEE Transactions on Image Processing, 25 (3), pp. 1368-1381; Tian, S., Bhattacharya, U., Lu, S., Su, B., Wang, Q., Wei, X., Tan, C. L., Multilingual scene character recognition with co-occurrence of histogram of oriented gradients (2016) Pattern Recognition, 51, pp. 125-134; Lawgali, A., (2016) Recognition of Handwritten Digits using Histogram of Oriented Gradients; Chowdhury, S. A., Uddin, M. N., Kowsar, M. M. S., Deb, K., Occlusion handling and human detection based on Histogram of Oriented Gradients for automatic video surveillance (2016) Innovations in Science, Engineering and Technology (ICISET), International Conference on, pp. 1-4. , (October) IEEE; Tanısık, G., Aselsan, A. S., Güçlü, O., Ikizler-Cinbis, N., Bölüt ve Kontur Özniteliklerini Kullanarak ImgelerdekiInsan Hareketlerini Tanıma Recognizing Human Actions in Images Using Segment and Contour Features; Sharifara, A., Rahim, M. S. M., Anisi, Y., A general review of human face detection including a study of neural networks and Haar feature-based cascade classifier in face detection (2014) Biometrics and Security Technologies (ISBAST), 2014 International Symposium on, pp. 73-78. , (August) IEEE; Goerick, C., Noll, D., Werner, M., Artificial neural networks in real-time car detection and tracking applications (1996) Pattern Recognition Letters, 17 (4), pp. 335-343; Krizhevsky, A., Sutskever, I., Hinton, G. E., Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, pp. 1097-1105; Başer, E., Altun, Y., Classification of vehicles in traffic and detection faulty vehicles by using ANN techniques (2017) Electric Electronics, Computer Science, Biomedical Engineerings' Meeting (EBBT), pp. 1-4. , (2017, April) IEEE; Yang, A., Yang, X., Wu, W., Liu, H., Zhuansun, Y., Research on feature extraction of tumor image based on convolutional neural network (2019) IEEE Access, 7, pp. 24204-24213; Passricha, V., Aggarwal, R. K., A hybrid of deep CNN and bidirectional LSTM for automatic speech recognition (2019) Journal of Intelligent Systems, 29 (1), pp. 1261-1274; Lv, Y., Duan, Y., Kang, W., Li, Z., Wang, F. Y., Traffic flow prediction with big data: A deep learning approach (2015) IEEE Trans. Intelligent Transportation Systems, 16 (2), pp. 865-873; Jin, Z., Iqbal, M. Z., Bobkov, D., Zou, W., Li, X., Steinbach, E., A flexible deep CNN framework for image restoration (2019) IEEE Transactions on Multimedia; Yang, W. J., Su, Y. S., Chung, P. C., Yang, J. F., Moving Object Detection Using Histogram of Uniformly Oriented Gradient (2017) World Academy of Science, Engineering and Technology, International Journal of Computer, Electrical, Automation, Control and Information Engineering, 11 (6), pp. 649-653; Kushwaha, A. K. S., Srivastava, S., Srivastava, R., Multi-view human activity recognition based on silhouette and uniform rotation invariant local binary patterns (2017) Multimedia Systems, 23 (4), pp. 451-467; Muthevi, A., Uppu, R. B., Leaf classification using completed local binary pattern of textures (2017) Advance Computing Conference (IACC), 2017 IEEE 7th International, pp. 870-874. , (January) IEEE; Sharifara, A., Rahim, M. S. M., Anisi, Y., A general review of human face detection including a study of neural networks and Haar feature-based cascade classifier in face detection (2014) Biometrics and Security Technologies (ISBAST), 2014 International Symposium on, pp. 73-78. , (August) IEEE; He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask r-cnn (2017) Computer Vision (ICCV), 2017 IEEE International Conference on, pp. 2980-2988. , (October) IEEE; Julina, J. K. J., Sharmila, T. S., Facial recognition using histogram of gradients and support vector machines (2017) 2017 International Conference on Computer, Communication and Signal Processing (ICCCSP), pp. 1-5. , (January) IEEE; Gkioxari, G., Girshick, R., Malik, J., Contextual action recognition with r* cnn (2015) Proceedings of the IEEE international conference on computer vision, pp. 1080-1088; Lu, M., Hu, Y., Lu, X., Driver action recognition using deformable and dilated faster R-CNN with optimized region proposals (2020) Applied Intelligence, 50 (4), pp. 1100-1111; Guo, S., Huang, W., Wang, L., Qiao, Y., Locally supervised deep hybrid model for scene recognition (2017) IEEE transactions on image processing, 26 (2), pp. 808-820; Lin, T. Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Zitnick, C. L., Microsoft coco: Common objects in context (2014) European conference on computer vision, pp. 740-755. , (September) Springer, Cham; Viola, P., Jones, M., Rapid object detection using a boosted cascade of simple features (2001) Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on, 1, p. I. , I). IEEE; Papageorgiou, C. P., Oren, M., Poggio, T., A general framework for object detection (1998) Computer vision, 1998. sixth international conference on, pp. 555-562. , (January) IEEE; Ojala, T., Pietikäinen, M., Harwood, D., A comparative study of texture measures with classification based on featured distributions (1996) Pattern recognition, 29 (1), pp. 51-59; Günay, A., Nabiyev, V. V., LBP Yardimiyla Görüntüdeki Kişinin Yaşinin Bulunmasi (2011) Çankaya University Journal of Science and Engineering, 8 (1), pp. 27-41; Shashua, A., Gdalyahu, Y., Hayun, G., Pedestrian detection for driving assistance systems: Single-frame classification and system level performance (2004) Intelligent Vehicles Symposium, 2004 IEEE, pp. 1-6. , (June) IEEE; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, 1, pp. 886-893. , (June) IEEE; Kim, S., Cho, K., Fast Calculation of Histogram of Oriented Gradient Feature by Removing Redundancy in Overlapping Block (2014) J. Inf. Sci. Eng, 30 (6), pp. 1719-1731; Krizhevsky, A., Sutskever, I., Hinton, G. E., Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, pp. 1097-1105; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition, , arXiv preprint arXiv:1409.1556; Szegedy, C., Toshev, A., Erhan, D., Deep neural networks for object detection (2013) Advances in neural information processing systems, pp. 2553-2561; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Kudlur, M., Tensorflow: A system for large-scale machine learning (2016) 12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16), pp. 265-283","Taspinar, Y.S.; Doganhisar Vocational School, Turkey; email: ytaspinar@selcuk.edu.tr",,,"Ismail Saritas",,,,,21476799,,,,"English","Internat. J. Intel. Syst. Appl. Eng.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85091510582
"Sigcha L., Costa N., Pavón I., Costa S., Arezes P., López J.M., De Arcas G.","57197813593;24490609700;19337337900;56374324800;57197814099;24776160300;16401639400;","Deep learning approaches for detecting freezing of gait in parkinson’s disease patients through on-body acceleration sensors",2020,"Sensors (Switzerland)","20","7","1895","","",,26,"10.3390/s20071895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082790799&doi=10.3390%2fs20071895&partnerID=40&md5=1738bd9030764d6506b3d15dd5f29404","Grupo de Investigación en Instrumentación y Acústica Aplicada (I2A2), ETSI Industriales, Universidad Politécnica de Madrid, Campus Sur UPM, Ctra. Valencia, Km 7., Madrid, 28031, Spain; ALGORITMI Research Center, School of Engineering, University of Minho, Guimaraes, 4800-058, Portugal","Sigcha, L., Grupo de Investigación en Instrumentación y Acústica Aplicada (I2A2), ETSI Industriales, Universidad Politécnica de Madrid, Campus Sur UPM, Ctra. Valencia, Km 7., Madrid, 28031, Spain, ALGORITMI Research Center, School of Engineering, University of Minho, Guimaraes, 4800-058, Portugal; Costa, N., ALGORITMI Research Center, School of Engineering, University of Minho, Guimaraes, 4800-058, Portugal; Pavón, I., Grupo de Investigación en Instrumentación y Acústica Aplicada (I2A2), ETSI Industriales, Universidad Politécnica de Madrid, Campus Sur UPM, Ctra. Valencia, Km 7., Madrid, 28031, Spain; Costa, S., ALGORITMI Research Center, School of Engineering, University of Minho, Guimaraes, 4800-058, Portugal; Arezes, P., ALGORITMI Research Center, School of Engineering, University of Minho, Guimaraes, 4800-058, Portugal; López, J.M., Grupo de Investigación en Instrumentación y Acústica Aplicada (I2A2), ETSI Industriales, Universidad Politécnica de Madrid, Campus Sur UPM, Ctra. Valencia, Km 7., Madrid, 28031, Spain; De Arcas, G., Grupo de Investigación en Instrumentación y Acústica Aplicada (I2A2), ETSI Industriales, Universidad Politécnica de Madrid, Campus Sur UPM, Ctra. Valencia, Km 7., Madrid, 28031, Spain","Freezing of gait (FOG) is one of the most incapacitating motor symptoms in Parkinson’s disease (PD). The occurrence of FOG reduces the patients’ quality of live and leads to falls. FOG assessment has usually been made through questionnaires, however, this method can be subjective and could not provide an accurate representation of the severity of this symptom. The use of sensor-based systems can provide accurate and objective information to track the symptoms’ evolution to optimize PD management and treatments. Several authors have proposed specific methods based on wearables and the analysis of inertial signals to detect FOG in laboratory conditions, however, its performance is usually lower when being used at patients’ homes. This study presents a new approach based on a recurrent neural network (RNN) and a single waist-worn triaxial accelerometer to enhance the FOG detection performance to be used in real home-environments. Also, several machine and deep learning approaches for FOG detection are evaluated using a leave-one-subject-out (LOSO) cross-validation. Results show that modeling spectral information of adjacent windows through an RNN can bring a significant improvement in the performance of FOG detection without increasing the length of the analysis window (required to using it as a cue-system). © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Accelerometer; Consecutive windows; Convolutional neural networks; Denoising autoencoder; IMU; LSTM; Spectral representation; Time distributed","Accelerometers; Convolutional neural networks; Freezing; Information management; Learning systems; Long short-term memory; Signal analysis; Surveys; Auto encoders; Laboratory conditions; LSTM; Objective information; Recurrent neural network (RNN); Spectral representations; Time distributed; Triaxial accelerometer; Deep learning; accelerometry; aged; electronic device; female; gait; genetic procedures; human; male; Parkinson disease; pathophysiology; physiologic monitoring; physiology; procedures; signal processing; very elderly; Accelerometry; Aged; Aged, 80 and over; Biosensing Techniques; Deep Learning; Female; Gait; Humans; Male; Monitoring, Physiologic; Parkinson Disease; Signal Processing, Computer-Assisted; Wearable Electronic Devices",,,,,"I2A2; SecretarÃ­a de EducaciÃ³n Superior, Ciencia, TecnologÃ­a e InnovaciÃ³n, SENESCYT; Universidad AutÃ³noma de Madrid, UAM; Instituto Nacional de Ciência e Tecnologia para Excitotoxicidade e Neuroproteção, INCT-EN: UIDB/00319/2020; Fundació Catalana de Trasplantament, FCT","Funding: This research was funded by the following projects: (1) “Tecnologías Capacitadoras para la Asistencia, Seguimiento y Rehabilitación de Pacientes con Enfermedad de Parkinson”. Centro Internacional sobre el envejecimiento, CENIE (código 0348_CIE_6_E) Interreg V-A España-Portugal (POCTEP). (2) Ecuadorian Government Granth “Becas internacionales de posgrado 2019” of the Secretaría de Educación Superior, Ciencia, Tecnología e Innovación (SENESCYT), received by the author Luis Sigcha.","Acknowledgments: This work has been supported by: (1) FCT—Fundação para a Ciência e Tecnologia within the R&D Units Project Scope: UIDB/00319/2020. (2) Grupo de Investigación en Instrumentación y Acústica Aplicada (I2A2). ETSI Industriales. Universidad Politécnica de Madrid. The authors would like to thank Technical Research Centre for Dependency Care and Autonomous Living (CETpD) for sharing the data of freezing of gait.","This research was funded by the following projects: (1) ?Tecnolog?as Capacitadoras para la Asistencia, Seguimiento y Rehabilitaci?n de Pacientes con Enfermedad de Parkinson?. Centro Internacional sobre el envejecimiento, CENIE (c?digo 0348_CIE_6_E) Interreg V-A Espa?a-Portugal (POCTEP). (2) Ecuadorian Government Granth ?Becas internacionales de posgrado 2019? of the Secretar?a de Educaci?n Superior, Ciencia, Tecnolog?a e Innovaci?n (SENESCYT), received by the author Luis Sigcha. This work has been supported by: (1) FCT?Funda??o para a Ci?ncia e Tecnologia within the R&D Units Project Scope: UIDB/00319/2020. (2) Grupo de Investigaci?n en Instrumentaci?n y Ac?stica Aplicada (I2A2). ETSI Industriales. Universidad Polit?cnica de Madrid. The authors would like to thank Technical Research Centre for Dependency Care and Autonomous Living (CETpD) for sharing the data of freezing of gait.",,,,,,,,"Chen, S., Tsai, S., The Epidemiology of Parkinson’s Disease (2010) Tzu. Chi Med. J., 22, pp. 73-81; Goetz, C.G., The history of Parkinson’s disease: Early clinical descriptions and neurological therapies (2011) Cold Spring Harb. Perspect Med., 1; Wirdefeldt, K., Adami, H., Cole, P., Trichopoulos, D., Mandel, J., Epidemiology and etiology of Parkinson’s disease: A review of the evidence (2011) Eur. J. Epidemiol., 26, pp. 1-58; Michel, P., Hirsch, E., Hunot, S., Understanding Dopaminergic Cell Death Pathways in Parkinson Disease (2016) Neuron, 90, pp. 675-691; (2007) Neurological Disorders: Public Health Challenges, Scitech Book News; World Health Organizatio, p. 31. , Geneva, Switzerland; Sveinbjornsdottir, S., The clinical symptoms of Parkinson’s disease (2016) J. Neurochem., 139, pp. 318-324; Understanding Parkinson’s., , https://www.parkinson.org/Understanding-Parkinsons/Statistics, Available online: , (accessed on 12 December 2019); Reeve, A., Simcox, E., Turnbull, D., Ageing and Parkinson’s disease: Why is advancing age the biggest risk factor? (2014) Ageing Res. Rev., 14, pp. 19-30; Giladi, N., Treves, T.A., Simon, E.S., Shabtai, H., Orlov, Y., Kandinov, B., Paleacu, D., Korczyn, A.D., Freezing of gait in patients with advanced Parkinson’s disease (2001) J. Neural. Transm., 108, pp. 53-61; Okuma, Y., Yanagisawa, N., The clinical spectrum of freezing of gait in Parkinson’s disease (2008) Mov. Disord, 23, p. 426; Giladi, N., Freezing of gait (2001) Clinical Overview. Adv. Neurol, 87, pp. 191-197; Fahn, S., The freezing phenomenon in parkinsonism (1995) Adv. Neurol, 67, pp. 53-63; Schaafsma, J.D., Balash, Y., Gurevich, T., Bartels, A.L., Hausdorff, J.M., Giladi, N., Characterization of freezing of gait subtypes and the response of each to levodopa in Parkinson’s disease (2003) Eur. J. Neurol., 10, pp. 391-398; Moore, S.T., Macdougall, H.G., Ondo, W.G., Ambulatory monitoring of freezing of gait in Parkinson’s disease (2008) J. Neurosci. Methods, 167, pp. 340-348; Ahlrichs, C., Samà, A., Lawo, M., Cabestany, J., Rodríguez-Martín, D., Pérez-López, C., Sweeney, D., Counihan, T., Detecting freezing of gait with a tri-axial accelerometer in Parkinson’s disease patients (2016) Med. Biol. Eng. Comput, 54, pp. 223-233; Kim, H., Lee, H.J., Lee, W., Kwon, S., Kim, S.K., Jeon, H.S., Park, H., Jeon, B.S., Unconstrained detection of freezing of Gait in Parkinson’s disease patients using smartphone Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBS), , Milano, Italy, 25–29 August 2015; Latt, M.D., Lord, S.R., Morris, J.G.L., Fung, V.S.C., Clinical and physiological assessments for elucidating falls risk in Parkinson’s disease (2009) Mov. Disord., 24, pp. 1280-1289; Kerr, G.K., Worringham, C.J., Cole, M.H., Lacherez, P.F., Wood, J.M., Silburn, P.A., Predictors of future falls in Parkinson disease (2010) Neurology, 75, pp. 116-124; Moore, O., Peretz, C., Giladi, N., Freezing of gait affects quality of life of peoples with Parkinson’s disease beyond its relationships with mobility and gait (2007) Mov. Disord., 22, pp. 2192-2195; Okuma, Y., Freezing of gait and falls in Parkinson’s disease (2014) J. Parkinsons Dis., 4, pp. 255-260; Nutt, J.G., Bloem, B.R., Giladi, N., Hallett, M., Horak, F.B., Nieuwboer, A., Freezing of gait: Moving forward on a mysterious clinical phenomenon (2011) Lancet Neurol, 10, pp. 734-744; Giladi, N., Shabtai, H., Simon, E.S., Biran, S., Tal, J., Korczyn, A.D., Construction of freezing of gait questionnaire for patients with Parkinsonism (2000) Parkinsonism Relat. Disord, 6, pp. 165-170; Giladi, N., Tal, J., Azulay, T., Rascol, O., Brooks, D.J., Melamed, E., Oertel, W., Tolosa, E., Validation of the freezing of gait questionnaire in patients with Parkinson’s disease (2009) Mov. Disord., 24, pp. 655-661; Nieuwboer, A., Rochester, L., Herman, T., Vandenberghe, W., Emil, G.E., Thomaes, T., Giladi, N., Reliability of the new freezing of gait questionnaire: Agreement between patients with Parkinson’s disease and their careers (2009) Gait Posture, 30, pp. 459-463; Nieuwboer, A., Weerdt, W.D., Dom, R., Lesaffre, E., A frequency and correlation analysis of motor deficits in Parkinson patients (1998) Disabil. Rehabil., 20, pp. 142-150; Sazonov, E., Neuman, M.R., (2014) Wearable Sensors: Fundamentals, Implementation and Applications, , Elsevier: Amsterdam, The Netherlands; Page, T., A Forecast of the Adoption of Wearable Technology Int. J. Technol. Diffus. 2015, 6, pp. 12-29; Lara, O.D., Labrador, M.A., A Survey on Human Activity Recognition using Wearable Sensors (2013) IEEE Commun. Surv. Tutor., 15, pp. 1192-1209; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Hassan, M., Huda, S., Uddin, M., Almogren, A., Alrubaian, M., Human Activity Recognition from Body Sensor Data using Deep Learning (2018) J. Med. Syst, 42, pp. 1-8; Nweke, H.F., Teh, Y.W., Al-Garadi, M., Alo, U.R., Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: State of the art and research challenges (2018) Expert Syst. Appl., 105, pp. 233-261; Yang, J.B., Nguyen, M.N., San, P.P., Li, X.L., Krishnaswamy, S., Deep Convolutional Neural Networks on Multichannel Time Series for Human Activity Recognition, pp. 3995-4001. , Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI), Buenos Aires, Argentina, 25–31 July 2015; Wang, J., Chen, Y., Hao, S., Peng, X., Hu, L., Deep learning for sensor-based activity recognition: A survey (2019) Pattern Recog. Lett, 119, pp. 3-11; Ordóñez, F.J., Roggen, D., Deep convolutional and LSTM recurrent neural networks for multimodal wearable activity recognition (2016) Sensors, 16, p. 115; Kubota, K.J., Chen, J.A., Little, M.A., Machine learning for large-scale wearable sensor data in Parkinson’s disease: Concepts, promises, pitfalls, and futures (2016) Mov. Disord., 31, pp. 1314-1326; Matias, R., Paixão, V., Bouça, R., Ferreira, J.J., A Perspective on Wearable Sensor Measurements and Data Science for Parkinson’s Disease (2017) Front. Neurol., 8, p. 677; Linares-Del Rey, M., Vela-Desojo, L., Cano-De, L.C., Aplicaciones móviles en la enfermedad de Parkinson: Una revisión sistemática (2019) Neurología, 34, pp. 38-54; Maetzler, W., Klucken, J., Horne, M., A clinical view on the development of technology-based tools in managing Parkinson’s disease (2016) Mov. Disord., 31, pp. 1263-1271; Sánchez-Ferro, Á., Elshehabi, M., Godinho, C., Salkovic, D., Hobert, M.A., Domingos, J., van Uem, J.M., Maetzler, W., New methods for the assessment of Parkinson’s disease (2005 to 2015): A systematic review (2016) Mov. Disord., 31, pp. 1283-1292; Maetzler, W., Domingos, J., Srulijes, K., Ferreira, J.J., Bloem, B.R., Quantitative wearable sensors for objective assessment of Parkinson’s disease (2013) Mov. Disord., 28, pp. 1628-1637; Lim, I., van Wegen, E., de Goede, C., Deutekom, M., Nieuwboer, A., Willems, A., Jones, D., Kwakkel, G., Effects of external rhythmical cueing on gait in patients with Parkinson’s disease: A systematic review (2005) Clin. Rehabil., 19, pp. 695-713; Rocha, P.A., Porfírio, G.M., Ferraz, H.B., Trevisani, V.F.M., Effects of external cues on gait parameters of Parkinson’s disease patients: A systematic review (2014) Clin. Neurol. Neurosurg., 124, pp. 127-134; Arias, P., Cudeiro, J., Effect of Rhythmic Auditory Stimulation on Gait in Parkinsonian Patients with and without Freezing of Gait (2010) Plos ONE, 5; Mazilu, S., Hardegger, M., Zhu, Z., Roggen, D., Tröster, G., Plotnik, M., Hausdorff, J., (2012) Online Detection of Freezing of Gait with Smartphones and Machine Learning Techniques., , In Proceedings of the 6th International Conference on Pervasive Computing Technologies for Healthcare, San Diego, CA, USA, 21–24 May; Md, Z.A., Taha, T.M., Yakopcic, C., Westberg, S., Sidike, P., Mst, S.N., Hasan, M., Asari, V.K., A State-of-the-Art Survey on Deep Learning Theory and Architectures (2019) Electronics, 8, p. 292; Bengio, Y., Courville, A., Vincent, P., Representation Learning: A Review and New Perspectives (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35, pp. 1798-1828; Li, F., Shirahama, K., Nisar, M.A., Köping, L., Grzegorzek, M., Comparison of Feature Learning Methods for Human Activity Recognition Using Wearable Sensors (2018) Sensors, 18, p. 679; Lecun, Y., Bengio, Y., Convolutional Networks for Images, Speech, and Time Series (1998) The Handbook of Brain Theory and Neural Networks, pp. 255-258. , MIT Press: Cambridge, MA, USA; Pascanu, R., Gulcehre, C., Cho, K., Bengio, Y., How to Construct Deep Recurrent Neural Networks Arxiv 2013, Arxiv; Karim, F., Majumdar, S., Darabi, H., Chen, S., LSTM Fully Convolutional Networks for Time Series Classification (2018) IEEE Access, 6, pp. 1662-1669; Hochreiter, S., Schmidhuber, J., Long Short-Term Memory (1997) Neural. Comput, 9, pp. 1735-1780; San-Segundo, R., Montero, J.M., Barra-Chicote, R., Fernández, F., Pardo, J.M., Feature extraction from smartphone inertial signals for human activity segmentation (2016) Signal. Process., 120, pp. 359-372; Smith, S.W., (2003) Digital Signal. Processing: A Practical Guide for Engineers and Scientists, , Newnes: Amsterdam, The Netherlands; Breiman, L.R.F., (2001) Mach. Learn, 45, pp. 5-32; Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P., Stacked denoising autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion (2010) J. Mach. Learn. Res, 11, pp. 3371-3408; Scholkopf, B., Williamson, R.C., Smola, A.J., Shawe-Taylor, J., Platt, J.C., Support Vector Method for Novelty Detection (2000) Advances in Neural Information Processing Systems 12, pp. 582-588. , Solla, S.A., Leen, T.K., Muller, K., Eds.; MIT Press: Cambridge, MA, USA; Cortes, C., Vapnik, V., Support-vector networks (1995) Mach. Learning, 20, pp. 273-297; Freund, Y., Schapire, R.E., A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting (1997) J. Comput Syst. Sci., 55, pp. 119-139; Rodríguez-Martín, D., Samà, A., Pérez-López, C., Català, A., Moreno Arostegui, J.M., Cabestany, J., Bayés, À., Prats, A., Home detection of freezing of gait using support vector machines through a single waist-worn triaxial accelerometer (2017) Plos ONE, 12; Bächlin, M., Hausdorff, J.M., Roggen, D., Giladi, N., Plotnik, M., Tr Oster, G., Online Detection of Freezing of Gait in Parkinson’s Disease Patients: A Performance Characterization (2009) Proceedings of the Fourth International Conference on Body Area Networks, , Los Angeles, CA, USA, 1–3 April 2009; Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering (ICST): Brussels, Belgium; Moore, S., Yungher, D., Morris, T., Dilda, V., Macdougall, H., Shine, J., Naismith, S., Lewis, S., Autonomous identification of freezing of gait in Parkinson’s disease from lower-body segmental accelerometry (2013) J. Neuroeng Rehabil, 10; Tripoliti, E.E., Tzallas, A.T., Tsipouras, M.G., Rigas, G., Bougia, P., Leontiou, M., Konitsiotis, S., Fotiadis, D.I., Automatic detection of freezing of gait events in patients with Parkinson’s disease (2013) Comput Methods Programs Biomed, 110, pp. 12-26; Zach, H., Janssen, A.M., Snijders, A.H., Delval, A., Ferraye, M.U., Auff, E., Weerdesteyn, V., Nonnekes, J., Identifying freezing of gait in Parkinson’s disease during freezing provoking tasks using waist-mounted accelerometry (2015) Parkinsonism Relat Disord, 21, pp. 1362-1366; Samà, A., Rodríguez-Martín, D., Pérez-López, C., Català, A., Alcaine, S., Mestre, B., Prats, A., Bayés, À., Determining the optimal features in freezing of gait detection through a single waist accelerometer in home environments (2018) Pattern Recog. Lett., 105, pp. 135-143; Camps, J., Sama, A., Martin, M., Rodriguez-Martin, D., Perez-Lopez, C., Arostegui, J.M.M., Cabestany, J., Mestre, B., Deep learning for freezing of gait detection in Parkinson’s disease patients in their homes using a waist-worn inertial measurement unit (2018) Knowl. Based Syst., 139, pp. 119-131; Mohammadian Rad, N., van Laarhoven, T., Furlanello, C., Marchiori, E., Novelty Detection using Deep Normative Modeling for IMU-Based Abnormal Movement Monitoring in Parkinson’s Disease and Autism Spectrum Disorders (2018) Sensors, 18, p. 3533; San-Segundo, R., Torres-Sánchez, R., Hodgins, J., Fernando De La, T., Increasing Robustness in the Detection of Freezing of Gait in Parkinson’s Disease (2019) Electronics, 8, p. 119; Bächlin, M., Plotnik, M., Roggen, D., Maidan, I., Hausdorff, J.M., Giladi, N., Troster, G., Wearable Assistant for Parkinson’s Disease Patients With the Freezing of Gait Symptom (2010) IEEE Trans. Inf. Technol. Biomed., 14, pp. 436-446; Marquand, A.F., Rezek, I., Buitelaar, J., Beckmann, C.F., Understanding Heterogeneity in Clinical Cohorts Using Normative Models: Beyond Case-Control Studies (2016) Biol. Psychiatry, 80, pp. 552-561; Raake, A., (2006) Speech Quality of Voip: Assessment and Prediction, , John Wiley & Sons Ltd.: Hoboken, NJ, USA; Pérez-López, C., Samà, A., Rodríguez-Martín, D., Català, A., Cabestany, J., Moreno-Arostegui, J., de Mingo, E., Hughes, A.J., Assessing Motor Fluctuations in Parkinson’s Disease Patients Based on a Single Inertial Sensor; Accuracy of clinical diagnosis of idiopathic Parkinson’s disease: A clinico-pathological study of 100 cases (1992) J. Neurol. Neurosurg Psychiatry, 16, p. 181; Hoehn, M.M., Yahr, M.D., Parkinsonism: Onset, Progression and Mortality (1967) Neurology, 17, p. 427; Zhou, H., Hu, H., Human motion tracking for rehabilitation-A survey (2008) Biomed. Signal. Process. Control, 3, pp. 1-18; Sweeney, D., Quinlan, L.R., Browne, P., Richardson, M., Meskell, P., Ólaighin, G., A technological review of wearable cueing devices addressing freezing of gait in Parkinson’s disease (2019) Sensors, 19, p. 1277; Credit Card Fraud Detection Using Autoencoders in Keras, , https://github.com/curiousily/Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras, Available online: , (accessed on 23 June 2019); Hinton, G., Srivastava, N., Swersky, K., Neural networks for machine learning lecture 6a overview of mini-batch gradient descent (2012) Cited, p. 14. , https://www.cs.toronto.edu/~{}hinton/coursera/lecture6/, accessed on 12 December 2019; Kingma, D.P., Ba, L.J., (2014) . Adam: A Method for Stochastic Optimization., , arXiv, arXiv; https://keras.io/layers/wrappers/, accessed on 23 June 2019; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) J. Mach. Learn. Res, 9, pp. 249-256; Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tang, P.T.P., On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima Arxiv 2016, Arxiv; Bergstra, J., Yamins, D., Cox, D.D., (2013) Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures, , Proceedings of the JMLR Workshop and Conference Proceedings 28, Atlanta, Gerorgia, 16–21 June; Nieuwboer, A., Dom, R., de Weerdt, W., Desloovere, K., Fieuws, S., Broens-Kaucsik, E., Abnormalities of the spatiotemporal characteristics of gait at the onset of freezing in Parkinson’s disease (2001) Mov Disord; Yungher, D.A., Morris, T.R., Dilda, V., Shine, J.M., Naismith, S.L., Lewis, S.J.G., Moore, S.T., Temporal Characteristics of High-Frequency Lower-Limb Oscillation during Freezing of Gait in Parkinson’s Disease (2014) Parkinsons Dis; Wang, Z., Li, J., Wang, J., Zhao, H., Qiu, S., Yang, N., Shi, X., Inertial Sensor-Based Analysis of Equestrian Sports Between Beginner and Professional Riders Under Different Horse Gaits (2018) IEEE Trans. Instrum. Meas., 67, pp. 2692-2704; Qiu, S., Wang, H., Li, J., Zhao, H., Wang, Z., Wang, J., Wang, Q., Bauer, T., Towards Wearable-Inertial-Sensor-Based Gait Posture Evaluation for Subjects with Unbalanced Gaits (2020) Sensors, 20, p. 1193; Anwary, A.R., Yu, H., Vassallo, M., Optimal Foot Location for Placing Wearable IMU Sensors and Automatic Feature Extraction for Gait Analysis (2018) IEEE Sens. J., 18, pp. 2555-2567; Erfani, S.M., Rajasegarar, S., Karunasekera, S., Leckie, C., High-dimensional and large-scale anomaly detection using a linear one-class SVM with deep learning (2016) Pattern Recognit, 58, pp. 121-134; Han, D., Feature Representation and Data Augmentation for Human Activity Classification Based on Wearable IMU Sensor Data Using a Deep LSTM Neural Network (2018) Sensors, 18, p. 2892","Pavón, I.; Grupo de Investigación en Instrumentación y Acústica Aplicada (I2A2), Campus Sur UPM, Ctra. Valencia, Km 7., Spain; email: ignacio.pavon@upm.es",,,"MDPI AG",,,,,14248220,,,"32235373","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85082790799
"Kreuter D., Takahashi H., Omae Y., Akiduki T., Zhang Z.","26422291200;56894677100;57188716887;16642372700;55721844200;","Classification of human gait acceleration data using convolutional neural networks",2020,"International Journal of Innovative Computing, Information and Control","16","2",,"609","619",,7,"10.24507/ijicic.16.02.609","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082078681&doi=10.24507%2fijicic.16.02.609&partnerID=40&md5=5c7c5b893ec72fd7e5c906f122e9194f","Department of Information and Management Systems Engineering, Nagaoka University of Technology, 1603-1, Kamitomioka, Niigata, Nagaoka, 940-2188, Japan; Department of Physics Technische, Universität Darmstadt, Hochschulstraße 12, Darmstadt, 64289, Germany; Department of Industrial Engineering and Management College of Industrial Technology, Nihon University, 1-2-1, Izumi, Chiba, Narashino, 275-8575, Japan; Department of Mechanical Engineering, Toyohashi University of Technology, 1-1, Hibarigaoka, Tenpakucho, Aichi, Toyohashi, 441-8580, Japan","Kreuter, D., Department of Information and Management Systems Engineering, Nagaoka University of Technology, 1603-1, Kamitomioka, Niigata, Nagaoka, 940-2188, Japan, Department of Physics Technische, Universität Darmstadt, Hochschulstraße 12, Darmstadt, 64289, Germany; Takahashi, H., Department of Information and Management Systems Engineering, Nagaoka University of Technology, 1603-1, Kamitomioka, Niigata, Nagaoka, 940-2188, Japan; Omae, Y., Department of Industrial Engineering and Management College of Industrial Technology, Nihon University, 1-2-1, Izumi, Chiba, Narashino, 275-8575, Japan; Akiduki, T., Department of Mechanical Engineering, Toyohashi University of Technology, 1-1, Hibarigaoka, Tenpakucho, Aichi, Toyohashi, 441-8580, Japan; Zhang, Z., Department of Mechanical Engineering, Toyohashi University of Technology, 1-1, Hibarigaoka, Tenpakucho, Aichi, Toyohashi, 441-8580, Japan","The human motion analysis using wearable sensors such as accelerometers and gyroscopes is one of the important issues in ubiquitous and wearable computing. Inspired by a paper by Akiduki et al. that was released in 2018 concerning the classification of human gait motion accelerometer data, this paper attempts to classify that same data using a convolutional neural network. In the original 2018 paper, a high degree of separation was found between the data of the 13 recorded test subjects, suggesting that classification purely by looking at the motion data is possible. For the purpose of classification using the neural network, the given time series data is converted into three matrices (equivalent to image data with three channels per pixel). Using these images as input for a convolutional neural network, an accuracy of 100% was achieved in classifying the subject number from previously unseen motion data. © 2020 ICIC International.","Human motion; Machine learning; Time series data; Time series imaging","Accelerometers; Classification (of information); Convolution; Learning systems; Motion sensors; Time series; Ubiquitous computing; Wearable technology; Accelerometer data; Degree of separation; Human motion analysis; Human motions; Motion data; Three channel; Time-series data; Wearable computing; Convolutional neural networks",,,,,"Japan Society for the Promotion of Science, JSPS: 16K06156, 17K05437, 17K13179, 19K14924, 19K20062","Acknowledgment. This work was supported in part by JSPS Grant-in-Aid for Scientific Research (C) (Grant No. 17K05437; H. Takahashi and Grant No. 16K06156; T. Akiduki). This work was also supported in part by JSPS Grant-in-Aid for Young Scientists (B) (Grant No. 17K13179 Y. Omae) and Young Scientists (Grant No. 19K20062; Y. Omae and Grant No. 19K14924; T. Akiduki).",,,,,,,,,,"Akiduki, T., Kawamura, K., Zhang, Z., Takahashi, H., Extraction and classification of human gait features from acceleration data (2018) International Journal of Innovative Computing, 14 (4), pp. 1361-1370. , Information and Control; Akiduki, T., Uchida, A., Zhang, Z., Imamura, T., Takahashi, H., Extraction of human gait feature from acceleration data (2016) ICIC Express Letters, 7 (3), pp. 649-656. , Part B: Applications; Mishima, K., Kanata, S., Nakanishi, H., Sawaragi, T., Horiguchi, Y., Extraction of similarities and differences in human behavior using singular value decomposition, IEICE Trans. Fundamentals of Electronics (2011) Communications and Computer Sciences, Vol.J94-A, 4, pp. 293-302; Kamio, I., Takahashi, H., Akiduki, T., Zhang, Z., Study of individual characteristics in human motion by using acceleration data (2016) ICIC Express Letters, 7 (10), pp. 2225-2232. , Part B: Applications; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Jeong, Y.S., Jeong, M.K., Omitaomu, O.A., Weighted dynamic time warping for time series classification (2011) Pattern Recognition, 44 (9), pp. 2231-2240; Wang, Z., Yan, W., Oates, T., Time series classification from scratch with deep neural networks: A strong baseline (2017) Proc. of the 2017 International Joint Conference on Neural Networks (IJCNN), pp. 1578-1585; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2017) Commun. ACM, 60 (6), pp. 84-90; Wang, Z., Oates, T., Imaging time-series to improve classification and imputation (2015) Proc. of the 24Th International Conference on Artificial Intelligence, pp. 3939-3945; Fischer, G., (2014) Lineare Algebra, , Springer Fachmedien Wiesbaden; Keogh, E.J., Pazzani, M.J., Scaling up dynamic time warping for datamining applications (2000) Proc. of the 6Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 285-289; Bouten, C.V.C., Koekkoek, K.T.M., Verduin, M., Kodde, R., Janssen, J.D., A triaxial accelerometer and portable data processing unit for the assessment of daily physical activity (1997) IEEE Trans. Biomedical Engineering, 4 (3), pp. 136-147; Tada, M., Naya, F., Ohmura, R., Okada, M., Noma, H., Toriyama, T., Kogure, K., A method for measuring and analyzing driving behavior using wireless accelerometers (2008) IEICE Trans. Information and Systems, (4), pp. 1115-1129. , J91-D; Kiss90”, Time-Series-Classification, , https://github.com/kiss90/time-series-classification, Accessed on August 28, 2019; Chollet, F., Keras, , https://keras.io, Accessed on August 28, 2019; Martin, A., (2019) Tensorflow: Large-Scale Machine Learning on Heterogeneous Systems, , https://www.tensorflow.org/, Accessed on August 28; Jia, Y., Shelhamer, E., Donahue, J., Long, S.K.J., Girshick, R., Guadarrama, S., Darrell, T., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding, Arxiv Preprint, Arxiv, 1408, p. 5093; Murphy, K.P., (2012) Machine Learning: A Probabilistic Perspective, , MIT Press; Chinchor, N., MUC-4 evaluation metrics (1992) Proc. of the 4Th Conference on Message Understanding, pp. 22-29; Akiduki, T., Zhang, Z., Takahashi, H., Feature extraction for gait identification by using trajectory attractors (2019) ICIC Express Letters, 13 (6), pp. 529-538; Zhang, Q., Lee, K.-C., Bao, H., You, Y., Li, W., Guo, D., Large scale classification in deep neural network with label mapping (2018) Proc. of the 2018 IEEE International Conference on Data Mining Workshops (ICDMW), pp. 1134-1143",,,,"ICIC International",,,,,13494198,,,,"English","Int. J. Innov. Comput. Inf. Control",Article,"Final","",Scopus,2-s2.0-85082078681
"Fu Q., Wang C., Han X.","56783519500;56011543200;57191243767;","A CNN-LSTM network with attention approach for learning universal sentence representation in embedded system",2020,"Microprocessors and Microsystems","74",,"103051","","",,10,"10.1016/j.micpro.2020.103051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079838755&doi=10.1016%2fj.micpro.2020.103051&partnerID=40&md5=f77ac7e05da5b99bd8dde149e591d932","School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, China; Institute of Scientific & Technical Information of China, Beijing, China","Fu, Q., School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China, Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, China; Wang, C., School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China, Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, China; Han, X., Institute of Scientific & Technical Information of China, Beijing, China","The model for obtaining universal sentence representation is getting larger and larger, making it unsuitable for small embedded systems. The paper presents an extended encoder-decoder model with introduced an attention mechanism for learning distributed sentence representation. We can extract the CNN encoder and apply to other NLP downstream tasks on small embedded systems. Inspired by the linguistic features of the word embeddings, the different dimensions of the sentence representation can be aligned to especially linguistic features. The decoder which decodes one word will focus on the partial dimension of sentence representation into a fixed-length vector where CNN is more effective than LSTM, especially on devices with limited computing power. Moreover, the expanded LSTM with attention mechanism as the decoder to learn multitask that reconstruct the original sentence and predict the next sentence. The model was trained on an extensive collection of a novel to learning sentence representation encoder. Finally, the small-scale CNN encoder obtained encouraging results on several benchmark datasets and multiple task. © 2020","Attention; CNN; Embedded system; LSTM; Sentence representation","Decoding; Embedded systems; Learning systems; Linguistics; Signal encoding; Attention; Attention mechanisms; Benchmark datasets; Computing power; Encoder-decoder; Linguistic features; LSTM; Sentence representation; Long short-term memory",,,,,"National Key Research and Development Program of China, NKRDPC: 2017YFC1307705","The authors acknowledge The National Key Research and Development Program of China (Grant: 2017YFC1307705 ).",,,,,,,,,,"Le, Q., Mikolov, T., Distributed representations of sentences and documents (2014) Int. Conf. Mach. Learn., 1 (31), pp. 1188-1196; Dai, A.M., Le, Q.V., Semi-supervised sequence learning (2015) Adv. Neural Inf. Process. Syst., 2 (29), pp. 3079-3087; Kiros, R., Skip-thought vectors (2015) Adv. Neural Inf. Process. Syst., 1 (29), pp. 3294-3302; Gan, Z., Learning generic sentence representations using convolutional neural networks (2017) Empir. Methods Natural Lang. Process., 1 (22), pp. 2390-2400; Masci, J., Stacked convolutional auto-encoders for hierarchical feature extraction (2011) Int. Conf. Artif. Neural Netw., 1 (20), pp. 52-59; Gao, L., Video captioning with attention-based LSTM and semantic consistency (2017) IEEE Trans Multimed., 19 (9), pp. 2045-2055; Bollegala, D., Hayashi, K., Kawarabayashi, K., Learning linear transformations between counting-based and prediction-based word embeddings (2017) PLoS ONE, 12 (9), pp. 84-97; Collobert, R., Natural language processing (almost) from scratch (2011) J. Mach. Learn. Res., 12 (8), pp. 2493-2537; Zhu, Y., Aligning books and movies: towards story-like visual explanations by watching movies and reading books (2015) IEEE Int. Conf. Comput. Vis., 1 (29), pp. 19-27; Kinga, D., Adam, J.B., A method for stochastic optimization (2015) Int. Conf. Learn. Represent., 1 (2), pp. 1875-1880; Bastien, F.E.D.E., Theano: new features and speed improvements (2012) Adv. Neural Inf. Process. Syst., 1 (26), pp. 3-8; Pang, B., Lee, L., Opinion mining and sentiment analysis (2008) Found. Trends Inf. Retr., 2 (12), pp. 1-13; Wang, D., Zhu, S., Li, T., SumView: a web-based engine for summarizing product reviews and customer opinions (2013) Expert Syst. Appl., 40 (1), pp. 27-33; Wiebe, J., Wilson, T., Cardie, C., Annotating expressions of opinions and emotions in language (2005) Lang. Resour. Eval., 39 (2-3), pp. 165-210; Li, X., Roth, D., Learning question classifiers: the role of semantic information (2006) Nat. Lang. Eng., 12 (3), pp. 229-249; Islam, A., Inkpen, D., Semantic text similarity using corpus-based word similarity and string similarity (2008) ACM Trans. Knowl. Discovery Data (TKDD), 2 (2), p. 10; Bentivogli, L., SICK through the Semeval glasses. Lesson learned from the evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment (2016) Lang. Resour. Eval., 50 (1), pp. 95-124; Yu, M., Dredze, M., Learning composition models for phrase embeddings (2015) Trans. Assoc. Comput. Ling., 3 (1), pp. 227-242; Palangi, H., Deep sentence embedding using long short-term memory networks: analysis and application to information retrieval (2016) IEEE/ACM Trans. Audio Speech Lang. Process. (TASLP), 24 (4), pp. 694-707; Bojanowski, P., Enriching word vectors with subword information (2017) Trans. Assoc. Comput. Ling., 5 (1), pp. 135-146; Yu, Z., Beyond bilinear: generalized multimodal factorized high-order pooling for visual question answering (2018) IEEE Trans. Neural Netw. Learn. Syst., 29 (12), pp. 5947-5959; Agarwal, B., A deep network model for paraphrase detection in short text messages (2018) Inf. Process. Manage., 54 (6), pp. 922-937; Devlin, J., (2018), BERT: pre-training of deep bidirectional transformers for language understanding. arXiv:","Fu, Q.; Beijing University of Posts and Telecommunications, No. 10 Xitucheng Road, China; email: fuqunchao@bupt.edu.cn",,,"Elsevier B.V.",,,,,01419331,,MIMID,,"English","Microprocessors Microsyst",Article,"Final","",Scopus,2-s2.0-85079838755
"Zhang J., Ghodsi Z., Garg S., Rangineni K.","57190071457;57201132625;20435727500;57203937596;","Enabling timing error resilience for low-power systolic-array based deep learning accelerators",2020,"IEEE Design and Test","37","2","8868188","93","102",,6,"10.1109/MDAT.2019.2947271","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073539087&doi=10.1109%2fMDAT.2019.2947271&partnerID=40&md5=76818e5151985e6f6799694abbf443b6","Department of Electrical and Computer Engineering, New York University, New York, NY, United States; New York University, United States; Intel India, India","Zhang, J., Department of Electrical and Computer Engineering, New York University, New York, NY, United States; Ghodsi, Z., Department of Electrical and Computer Engineering, New York University, New York, NY, United States; Garg, S., New York University, United States; Rangineni, K., Intel India, India","Hardware-accelerated learning and inference algorithms are quite popular in edge devices where predictable timing behavior and minimal energy consumption are required, while maintaining robustness to timing errors. To achieve this, dynamic voltage scaling techniques have been utilized in several accelerators. Therefore, this article presents Thundervolt, a framework allowing adaptive aggressive voltage underscaling while maintaining the robustness (reliability, predictability, performance) of such accelerators. - Theocharis Theocharides, University of Cyprus - Muhammad Shafique, Technische Universitat Wien. © 2013 IEEE.","Deep Neural Network; Energy Efficiency; Hardware Accelerator; Systolic Arrays; Timing Error; Timing Speculation","Acceleration; Benchmarking; Energy efficiency; Errors; Image recognition; Speech recognition; Systolic arrays; Timing circuits; Accelerator architectures; Classification accuracy; Hardware accelerators; Process Variation; Pruning techniques; Timing errors; Timing simulations; Timing speculations; Deep neural networks",,,,,,,,,,,,,,,,"Chen, Y.-H., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2017) Ieee J. Solid-State Circuits, 52 (1), pp. 127-138; Jouppi, N.P., (2017) Datacenter Performance Analysis of a Tensor Processing Unit; Samajdar, A., (2018) Scale-sim: Systolic Cnn Accelerator; Ernst, D., Razor: Circuit-level correction of timing errors for low-power operation (2004) Ieee Micro, 24 (6), pp. 10-20; Jiao, X., An assessment of vulnerability of hardware neural networks to dynamic voltage and temperature variations (2017) Proc. IEEE/ACMICCAD, pp. 945-950; Zhang, J., Thundervolt: Enabling aggressive voltage underscaling and timing error resilience for energy efficient deep learning accelerators (2018) Proc. 55th Annu. Design Autom. Conf., p. 19; Sze, V., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. Ieee, 105 (12), pp. 2295-2329; Hegde, R., Shanbhag, N.R., Soft digital signal processing (2001) Ieee Trans. Very Large Scale Integr. (VLSI) Syst., 9 (6), pp. 813-823; Krizhevsky, A., (2014) One Weird Trick for Parallelizing Convolutional Neural Networks; Bull, D., A power-efficient 32 bit arm processor using timing-error detection and correction for transient-error tolerance and adaptation to PVT variation (2011) Ieee J. Solid-State Circuits, 46 (1), pp. 18-31; Zhang, J.J., Garg, S., Fate: Fast and accurate timing error prediction framework for low power dnn accelerator design (2018) Proc. Int. Conf. Comput.-Aided Design (ICCAD'18), pp. 241-248. , http://doi.acm.org/10.1145/3240765.3240809, New York, NY, USA; Raghunathan, B., Cherry-picking: Exploiting process variations in dark-silicon homogeneous chip multi-processors (2013) Proc. Conf. Design Autom. Test Eur., Eda Consortium, pp. 39-44; Whatmough, P.N., 14.3 A 28nm SoC with a 1.2GHz 568nJ/prediction sparse deep-neural-network engine with 0.1 timing error rate tolerance for IoT applications (2017) Proc. Ieee Int. Solid-State Circuits Conf. (ISSCC), pp. 242-243; Greskamp, B., Blueshift: Designing processors for timing speculation from the ground up (2009) Proc. Ieee 15th Int. Symp. High-Perf. Comput. Archit., pp. 213-224. , Feb; Reda, S., Shafique, M., (2018) Approximate Circuits: Methodologies and Cad, , https://books.google.com/books?id=AFFauQEACAAJ, Springer International Publishing; Han, S., Mao, H., Dally, W.J., (2015) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding","Zhang, J.; Department of Electrical and Computer Engineering, United States; email: jz2163@nyu.edu",,,"IEEE Computer Society",,,,,21682356,,,,"English","IEEE Des. Test",Article,"Final","",Scopus,2-s2.0-85073539087
"Kim Y., Kim H., Yadav N., Li S., Choi K.K.","57193073016;57193126483;56007545200;56645088000;23975486700;","Low-power RTL code generation for advanced cnn algorithms toward object detection in autonomous vehicles",2020,"Electronics (Switzerland)","9","3","478","","",,4,"10.3390/electronics9030478","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082200494&doi=10.3390%2felectronics9030478&partnerID=40&md5=6ef35911121510f92c2db27b96b2db76","DA-lab, Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Siegel Hall, Chicago, IL  60616, United States","Kim, Y., DA-lab, Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Siegel Hall, Chicago, IL  60616, United States; Kim, H., DA-lab, Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Siegel Hall, Chicago, IL  60616, United States; Yadav, N., DA-lab, Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Siegel Hall, Chicago, IL  60616, United States; Li, S., DA-lab, Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Siegel Hall, Chicago, IL  60616, United States; Choi, K.K., DA-lab, Electrical and Computer Engineering, Illinois Institute of Technology, 3301 South Dearborn Street, Siegel Hall, Chicago, IL  60616, United States","In the implementation process of a convolution neural network (CNN)-based object detection system, the primary issues are power dissipation and limited throughput. Even though we utilize ultra-low power dissipation devices, the dynamic power dissipation issue will be difficult to resolve. During the operation of the CNN algorithm, there are several factors such as the heating problem generated from the massive computational complexity, the bottleneck generated in data transformation and by the limited bandwidth, and the power dissipation generated from redundant data access. This article proposes the low-power techniques, applies them to the CNN accelerator on the FPGA and ASIC design flow, and evaluates them on the Xilinx ZCU-102 FPGA SoC hardware platform and 45 nm technology for ASIC, respectively. Our proposed low-power techniques are applied at the register-transfer-level (RT-level), targeting FPGA and ASIC. In this article, we achieve up to a 53.21% power reduction in the ASIC implementation and saved 32.72% of the dynamic power dissipation in the FPGA implementation. This shows that our RTL low-power schemes have a powerful possibility of dynamic power reduction when applied to the FPGA design flow and ASIC design flow for the implementation of the CNN-based object detection system. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Low-power hardware design; Low-power techniques; Platform reusability; RT level low-power technique",,,,,,"Ministry of Trade, Industry and Energy, MOTIE; Korea Evaluation Institute of Industrial Technology, KEIT: 10083639","This work is supported by the Industrial Core Technology Development Program of MOTIE/KEIT, KOREA. (#10083639, Development of Camera-based Real-time Artificial Intelligence System for Detecting Driving Environment & Recognizing Objects on Road Simultaneously).",,,,,,,,,,"Nishani, E., Çiço, B., Computer vision approaches based on deep learning and neural networks: Deep neural networks for video analysis of human pose estimation (2017) Proceedings of the 2017 6Th Mediterranean Conference on Embedded Computing (MECO), pp. 1-4. , Bar, Montenegro, 11–15 June; pp. [CrossRef]; Zhao, Y., Zhao, J., Zhao, C., Xiong, W., Li, Q., Yang, J., Robust Real-Time Object Detection Based on Deep Learning for Very High Resolution Remote Sensing Images (2019) Proceedings of the IGARSS 2019—2019 IEEE International Geoscience and Remote Sensing Symposium, pp. 1314-1317. , Yokohama, Japan, 28 July–2 August; Zhang, Y., Ming, Y., Zhang, R., Object Detection and Tracking based on Recurrent Neural Networks In Proceedings of the 2018 14Th IEEE International Conference on Signal Processing (ICSP), pp. 338-343. , Beijing, China, 12–16 August 2018, [CrossRef]; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S.E., Fu, C., Berg, A.C., SSD: Single Shot MultiBox Detector Arxiv 2015, Arxiv; Ren, S., He, K., Girshick, R.B., Sun, J., (2015) Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks; Redmon, J., Farhadi, A., YOLO9000: Better, Faster (1612) Stronger. Arxiv 2016, Arxiv, p. 08242; Pan, S., Shi, L., Guo, S., Guo, P., He, Y., Xiao, R., A low-power SoC-based moving target detection system for amphibious spherical robots In Proceedings of the 2015 IEEE International Conference on Mechatronics and Automation (ICMA), pp. 1116-1121. , Beijing, China, 2–5 August 2015; pp., [CrossRef]; Liu, W., Chen, H., Ma, L., Moving object detection and tracking based on ZYNQ FPGA and ARM SOC Proceedings of the IET International Radar Conference 2015, Hangzhou, China, 14–, pp. 1-4. , October 2015; Padmanabha, M., Schott, C., Rößler, M., Kriesten, D., Heinkel, U., ZYNQ flexible platform for object recognition tracking (2016) Proceedings of the 2016 13Th Workshop on Positioning, Navigation and Communications (WPNC), pp. 1-6. , Bremen, Germany, 19–20 October; Desmouliers, C., Aslan, S., Oruklu, E., Saniie, J., Vallina, F.M., HW/SW co-design platform for image and video processing applications on Virtex-5 FPGA using PICO (2010) Proceedings of the 2010 IEEE International Conference on Electro/Information Technology, pp. 1-6. , Normal, IL, USA, 20–22 May; Canziani, A., Paszke, A., Culurciello, E., An Analysis of Deep Neural Network Models for Practical Applications Arxiv 2016, Arxiv; Nakahara, H., Yonekawa, H., Fujii, T., Sato, S., A Lightweight YOLOv2: A Binarized CNN with A Parallel Support Vector Regression for an FPGA (2018) Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 31-40. , Monterey, CA, USA, 25–27 February; Hardware Acceleration of Deep Neural Networks: GPU, FPGA, ASIC, TPU, VPU, IPU, DPU, NPU, RPU, NNP and Other Letters, , https://itnesweb.com/article/hardware-acceleration-of-deep-neural-networks-gpu-fpga-asic-tpu-vpu-ipu-dpu-npu-rpu-nnp-and-other-letters, (accessed on 12 March 2020); Pedram, M., Abdollahi, A., Low-power RT-level synthesis techniques: A tutorial (2005) IEE Proc. Comput. Digit. Tech., 152, pp. 333-343; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FP GA-based Accelerator Design for Deep Convolutional Neural Networks (2015) Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 161-170. , Monterey, CA, USA, 22–24 February; Alwani, M., Chen, H., Ferdman, M., Milder, P., Fused-layer CNN accelerators (2016) Proceedings of the 2016 49Th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), pp. 1-12. , Taipei, Taiwan, 15–19 October; Sun, F., Wang, C., Gong, L., Xu, C., Zhang, Y., Lu, Y., Li, X., Zhou, X.A., High-Performance Accelerator for Large-Scale Convolutional Neural Networks Proceedings of the 2017 IEEE International Symposium on Parallel and Distributed Processing with Applications and 2017 IEEE International Conference on Ubiquitous Computing and Communications (ISPA/IUCC), pp. 622-629. , Guangzhou, China, 12–15 December 2017; Shen, Y., Ferdman, M., Milder, P., Maximizing CNN Accelerator Efficiency Through Resource Partitioning Arxiv 2016, Arxiv; Li, L., Choi, K., Park, S., Chung, M., Selective clock gating by using wasting toggle rate (2009) Proceedings of the 2009 IEEE International Conference on Electro/Information Technology, pp. 399-404. , Windsor, ON, Canada, 7–9 June; Wang, W., Tsao, Y.-C., Choi, K., Park, S.M., Chung, M.-K., Pipeline power reduction through single comparator-based clock gating (2009) Proceedings of the 2009 International Soc Design Conference (ISOCC), pp. 480-483. , Busan, Korea, 22–24 November; Zhang, Y., Tong, Q., Li, L., Wang, W., Choi, K., Jang, J., Jung, H., Ahn, S., Automatic Register Transfer level CAD tool design for advanced clock gating and low power schemes (2012) Proceedings of the 2012 International Soc Design Conference (ISOCC), pp. 21-24. , Jeju Island, Korea, 4–7 November; Kim, H., Choi, K., The Implementation of a Power Efficient BCNN-Based Object Detection Acceleration on a Xilinx FPGA-SoC (2019) Proceedings of the 2019 International Conference on Internet of Things (Ithings) and IEEE Green Computing and Communications (Greencom) and IEEE Cyber, pp. 240-243. , Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData), Atlanta, GA, USA; Ma, Y., Cao, Y., Vrudhula, S., Seo, J., Optimizing the Convolution Operation to Accelerate Deep Neural Networks on FPGA (2018) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 26, pp. 1354-1367; Nguyen, D.T., Nguyen, T.N., Kim, H., Lee, H., A High-Throughput and Power-Efficient FPGA Implementation of YOLO CNN for Object Detection (2019) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 27, pp. 1861-1873; Fraser, N.J., Umuroglu, Y., Gambardella, G., Blott, M., Leong, P.H.W., Jahre, M., Vissers, K.A., Scaling Binarized Neural Networks on Reconfigurable Logic Arxiv 2017, Arxiv; Lin, D.D., Talathi, S.S., Annapureddy, V.S., (2015) Fixed Point Quantization of Deep Convolutional Networks.; Ioffe, S., Szegedy, C., (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift; Aydonat, U., O’Connell, S., Capalija, D., Ling, A.C., Chiu, G.R., (2017) An Opencl(Tm) Deep Learning Accelerator on Arria 10; Zhao, Y., Zhang, X., Fang, X., Li, L., Li, X., Guo, Z., Liu, X., A Deep Residual Networks Accelerator on FPGA (2019) Proceedings of the 2019 Eleventh International Conference on Advanced Computational Intelligence (ICACI), pp. 13-17. , Guilin, China, 7–9 June; Kim, H., Choi, K., Low Power FPGA-SoC Design Techniques for CNN-based Object Detection Accelerator (2019) Proceedings of the 2019 IEEE Annual Ubiquitous Computing, Electronics & Mobile Communication Conference, , New York City, NY, USA, 10–12 October; https://www.eda.ncsu.edu/wiki/FreePDK45:Contents, (accessed on 12 March 2020); Zhijie, Y., Lei, W., Li, L., Shiming, L., Shasha, G., Shuquan, W., Bactran: A Hardware Batch Normalization Implementation for CNN Training Engine (2020) IEEE Embed. Syst. Lett.; Piyasena, D., Wickramasinghe, R., Paul, D., Lam, S., Wu, M., Reducing Dynamic Power in Streaming CNN Hardware Accelerators by Exploiting Computational Redundancies (2019) Proceedings of the 2019 29Th International Conference on Field Programmable Logic and Applications (FPL), pp. 354-359. , Barcelona, Spain, 8–12 September","Kim, Y.; DA-lab, 3301 South Dearborn Street, Siegel Hall, United States; email: ykim102@hawk.iit.edu",,,"MDPI AG",,,,,20799292,,,,"English","Electronics (Switzerland)",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85082200494
"Kim H.-J., Han J.-Y., Lee S., Kwag J.-R., Kuk M.-G., Han I.-H., Kim M.-H.","56537275200;57215410649;57218147654;57215409811;57215420434;57217549753;57192185368;","A road condition classification algorithm for a tire acceleration sensor using an artificial neural network",2020,"Electronics (Switzerland)","9","3","404","","",,2,"10.3390/electronics9030404","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080884572&doi=10.3390%2felectronics9030404&partnerID=40&md5=877910922785862df3224acb82134de4","School of Mechanical Engineering, Pusan National University, Pusan, 46241, South Korea; Performance Research Team, NEXEN Tire, Yangsan-si, 50592, South Korea; Division of Automotive Engineering, Dong-eui Institute of Technology, Pusan, 47230, South Korea","Kim, H.-J., School of Mechanical Engineering, Pusan National University, Pusan, 46241, South Korea; Han, J.-Y., School of Mechanical Engineering, Pusan National University, Pusan, 46241, South Korea; Lee, S., School of Mechanical Engineering, Pusan National University, Pusan, 46241, South Korea; Kwag, J.-R., Performance Research Team, NEXEN Tire, Yangsan-si, 50592, South Korea; Kuk, M.-G., Performance Research Team, NEXEN Tire, Yangsan-si, 50592, South Korea; Han, I.-H., Performance Research Team, NEXEN Tire, Yangsan-si, 50592, South Korea; Kim, M.-H., Division of Automotive Engineering, Dong-eui Institute of Technology, Pusan, 47230, South Korea","The automotive industry is experiencing a period of innovation, represented by the term CASE (connected, autonomous, shared, and electric). Among the innovative new technologies for automobiles, intelligent tire (iTire) collects road surface information through sensors installed inside a tire and informs the driver of the road conditions. iTire can promote safe driving. Various kinds of research on iTire is ongoing, and this paper proposes an algorithm to determine the road surface conditions while driving. Specifically, we have proposed a method for extracting the feature points of a frequency band, by converting acceleration data collected by sensors through fast Fourier transform (FFT) and determining road surface conditions via an artificial neural network. Lastly, the applicability of the algorithm was verified. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial neural network; Intelligent tire (iTire); Road condition classification; Tire acceleration sensor; Tire pressure monitoring system (TPMS)",,,,,,,,,,,,,,,,,"Moon, J.Y., Bae, I., Kim, S., An Inverse Vehicle Model for a Neural-Network-based Integrated Lateral and Longitudinal Automatic Parking Controller (2019) Electronics, 8, pp. 1452-1467; Pevec, D., Babic, J., Podobnik, V., Electric Vehicles: A Data Science Perspective Review (2019) Electronics, 8, pp. 1190-1220; Uhlemann, E., Introducing Connected (2015) Vehicles IEEE Vehicular Technology Magazine, 10, pp. 23-31; Guan, K., Ai, B., Peng, B., He, D.P., Li, G.K., Yang, J.Y., Zhong, Z.D., Kürner, T., Towards Realistic High- Speed Train Channels at 5G Millimeter-Wave Band Part I: Paradigm, Significance Analysis, and Scenario Reconstruction (2018) IEEE Trans. Veh. Technol., 67, pp. 9112-9128; Hu, Q., Luo, F., Review of Secure Communication Approaches For In-Vehicle Network (2018) Int. J. Automot. Technol., 19, pp. 879-894; Doecke, S., Grant, A., Robert, W.G., The Real-World Safety Potential of Connected Vehicle Technology (2015) Traffic Inj. Prev., 16, pp. 531-535; Wang, J., Song, F., On-Chip Integration of Pressure Plus 2-Axis (X/Z) Acceleration Composite TPMS Sensors with a Single-Sided Bulk-Micromachining Technique (2019) Micromachines, 10, p. 473; Velupillai, S., Guvenc, L., Tire Pressure Monitoring [Applications of Control] (2007) IEEE Control. Syst. Mag., 27, pp. 22-25; Alexander, O., Salem, E., Chakhar, B., Brown, D., An innovative decision rule approach to tire pressure monitoring (2019) Expert Syst. Appl., 124, pp. 252-270; Robbems, W.B., (2017) Understanding Automotive Electronics: An Engineering Perspective, , 8th ed.; Butterworth- Heinemann: Oxford, England; Lee, S.B., Kim, D.H., Durable and Sustainable Strap Type Electromagnetic Harvester for Tire Pressure Monitoring System (2013) J. Magn., 18, pp. 473-480; Matsuzaki, R., Keating, T., Todoroki, A., Hiraoka, N., Rubber-based strain sensor fabricated using photolithography for intelligent tires (2008) Sens. Actuators: Phys., 148, pp. 1-9; Lee, H.J., Taheri, S., Intelligent Tires? A Review of Tire Characterization Literature (2017) IEEE Intell. Transp. Syst. Mag., 9, p. 10; Hariri, H., Kim, J., Kim, W.S., Frechette, L.G., Masson, P., Performance validation of printed strain sensors for active control of intelligent tires (2017) Appl. Acoust., 123, pp. 73-84; Garcia Pozuelo, D., Olatunbosun, O., Strano, S., Terzo, M., A real-time physical model for strain-based intelligent tires (2019) Sens. Actuators A: Phys., 288, pp. 1-9; Khaleghian, S., Taheri, S., Terrain classification using intelligent tire (2017) J. Terramechanics., 71, pp. 15-24; Kanwar, B.S., Saied, T., Estimation of Tire-road Friction Coefficient and its Application in Chassis Control Systems (2015) Syst. Sci. Control. Eng., 3, pp. 39-61; Niskanen, A., Tuononen, A.J., Three Axis IEPE Accelerometers on the Inner Liner of a Tire for Finding the Tire-Road Friction Potential Indicators (2015) Sensors, 15, pp. 19251-19263; Hanatsuka, Y., Higuchi, T., Matsui, T., Development of the Road Surface Condition Classification system Proceedings of the IET International Conference on Information Science and Control Engineering, Shenzhen, China, pp. 413-416. , 7–9 December 2012; Hanatsuka, Y., Goto, T., Higuchi, T., Matsui, T., Road Condition Classification using a New Global Alignment Kernel (2015) Proceedings of the IEEE International Workshop on Machine Learning for Signal. Processing, pp. 17-20. , Boston, MA, USA, 17–20 September; Rehman, I.U., Nasralla, M.M., Philip, Y., Multilayer Perceptron Neural Network-Based QoS-Aware, Content-Aware and Device-Aware QoE Prediction Model: A Proposed Prediction Model for Medical Ultrasound Streaming Over Small Cell Networks (2019) Electronics, 8, pp. 194-221","Kim, M.-H.; Division of Automotive Engineering, South Korea; email: mhkim@dit.ac.kr",,,"MDPI AG",,,,,20799292,,,,"English","Electronics (Switzerland)",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85080884572
"Loni M., Sinaei S., Zoljodi A., Daneshtalab M., Sjödin M.","57203898036;53164819500;57211168664;23004285900;6602489915;","DeepMaker: A multi-objective optimization framework for deep neural networks in embedded systems",2020,"Microprocessors and Microsystems","73",,"102989","","",,27,"10.1016/j.micpro.2020.102989","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077516447&doi=10.1016%2fj.micpro.2020.102989&partnerID=40&md5=4685c123e3bd9a991ababa81b72408c8","School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden; Shiraz University of Technology, Shiraz, Iran","Loni, M., School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden; Sinaei, S., School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden; Zoljodi, A., Shiraz University of Technology, Shiraz, Iran; Daneshtalab, M., School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden; Sjödin, M., School of Innovation, Design and Engineering, Mälardalen University, Västerås, Sweden","Deep Neural Networks (DNNs) are compute-intensive learning models with growing applicability in a wide range of domains. Due to their computational complexity, DNNs benefit from implementations that utilize custom hardware accelerators to meet performance and response time as well as classification accuracy constraints. In this paper, we propose DeepMaker framework that aims to automatically design a set of highly robust DNN architectures for embedded devices as the closest processing unit to the sensors. DeepMaker explores and prunes the design space to find improved neural architectures. Our proposed framework takes advantage of a multi-objective evolutionary approach that exploits a pruned design space inspired by a dense architecture. DeepMaker considers the accuracy along with the network size factor as two objectives to build a highly optimized network fitting with limited computational resource budgets while delivers an acceptable accuracy level. In comparison with the best result on the CIFAR-10 dataset, a generated network by DeepMaker presents up to a 26.4x compression rate while loses only 4% accuracy. Besides, DeepMaker maps the generated CNN on the programmable commodity devices, including ARM Processor, High-Performance CPU, GPU, and FPGA. © 2020","Convolutional Neural Networks (CNNs); Design Space Exploration (DSE); Embedded systems; Multi-Objective Optimization (MOO)","Budget control; Embedded systems; Evolutionary algorithms; Integrated circuit design; Multiobjective optimization; Network architecture; Neural networks; Classification accuracy; Compression rates; Computational resources; Convolutional neural network; Custom hardwares; Design space exploration; Multi-objective evolutionary; Neural architectures; Deep neural networks",,,,,,"KKS has supported this work within the projects DeepMaker and DPAC.",,,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Adv. Neural Inf. Process. Syst., pp. 1097-1105; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.R., Jaitly, N., Kingsbury, B., Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups (2012) IEEE Signal Process. Mag., 29 (6), pp. 82-97; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Petersen, S., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), p. 529; Zhang, R., Isola, P., Efros, A.A., Colorful image colorization (2016) European Conference on Computer Vision, pp. 649-666; T., J., Song Han, W.D., Pool, J., Learning both weights and connections for efficient neural networks (2015) Adv. Neural Inf. Process. Syst., 50 (2), pp. 1135-1143; Huang, G., Liu, Z., Weinberger, K.Q., van der Maaten, L., Densely connected convolutional networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1, p. 3; Yazdanbakhsh, A., Mahajan, D., Esmaeilzadeh, H., Lotfi-Kamran, P., AxBench: a multiplatform benchmark suite for approximate computing (2017) IEEE Des. Test., 34 (2), pp. 60-68; Deb, K., Pratap, A., Agarwal, S., Meyarivan, T., A fast and elitist multiobjective genetic algorithm: NSGA-II (2002) IEEE Trans. Evol. Comput., 6 (2), pp. 182-197; Zhang, C., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: towards uniformed representation and acceleration for deep convolutional neural networks (2016) Proc. 35th Int. Conf. Comput. Des., p. 18; Chollet, F., (2015), https://github.com/fchollet/keras, Keras, github [Online]. Available:; Esmaeilzadeh, H., Blem, E., St. Amant, R., Sankaralingam, K., Burger, D., Power challenges may end the multicore era (2013) Commun. ACM, 56 (2), p. 93; Falsafi, B., Dally, B., Singh, D., Chiou, D., Yi, J.J., Sendag, R., FPGAs versus GPUs in data centers (2017) IEEE Micro, 37 (1), pp. 60-72; Sharma, H., Park, J., Amaro, E., Thwaites, B., Kotha, P., Gupta, A., Kyung, J., Esmaeilzadeh, H., DNNWEAVER: from high-level deep network models to FPGA acceleration (2015) IEEE Int. Conf. Mechatron. Electron. Autom. Eng., (2), pp. 76-80; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Krizhevsky, A., https://www.cs.toronto.edu/kriz/cifar.html, G. Hinton. Cifar-10 dataset; Bergstra, J., Bardenet, R., Bengio, Y., Kgl, B., Algorithms for hyperparameter optimization (2011) Advances in Neural Information Processing Systems, pp. 2546-2554; Bengio, Y., Gradient-based optimization of hyperparameters (2000) Neural Comput., 8, pp. 1889-1900; Bergstra, J., Yoshua Bengio, U., Random search for hyper-parameter optimization (2012) J. Mach. Learn. Res., (13), pp. 281-305; Snoek, J., Larochelle, H., Adams, R.P., Practical bayesian optimization of machine learning algorithms (2012) Adv. Neural Inf. Process. Syst., (25), pp. 2960-2968; Sun, Y., Xue, B., Zhang, M., (2017), Evolving deep convolutional neural networks for image classification. arXiv:; Baker, B., Gupta, O., Naik, N., Raskar, R., (2016), Designing neural network architectures using reinforcement learning arXiv Prepr 116; Zoph, B., Le, Q.V., (2016), Neural architecture search with reinforcement learning arXiv prepr. arXiv:; Zhong, Z., Yan, J., Liu, C.L., (2017), Practical network blocks design with Q-Learning arXiv prepr. arXiv:; Suganuma, M., Shirakawa, S., Nagao, T., A genetic programming approach to designing convolutional neural network architectures (2017) Genet. Evol. Comput. Conf., pp. 497-504; Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y.L., Le, Q., Kurakin, A., (2017), Large-scale evolution of image classifiers. arXiv:; Gastaldi, X., (2017), Shake-shake regularization. arXiv:; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Dufourq, E., Bassett, B.A., (2017), EDEN: evolutionary deep networks for efficient machine learning. arXiv:; Hasanpour, S.H., Rouhani, M., Fayyaz, M., Sabokrou, M., (2016), Lets keep it simple, using simple architectures to outperform deeper and more complex architectures. arXiv:; Wan, L., Zeiler, M., Zhang, S., LeCun, Y., Fergus, R., (2013), pp. 109-111. , Regularization of neural networks using dropconnect, 1; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Int. Conf. Learn. Represent., p. 114; Grigorian, B., Reinman, G., Accelerating divergent applications on simd architectures using neural networks (2014) 32nd IEEE International Conference on Computer Design, pp. 317-323; Du, Z., Lingamneni, A., Chen, Y., Palem, K.V., Temam, O., Wu, C., Leveraging the error resilience of neural networks for designing highly energy efficient accelerators (2015) IEEE Trans. Comput. Des. Integr. Circt. Syst., 34 (8), pp. 1223-1235; Moreau, T., Wyse, M., Nelson, J., Sampson, A., Esmaeilzadeh, H., Ceze, L., Oskin, M., SNNAP: approximate computing on programmable SOCS via neural acceleration (2015) 2015 IEEE 21st International Symposium on High-Performance Computer Architecture, pp. 603-614; Yazdanbakhsh, A., Park, J., Sharma, H., Lotfi-Kamran, P., Esmaeilzadeh, H., Neural acceleration for GPU throughput processors (2015) Proceedings of the 48th International Symposium on Microarchitecture – MICRO48, pp. 482-493; Li, H., (2016), A. K., I. Durdanovic, H. Samet, and H.P. Graf, Pruning filters for efficient convnets. arXiv:; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Advances in neural information processing systems, pp. 1135-1143; Hu, H., Peng, R., Tai, Y.W., Tang, C.K., (2016), Network trimming: a data-driven neuron pruning approach towards efficient deep architectures arXiv preprint arXiv:; Li, L., Xu, Y., Zhu, J., Filter level pruning based on similar feature extraction for convolutional neural networks (2018) IEICE Trans. Inf. Syst., 101 (4), pp. 203-1206; Srinivas, S., Babu, R.V., (2015), Data-free parameter pruning for deep neural networks. arXiv:; Zitzler, E., Thiele, L., Multiobjective optimization using evolutionary algorithms—a comparative case study (1998) International Conference on Parallel Problem Solving From Nature, pp. 292-301; Esmaeilzadeh, H., Blem, E., St. Amant, R., Sankaralingam, K., Burger, D., Dark silicon and the end of multicore scaling (2012) IEEE Micro, 32 (3); Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Kudlur, M., Tensorflow: a system for large-scale machine learning (2016) 12th USENIX Symposium on Operating Systems Design and Implementation, pp. 265-283; Loni, M., Daneshtalab, M., Sjodin, M., ADONN: adaptive design of optimized deep neural networks for embedded systems (2018) Euromicro Conference on Digital System Design, pp. 397-404; Lu, Z., Whalen, I., Boddeti, V., Dhebar, Y., Deb, K., Goodman, E., Banzhaf, W., NSGA-Net: neural architecture search using multi-objective genetic algorithm (2019) Proceedings of the Genetic and Evolutionary Computation Conference, pp. 419-427; Mahdiani, H., Ghanbari, A., Khadem, A., Modarressi, M., Daneshtalab, M., ΔNN: power-efficient neural network acceleration using differential weights (2020) IEEE Micro","Daneshtalab, M.; School of Innovation, Sweden; email: masdan@kth.se",,,"Elsevier B.V.",,,,,01419331,,MIMID,,"English","Microprocessors Microsyst",Article,"Final","",Scopus,2-s2.0-85077516447
"Marco V.S., Taylor B., Wang Z., Elkhatib Y.","57195337351;57198303996;35111811300;55777338100;","Optimizing deep learning inference on embedded systems through adaptive model selection",2020,"ACM Transactions on Embedded Computing Systems","19","1","2","","",,18,"10.1145/3371154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079572857&doi=10.1145%2f3371154&partnerID=40&md5=6ba4311f3e3e98eb6624a6427b72952d","Osaka University, Japan; Lancaster University, United Kingdom; University of Leeds, United Kingdom","Marco, V.S., Osaka University, Japan; Taylor, B., Lancaster University, United Kingdom; Wang, Z., University of Leeds, United Kingdom; Elkhatib, Y., Lancaster University, United Kingdom","Deep neural networks (DNNs) are becoming a key enabling technique for many application domains. However, on-device inference on battery-powered, resource-constrained embedding systems is often infeasible due to prohibitively long inferencing time and resource requirements of many DNNs. Offloading computation into the cloud is often unacceptable due to privacy concerns, high latency, or the lack of connectivity. Although compression algorithms often succeed in reducing inferencing times, they come at the cost of reduced accuracy. This article presents a new, alternative approach to enable efficient execution of DNNs on embedded devices. Our approach dynamically determines which DNN to use for a given input by considering the desired accuracy and inference time. It employs machine learning to develop a low-cost predictive model to quickly select a pre-trained DNN to use for a given input and the optimization constraint. We achieve this first by offline training a predictive model and then using the learned model to select a DNN model to use for new, unseen inputs. We apply our approach to two representative DNN domains: image classification and machine translation. We evaluate our approach on a Jetson TX2 embedded deep learning platform and consider a range of influential DNN models including convolutional and recurrent neural networks. For image classification, we achieve a 1.8x reduction in inference time with a 7.52% improvement in accuracy over the most capable single DNN model. For machine translation, we achieve a 1.34x reduction in inference time over the most capable single model with little impact on the quality of translation. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Adaptive computing; Deep learning; Embedded systems","Computational linguistics; Computer aided language translation; Convolutional neural networks; Deep learning; Deep neural networks; Embedded systems; Image classification; Image enhancement; Recurrent neural networks; Adaptive computing; Adaptive model selection; Compression algorithms; Enabling techniques; Machine translations; Offloading computations; Predictive modeling; Resource requirements; Learning systems",,,,,"Engineering and Physical Sciences Research Council, EPSRC: EP/M01567X/1, EP/M015734/1","V. Sanz Marco and B. Taylor contributed equally to this research. A preliminary version of this article appeared in ACM LCTES 2018 [68]. This work was partly supported by the UK EPSRC under grants EP/M015734/1 (Dionasys) and EP/M01567X/1 (SANDeRs). Authors’ addresses: V. Sanz Marco, Osaka University, Japan; email: v.sanzmarco@cmc.osaka-u.ac.jp; B. Taylor and Y. Elkhatib, Lancaster University, United Kingdom; emails: {b.d.taylor, y.elkhatib}@lancaster.ac.uk; Z. Wang (corresponding author), University of Leeds, United Kingdom; email: z.wang5@leeds.ac.uk. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM. 1539-9087/2020/02-ART2 $15.00 https://doi.org/10.1145/3371154",,,,,,,,,,"Allaire, J.J., Eddelbuettel, D., Golding, N., Tang, Y., (2016) TensorFlow for R, , https://tensorflow.rstudio.com/; Amodei, D., Ananthanarayanan, S., Anubhai, R., Bai, J., Battenberg, E., Case, C., Casper, J., Catanzaro, B., Deep speech 2: End-to-end speech recognition in English and Mandarin (2016) Proceedings of ICML’16; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural Machine Translation by Jointly Learning to Align and Translate; Bai, J., Li, Y., Li, J., Jiang, Y., Xia, S., (2019) Rectified Decision Trees: Towards Interpretability, Compression and Empirical Soundness; Bhattacharya, S., Lane, N.D., Sparsification and separation of deep learning layers for constrained resource inference on wearables (2016) Proceedings of SenSys’16; Canziani, A., Paszke, A., Culurciello, E., (2016) An Analysis of Deep Neural Network Models for Practical Applications; Chen, D., Fang, J., Xu, C., Chen, S., Wang, Z., Characterizing scalability of sparse matrix-vector multiplications on phytium FT-2000+ (2019) International Journal of Parallel Programming, , https://link.springer.com/article/10.1007/s10766-019-00646-x, Retrieved December 14, 2019 from; Chen, S., Fang, J., Chen, D., Xu, C., Wang, Z., Adaptive optimization of sparse matrix-vector multiplication on emerging many-core architectures (2018) Proceedings of HPCC’18; Chen, W., Wilson, J.T., Tyree, S., Weinberger, K.Q., Chen, Y., Compressing neural networks with the hashing trick (2015) Proceedings of ICML’15; Cummins, C., Petoumenos, P., Wang, Z., Leather, H., End-to-end deep learning of optimization heuristics (2017) Proceedings of PACT’17; Cummins, C., Petoumenos, P., Wang, Z., Leather, H., Synthesizing benchmarks for predictive modeling (2017) Proceedings of CGO’17; Delimitrou, C., Kozyrakis, C., Quasar: Resource-efficient and QoS-aware cluster management (2014) Proceedings of ASPLOS’14; Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T., DeCAF: A deep convolutional activation feature for generic visual recognition (2014) Proceedings of ICML’14; Elkhatib, Y., Building cloud applications for challenged networks (2015) Embracing Global Computing in Emerging Economies. Communications in Computer and Information Science, 514, pp. 1-10. , Springer; Elkhatib, Y., Porter, B., Ribeiro, H.B., Zhani, M.F., Qadir, J., Riviere, E., On using micro-clouds to deliver the fog (2017) Internet Computing, 21 (2), pp. 8-15. , March 2017; Emani, M.K., Wang, Z., O’Boyle, M.F.P., Smart, adaptive mapping of parallelism in the presence of external workload (2013) Proceedings of CGO’13; Emani, M.K., O’Boyle, M., Celebrating diversity: A mixture of experts approach for runtime mapping in dynamic environments (2015) Proceedings PLDI’15; Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey, W., Krikun, M., (2016) Google’S Neural Machine Translation System: Bridging the Gap between Human and Machine Translation; Georgiev, P., Bhattacharya, S., Lane, N.D., Mascolo, C., Low-resource multi-task audio sensing for mobile and embedded devices via shared deep neural network representations (2017) Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technology, 1 (3). , 2017, Article; Grewe, D., Wang, Z., O’Boyle, M.F.P., A workload-aware mapping approach for data-parallel programs (2011) Proceedings of HiPEAC’11; Grewe, D., Wang, Z., O’Boyle, M.F.P., OpenCL task partitioning in the presence of GPU contention (2013) Proceedings of LCPC’13; O’Boyle, M.F.P., Wang, Z., Grewe, D., Portable mapping of data parallel programs to OpenCL for heterogeneous systems (2013) Proceedings of CGO’13; Guo, T., (2017) Towards Efficient Deep Inference for Mobile Applications; Han, S., Mao, H., Dally, W.J., (2015) Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding; Han, S., Pool, J., Tran, J., Dally, W.J., Learning both weights and connections for efficient neural network (2015) Proceedings of NIPS’15; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: Efficient inference engine on compressed deep neural network (2016) Proceedings of ISCA’16; Hassaballah, M., Abdelmgeid, A.A., Alshazly, H.A., Image features detection, description and matching (2016) Image Feature Detectors and Descriptors. Studies in Computational Intelligence, 630, pp. 11-45. , Springer; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of CVPR’16; He, K., Zhang, X., Ren, S., Sun, J., Identity mappings in deep residual networks (2016) Proceedings of ECCV’16; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications; Huynh, L.N., Lee, Y., Balan, R.K., DeepMon: Mobile GPU-based deep learning framework for continuous vision applications (2017) Proceedings of MobiSys’17; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) Proceedings of ICML’15; Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., Kalenichenko, D., Quantization and training of neural networks for efficient integer-arithmetic-only inference (2018) Proceedings of CVPR’18; Joulin, A., Grave, E., Bojanowski, P., Mikolov, T., Bag of tricks for efficient text classification (2017) Proceedings of EACL’17; Kang, Y., Hauswald, J., Gao, C., Rovinski, A., Mudge, T., Mars, J., Tang, L., Neurosurgeon: Collaborative intelligence between the cloud and mobile edge (2017) Proceedings of ASPLOS’17; Khoo, A., Marom, Y., Albrecht, D., Experiments with sentence classification (2006) Proceedings of the ALTA’06 Workshop; Kim, Y., (2014) Convolutional Neural Networks for Sentence Classification; Klein, A., Falkner, S., Bartels, S., Hennig, P., Hutter, F., (2016) Fast Bayesian Optimization of Machine Learning Hyperparameters on Large Datasets; Lane, N.D., Warden, P., The deep (learning) transformation of mobile and embedded computing (2018) Computer, 51 (5), pp. 12-16. , 2018; Oskouei, S.S.L., Golestani, H., Hashemi, M., Ghiasi, S., Cnndroid: GPU-accelerated execution of trained deep convolutional neural networks on Android (2016) Proceedings of MM’16; Lin, T.-Y., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., Perona, P., Dollar, P., Microsoft COCO: Common objects in context (2014) Proceedings of ECCV’14; Lui, M., Feature stacking for sentence classification in evidence-based medicine (2012) Proceedings of the ALTA’12 Workshop; Luong, M.-T., Brevdo, E., Zhao, R., (2017) Neural Machine Translation (Seq2seq) Tutorial, , https://github.com/tensorflow/nmt, Retrieved December 14, 2019 from; Magdy, W., Elkhatib, Y., Tyson, G., Joglekar, S., Sastry, N., Fake it till you make it: Fishing for catfishes (2017) Proceedings of ASONAM’17; Marco, V.S., Taylor, B., Porter, B., Wang, Z., Improving spark application throughput via memory aware task co-location: A mixture of experts approach (2017) Proceedings of Middleware’17; Marco, V.S., Taylor, B., Porter, B., Wang, Z., Improving spark application throughput via memory aware task co-location: A mixture of experts approach (2017) Proceedings of Middleware’17; Motamedi, M., Fong, D., Ghiasi, S., Machine intelligence on resource-constrained IoT devices: The case of thread granularity optimization for CNN inference (2017) ACM Transactions on Embedded Computing Systems, 16 (5). , 2017, Article; Ogilvie, W.F., Petoumenos, P., Wang, Z., Leather, H., Fast automatic heuristic construction using active learning (2014) Proceedings of LCPC’14; Ogilvie, W.F., Petoumenos, P., Wang, Z., Leather, H., Minimizing the cost of iterative compilation with active learning (2017) Proceedings of CGO’17; Ossia, S.A., Shamsabadi, A.S., Sajadmanesh, S., Taheri, A., Katevas, K., Rabiee, H.R., Lane, N.D., Haddadi, H., (2017) A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics; Parkhi, O.M., Vedaldi, A., Zisserman, A., Deep face recognition (2015) Proceedings of BMVC’15; Rallapalli, S., Qui, H., Bency, A.J., Karthikeyan, S., Govindan, R., Manjunath, B.S., Urgaonkar, R., (2016) Are Very Deep Neural Networks Feasible on Mobile Devices?, , Technical Report. University of Southern California; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., (2016) XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks; Ravi, S., (2015) ProjectionNet: Learning Efficient on-Device Deep Networks Using Neural Projections; Ren, J., Optimise web browsing on heterogeneous mobile platforms: A machine learning based approach (2017) Proceedings of INFOCOM’17; Ren, J., Gao, L., Wang, H., Wang, Z., Proteus: Network-aware web browsing on heterogeneous mobile systems (2018) Proceedings of CoNEXT’18; Rodríguez, S.S., Wang, L., Zhao, J.R., Mortier, R., Haddadi, H., (2017) Privacy-Preserving Personal Model Training; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., ImageNet large scale visual recognition challenge (2015) Proceedings of IJCV’15; Samreen, F., Daleel: Simplifying cloud instance selection using machine learning (2016) Proceedings of NOMS’16; Samreen, F., Elkhatib, Y., Rowe, M., Blair, G.S., (2019) Transferable Knowledge for Low-Cost Decision Making in Cloud Environments; Saunders, D., Stahlberg, F., de Gispert, A., Byrne, B., (2018) Multi-Representation Ensembles and Delayed SGD Updates Improve Syntax-Based NMT; Shafer, G., Vovk, V., A tutorial on conformal prediction (2008) Journal of Machine Learning Research, 9, pp. 371-421. , 2008; Silberman, N., Guadarrama, S., (2013) TensorFlow-Slim Image Classification Library, , https://github.com/tensorflow/models/tree/master/research/slim, Retrieved December 14, 2019 from; Song, M., Hu, Y., Chen, H., Li, T., Towards pervasive and user satisfactory CNN across GPU microarchitectures (2017) Proceedings of HPCA’17; Stahlberg, F., de Gispert, A., Byrne, B., (2018) The University of Cambridge’S Machine Translation Systems for WMT18; Sun, Y., Wang, X., Tang, X., Deep learning face representation by joint identification-verification (2014) Proceedings of NIPS’14; Taylor, B., Marco, V.S., Wang, Z., Adaptive optimization for Open CL programs on embedded heterogeneous systems (2017) Proceedings of LCTES’17; Taylor, B., Marco, V.S., Wolff, W., Elkhatib, Y., Wang, Z., Adaptive deep learning model selection on embedded systems (2018) Proceedings of LCTES’18, pp. 31-43. , ACM, New York, NY; Teerapittayanon, S., McDanel, B., Kung, H.T., Distributed deep neural networks over the cloud, the edge and end devices (2017) Proceedings of ICDCS’17; Tournavitis, G., Wang, Z., Franke, B., O’Boyle, M.F.P., Towards a holistic approach to auto-parallelization: Integrating profile-driven parallelism detection and machine-learning based mapping (2009) Proceedings of PLDI’09; (2015) EMNLP 2015 Tenth Workshop on Statistical Machine Translation, , https://www.statmt.org/wmt15/translation-task.html, Shared Task: Machine Translation. Retrieved December 14, 2019 from; Usama, M., Qadir, J., Raza, A., Arif, H., Yau, K.-L.A., Elkhatib, Y., Hussain, A., Al-Fuqaha, A., (2017) Unsupervised Machine Learning for Networking: Techniques, Applications and Research Challenges; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., (2017) Attention Is All You Need; Wang, Z., Grewe, D., O’Boyle, M.F.P., Automatic and portable mapping of data parallel programs to OpenCL for GPU-based heterogeneous systems (2015) ACM Transactions on Architecture and Code Optimization, 11 (4). , 2015, Article; Wang, Z., Tournavitis, G., Franke, B., O’Boyle, M.F.P., Integrating profile-driven parallelism detection and machine-learning-based mapping (2014) ACM Transactions on Architecture and Code Optimization, 11 (1). , 2014, Article; Wang, Z., O’Boyle, M., Machine learning in compiler optimization (2018) Proceedings of the IEEE, 106 (11), pp. 1879-1901. , 2018; Wang, Z., O’Boyle, M.F.P., Mapping parallelism to multi-cores: A machine learning based approach (2009) Proceedings of PPoPP’09; Wang, Z., O’Boyle, M.F.P., Partitioning streaming parallelism for multi-cores: A machine learning based approach (2010) Proceedings of PACT’10; Wang, Z., O’Boyle, M.F.P., Using machine learning to partition streaming programs (2013) ACM Transactions on Architecture and Code Optimization, 10 (3). , 2013, Article; Zhang, J., Tang, Z., Li, M., Fang, D., Nurmi, P., Wang, Z., CrossSense: Towards cross-site and large-scale WiFi sensing (2018) Proceedings of MobiCom’18; Zhang, P., Fang, J., Tang, T., Yang, C., Wang, Z., Auto-tuning streamed applications on Intel Xeon Phi (2018) Proceedings of IPDPS’18",,,,"Association for Computing Machinery",,,,,15399087,,,,"English","ACM Trans. Embedded Comput. Syst.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85079572857
"Yan H., Cherian H.R., Ahn E.C., Qian X., Duan L.","57195980119;57204508375;56583724700;57194286286;26435787800;","ICELIA: A Full-Stack Framework for STT-MRAM-Based Deep Learning Acceleration",2020,"IEEE Transactions on Parallel and Distributed Systems","31","2","8812913","408","422",,9,"10.1109/TPDS.2019.2937517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078311506&doi=10.1109%2fTPDS.2019.2937517&partnerID=40&md5=e67c3c0511f051c7e5c375bcefa22b6b","Samsung, Austin, TX  78746, United States; Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX  78249, United States; Ming Hsieh Department of Electrical Engineering and the Department of Computer Science, University of Southern California, Los Angeles, CA  90089, United States; Computing Technology Lab, Alibaba DAMO Academy, Sunnyvale, CA  94085, United States","Yan, H., Samsung, Austin, TX  78746, United States; Cherian, H.R., Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX  78249, United States; Ahn, E.C., Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX  78249, United States; Qian, X., Ming Hsieh Department of Electrical Engineering and the Department of Computer Science, University of Southern California, Los Angeles, CA  90089, United States; Duan, L., Computing Technology Lab, Alibaba DAMO Academy, Sunnyvale, CA  94085, United States","A large variety of applications rely on deep learning to process big data, learn sophisticated features, and perform complicated tasks. Utilizing emerging non-volatile memory (NVM)'s unique characteristics, including the crossbar array structure and gray-scale cell resistances, to perform neural network (NN) computation is a well-studied approach in accelerating deep learning applications. Compared to other NVM technologies, STT-MRAM has its unique advantages in performing NN computation. However, the state-of-the-art research have not utilized STT-MRAM for deep learning acceleration due to its device- and architecture-level challenges. Consequently, this paper enables STT-MRAM, for the first time, as an effective and practical deep learning accelerator. In particular, it proposes a full-stack framework iCELIA spanning multiple design levels, including device-level fabrication, circuit-level enhancements, architecture-level synaptic weight quantization, and system-level accelerator design. The primary contributions of iCELIA over our prior work CELIA include a new non-uniform weight quantization scheme and much enhanced accelerator system design. The proposed framework significantly mitigates the model accuracy loss due to reduced data precision in a cohesive manner, constructing a comprehensive STT-MRAM accelerator system for fast NN computation with high energy efficiency and low cost. © 1990-2012 IEEE.","deep learning acceleration; device and architecture co-design; processing-in-memory; STT-MRAM","Acceleration; Computational efficiency; Digital storage; Energy efficiency; Magnetic recording; Magnetic storage; Memory architecture; MRAM devices; Network architecture; Co-designs; Emerging non-volatile memory; High energy efficiency; Neural network (nn); Primary contribution; Processing in memory; Quantization schemes; STT-MRAM; Deep learning",,,,,"National Science Foundation, NSF: CCF-1566158; Office of the Executive Vice President for Research and Partnerships, Purdue University, EVPRP","This work is supported in part by National Science Foundation (NSF) under Grant CCF-1566158, the University of Texas System Faculty Science and Technology Acquisition and Retention (STARs) fund, and the GREAT seed grant from UTSA Office of Vice President for Research, Economic Development and Knowledge Enterprise.",,,,,,,,,,"Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252. , Dec; Sze, V., Chen, Y.H., Yang, T.J., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. IEEE, 105 (12), pp. 2295-2329. , Dec; Chen, Y., Luo, T., Liu, S., Zhang, S., He, L., Wang, J., Li, L., Temam, O., Dadiannao: A machine-learning supercomputer (2014) Proc. Int. Symp. Microarchitecture, pp. 609-622; Lee, D., Kim, Y., Seshadri, V., Liu, J., Subramanian, L., Mutlu, O., Tiered-latency dram: A low latency and low cost dram architecture (2013) Proc. Int. Symp. High Perform. Comput. Archit., pp. 615-626; Kang, U., Soo Yu, H., Park, C., Zheng, H., Halbert, J., Bains, K., Jang, S., Choi, J.S., Co-architecting controllers and dram to enhance dram process scaling (2014) the Memory Forum; Lee, B.C., Ipek, E., Mutlu, O., Burger, D., Architecting phase change memory as a scalable dram alternative (2009) Proc. 36th Annu. Int. Symp. Comput. Architect., pp. 2-13; Huai, Y., Spin-transfer torque mram (stt-mram): Challenges and prospects (2008) AAPPS Bull., 18 (6); Wong, H.S.P., Lee, H.Y., Yu, S., Chen, Y.S., Wu, Y., Chen, P.S., Lee, B., Tsai, M.J., Metal-oxide rram (2012) Proc. IEEE, 100 (6), pp. 1951-1970. , Jun; Chi, P., Li, S., Xu, C., Zhang, T., Zhao, J., Liu, Y., Wang, Y., Xie, Y., Prime: A novel processing-in-memory architecture for neural network computation in reram-based main memory (2016) Proc. Int. Symp. Comput. Archit., pp. 27-39; Shafiee, A., Nag, A., Muralimanohar, N., Balasubramonian, R., Strachan, J.P., Hu, M., Williams, R.S., Srikumar, V., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) Proc. Int. Symp. Comput. Archit., pp. 14-26; Song, L., Qian, X., Li, H., Chen, Y., Pipelayer: A pipelined reram-based accelerator for deep learning (2017) Proc. Int. Symp. High Perform. Comput. Archit., pp. 541-552; Yan, H., Cherian, H.R., Ahn, E.C., Duan, L., Celia: A device and architecture co-design framework for stt-mram-based deep learning acceleration (2018) Proc. ACM Int. Conf. Supercomputing, pp. 149-159; Ramasubramanian, S.G., Venkatesan, R., Sharad, M., Roy, K., Raghunathan, A., Spindle: Spintronic deep learning engine for large-scale neuromorphic computing (2014) Proc. Int. Symp. Low Power Electron. Des., pp. 15-20; Qiu, J., Wang, J., Yao, S., Guo, K., Li, B., Zhou, E., Yu, J., Yang, H., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proc. ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays, pp. 26-35; Song, M., Hu, Y., Chen, H., Li, T., Towards pervasive and user satisfactory cnn across GPU microarchitectures (2017) Proc. Int. Symp. High Perform. Comput. Archit., pp. 1-12; Chen, T., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., Temam, O., Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning (2014) Proc. Int. Conf. Architectural Support Program. Lang. Operating Syst., pp. 269-284; Chen, Y.H., Emer, J., Sze, V., Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks (2016) Proc. 43rd Int. Symp. Comput. Archit., pp. 367-379; Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Yoon, D.H., In-datacenter performance analysis of a tensor processing unit (2017) Proc. 44th Annu. Int. Symp. Comput.Archit., pp. 1-12; Kang, M.J., Park, T.J., Kwon, Y.W., Ahn, D.H., Kang, Y.S., Jeong, H., Ahn, S.J., Chung, C.H., Pram cell technology and characterization in 20nm node size (2011) Proc. Int. Electron Dev. Meet., pp. 311-314; Hsu, C.W., Wang, I.T., Lo, C.L., Chiang, M.C., Jang, W.Y., Lin, C.H., Hou, T.H., Self-rectifying bipolar taox/tio2 rramwith superior endurance over 1012 cycles for 3d high-density storage-class memory (2013) Proc. Symp.VLSI Technol., pp. T166-T167; Kan, J.J., Park, C., Ching, C., Ahn, J., Xue, L., Wang, R., Kontos, A., Kang, S.H., Systematic validation of 2x nm diameter perpendicular mtj arrays and mgo barrier for sub-10 nm embedded stt-mram with practically unlimited endurance (2016) Proc. IEEE Int. Electron Dev. Meet., pp. 2741-2744; Grollier, J., Querlioz, D., Stiles, M.D., Spintronic nanodevices for bioinspired computing (2016) Proc. IEEE, 104 (10), pp. 2024-2039. , Oct; Schuman, C.D., Potok, T.E., Patton, R.M., Birdwell, J.D., Dean, M.E., Rose, G.S., Plank, J.S., (2017) A Survey of Neuromorphic Computing and Neural Networks in Hardware, , http://arxiv.org/abs/1705.06963, CoRR abs/1705.06963; Hilson, G., Everspin aims mram at ssd storage tiers (2016) Proc. EETimes, , https://www.eetimes.com/document.asp?doc_id=1329477#, Apr; Ikeda, S., Hayakawa, J., Ashizawa, Y., Lee, Y.M., Miura, K., Hasegawa, H., Tsunoda, M., Ohno, H., Tunnel magnetoresistance of 604% at 300k by suppression of ta diffusion in CoFeB/MgO/CoFeB pseudo-spin-valves annealed at high temperature (2008) Appl. Phys. Lett., 93 (8); https://en.wikipedia.org/wiki/Fixed-point_arithmetic, Fixed-point arithmetic; Lequeux, S., Sampaio, J., Cros, V., Yakushiji, K., Fukushima, A., Matsumoto, R., Kubota, H., Grollier, J., A magnetic synapse: Multilevel spin-torque memristor with perpendicular anisotropy (2016) Sci. Rep., 6 (31510). , Aug; Lee, E.H., Miyashita, D., Chai, E., Murmann, B., Wong, S.S., Lognet: Energy-efficient neural networks using logarithmic computation (2017) Proc. Int. Conf. Acoust. Speech Signal Process., pp. 5900-5904; Li, F., Liu, B., (2016) Ternary Weight Networks, , http://arxiv.org/abs/1605.04711, CoRR abs/ 1605.04711; Lloyd, S., Least squares quantization in pcm (1982) IEEE Trans. Inf. Theory, 28 (2), pp. 129-137. , Mar; Jenks, G.F., The data model concept in statistical mapping (1967) Int. Yearbook Cartography, 7, pp. 186-190; Rosenblatt, M., Remarks on some nonparametric estimates of a density function (1956) Ann.Math. Statist., 27 (3), pp. 832-837; https://en.wikipedia.org/wiki/Expectation?maximization_algorithm, Expectation?maximization algorithm; Wang, H., Song, M., Ckmeans.1d.dp: Optimal k-means clustering in one dimension by dynamic programming (2011) R J., 3 (2), pp. 29-33; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2016) Proc. Int. Conf. Learn. Representations; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. 22nd ACM Int. Conf. Multimedia, pp. 675-678; Sun, G., Dong, X., Xie, Y., Li, J., Chen, Y., A novel architecture of the 3d stacked mram l2 cache for cmps (2009) Proc. IEEE 15th Int. Symp. High Perform. Comput. Archit., pp. 239-249; Kultursay, E., Kandemir, M., Sivasubramaniam, A., Mutlu, O., Evaluating STT-RAM as an energy-efficient main memory alternative (2013) Proc. IEEE Int. Symp. Perform. Anal. Syst. Softw., pp. 256-267; Yan, H., Jiang, L., Duan, L., Lin, W.-M., John, E., Flowpap and flowrer: Improving energy efficiency and performance for sttmram-based handheld devices under read disturbance (2017) ACM Trans. Embedded Comput. Syst.-Special Issue ESWEEK, 16 (5 s); Song, L., Wang, Y., Han, Y., Li, H., Cheng, Y., Li, X., STT-RAM buffer design for precision-tunable general-purpose neural network accelerator (2017) IEEE Trans. Very Large Scale Integr. Syst., 25 (4), pp. 1285-1296. , Apr; Smullen, C.W., Mohan, V., Nigam, A., Gurumurthi, S., Stan, M.R., Relaxing non-volatility for fast and energy-efficient stt-ram caches (2011) Proc. Int. Symp. High Perform. Comput. Archit., pp. 50-61; Sun, Z., Bi, X., Li, H.H., Wong, W.-F., Ong, Z.-L., Zhu, X., Wu, W., Multi retention level STT-RAM cache designs with a dynamic refresh scheme (2011) Proc. Int. Symp. Microarchitecture, pp. 329-338; Jog, A., Mishra, A., Xu, C., Xie, Y., Narayanan, V., Iyer, R., Das, C., Cache revive: Architecting volatile STT-RAM caches for enhanced performance in cmps (2012) Proc. ACM/EDAC/IEEE Des. Autom. Conf., pp. 243-252; http://caffe.berkeleyvision.org/model_zoo.html, Caffe model zoo; Rosenfeld, P., Cooper-Balis, E., Jacob, B., Dramsim2: A cycle accurate memory system simulator (2011) Comput. Archit. Lett., 10 (1), pp. 16-19. , Jan.-Jun; Dong, X., Xu, C., Xie, Y., Jouppi, N.P., Nvsim: A circuit-level performance, energy, and area model for emerging nonvolatile memory (2012) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst., 31 (7), pp. 994-1007. , Jul; Chung, J., Park, J., Ghosh, S., Domain wall memory based convolutional neural networks for bit-width extendability and energy-efficiency (2016) Proc. Int. Symp. Low Power Electron. Des., pp. 332-337; Fan, D., Angizi, S., Energy efficient in-memory binary deep neural network accelerator with dual-mode SOT-MRAM (2017) Proc. Int. Conf. Comput. Des., pp. 609-612; Guo, Q., Guo, X., Patel, R., Ipek, E., Friedman, E.G., AC-DIMM: Associative computing with stt-mram (2013) Proc. Int. Symp. Comput. Archit., pp. 189-200; Aga, S., Jeloka, S., Subramaniyan, A., Narayanasamy, S., Blaauw, D., Das, R., Compute caches (2017) Proc. Int. Symp. High Perform. Comput. Archit., pp. 481-492","Duan, L.; Computing Technology Lab, United States; email: lide.duan@alibaba-inc.com",,,"IEEE Computer Society",,,,,10459219,,ITDSE,,"English","IEEE Trans Parallel Distrib Syst",Article,"Final","",Scopus,2-s2.0-85078311506
"Lee S., Joo S., Ahn H.K., Jung S.-O.","57225122904;57220639522;57202499921;7403677250;","CNN acceleration with hardware-efficient dataflow for super-resolution",2020,"IEEE Access","8",,,"187754","187765",,3,"10.1109/ACCESS.2020.3031055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102880317&doi=10.1109%2fACCESS.2020.3031055&partnerID=40&md5=b63c84925a56860d4236728fa281f7bd","School of Electrical and Electronic Engineering, Yonsei University, Seoul, 03722, South Korea","Lee, S., School of Electrical and Electronic Engineering, Yonsei University, Seoul, 03722, South Korea; Joo, S., School of Electrical and Electronic Engineering, Yonsei University, Seoul, 03722, South Korea; Ahn, H.K., School of Electrical and Electronic Engineering, Yonsei University, Seoul, 03722, South Korea; Jung, S.-O., School of Electrical and Electronic Engineering, Yonsei University, Seoul, 03722, South Korea","The convolutional neural network (CNN)-based super-resolution (SR) has shown outstanding performance in the field of computer vision. The implementation of inference hardware for CNN-based SR has suffered from the intensive computation with severely unbalanced computation load among layers. Various light-weighted SR networks have been researched with little performance degradation. However, the hardware-efficient dataflow is also required to efficiently accelerate inference hardware within limited resources. In this article, we propose the hardware-efficient dataflow of CNN-based SR that reduces computation load by increasing data reuse and increases process element (PE) utilization by balancing the computation load among layers for high throughput. In the proposed dataflow, row-wise pixels in the receptive field are computed by circularly shifting memory addresses to maximize data reuse. The partial convolution is exploited in a layer-based pipeline architecture to relieve intensive computation in a single pipeline stage. The delay-balancing with adjusting parallelism is employed for balancing computations precisely in the overall layers. Furthermore, the inference hardware of CNN-based SR is implemented for 4K ultrahigh definition at 60 fps on a field-programmable gate array (FPGA). For hardware-friendly computation, the quantization of activation and weight is adopted. The proposed hardware shows an average peak signal-to-noise ratio of 36.42 dB in the Set-5 dataset with a memory usage of 53 KB and an average PE utilization of 76.7% in the overall layers. Thus, it achieves the lowest memory usage and highest PE utilization compared with other inference hardware for CNN-based SR. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","4K ultrahigh definition; Convolutional neural network; Dataflow; Field-programmable gate array; Inference hardware; Process element utilization; Super-resolution","Convolution; Convolutional neural networks; Field programmable gate arrays (FPGA); Image coding; Optical resolving power; Pipelines; Signal to noise ratio; Computation loads; Peak signal to noise ratio; Performance degradation; Pipeline architecture; Process elements; Receptive fields; Super resolution; Ultra-high definitions; Computer hardware",,,,,"SRFC-IT1802-06","This work was supported by the Samsung Research Funding and Incubation Center for Future Technology under Grant SRFC-IT1802-06.",,,,,,,,,,"Sakurai, M., Sakuta, Y., Watanabe, M., Goto, T., Hirano, S., Super-resolution through non-linear enhancement filters (2013) Proc. IEEE Int. Conf. Image Process., pp. 854-858. , Sep; Choi, J.-S., Kim, M., Single image super-resolution using global regression based on multiple local linear mappings (2017) IEEE Trans. Image Process., 26 (3), pp. 1300-1314. , Mar; Dong, C., Loy, C.C., He, K., Tang, X., Learning a deep convolutional network for image super-resolution (2014) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 184-199. , Cham, Switzerland: Springer; Dong, C., Loy, C.C., He, K., Tang, X., Image super-resolution using deep convolutional networks (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (2), pp. 295-307. , Feb; Kim, J., Lee, J.K., Lee, K.M., Accurate image super-resolution using very deep convolutional networks (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1646-1654. , Jun; Lim, B., Son, S., Kim, H., Nah, S., Lee, K.M., Enhanced deep residual networks for single image super-resolution (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 1132-1140. , Jul; Dong, C., Loy, C.C., Tang, X., Accelerating the super-resolution convolutional neural network (2016) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 391-407. , Cham, Switzerland: Springer; Shi, W., Caballero, J., Huszar, F., Totz, J., Aitken, A.P., Bishop, R., Rueckert, D., Wang, Z., Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1874-1883. , Jun; Shawahna, A., Sait, S.M., El-Maleh, A., FPGA-based accelerators of deep learning networks for learning and classification: A review (2019) IEEE Access, 7, pp. 7823-7859; Hailesellasie, M.T., Hasan, S.R., Mulnet: A flexible CNN processor with higher resource utilization efficiency for constrained devices (2019) IEEE Access, 7, pp. 47509-47524; Shen, Y., Han, T., Yang, Q., Yang, X., Wang, Y., Li, F., Wen, H., CS-CNN: Enabling robust and efficient convolutional neural networks inference for Internet-of-Things applications (2018) IEEE Access, 6, pp. 13439-13448; Shu, G., Liu, W., Zheng, X., Li, J., IF-CNN: Image-aware inference framework for CNN with the collaboration of mobile devices and cloud (2018) IEEE Access, 6, pp. 68621-68633; Li, Y., Du, Y., A novel software-defined convolutional neural networks accelerator (2019) IEEE Access, 7, pp. 177922-177931; Li, S., Luo, Y., Sun, K., Yadav, N., Choi, K.K., A novel FPGA accelerator design for real-time and ultra-low power deep convolutional neural networks compared with titan X GPU (2020) IEEE Access, 8, pp. 105455-105471; Hatcher, W.G., Yu, W., A survey of deep learning: Platforms, applications and emerging research trends (2018) IEEE Access, 6, pp. 24411-24432; Lu, W., Yan, G., Li, J., Gong, S., Han, Y., Li, X., FlexFlow: A flexible dataflow accelerator architecture for convolutional neural networks (2017) Proc. IEEE Int. Symp. High Perform. Comput. Archit. (HPCA), pp. 553-564. , Feb; Venieris, S.I., Bouganis, C.-S., FPGAconvNet: A framework for mapping convolutional neural networks on FPGAs (2016) Proc. IEEE 24th Annu. Int. Symp. Field-Program. Custom Comput. Mach. (FCCM), pp. 40-47. , May; Choi, W., Choi, K., Park, J., Low cost convolutional neural network accelerator based on bi-directional filtering and bit-width reduction (2018) IEEE Access, 6, pp. 14734-14746; Park, C., Park, S., Park, C.S., Roofline-Model-Based design space exploration for dataflow techniques of CNN accelerators (2020) IEEE Access, 8, pp. 172509-172523; Hu, X., Zeng, Y., Li, Z., Zheng, X., Cai, S., Xiong, X., A resources-efficient configurable accelerator for deep convolutional neural networks (2019) IEEE Access, 7, pp. 72113-72124; Alwani, M., Chen, H., Ferdman, M., Milder, P., Fused-layer CNN accelerators (2016) Proc. 49th Annu. IEEE/ACM Int. Symp. Microarchitecture (MICRO), pp. 1-12. , Oct; Chen, Y.-H., Emer, J., Sze, V., Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit. (ISCA), pp. 367-379. , Jun; Lee, J., Park, I.-C., High-performance low-area video up-scaling architecture for 4-K UHD video (2017) IEEE Trans. Circuits Syst. II, Exp. Briefs, 64 (4), pp. 437-441. , Apr; Perez-Pellitero, E., Salvador, J., Ruiz-Hidalgo, J., Rosenhahn, B., Accelerating super-resolution for 4K upscaling (2015) Proc. IEEE Int. Conf. Consum. Electron. (ICCE), pp. 317-320. , Jan; Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. IEEE, 105 (12), pp. 2295-2329. , Dec; Yang, M.-C., Liu, K.-L., Chien, S.-Y., A real-time FHD learning-based super-resolution system without a frame buffer (2017) IEEE Trans. Circuits Syst. II, Exp. Briefs, 64 (12), pp. 1407-1411. , Dec; Kim, Y., Choi, J.-S., Kim, M., 2X super-resolution hardware using edge-orientation-based linear mapping for real-time 4K UHD 60 fps video applications (2018) IEEE Trans. Circuits Syst. II, Exp. Briefs, 65 (9), pp. 1274-1278. , Sep; Kim, Y., Choi, J.-S., Kim, M., A real-time convolutional neural network for super-resolution on FPGA with applications to 4K UHD 60 fps video services (2019) IEEE Trans. Circuits Syst. Video Technol., 29 (8), pp. 2521-2534. , Aug; Lee, J., Shin, D., Lee, J., Lee, J., Kang, S., Yoo, H.-J., A full HD 60 fps CNN super resolution processor with selective caching based layer fusion for mobile devices (2019) Proc. Symp. VLSI Circuits, pp. C302-C303. , Jun; Chakradhar, S., Sankaradas, M., Jakkula, V., Cadambi, S., A dynamically configurable coprocessor for convolutional neural networks (2010) Proc. 37th Annu. Int. Symp. Comput. Archit. (ISCA), pp. 247-257. , Saint-Malo, France; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , http://arxiv.org/abs/1704.04861, Apr; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., Optimizing the convolution operation to accelerate deep neural networks on FPGA (2018) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 26 (7), pp. 1354-1367. , Jul; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst. (NIPS), pp. 1097-1105; Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.-L.-A., Low-complexity single-image super-resolution based on nonnegative neighbor embedding (2012) Proc. Brit. Mach. Vis. Conf. Swansea, p. 135. , U.K.: BMVA Press; Zeyde, R., Elad, M., Protter, M., On single image scale-up using sparse-representations (2012) Proc. Int. Conf. Curves Surf., pp. 711-730. , Berlin, Germany: Springer; Huang, J.-B., Singh, A., Ahuja, N., Single image super-resolution from transformed self-exemplars (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 5197-5206. , Jun; Martin, D., Fowlkes, C., Tal, D., Malik, J., A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics (2001) Proc. 8th IEEE Int. Conf. Comput. Vis. (ICCV), 2, pp. 416-423. , Jul","Jung, S.-O.; School of Electrical and Electronic Engineering, South Korea; email: sjung@yonsei.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85102880317
"Huang Z., Xie Z., Jin L., Li Y.","57193226888;57217060348;7403329173;57193230951;","A Gradient-Based Recurrent Neural Network for Visual Servoing of Robot Manipulators with Acceleration Command",2020,"Complexity","2020",,"2305459","","",,,"10.1155/2020/2305459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099305451&doi=10.1155%2f2020%2f2305459&partnerID=40&md5=15915b0a7585caefd10bfb5f404ef859","Guangdong Provincial Engineering Technology Research Center for Sports Assistive Devices, Guangzhou Sport University, Guangzhou, China; School of Information Science and Engineering, Lanzhou University, Lanzhou, China","Huang, Z., Guangdong Provincial Engineering Technology Research Center for Sports Assistive Devices, Guangzhou Sport University, Guangzhou, China; Xie, Z., School of Information Science and Engineering, Lanzhou University, Lanzhou, China; Jin, L., Guangdong Provincial Engineering Technology Research Center for Sports Assistive Devices, Guangzhou Sport University, Guangzhou, China, School of Information Science and Engineering, Lanzhou University, Lanzhou, China; Li, Y., Guangdong Provincial Engineering Technology Research Center for Sports Assistive Devices, Guangzhou Sport University, Guangzhou, China","Recent decades have witnessed the rapid evolution of robotic applications and their expansion into a variety of spheres with remarkable achievements. This article researches a crucial technique of robot manipulators referred to as visual servoing, which relies on the visual feedback to respond to the external information. In this regard, the visual servoing issue is tactfully transformed into a quadratic programming problem with equality and inequality constraints. Differing from the traditional methods, a gradient-based recurrent neural network (GRNN) for solving the visual servoing issue is newly proposed in this article in the light of the gradient descent method. Then, the stability proof is presented in theory with the pixel error convergent exponentially to zero. Specifically speaking, the proposed method is able to impel the manipulator to approach the desired static point while maintaining physical constraints considered. After that, the feasibility and superiority of the proposed GRNN are verified by simulative experiments. Significantly, the proposed visual servo method can be leveraged to medical robots and rehabilitation robots to further assist doctors in treating patients remotely. © 2020 Zhiguan Huang et al.",,"Constraint theory; Flexible manipulators; Gradient methods; Industrial manipulators; Medical robotics; Modular robots; Patient rehabilitation; Quadratic programming; Robot applications; Visual communication; Visual servoing; External informations; Gradient Descent method; Inequality constraint; Physical constraints; Quadratic programming problems; Rehabilitation robot; Robot manipulator; Robotic applications; Recurrent neural networks",,,,,,,,,,,,,,,,"Shen, Z., Elibol, A., Chong, N.Y., Understanding nonverbal communication cues of human personality traits in human-robot interaction (2020) IEEE/CAA Journal of Automatica Sinica, 7 (6), pp. 1465-1477; Li, T., Zhao, H., Chang, Y., Delay-dependent stability in uncalibrated image-based dynamic visual servoing robotic system (2018) Complexity, 2018, p. 14. , 1360874 2-s2.0-85056253222; Yang, C., Chen, C., He, W., Cui, R., Li, Z., Robot learning system based on adaptive neural control and dynamic movement primitives (2019) IEEE Transactions on Neural Networks and Learning Systems, 30 (3), pp. 777-787; Jin, L., Li, S., Xiao, L., Lu, R., Liao, B., Cooperative motion generation in a distributed network of redundant robot manipulators with noises (2018) IEEE Transactions on Systems, Man, and Cybernetics: Systems, 48 (10), pp. 1715-1724. , 2-s2.0-85018962615; Xie, Z., Jin, L., Du, X., Xiao, X., Li, H., Li, S., On generalized RMP scheme for redundant robot manipulators aided with dynamic neural networks and nonconvex bound constraints (2019) IEEE Transactions on Industrial Informatics, 15 (9), pp. 5172-5181; Zhang, Y., Li, S., Kadry, S., Liao, B., Recurrent neural network for kinematic control of redundant manipulators with periodic input disturbance and physical constraints (2019) IEEE Transactions on Cybernetics, 49 (12), pp. 4194-4205. , 2-s2.0-85052552549; Zhang, J., Jin, L., Cheng, L., RNN for perturbed manipulability optimization of manipulators based on a distributed scheme: a game-theoretic perspective (2020) IEEE Transactions on Neural Networks and Learning Systems, 31 (12), p. 5116; Jin, L., Li, S., La, H.M., Luo, X., Manipulability optimization of redundant manipulators using dynamic neural networks (2017) IEEE Transactions on Industrial Electronics, 64 (6), pp. 4710-4720. , 2-s2.0-85020234754; Yang, C., Zeng, C., Cong, Y., Wang, N., Wang, M., A learning framework of adaptive manipulative skills from human to robot (2019) IEEE Transactions on Industrial Informatics, 15 (2), pp. 1153-1161. , 2-s2.0-85045347550; Huang, H., Zhang, T., Yang, C., Chen, C.L.P., Motor learning and generalization using broad learning adaptive neural control (2020) IEEE Transactions on Industrial Electronics, 67 (10), pp. 8608-8617; Huang, D., Yang, C., Pan, Y., Cheng, L., Composite learning enhanced neural control for robot manipulator with output error constraints (2021) IEEE Transactions on Industrial Informatics, 17 (1), pp. 209-218; Kong, Y., Zhang, R., Jiang, Y., Xia, X., A repeatable optimization for kinematic energy system with its mobile manipulator application (2019) Complexity, 2019, p. 16. , 8642027 2-s2.0-85071232368; Zhang, H., Fang, H., Zhang, D., Luo, X., Zou, Q., Adaptive fuzzy sliding mode control for a 3-DOF parallel manipulator with parameters uncertainties (2020) Complexity, 2020, p. 16. , 2565316; Pradhan, S.K., Subudhi, B., Position control of a flexible manipulator using a new nonlinear self-tuning PID controller (2020) IEEE/CAA Journal of Automatica Sinica, 7 (1), pp. 82-95; Jin, L., Zhang, Y., G2-type SRMPC scheme for synchronous manipulation of two redundant robot arms (2015) IEEE Transactions on Cybernetics, 45 (2), pp. 153-164. , 2-s2.0-85027943391; Yang, C., Peng, G., Li, Y., Cui, R., Cheng, L., Li, Z., Neural networks enhanced adaptive admittance control of optimized robot-environment interaction (2019) IEEE Transactions on Cybernetics, 49 (7), pp. 2568-2579. , 2-s2.0-85046737960; Zhang, Z., Zhang, Y., Variable joint-velocity limits of redundant robot manipulators handled by quadratic programming (2013) IEEE/ASME Transactions on Mechatronics, 18 (2), pp. 674-686. , 2-s2.0-84889101849; Li, S., Zhang, Y., Jin, L., Kinematic control of redundant manipulators using neural networks (2017) IEEE Transactions on Neural Networks and Learning Systems, 28 (10), pp. 2243-2254. , 2-s2.0-84976328890; Zhang, Y., Li, S., Zhou, X., Recurrent-neural-network-based velocity-level redundancy resolution for manipulators subject to a joint acceleration limit (2019) IEEE Transactions on Industrial Electronics, 66 (5), pp. 3573-3582. , 2-s2.0-85049672530; Boyd, S., Vandenberghe, L., (2004) Convex Optimization, , Cambridge, UK Cambridge University Press; Anwar, A., Lin, W., Deng, X., Qiu, J., Gao, H., Quality inspection of remote radio units using depth-free image-based visual servo with acceleration command (2019) IEEE Transactions on Industrial Electronics, 66 (10), pp. 8214-8223. , 2-s2.0-85057366395; Ke, F., Li, Z., Yang, C., Robust tube-based predictive control for visual servoing of constrained differential-drive mobile robots (2018) IEEE Transactions on Industrial Electronics, 65 (4), pp. 3437-3446. , 2-s2.0-85030705703; Tsai, D., Dansereau, D.G., Peynot, T., Corke, P., Image-based visual servoing with light field cameras (2017) IEEE Robotics and Automation Letters, 2 (2), pp. 912-919. , 2-s2.0-85044063592; Osa, T., Staub, C., Knoll, A., Framework of automatic robot surgery system using visual servoing, , Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems October 2010 Taipei, Taiwan; Li, W., Chiu, P.W.Y., Li, Z., An accelerated finite-time convergent neural network for visual servoing of a flexible surgical endoscope with physical and RCM constraints (2020) IEEE Transactions on Neural Networks and Learning Systems, 31 (12), p. 5272; Keshmiri, M., Wen-Fang Xie, W., Mohebbi, A., Augmented image-based visual servoing of a manipulator using acceleration command (2014) IEEE Transactions on Industrial Electronics, 61 (10), pp. 5444-5452. , 2-s2.0-84900528145; Van, M., Ge, S.S., Ceglarek, D., Fault estimation and accommodation for virtual sensor bias fault in image-based visual servoing using particle filter (2018) IEEE Transactions on Industrial Informatics, 14 (4), pp. 1312-1322. , 2-s2.0-85023166928; Cigliano, P., Lippiello, V., Ruggiero, F., Siciliano, B., Robotic ball catching with an eye-in-hand single-camera system (2015) IEEE Transactions on Control Systems Technology, 23 (5), pp. 1657-1671. , 2-s2.0-84939496539; Kebria, P.M., Khosravi, A., Salaken, S.M., Nahavandi, S., Deep imitation learning for autonomous vehicles based on convolutional neural networks (2020) IEEE/CAA Journal of Automatica Sinica, 7 (1), pp. 136-149; Huang, Y., Na, J., Wu, X., Gao, G., Approximation-free control for vehicle active suspensions with hydraulic actuator (2018) IEEE Transactions on Industrial Electronics, 65 (9), pp. 7258-7267. , 2-s2.0-85041281353; Li, Y., Li, S., Hannaford, B., A model-based recurrent neural network with randomness for efficient control with applications (2019) IEEE Transactions on Industrial Informatics, 15 (4), pp. 2054-2063. , 2-s2.0-85053115138; Qi, Y., Jin, L., Wang, Y., Xiao, L., Zhang, J., Complex-valued discrete-time neural dynamics for perturbed time-dependent complex quadratic programming with applications (2020) IEEE Transactions on Neural Networks and Learning Systems, 31 (9), pp. 3555-3569; StanimiroviĆ, P.S., ivkoviĆ, Wei, Y., Recurrent neural network for computing the drazin inverse (2015) IEEE Transactions on Neural Networks and Learning Systems, 26 (11), pp. 2830-2843; Stanimirovi, P.S., Ciri, M., Stojanovic, I., Gerontitis, D., Conditions for existence, representations, and computation of matrix generalized inverses (2017) Complexity, 2017, p. 27. , 6429725 2-s2.0-85021632844; Luo, X., Zhou, M., Xia, Y., Zhu, Q., Ammari, A.C., Alabdulwahab, A., Generating highly accurate predictions for missing QoS data via aggregating nonnegative latent factor models (2016) IEEE Transactions on Neural Networks and Learning Systems, 27 (3), pp. 524-537. , 2-s2.0-84928248687; Luo, X., Wu, H., Yuan, H., Zhou, M., Temporal pattern-aware QoS prediction via biased non-negative latent factorization of tensors (2020) IEEE Transactions on Cybernetics, 50 (5), pp. 1798-1809; Cheng, L., Liu, W., Huang, T., Hou, Z.-G., Tan, M., A neural-network-based controller for piezoelectric-actuated stick-slip devices (2018) IEEE Transactions on Industrial Electronics, 65 (3), pp. 2598-2607; Shah, S.A.A., Uddin, I., Aziz, F., Ahmad, S., Al-Khasawneh, M.A., Sharaf, M., An enhanced deep neural network for predicting workplace absenteeism (2020) Complexity, 2020, p. 12. , 5843932; Jin, L., Li, S., Hu, B., Liu, M., Yu, J., A noise-suppressing neural algorithm for solving the time-varying system of linear equations: a control-based approach (2019) IEEE Transactions on Industrial Informatics, 15 (1), pp. 236-246. , 2-s2.0-85041285612; Guo, D., Xu, F., Li, Z., Nie, Z., Shao, H., Design, verification, and application of new discrete-time recurrent neural network for dynamic nonlinear equations solving (2018) IEEE Transactions on Industrial Informatics, 14 (9), pp. 3936-3945. , 2-s2.0-85040073893; Guo, D., Li, S., Stanimirovic, P.S., Analysis and application of modified ZNN design with robustness against harmonic noise (2020) IEEE Transactions on Industrial Informatics, 16 (7), pp. 4627-4638; Zhang, Y., Li, S., Liao, B., Jin, L., Zheng, L., A recurrent neural network approach for visual servoing of manipulators, pp. 614-619. , Proceedings of the International Conference on Intelligent Manufacturing and Automation August 2017 Melbourne, Australia; Zhang, Y., Li, S., A neural controller for image-based visual servoing of manipulators with physical constraints (2018) IEEE Transactions on Neural Networks and Learning Systems, 29 (11), pp. 5419-5429. , 2-s2.0-85042876676; Song, Q., Wu, Y., Soh, Y.C., Robust adaptive gradient-descent training algorithm for recurrent neural networks in discrete time domain (2008) IEEE Transactions on Neural Networks, 19 (11), pp. 1841-1853. , 2-s2.0-56449088476; Zhang, N., Wu, W., Zheng, G., Convergence of gradient method with momentum for two-Layer feedforward neural networks (2006) IEEE Transactions on Neural Networks, 17 (2), pp. 522-525. , 2-s2.0-33644892170; Jin, L., Xie, Z., Liu, M., Ke, C., Li, C., Yang, C., Novel joint-drift-free scheme at acceleration level for robotic redundancy resolution with tracking error theoretically eliminated IEEE/ASME Transactions on Mechatronics, p. 1. , 2020, In press; Hutchinson, S., Hager, G.D., Corke, P.I., A tutorial on visual servo control (1996) IEEE Transactions on Robotics and Automation, 12 (5), pp. 651-670. , 2-s2.0-0030261036; Hashimoto, K., Kimoto, T., Ebine, T., Kimura, H., Manipulator control with image-based visual servo, , IEEE International Conference on Robotics and Automation April 1991 Sacramento, CA, USA; Stanimirovi, P.S., Petkovi, M.D., Gradient neural dynamics for solving matrix equations and their applications (2018) Neurocomputing, 306, pp. 200-212; Zhang, Y., Ge, S.S., Design and analysis of a general recurrent neural network model for time-varying matrix inversion (2005) IEEE Transactions on Neural Networks, 16 (6), pp. 1477-1490. , 2-s2.0-28244493362; Luo, X., Wang, D., Zhou, M., Yuan, H., Latent factor-based recommenders relying on extended stochastic gradient descent algorithms IEEE Transactions on Systems, Man, and Cybernetics: Systems, p. 1. , 2019, In press; Luo, X., Zhou, M., Li, S., Incorporation of efficient second-order solvers into latent factor models for accurate prediction of missing QoS data (2018) IEEE Transactions on Cybernetics, 48 (4), pp. 1216-1228. , 2-s2.0-85018486012; Luo, X., Zhou, M., Li, S., Shang, M., An inherently nonnegative latent factor model for high-dimensional and sparse matrices from industrial applications (2018) IEEE Transactions on Industrial Informatics, 14 (5), pp. 2011-2022. , 2-s2.0-85032731287; Xie, Z., Jin, L., Luo, X., Sun, Z., Liu, M., RNN for repetitive motion generation of redundant robot manipulators: an orthogonal projection-based scheme IEEE Transactions on Neural Networks and Learning Systems, p. 1. , 2020, In press; Khalil, H.K., (2001) Nonlinear Systems, , 3rd Englewood Cliffs, NJ, USA Prentice-Hall; Xiao, L., Li, S., Li, K., Jin, L., Liao, B., Co-design of finite-time convergence and noise suppression: a unified neural model for time varying linear equations with robotic applications (2020) IEEE Transactions on Systems, Man, and Cybernetics: Systems, 50 (12), p. 5233. , 2-s2.0-85054510737; Xie, Z., Jin, L., Luo, X., Li, S., Xiao, X., A data-driven cyclic-motion generation scheme for kinematic control of redundant manipulators (2021) IEEE Transactions on Control Systems Technology, 29 (1), p. 53; Jin, L., Zhang, Z., Liu, M., Li, S., Xiao, L., Yang, Z., Perturbed manipulability optimization in a distributed network of redundant robots IEEE Transactions on Industrial Electronics, p. 1. , 2020, In press","Jin, L.; Guangdong Provincial Engineering Technology Research Center for Sports Assistive Devices, China; email: jinlongsysu@foxmail.com
Li, Y.; Guangdong Provincial Engineering Technology Research Center for Sports Assistive Devices, China; email: 13922738963@139.com",,,"Hindawi Limited",,,,,10762787,,,,"English","Complexity",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85099305451
"Kim B., Lee S., Trivedi A.R., Song W.J.","57220177945;57220178754;23480816200;55491183400;","Energy-Efficient Acceleration of Deep Neural Networks on Realtime-Constrained Embedded Edge Devices",2020,"IEEE Access","8",,"9262933","216259","216270",,6,"10.1109/ACCESS.2020.3038908","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097127480&doi=10.1109%2fACCESS.2020.3038908&partnerID=40&md5=37b131487034bc5aa132735ec6172b13","School of Electrical and Electronic Engineering, Yonsei University, Seoul, 03722, South Korea; Department of Electrical and Computer Engineering, University of Illinois at Chicago, Chicago, IL  60607, United States","Kim, B., School of Electrical and Electronic Engineering, Yonsei University, Seoul, 03722, South Korea; Lee, S., School of Electrical and Electronic Engineering, Yonsei University, Seoul, 03722, South Korea; Trivedi, A.R., Department of Electrical and Computer Engineering, University of Illinois at Chicago, Chicago, IL  60607, United States; Song, W.J., School of Electrical and Electronic Engineering, Yonsei University, Seoul, 03722, South Korea","This paper presents a hardware management technique that enables energy-efficient acceleration of deep neural networks (DNNs) on realtime-constrained embedded edge devices. It becomes increasingly common for edge devices to incorporate dedicated hardware accelerators for neural processing. The execution of neural accelerators in general follows a host-device model, where CPUs offload neural computations (e.g., matrix and vector calculations) to the accelerators for datapath-optimized executions. Such a serialized execution is simple to implement and manage, but it is wasteful for the resource-limited edge devices to exercise only a single type of processing unit in a discrete execution phase. This paper presents a hardware management technique named NeuroPipe that utilizes heterogeneous processing units in an embedded edge device to accelerate DNNs in energy-efficient manner. In particular, NeuroPipe splits a neural network into groups of consecutive layers and pipelines their executions using different types of processing units. The proposed technique offers several advantages to accelerate DNN inference in the embedded edge device. It enables the embedded processor to operate at lower voltage and frequency to enhance energy efficiency while delivering the same performance as uncontrolled baseline executions, or inversely it can dispatch faster inferences at the same energy consumption. Our measurement-driven experiments based on NVIDIA Jetson AGX Xavier with 64 tensor cores and eight-core ARM CPU demonstrate that NeuroPipe reduces energy consumption by 11.4% on average without performance degradation, or it can achieve 30.5% greater performance for the same energy consumption. © 2013 IEEE.","Deep neural networks; embedded processors; energy efficiency; hardware management; hardware measurement; heterogeneous computing; performance","Acceleration; Deep neural networks; Energy efficiency; Energy utilization; Image coding; Multilayer neural networks; Program processors; Dedicated hardware; Embedded processors; Hardware management; Heterogeneous processing; Neural computations; Neural-processing; Performance degradation; Vector calculations; Pipeline processing systems",,,,,"2020-0-01847; 10080674","This work was supported by the Ministry of Trade, Industry and Energy and Korea Semiconductor Research Consortium under Grant #10080674, and in part by the Ministry of Science and ICT, South Korea, through the ITRC-supported program supervised by the Institute of Information and Communications Technology Planning and Evaluation under Grant #2020-0-01847.",,,,,,,,,,"Cass, S., Taking AI to the edge: Google's TPU now comes in a makerfriendly package (2019) IEEE Spectr., 56 (5), pp. 16-17. , May; Cireşan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J., Deep, big, simple neural nets for handwritten digit recognition (2010) Neural Comput., 22 (12), pp. 3207-3220. , Dec; (2019) NVIDIA Jetson Linux Driver Package Developer Guide, 32.3.1 Release, , https://docs.nvidia.com/jetson/l4t/, (Dec.). [Online]; Ditty, M., Karandikar, A., Reed, D., Nvidia's xavier SoC (2018) Proc. IEEE Hot Chips Symp. (HCS), pp. 1-17. , Aug; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 580-587. , Jun; Han, S., Mao, H., Dally, W., Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding (2016) Proc. Int. Conf. Learn. Represent., pp. 1-14. , May; Han, S., Pool, J., Tran, J., Dally, W.J., Learning both weights and connections for efficient neural networks (2015) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 1135-1143. , Dec; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Howard, A., Sandler, M., Chen, B., Wang, W., Chen, L.-C., Tan, M., Chu, G., Le, Q., Searching for MobileNetV3 (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 1314-1324. , Oct; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , http://arxiv.org/abs/1704.04861, [Online]; Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., Kalenichenko, D., Quantization and training of neural networks for efficient integer-arithmetic-only inference (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 2704-2713. , Jun; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. ACM Int. Conf. Multimedia (MM), pp. 675-678; Kim, B., Lee, S., Park, C., Kim, H., Song, W., The nebula benchmark suite: Implications of lightweight neural networks (2020) IEEE Trans. Comput., , early access, Oct. 7; Lin, J., Rao, Y., Lu, J., Zhou, J., Runtime neural pruning (2017) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 2181-2191. , Dec; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3431-3440. , Jun; Micikevicius, P., Narang, S., Alben, J., Diamos, G., Elsen, E., Garcia, D., Ginsburg, B., Wu, H., Mixed precision training (2018) Proc. Int. Conf. Learn. Represent., pp. 1-12. , May; Mittal, S., Vetter, J.S., A survey of CPU-GPU heterogeneous computing techniques (2015) ACM Comput. Surv., 47 (4), pp. 1-35. , Jul; Moloney, D., Barry, B., Richmond, R., Connor, F., Brick, C., Donohoe, D., Myriad 2: Eye of the computational vision storm (2014) Proc. IEEE Hot Chips 26 Symp. (HCS), pp. 1-18. , Aug; Narayanan, D., Harlap, A., Phanishayee, A., Seshadri, V., Devanur, N.R., Ganger, G.R., Gibbons, P.B., Zaharia, M., PipeDream: Generalized pipeline parallelism for DNN training (2019) Proc. 27th ACM Symp. Operating Syst. Princ., pp. 1-15. , Oct; Ohshima, S., Kise, K., Katagiri, T., Yuba, T., Parallel processing of matrix multiplication in a CPU and GPU heterogeneous environment (2006) Proc. Int. Conf. High Perform. Comput. Comput. Sci., pp. 305-318. , Jun; (2020) Snapdragon Neural Processing Engine SDK: Reference Guide, , https://developer.qualcomm.com/docs/snpe/index.html, (Sep.). 80-NL315-14. [Online]; Quartermain, M., Arora, T., Jagtap, R., (2020) Technical Overview of the ARM Cortex-M55 and Ethos-U55 Processors, , https://www.brighttalk.com/webcast/17792/391867, (Mar.). [Online]; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 779-788. , Jun; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Toward real-time object detection with region proposal networks (2015) Proc. Int. Conf. Neural Inf. Process. Syst., pp. 91-99. , Dec; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., MobileNetV2: Inverted residuals and linear bottlenecks (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 4510-4520. , Jun; Sharma, H., Park, J., Suda, N., Lai, L., Chau, B., Chandra, V., Esmaeilzadeh, H., Bit fusion: Bit-level dynamically composable architecture for accelerating deep neural network (2018) Proc. ACM/IEEE 45th Annu. Int. Symp. Comput. Archit. (ISCA), pp. 764-775. , Jun; Talpes, E., Sarma, D.D., Venkataramanan, G., Bannon, P., McGee, B., Floering, B., Jalote, A., Sachdev, G.S., Compute solution for Tesla's full self-driving computer (2020) IEEE Micro, 40 (2), pp. 25-35. , Mar; Wang, S., Ananthanarayanan, G., Zeng, Y., Goel, N., Pathania, A., Mitra, T., High-throughput CNN inference on embedded ARM Big.LITTLE multicore processors (2020) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 39 (10), pp. 2254-2267. , Oct; Yang, J., Shen, X., Xing, J., Tian, X., Li, H., Deng, B., Huang, J., Hua, X., Quantization networks (2019) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 7300-7308. , Jun; Yang, M., Wang, S., Bakita, J., Vu, T., Smith, F.D., Anderson, J.H., Frahm, J.-M., Re-thinking CNN frameworks for time-sensitive autonomous-driving applications: Addressing an industrial challenge (2019) Proc. IEEE Real-Time Embedded Technol. Appl. Symp. (RTAS), pp. 305-371. , Apr; Zhang, X., Zhou, X., Lin, M., Sun, J., ShuffleNet: An extremely efficient convolutional neural network for mobile devices (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 6848-6856. , Jun; Zhong, Z., Rychkov, V., Lastovetsky, A., Data partitioning on multicore and multi-GPU platforms using functional performance models (2015) IEEE Trans. Comput., 64 (9), pp. 2506-2518. , Sep","Song, W.J.; School of Electrical and Electronic Engineering, South Korea; email: wjhsong@yonsei.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85097127480
"Kim Y., Kong J., Munir A.","57216737789;25927220400;24587067400;","CPU-Accelerator Co-Scheduling for CNN Acceleration at the Edge",2020,"IEEE Access","8",,"9264125","211422","211433",,3,"10.1109/ACCESS.2020.3039278","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096863327&doi=10.1109%2fACCESS.2020.3039278&partnerID=40&md5=d597d16a75e922f627114cf7aca59749","School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, South Korea; School of Electronics Engineering, Kyungpook National University, Daegu, South Korea; Department of Computer Science, Kansas State University, Manhattan, KS, United States","Kim, Y., School of Electronic and Electrical Engineering, Kyungpook National University, Daegu, South Korea; Kong, J., School of Electronics Engineering, Kyungpook National University, Daegu, South Korea; Munir, A., Department of Computer Science, Kansas State University, Manhattan, KS, United States","Convolutional neural networks (CNNs) are widely deployed for many artificial intelligence (AI) applications, such as object detection and image classification. Due to the burgeoning revolution in edge AI, CNN hardware accelerators are also being employed in resource-constrained edge devices for achieving better performance and energy efficiency at the edge. Although CNN accelerators enable fast and energy-efficient CNN inference at the edge, the remaining hardware resources on the edge devices except for the CNN accelerator remain idle, which could otherwise be utilized for attaining even better performance and energy efficiency for CNN inferences. In this paper, we propose a CPU-accelerator co-scheduling technique for convolution (CONV) layer operations of CNN inferences in resource-constrained edge devices. Our proposed co-scheduling technique exploits an inherent parallelism in CNN output channels, that is, the operations for generating different output channels in a CONV layer can be executed in parallel. For load balancing between the CPU and the CNN accelerator, we also propose a simple, yet accurate latency model for CONV layer operations in the CPU and the accelerator. Based on the latency estimation of CONV layer operations provided by our proposed model, we distribute the tasks to the CPU and the CNN accelerator in a load-balance manner to minimize the idle period during the CONV layer operations in both the CPU and the CNN accelerator. We implement our proposed hardware/software (HW/SW) co-scheduling technique in various field-programmable gate array system-on-chip (FPGA-SoC) platforms as a proof-of-concept. Experimental results indicate that our proposed co-scheduling technique improves system performance by $1.18\times -2.00\times $ with energy reduction of 14.9% - 49.7% as compared to the accelerator-only execution. © 2013 IEEE.","co-scheduling; Convolutional neural networks; latency model; load balancing; resource-constrained edge devices","Acceleration; Convolution; Energy efficiency; Field programmable gate arrays (FPGA); Object detection; Programmable logic controllers; Scheduling; System-on-chip; Energy efficient; Energy reduction; Hardware accelerators; Hardware resources; Hardware/software; Inherent parallelism; Latency estimation; Proof of concept; Convolutional neural networks",,,,,"National Research Foundation of Korea, NRF; Kementerian Pendidikan Malaysia, KPM: NRF-2018R1D1A3B07045908","This research was supported by the Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF-2018R1D1A3B07045908).",,,,,,,,,,"Gu, B., Kong, J., Munir, A., Kim, Y.G., A framework for distributed deep neural network training with heterogeneous computing platforms (2019) Proc. IEEE 25th Int. Conf. Parallel Distrib. Syst. (ICPADS), pp. 430-437. , Dec; Zhong, G., Dubey, A., Tan, C., Mitra, T., Synergy: An HW/SW frame-work for high throughput CNNs on embedded heterogeneous SoC (2019) Acm Trans. Embedded Comput. Syst., 18 (2), pp. 1-23. , Apr; Han, S., Pool, J., Tran, J., Dally, W.J., Learning both weights and con-nections for efficient neural network (2015) Proc. Adv. Neural Inf. Process. Syst., Annu. Conf. Neural Inf. Process. Syst., pp. 1135-1143; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural network with pruning, trained quantization and Huffman coding (2016) Proc. 4th Int. Conf. Learn. Represent., Iclr, pp. 1-14; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016) SqueezeNet: AlexNet-level Accuracy with 50x Fewer Param-eters and 0.5 Mb Model Size, , http://arxiv.org/abs/1602.07360; (2019), https://pjreddie.com/darknet/, DarkNet: Open Source Neural Networks in C. Accessed: Jul. 1; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1-9. , Jun; (2020), https://coral.ai/products/dev-board/, Google Coral Dev Board. Accessed: Aug. 21; Guo, K., Sui, L., Qiu, J., Yu, J., Wang, J., Yao, S., Han, S., Yang, H., Angel-eye: A complete design flow for mapping CNN onto embedded FPGA (2018) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 37 (1), pp. 35-47. , Jan; Li, Y., Ma, S., Guo, Y., Xu, R., Chen, G., Configurable CNN accelerator based on tiling dataflow (2018) Proc. IEEE 9th Int. Conf. Softw. Eng. Service Sci. (ICSESS), pp. 309-313. , Nov; Zhao, Y., Chen, X., Wang, Y., Li, C., You, H., Fu, Y., Xie, Y., Lin, Y., SmartExchange: Trading higher-cost memory storage/access for lower-cost computation (2020) Proc. ACM/IEEE 47th Annu. Int. Symp. Comput. Archit. (ISCA), pp. 1-14. , May; (2020), https://www.96boards.org/product/ultra96/, Linaro Ultra96 Evaluation Board. Accessed: Jun. 16; (2020), http://www.zedboard.org/, Accessed: Apr. 7; (2020), https://www.xilinx.com/products/boards-and-kits/zcu104.html, Xilinx Zcu104 Evaluation Board. Accessed: Jul. 20; (2020), https://www.xilinx.com/products/boards-and-kits/zcu106.html, Xilinx Zcu106 Evaluation Board. Accessed: Jul. 20; Lee, K., Kong, J., Kim, Y.G., Chung, S.W., Memory stream-ing acceleration for embedded systems with CPU-accelerator coopera-tive data processing (2019) Microprocessors Microsyst., 71. , Nov; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., MobileNetV2: Inverted residuals and linear bottlenecks (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 4510-4520. , Jun; (2020), https://pjreddie.com/darknet/tiny-darknet/, Accessed: Oct. 11; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 248-255. , Jun; (2020) Hpm-300A Digital Power Meter and Analyzer, , http://adpower21.com/, Accessed: Mar. 13; Lee, K., Kong, J., Munir, A., Hw/sw co-design of cost-efficient CNN inference for cognitive IoT (2020) Proc. IEEE Int. Conf. Intell. Comput. Data Sci. (ICDS), pp. 1063-1076; Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. Ieee, 105 (12), pp. 2295-2329. , Dec; George, V.K.A., Gunisetty, S., Subramanian, S., Re, S.K., Purnaprajna, M., CoIn: Accelerated CNN co-inference through data par-titioning on heterogeneous devices (2020) Proc. 6th Int. Conf. Adv. Comput. Commun. Syst. (ICACCS), pp. 90-95. , Mar; Zhu, J., Wang, L., Liu, H., Tian, S., Deng, Q., Li, J., An efficient task assignment framework to accelerate DPU-based convolutional neural network inference on FPGAS (2020) IEEE Access, 8, pp. 83224-83237; Meloni, P., Capotondi, A., Deriu, G., Brian, M., Conti, F., Rossi, D., Raffo, L., Benini, L., (2017) NEURAghe: Exploiting CPU-FPGA Synergies for Effi-cient and Fiexible Cnn Inference Acceleration on Zynq SoCs, , http://arxiv.org/abs/1712.00994; Kim, Y., Kim, J., Chae, D., Kim, D., Kim, J., Flayer: Low latency on-device inference using cooperative single-layer acceleration and processor-friendly quantization (2019) Proc. EuroSys, pp. 1-15","Kong, J.; School of Electronics Engineering, South Korea; email: joonho.kong@knu.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85096863327
"Zhao J.","57219902250;","Corporate Financial Risk Prediction Based on Embedded System and Deep Learning",2020,"Microprocessors and Microsystems",,,"103405","","",,4,"10.1016/j.micpro.2020.103405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096003992&doi=10.1016%2fj.micpro.2020.103405&partnerID=40&md5=713b87cce7210c3a88f3be63f41a3de0","School of Management, University of Science and Technology of China, Hefei, Anhui  230026, China","Zhao, J., School of Management, University of Science and Technology of China, Hefei, Anhui  230026, China","In recent years, the in-depth learning sector has become the most popular area of human life due to the increased potential of artificial intelligence. By using embedded deep learning techniques, the embedded smart school system is designed based on face recognition. For this reason, embedded platforms are used to achieve efficient systems. There is a financial database to identify identity, which find operational risks when choosing a loan. From time to time, someone may send their name to another person on behalf of his / her fake identity for a recommended test. During the work of all financial centers, they are appropriately investigated. Simultaneously, the smart system sends alerts and notifications directly and sends anonymous photos to financial institutions. Financial institutions are based on the Internet of Things (IoT) and use deep learning. The proposed system is accurate, fast, and has low computational costs. © 2020","Deep Learning; Embedded System; Financial Risk Prediction; Operational Risk","Embedded systems; Face recognition; Finance; Internet of things; Learning systems; Computational costs; Embedded platforms; Financial institution; Financial risks; Internet of thing (IOT); Learning techniques; Operational risks; Smart schools; Deep learning",,,,,,,,,,,,,,,,"Yong, L., Rong, X., Big Data and Finance [M] (2016), Publishing House of Electronics Industry Beijing; Jianguang, M., Wei, J., The Concept, Characteristic and Application of Big Data [J] (2013) National Defense Science & Technology; Pingping, T., How can Banks Use Big Data at the Present Stage [J] (2014) Marketing Research; Zhang, L., Xiao, K., Zhu, H., Liu, C., Yang, J., (2018), Jin, B ""A Context-Aware Deep Embedding Network for Financial Opinions Mining""; Zhang, L., Zhang, L., Xiao, K., Liu, Q., Forecasting price shocks with social attention and sentiment analysis (2016) Advances in Social Networks Analysis and Mining, 2016 IEEE/ACM Int'l Conf. on. IEEE; Zhang, L., Xiao, K., Zhu, H., Liu, C., Yang, J., Jin, B., (2018), ""A Context-Aware Deep Embedding Network for Financial Opinions Mining""; Goularas, D., Kamis, S., (2019), ""Evaluation of Deep Learning Techniques in Sentiment Analysis from Twitter Data""; Yoo, S., Cho, C., Lee, K.H., Park, J., Jin, S., Lee, Y., Kim, B., (2019), ""Structure of Deep Learning Inference Engines for Embedded Systems""; Tsai, T.-H., Chi, P.-T., Cheng, K.-H., A Sketch Classifier Technique with Deep Learning Models Realized in an Embedded System (2019); Bataev, A.V., Rodionov, D.G., Kosonogova, E., (2018), S. ""Evaluation of efficiency of using bank smart-card in financial institutions""; Madhusudanan, J., Prasanna Venkatesan, V., Karthikeyan, P., (2012), & Shilpa Devi, S. ""Smart bank simulation using Context awareness""; Zhang, M., Gu, Y., Zhu, J., (2009), ""Analysis of the Framework for Financial Decision Support System""; Ye, H., Zhu, L., (2010), Gan, Y ""An overall framework study of financial supervision information system based on Web Service and MAS”; Yang, Y., Peng, Y.X., Feng, G., Tian, L., (2017), Y. ""Application of Distributed Storage Technology for Financial Management and Control System in Electric Power System""; Min, Z., (2014), ""Analysis of the Nature of Embedded Options of Cash Discounts""; Zhang, L., Xiao, K., Zhu, H., Liu, C., Yang, J., (2018), Jin, B ""A Context-Aware Deep Embedding Network for Financial Opinions Mining""; Xiao, K., Liu, Q., Liu, C., Xiong, H., (2017), “Price shock detection with an influence-based model of social attention,”; Croitorov, O., Giovannini, M., Hohberger, S., Ratto, M., Vogel, L., Financial spillover and global risk in a multi-region model of the world economy (2020) journal of economic behavior and organization, 177. , ISSN 0167-2681 (online); Susana Pereira, R., Design and development of an embedded sensors matrix for pressure mapping and monitoring applications (2020) Microprocessors and Microsystems, 74; Fanariotis, A., Andriopoulou, F., An embedded framework was enabling access of elderly and disabled persons to IP-based emergency communications (2019) Microprocessors and Microsystems, 68",,,,"Elsevier B.V.",,,,,01419331,,MIMID,,"English","Microprocessors Microsyst",Article,"Article in Press","",Scopus,2-s2.0-85096003992
"Xie C., Wang D., Wu H., Gao L.","57195199032;57155336300;57197813532;7401800717;","A long short-term memory neural network model for knee joint acceleration estimation using mechanomyography signals",2020,"International Journal of Advanced Robotic Systems","17","6",,"","",,3,"10.1177/1729881420968702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095118891&doi=10.1177%2f1729881420968702&partnerID=40&md5=8e537dad6065b52ce384f135f801cb86","Institute of Intelligent Machines, Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, China; Department of Science Island, University of Science and Technology of China, Hefei, China; Anhui Province Key Laboratory of Intelligent Building and Building Energy Saving, Anhui Jianzhu University, Hefei, China; High Magnetic Field Laboratory, Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, China","Xie, C., Institute of Intelligent Machines, Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, China, Department of Science Island, University of Science and Technology of China, Hefei, China, Anhui Province Key Laboratory of Intelligent Building and Building Energy Saving, Anhui Jianzhu University, Hefei, China; Wang, D., Institute of Intelligent Machines, Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, China; Wu, H., High Magnetic Field Laboratory, Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, China; Gao, L., Institute of Intelligent Machines, Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, China","With the growth of the number of elderly and disabled with motor dysfunction, the demand for assisted exercise is increasing. Wearable power assistance robots are developed to provide athletic ability of limbs for the elderly or the disabled who have weakened limbs to better self-care ability. Existing wearable power-assisted robots generally use surface electromyography (sEMG) to obtain effective human motion intentions. Due to the characteristics of sEMG signals, it is limited in many applications. To solve the above problems, we design a long short-term memory (LSTM) neural network model based on human mechanomyography (MMG) signals to estimate the motion acceleration of knee joint. The acceleration can be further calculated by the torque required for movement control of the wearable power assistance robots for the lower limb. We detect MMG signals on the clothed thigh, extract features of the MMG signals, and then, use principal component analysis to reduce the features’ dimensions. Finally, the dimension-reduced features are inputted into the LSTM neural network model in time series for estimating the acceleration. The experimental results show that the average correlation coefficient (R) is 94.48 ± 1.91% for the estimation of acceleration in the process of continuously performing under approximately π/4 rad/s. This approach can be applied in the practical applications of wearable field. © The Author(s) 2020.","acceleration estimation; Knee joint; LSTM; MMG; PCA","Acceleration; Agricultural robots; Brain; Joints (anatomy); Robots; Wearable technology; Acceleration estimation; Athletic abilities; Average correlation coefficients; Human motion intention; Mechanomyography; Movement control; Neural network model; Surface electromyography; Long short-term memory",,,,,"Chinese Academy of Sciences, CAS: XDA22040303; University Natural Science Research Project of Anhui Province: JZ192012","The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported in part by the Strategic Priority Research Program of the Chinese Academy of Sciences under Grant No. XDA22040303, Natural Science Research Project of Anhui Jianzhu University No. JZ192012 and the State Key Laboratory of Transducer Technology.","The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported in part by the Strategic Priority Research Program of the Chinese Academy of Sciences under Grant No. XDA22040303, Natural Science Research Project of Anhui Jianzhu University No. JZ192012 and the State Key Laboratory of Transducer Technology.",,,,,,,,,"Yang, K., Isaia, B., Brown, L.J.E., E-textiles for healthy ageing (2019) Sensors, 19, p. 4463; Zhao, Y.C., China Disabled Persons’ Federation released the latest data of disabled population in China (2012) Disability Research, 1, p. 11; Yu, Y.P., (2016) The research of motion pattern recognition and joint moment analysis of human lower limb based on sEMG, , MS Thesis, Department of SOMAEE, Soochow University, Shanghai, China; Zhang, T.Y., Lan, T., Fan, Y.B., Technical development and trend analysis of smart knee prostheses (2017) Chinese J Rehabilitation Med, 32, pp. 451-453; Staudenmann, D., Roeleveld, K., Stegeman, D.F., Methodological aspects of SEMG recordings for force estimation–a tutorial and review (2010) J Electromyogr Kinesiol, 20, pp. 375-387; Bai, D., Yao, S., Yang, J., Upper arm force sEMG analysis based on SVM, pp. 569-574. , 2018 IEEE International Conference on Intelligence and Safety for Robotics (ISR), Shenyang, China, 24–27 August 2018, Washington, DC, IEEE, In; Takei, Y., Yoshida, M., Kobayashi, T., Wearable muscle training and monitoring device, pp. 55-58. , 2018 IEEE Micro Electro Mechanical Systems (MEMS), Belfast, United Kingdom, 21–25 January 2018, Washington, DC, IEEE, In; Orizio, C., Muscle sound: bases for the introduction of a mechanomyographic signal in muscle studies (1993) Crit Rev Biomed Eng, 21 (3), pp. 201-243; Beck, T.W., Housh, T.J., Johnson, G.O., Mechanomyographic amplitude and mean power frequency versus torque relationships during isokinetic and isometric muscle actions of the biceps brachii (2004) J Electromyogr Kinesiol, 14 (5), pp. 555-564; Evetovich, T.K., Housh, T.J., Stout, J.R., Mechanomyographic responses to concentric isokinetic muscle contractions (1997) Eur J Appl Physiol, 75 (2), pp. 166-169; Park, J., Kim, S.J., Na, Y., Custom optoelectronic force sensor based ground reaction force (GRF) measurement system for providing absolute force, pp. 75-77. , 2016 13th international conference on ubiquitous robots and ambient intelligence (URAI), Xian, China, 19–22 August 2016, Washington, DC, IEEE, In; Talib, I., Sundaraj, K., Lam, C.K., Choice of mechanomyography sensors for diverse types of muscle activities (2018) J Telecommun Electron Comput Eng, 10, pp. 79-82; Plewa, K., Samadani, A., Orlandi, S., A novel approach to automatically quantify the level of coincident activity between EMG and MMG signals (2018) J Electromyogr Kinesiol, 41, pp. 34-40; Wu, H.F., Wang, D.Q., Huang, Q., Real-time continuous recognition of knee motion using multi-channel mechanomyography signals detected on clothes (2018) J Electromyogr Kinesiol, 38, pp. 94-102. , Washington, DC: IEEE; Alves, N., Chau, T., Recognition of forearm muscle activity by continuous classification of multi-site mechanomyogram signals, pp. 3531-3534. , 2010 annual international conference of the IEEE engineering medicine and biology, Buenos Aires, Argentina, 31 August–4 September 2010, In; Silva, J., Heim, W., Chau, T., MMG-based classification of muscle activity for prosthesis control, pp. 968-971. , 26th annual international conference of the IEEE engineering medicine and biology society, San Francisco, USA, 1–5 September 2004, Washington, DC, IEEE, In; Zeng, Y., (2010) Mechanomyographic hand-motion pattern identification and its application in prosthetic hand manipulation, , MS Thesis, Department of SOMAPE, East China University of Science and Technology, Shanghai, China; Ibitoye, M.O., Hamzaid, N.A., Wahab, A.K.A., SVR modelling of mechanomyographic signals predicts neuromuscular stimulation-evoked knee torque in paralyzed quadriceps muscles undergoing knee extension exercise (2020) Comput Biol Med, 117, p. 103614; Dzulkifli, M.A., Hamzaid, N.A., Davis, G.M., Neural network-based muscle torque estimation using mechanomyography during electrically-evoked knee extension and standing in spinal cord injury (2018) Front Neurorobot, 12, p. 50; Youn, W., Kim, J., Feasibility of using an artificial neural network model to estimate the elbow flexion force from mechanomyography (2011) J Neurosci Methods, 194, pp. 386-393; Bouktif, S., Fiaz, A., Ouni, A., Optimal deep learning LSTM model for electric load forecasting using feature selection and genetic algorithm: comparison with machine learning approaches (2018) Energies, 11, pp. 1-20; Jolliffe, I.T., Cadima, J., Principal component analysis: a review and recent developments (2016) Philos Trans Royal Soc A: Math Phys Eng Sci, 374, pp. 1-16; Li, B., Zhou, E., Huang, B., Large scale recurrent neural network on GPU, pp. 4062-4069. , 2014 international joint conference on neural networks (IJCNN), Beijing, China, 6–11 July 2014, Berlin, BER, Springer-Verlag, In; Huan, J., Li, H., Li, M., Prediction of dissolved oxygen in aquaculture based on gradient boosting decision tree and long short-term memory network: a study of Chang Zhou fishery demonstration base, China (2020) Comput Electron Agric, 175, p. 105530; Zhu, J., Yang, Z., Guo, Y., Short-term load forecasting for electric vehicle charging stations based on deep learning approaches (2019) Appl Sci, 9, p. 1723; Liu, S., Li, Z., Li, H., Research on short-term traffic flow prediction model based on RNN-LSTM, pp. 12-17. , International conference on AI and big data alication (AIBDA 2019), Guangzhou, China, 20–22 December 2019, In; Wu, H.F., Huang, Q., Wang, D.Q., A CNN-SVM combined model for pattern recognition of knee motion using mechanomyography signals (2018) J Electromyogr Kinesiol, 42, pp. 136-142; Knudson, D., (2007) Fundamentals of biomechanics, , Berlin, Springer Science & Business Media; Fan, Z., Wang, Z., Li, G., A canonical correlation analysis based EMG classification algorithm for eliminating electrode shift effect, pp. 867-870. , 2016 38th annual international conference of the IEEE engineering medicine and biology society (EMBC), Florida, USA, 16–20 August 2016, Washington, DC, IEEE, In; Abdelouahad, A., Belkhou, A., Jbari, A., Time and frequency parameters of sEMG signal—force relationship, pp. 1-5. , 2018 4th international conference on optimization and alications (ICOA), Mohammedia, Morocco, 26–27 April 2018, Washington, DC, IEEE, In; Xie, C.L., Wang, D.Q., Wu, H.F., Angular velocity estimation of knee joint based on MMG signals, pp. 15-25. , International conference on intelligent robotics and alications, Shenyang, China, 8–11 August 2019, Berlin, BER, Springer-Verlag, In; Saranya, C., Manikandan, G., A study on normalization techniques for privacy preserving data mining (2013) Int J Eng Technol, 5, pp. 2701-2704","Gao, L.; Institute of Intelligent Machines, China; email: lifugao@iim.ac.cn",,,"SAGE Publications Inc.",,,,,17298806,,,,"English","Int. J. Adv. Rob. Syst.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85095118891
"Lee S.-T., Woo S.Y., Lee J.-H.","57203597778;57201527826;57221622173;","Low-Power Binary Neuron Circuit with Adjustable Threshold for Binary Neural Networks Using NAND Flash Memory",2020,"IEEE Access","8",,"9172056","153334","153340",,2,"10.1109/ACCESS.2020.3018226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090598060&doi=10.1109%2fACCESS.2020.3018226&partnerID=40&md5=88d5b6bfea9e02ae02552b443d38c844","Department of Electrical and Computer Engineering and Isrc, Seoul National University, Seoul, South Korea","Lee, S.-T., Department of Electrical and Computer Engineering and Isrc, Seoul National University, Seoul, South Korea; Woo, S.Y., Department of Electrical and Computer Engineering and Isrc, Seoul National University, Seoul, South Korea; Lee, J.-H., Department of Electrical and Computer Engineering and Isrc, Seoul National University, Seoul, South Korea","Recent studies have demonstrated that binary neural networks (BNN) could achieve a satisfying inference accuracy on representative image datasets. BNN conducts XNOR and bit-counting operations instead of high-precision vector-matrix multiplication (VMM), significantly reducing the memory storage. In this work, an analog bit-counting scheme is proposed to decrease the burden of neuron circuits with a synaptic architecture utilizing NAND flash memory. A novel binary neuron circuit with a double-gate positive feedback (PF) device is demonstrated to replace the sense amplifier, adder, and comparator, thereby reducing the burden of the complementary metal-oxide semiconductor (CMOS) circuits and power consumption. By using the double-gate PF device, the threshold voltage of the neuron circuits can be adaptively matched to the threshold value in the algorithms eliminating the accuracy degradation introduced by the process variation. Thanks to the super-steep SS characteristics of the PF device, the proposed neuron circuit with the PF device has an off-state current of 1 pA, representing 105 times improvement compared to the neuron circuit with a conventional metal-oxide-semiconductor field effect transistor (MOSFET) device. A system simulation of a hardware-based BNN shows that the low-variance conductance distribution (8.4 %) of the synaptic device and the adjustable threshold of the neuron circuit implement a highly efficient BNN with a high inference accuracy. © 2013 IEEE.","hardware neural networks; in-memory computing; NAND flash memory; Neuromorphic; neuron circuits; synaptic device","CMOS integrated circuits; Computer circuits; Dielectric devices; Feedback; Feedback amplifiers; Flash memory; Low power electronics; Memory architecture; Metallic compounds; Metals; MOS devices; NAND circuits; Neurons; Oxide semiconductors; Power MOSFET; Static random access storage; Threshold voltage; Timing circuits; Transistors; Binary neural networks; Complementary metal oxide semiconductors; Conductance distribution; Conventional metals; Off-state current; Process Variation; System simulations; Vector-matrix multiplications; Neural networks",,,,,"National Research Foundation of Korea, NRF: NRF-2016M3A7B4909604","This work was supported in part by the National Research Foundation of Korea under Grant NRF-2016M3A7B4909604, and in part by the Brain Korea 21 Plus Project in 2020.",,,,,,,,,,"Jackson, B.L., Rajendran, B., Corrado, G.S., Breitwisch, M., Burr, G.W., Cheek, R., Gopalakrishnan, K., Modha, D.S., Nanoscale electronic synapses using phase change devices (2013) ACM J. Emerg. Technol. Comput. Syst, 9 (2), pp. 1-20. , May; Suri, M., Bichler, O., Querlioz, D., Cueto, O., Perniola, L., Sousa, V., Vuillaume, D., DeSalvo, B., Phase change memory as synapse for ultra-dense neuromorphic systems: Application to complex visual pattern extraction (2011) IEDM Tech. Dig, pp. 441-444. , Dec; Park, S., Sheri, A., Kim, J., Noh, J., Jang, J., Jeon, M., Lee, B., Hwang, H., Neuromorphic speech systems using advanced ReRAM-based synapse (2013) IEDM Tech. Dig, pp. 6-25. , Dec; Burr, G.W., Shelby, R.M., Sidler, S., Di Nolfo, C., Jang, J., Boybat, I., Shenoy, R.S., Hwang, H., Experimental demonstration and tolerancing of a large-scale neural network (165 000 synapses) using phase-change memory as the synaptic weight element (2015) IEEE Trans. Electron Devices, 62 (11), pp. 3498-3507. , Nov; Chen, P.-Y., Lin, B., Wang, I.-T., Hou, T.-H., Ye, J., Vrudhula, S., Seo, J.-S., Yu, S., Mitigating effects of non-ideal synaptic device char-acteristics for on-chip learning (2015) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 194-199. , Nov; Jiang, L., Kim, M., Wen, W., Wang, D., XNOR-POP: A processing-in-memory architecture for binary convolutional neural networks in wide-IO2 DRAMs (2017) Proc. IEEE/ACMInt. Symp. Low Power Electron. Design (ISLPED), pp. 1-6. , Jul; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Bina-rized neural networks (2016) Proc. 30th Conf. Neural Inf. Process. Syst. (NIPS), pp. 4107-4115; Sun, X., Yin, S., Peng, X., Liu, R., Seo, J.-S., Yu, S., XNOR-RRAM: A scalable and parallel resistive synaptic architecture for binary neural net-works (2018) Proc. Design, Autom. Test Eur. Conf. Exhib. (DATE), pp. 1423-1428. , Mar; Andri, R., Cavigelli, L., Rossi, D., Benini, L., YodaNN: An architec-ture for ultralow power binary-weight CNN acceleration (2018) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst, 37 (1), pp. 48-60. , Jan; Yu, S., Neuro-inspired computing with emerging nonvolatile memorys (2018) Proc. IEEE, 106 (2), pp. 260-285. , Feb; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to C1 or 1, , http://arxiv.org/abs/1602.02830, Mar. 2016, arXiv:1602.02830; Tang, T., Xia, L., Li, B., Wang, Y., Yang, H., Binary convolutional neural network on RRAM (2017) Proc. 22nd Asia South Paci-c Design Autom. Conf. (ASP-DAC), pp. 782-787. , Jan; Guan, Y., Ohsawa, T., Co-design of DNN model optimization for binary ReRAM array in-memory processing (2019) Proc. IEEE 11th Int. Memory Workshop (IMW), pp. 1-4. , May; Zhou, Z., Huang, P., Xiang, Y.C., Shen, W.S., Zhao, Y.D., Feng, Y.L., Gao, B., Kang, J.F., A new hardware implementation approach of BNNs based on nonlinear 2T2R synaptic cell (2018) IEDM Tech. Dig, pp. 2071-2074. , Dec; Yamashita, R., A 512 Gb 3b/cell-ash memory on 64-word-line-layer BiCS technology (2017) IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, pp. 196-197. , Feb; Kang, D., A 512 Gb 3-bit/cell 3D 6th-generation V-NAND-ash memory with 82 MB/s write throughput and 1.2 Gb/s interface (2019) IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, pp. 216-218; Huh, H., A 1 Tb 4b/cell 96-stacked-WL 3D NAND-ash memory with 30 MB/s program throughput using peripheral circuit under memory cell array technique (2020) IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, pp. 220-221. , Feb; Lee, S.-T., Lim, S., Choi, N., Bae, J.-H., Kim, C.-H., Lee, S., Lee, D.H., Lee, J.-H., Neuromorphic technology based on charge storage memory devices (2018) Proc. IEEE Symp. VLSI Technol, pp. 169-170. , Jun; Lee, S.-T., Kim, H., Bae, J.-H., Yoo, H., Choi, N.Y., Kwon, D., Lim, S., Lee, J.-H., High-density and highly-reliable binary neural networks using NAND-ash memory cells as synaptic devices (2019) IEDM Tech. Dig, pp. 3841-3844. , Dec; Lo, C.-P., Lin, W.-Z., Lin, W.-Y., Lin, H.-T., Yang, T.-H., Chiang, Y.-N., King, Y.-C., Chang, M.-F., Embedded 2 Mb ReRAM macro with 2.6 ns read access time using dynamic-trip-point-mismatch sampling current-mode sense ampli-er for IoE applications (2017) Proc. Symp. VLSI Circuits, pp. C164-C165; Wan, J., Royer, C.L., Zaslavsky, A., Cristoloveanu, S., A systematic study of the sharp-switching Z2-FET device: From mechanism to mod-eling and compact memory applications (2013) Solid-State Electron, 90, pp. 2-11. , Dec; Jeon, Y., Kim, M., Lim, D., Kim, S., Steep subthreshold swing n-and p-channel operation of bendable feedback field-effect transistors with pC i nC nanowires by dual-top-gate voltage modulation (2015) Nano Lett, 15 (8), pp. 4905-4913. , Aug; Choi, K.B., Woo, S.Y., Kang, W.-M., Lee, S., Kim, C.-H., Bae, J.-H., Lim, S., Lee, J.-H., A split-gate positive feedback device with an integrate-and-re capability for a high-density low-power neuron circuit (2018) Frontiers Neurosci, 12 (704), pp. 1-13. , Oct; Lee, S.-T., Lim, S., Choi, N.Y., Bae, J.-H., Kwon, D., Park, B.-G., Lee, J.-H., Operation scheme of multi-layer neural networks using NAND-ash memory as high-density synaptic devices (2019) IEEE J. Electron Devices Soc, 7, pp. 1085-1093","Lee, J.-H.; Department of Electrical and Computer Engineering and Isrc, South Korea; email: jhl@snu.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85090598060
"Haryanto T., Pratama A., Suhartanto H., Murni A., Kusmardi K., Pidanic J.","57193869197;57217229590;16423632300;36815724000;56966625300;57209730142;","Multipatch-GLCM for texture feature extraction on classification of the colon histopathology images using deep neural network with GPU acceleration",2020,"Journal of Computer Science","16","3",,"280","294",,4,"10.3844/JCSSP.2020.280.294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086875982&doi=10.3844%2fJCSSP.2020.280.294&partnerID=40&md5=e02bf5629c6c2869ee2a8e0d14d6aaf8","Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Department of Pathology Anatomy Faculty of Medicine, Universitas Indonesia, Jakarta, Indonesia; Faculty of Electrical Engineering and Informatics, University of Pardubice, Studentska 95, Pardubice, 532 10, Czech Republic","Haryanto, T., Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Pratama, A., Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Suhartanto, H., Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Murni, A., Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Kusmardi, K., Department of Pathology Anatomy Faculty of Medicine, Universitas Indonesia, Jakarta, Indonesia; Pidanic, J., Faculty of Electrical Engineering and Informatics, University of Pardubice, Studentska 95, Pardubice, 532 10, Czech Republic","Cancer is one of the leading causes of death in the world. It is the main reason why research in this field becomes challenging. Not only for the pathologist but also from the view of a computer scientist. Hematoxylin and Eosin (H&E) images are the most common modalities used by the pathologist for cancer detection. The status of cancer with histopathology images can be classified based on the shape, morphology, intensity, and texture of the image. The use of full high-resolution histopathology images will take a longer time for the extraction of all information due to the huge amount of data. This study proposed advance texture extraction by multi-patch images pixel method with sliding windows that minimize loss of information in each pixel patch. We use texture feature Gray Level Co-Occurrence Matrix (GLCM) with a meanshift filter as the data pre-processing of the images. The mean-shift filter is a low-pass filter technique that considers the surrounding pixels of the images. The proposed GLCM method is then trained using Deep Neural Networks (DNN) and compared to other classification techniques for benchmarking. For training, we use two hardware: NVIDIA GPU GTX-980 and TESLA K40c. According to the study, Deep Neural Network outperforms other classifiers with the highest accuracy and deviation standard 96.72±0.48 for four cross-validations. The additional information is that training using Theano framework is faster than Tensorflow for both in GTX-980 and Tesla K40c. © 2020 Toto Haryanto, Adib Pratama, Heru Suhartanto, Aniati Murni, Kusmardi Kusmardi and Jan Pidanic.","Deep neural network; GLCM; Histopathology; Multipatch",,,,,,"CZ.02.1.01/0.0/0.0/17_049/0008394; 1/E1/KP, 234/PKS/R/UI/2019, PTNBH/2019; NKB-1691/UN2.R3.1/HKP.05.00/2019; European Social Fund, ESF; European Regional Development Fund, ERDF; Univerzita Pardubice, UPA","This research was supported by Penelitian Terapan Unggulan Perguruan Tinggi (PTUPT) grant number No. NKB-1691/UN2. R3.1/HKP.05.00/2019 from the Ministry of the Research Technology Republic of Indonesia. Contract Number: 1/E1/KP. PTNBH/2019 and 234/PKS/R/UI/2019. The work supported by ERDF/ESF ""Cooperation in Applied Research between the University of Pardubice and companies, in the Field of Positioning, Detection and Simulation Technology for Transport Systems (PosiTrans)"" (No. CZ.02.1.01/0.0/0.0/17_049/0008394).","This research was supported by Penelitian Terapan Unggulan Perguruan Tinggi (PTUPT) grant number No. NKB-1691/UN2.R3.1/HKP.05.00/2019 from the Ministry of the Research Technology Republic of Indonesia. Contract Number: 1/E1/KP.PTNBH/2019 and 234/PKS/R/UI/2019. The work supported by ERDF/ESF ""Cooperation in Applied Research between the University of Pardubice and companies, in the Field of Positioning, Detection and Simulation Technology for Transport Systems (PosiTrans)"" (No. CZ.02.1.01/0.0/0.0/17_049/0008394).",,,,,,,,,"Ali, H., Yasmin, M., Sharif, M., Rehmani, M.H., Computer assisted gastric abnormalities detection using hybrid texture descriptors for chromoendoscopy images (2018) Comput. Methods Programs Biomed, 157, pp. 39-47; Aparajeeta, J., Mahakud, S., Nanda, P.K., Das, N., Variable variance adaptive mean-shift and possibilistic fuzzy c-means based recursive framework for brain MR image segmentation (2018) Expert Syst. Applic, 92, pp. 317-333; Bai, P.R., Liu, Q.Y., Li, L., Teng, S.H., Li, J., A novel region-based level set method initialized with mean shift clustering for automated medical image segmentation (2013) Comput. Biol. Med, 43, pp. 1827-1832; Banaie, M., Soltanian-Zadeh, H., Saligheh-Rad, H.R., Gity, M., Spatiotemporal features of DCE-MRI for breast cancer diagnosis (2018) Comput. Methods Programs Biomed, 155, pp. 153-164; Bengio, Y., Learning deep architectures for AI (2009) Foundat. Trends® Machine Learn, 2, pp. 1-127; Bianchini, M., Scarselli, F., On the complexity of shallow and deep neural network classifiers (2014) IEEE Trans. Neural Netw. Learn. Syst, 25, pp. 1553-1565; Comaniciu, D., Meer, P., Mean shift: A robust approach toward feature space analysis (2002) IEEE Trans. Patt. Anal. Machine Intell, 24, pp. 603-619; Dhahbi, S., Barhoumi, W., Kurek, J., Swiderski, B., Kruk, M., False-positive reduction in computer-aided mass detection using mammographic texture analysis and classification (2018) Comput. Meth. Programs Biomed, 160, pp. 75-83; Du, X., Tang, J., Li, Z., Qin, Z., Wheel: Accelerating CNNs with distributed GPUs via hybrid parallelism and alternate strategy (2017) Proceedings of the 25th ACM International Conference on Multimedia, pp. 393-401. , (ICM' 17), ACM, California; Ghassabeh, Y.A., On the convergence of the mean shift algorithm in the one-dimensional space (2013) Patt. Recognit. Lett, 34, pp. 1423-1427; Guo, Y., Sengür, A., Akbulut, Y., Shipley, A., An effective color image segmentation approach using neutrosophic adaptive mean shift clustering (2018) Measurement: J. Int. Measurement Confederal, 119, pp. 28-40; Gurcan, M.N., Boucheron, L.E., Can, A., Madabhushi, A., Rajpoot, N.M., Histopathological image analysis: A review (2009) IEEE Rev. Biomedical Eng, 2, pp. 147-171; Haralick, R.M., Shanmugam, K., Dinstein, I., Textural features for image classification (1973) IEEE Trans. Syst. Man Cybernet, 6, pp. 610-621; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2015) Proceedings of the International Conference on Learning Representations, pp. 1-15. , May 7-9, San Diego; Li, S., Dou, Y., Lv, Q., Wang, Q., Niu, X., Optimized GPU acceleration algorithm of convolutional neural networks for target detection (2017) Proceedings of the 18th IEEE International Conference on High Performance Computing and Communications, pp. 224-230. , 14th IEEE International Conference on Smart City and 2nd IEEE International Conference on Data Science and Systems, Dec. 12-14, IEEE Xplore Press, Sydney, NSW, Australia; Li, S., Dou, Y., Niu, X., Lv, Q., Wang, Q., A fast and memory saved GPU acceleration algorithm of convolutional neural networks for target detection (2017) Neurocomputing, 230, pp. 48-59; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., (2015) TensorFlow: Large-scale machine learning on heterogeneous systems; Men, L., Huang, M., Gauch, J., Accelerating Mean Shift Segmentation Algorithm on Hybrid CPU/GPU Platforms (2013) Modern Accelerator Technologies for Geographic Information Science, pp. 157-166. , Shi, X., V. Kindratenko and C. Yang (Eds.), Springer, Boston, MA; Mohsen, H., El-Dahshan, E.S.A., El-Horbaty, E.S.M., Salem, A.B.M., Classification using deep learning neural networks for brain tumors (2017) Future Comput. Inform. J, 3, pp. 68-71; Mukhopadhyay, S., Feldman, M.D., Abels, E., Ashfaq, R., Beltaifa, S., Whole slide imaging versus microscopy for primary diagnosis in surgical pathology of 1992 cases (Pivotal Study) (2018) Am. J. Surgical Pathol, 42, pp. 39-52; Mure, S., Grenier, T., Meier, D.S., Guttmann, C.R.G., Benoit-Cattin, H., Unsupervised spatio-temporal filtering of image sequences (2015) A mean-shift specification. Patt. Recognit. Lett, 68, pp. 48-55; Oskouei, S.S.L., Golestani, H., Hashemi, M., Ghiasi, S., CNNdroid: GPU-accelerated execution of trained deep convolutional neural networks on android (2015) Proceedings of the 24th ACM International Conference on Multimedia, pp. 1201-1205. , (ICM' 15), ACM; Oztürk, S., Akdemir, B., Application of feature extraction and classification methods for histopathological image using GLCM, LBP, LBGLCM, GLRLM and SFTA (2018) Proc. Comput. Sci, 132, pp. 40-46; Peyret, R., Bouridane, A., Khelifi, F., Tahir, M.A., Al-Maadeed, S., Automatic classification of colorectal and prostatic histologic tumor images using multiscale multispectral local binary pattern texture features and stacked generalization (2018) Neurocomputing, 275, pp. 83-93; Qayyum, A., Anwar, S.M., Awais, M., Majid, M., Medical image retrieval using deep convolutional neural network (2017) Neurocomputing, 266, pp. 8-20; Schmidhuber, J., Deep learning in neural network: An overview (2014) Neural Netw, 61, pp. 85-117; Sheela, K.G., Deepa, S.N., Review on methods to fix number of hidden neurons in neural networks (2013) Math. Problems Eng; Siegel, R.L., Miller, K.D., Jemal, A., Cancer statistics, 2018 (2018) CA: A Cancer J. Clinicians, 68, pp. 7-30; Sirinukunwattana, K., Raza, S.E.A., Tsang, Y.W., Snead, D.R.J., Cree, I.A., Locality sensitive deep learning for detection and classification of nuclei in routine colon cancer histology images (2016) IEEE Trans. Med. Imag, 35, pp. 1196-1206; Theano: A python framework for fast computation of mathematical expressions (2016) The Theano Development Team; Vallabhaneni, R.B., Rajesh, V., Brain tumor detection using mean shift clustering and GLCM features with edge adaptive total variation denoising technique (2017) ARPN J. Eng. Applied Sci, 12, pp. 666-671; Yang, X., Pei, J., Sun, W., Elastic image registration using hierarchical spatially based mean shift (2013) Comput. Biol. Med, 43, pp. 1086-1097; Zhang, J., Xiao, J., Wan, J., Yang, J., Ren, Y., A parallel strategy for convolutional neural network based on heterogeneous cluster for mobile information system (2017) Mobile Inform. Syst","Haryanto, T.; Faculty of Computer Science, Indonesia; email: toto.haryanto@ui.ac.id",,,"Science Publications",,,,,15493636,,,,"English","J. Comput. Sci.",Article,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85086875982
"Li S., Luo Y., Sun K., Yadav N., Choi K.K.","56645088000;57202471392;57202467811;56007545200;23975486700;","A Novel FPGA Accelerator Design for Real-Time and Ultra-Low Power Deep Convolutional Neural Networks Compared with Titan X GPU",2020,"IEEE Access","8",,"9108269","105455","105471",,14,"10.1109/ACCESS.2020.3000009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086711993&doi=10.1109%2fACCESS.2020.3000009&partnerID=40&md5=5d9e310083ca3c779941fef143dcc4f8","VLSI Design and Automation Laboratory, Illinois Institute of Technology, Chicago, IL, United States; Department of Electrical and Computer Engineering, University of Illinois at Chicago, Chicago, IL, United States; Department of Computer Science, Rice University, Houston, TX, United States","Li, S., VLSI Design and Automation Laboratory, Illinois Institute of Technology, Chicago, IL, United States; Luo, Y., Department of Electrical and Computer Engineering, University of Illinois at Chicago, Chicago, IL, United States; Sun, K., Department of Computer Science, Rice University, Houston, TX, United States; Yadav, N., VLSI Design and Automation Laboratory, Illinois Institute of Technology, Chicago, IL, United States; Choi, K.K., VLSI Design and Automation Laboratory, Illinois Institute of Technology, Chicago, IL, United States","Convolutional neural networks (CNNs) based deep learning algorithms require high data flow and computational intensity. For real-time industrial applications, they need to overcome challenges such as high data bandwidth requirement and power consumption on hardware platforms. In this work, we have analyzed in detail the data dependency in the CNN accelerator and propose specific pipelined operations and data organized manner to design a high throughput CNN accelerator on FPGA. Besides, we have optimized the kernel operations to obtain a high power efficiency. The proposed CNN accelerator supports image classification and real-time object detection with high accuracy. The evaluation results show that our CNN-based FPGA accelerator can achieve 740 Giga operations per second (GOPS) at 200 MHz with kernel power of 12.2 watts on Intel Arria 10 FPGA. For object detection tasks, our system can achieve 105 fps with 56.5 mAP or 25 fps with 73.6 mAP on VOC dataset. Since we use the mixed fixed-point data representation, the detection accuracy is comparable with the GPU-based YOLO V2 framework. The power efficiency of our system is sim 3.3 times better than Titan X GPU and sim 418 times better than Intel E5-2620 V4 CPU. © 2013 IEEE.","Deep neural network accelerator; FPGA; low power; mixed fixed-point; object detection; parallel computing; pipeline architecture","Acceleration; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Efficiency; Field programmable gate arrays (FPGA); Graphics processing unit; Integrated circuit design; Low power electronics; Object detection; Object recognition; Computational intensity; Data dependencies; Detection accuracy; Evaluation results; Fpga accelerators; Giga-operations per seconds; Hardware platform; High power efficiencies; Pipeline processing systems",,,,,"10083639; Ministry of Trade, Industry and Energy, MOTIE","This work was supported by the Industrial Core Technology Development Program of the Ministry of Trade, Industry and Energy (MOTIE)/Korea Electronics Technology Institute (KETI), South Korea (Development of Camera-Based Real-Time Artificial Intelligence System for Detecting Driving Environment and Recognizing Objects on Road Simultaneously), under Grant 10083639.",,,,,,,,,,"Li, S., Luo, Y., Sun, K., Choi, K., Heterogeneous system implementa-tion of deep learning neural network for object detection in OpenCL frame-work (2018) Proc. Int. Conf. Electron., Inf., Commun. (ICEIC), pp. 1-4. , Jan; Redmon, J., Farhadi, A., YOLO9000: Better, faster, stronger (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 7263-7271. , Jul; The OpenCL specification (2017) Khronos OpenCL Working Group, Beaverton, OR, USA, Tech. Rep. Version 2.1, , K. Group; (2017) CUDA Toolkit Documentation: Nvidia Developer ZoneCUDA C Program-ming Guide V8.0, Nvidia, Santa Clara, CA, USA; (2015) CuDNN. Nvidia, Santa Clara, CA, USA, , https://developer.nvidia.com/cudnn2015; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. ACM Int. Conf. Multimedia MM, pp. 675-678; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., Optimizing the convolution operation to accelerate deep neural networks on FPGA (2018) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 26 (7), pp. 1354-1367. , Jul; Geng, T., Wang, T., Sanaullah, A., Yang, C., Patel, R., Herbordt, M., Aframework for acceleration ofCNNtraining on deeply-pipelined FPGA clusters with work and weight load balancing (2018) Proc. 28th Int. Conf. Field Program. Log. Appl. (FPL), pp. 394-3944. , Aug; Bai, L., Zhao, Y., Huang, X., A CNN accelerator on FPGA using depthwise separable convolution (2018) IEEE Trans. Circuits Syst. II, Exp. Briefs, 65 (10), pp. 1415-1419. , Oct; Zeng, H., Chen, R., Zhang, C., Prasanna, V., Aframework for generating high throughput CNN implementations on FPGAs (2018) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays, pp. 117-126. , Feb; Nakahara, H., Yonekawa, H., Fujii, T., Sato, S., A lightweight YOLOv2: A binarized CNN with a parallel support vector regression for an FPGA (2018) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays, pp. 31-40. , Feb; Preuser, T.B., Gambardella, G., Fraser, N., Blott, M., Inference of quantized neural networks on heterogeneous all-programmable devices (2018) Proc. Design, Autom. Test Eur. Conf. Exhib. (DATE), pp. 833-838. , Mar; Cong, J., Xiao, B., Minimizing computation in convolutional neu-ral networks (2014) Proc. Int. Conf. Artif. Neural Netw. Berlin, Germany: Springer, pp. 281-290; Aydonat, U., O'Connell, S., Capalija, D., Ling, A.C., Chiu, G.R., An OpenCL deep learning accelerator on arria 10 (2017) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays FPGA, pp. 55-64; Suda, N., Chandra, V., Dasika, G., Mohanty, A., Ma, Y., Vrudhula, S., Seo, J.-S., Cao, Y., Throughput-optimized OpenCL-based FPGA accelerator for large-scale convolutional neural networks (2016) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays FPGA, pp. 16-25; Li, H., Fan, X., Jiao, L., Cao, W., Zhou, X., Wang, L., A high performance FPGA-based accelerator for large-scale convolutional neural networks (2016) Proc. 26th Int. Conf. Field Program. Log. Appl. (FPL), pp. 1-9. , Aug; Motamedi, M., Gysel, P., Akella, V., Ghiasi, S., Design space explo-ration of FPGA-based deep convolutional neural networks (2016) Proc. 21st Asia South Pacific Design Autom. Conf. (ASP-DAC), pp. 575-580. , Jan; Nurvitadhi, E., Weisz, G., Wang, Y., Hurkat, S., Nguyen, M., Hoe, J.C., Martinez, J.F., Guestrin, C., GraphGen: An FPGA framework for vertex-centric graph computation (2014) Proc. IEEE 22nd Annu. Int. Symp. Field-Program. Custom Comput. Mach., pp. 25-28. , May; Farabet, C., Poulet, C., Han, J.Y., LeCun, Y., CNP: An FPGA-based processor for convolutional networks (2009) Proc. Int. Conf. Field Program. Log. Appl., pp. 32-37. , Aug; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays FPGA, pp. 161-170; Gokhale, V., Jin, J., Dundar, A., Martini, B., Culurciello, E., A 240 G-ops/s mobile coprocessor for deep neural networks (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops, pp. 682-687. , Jun; Fujii, T., Sato, S., Nakahara, H., A threshold neuron pruning for a binarized deep neural network on an FPGA (2018) IEICE Trans. Inf. Syst., 101 (2), pp. 376-386. , Feb; Hailesellasie, M., Hasan, S.R., Khalid, F., Wad, F.A., Shafique, M., FPGA-based convolutional neural network architecture with reduced parameter requirements (2018) Proc. IEEE Int. Symp. Circuits Syst. (ISCAS), pp. 1-5. , May; Zhang, C., Sun, G., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: Towards uniformed representation and acceleration for deep convolutional neural networks (2019) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 38 (11), pp. 2072-2085. , Nov; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: Efficient inference engine on compressed deep neural network (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit. (ISCA), pp. 243-254. , Jun; Motamedi, M., Gysel, P., Ghiasi, S., PLACID: A platform for FPGA-based accelerator creation for DCNNs (2017) ACM Trans. Multimedia Comput., Commun., Appl., 13 (4), p. 62; Guan, Y., Liang, H., Xu, N., Wang, W., Shi, S., Chen, X., Sun, G., Cong, J., FP-DNN: An automated framework for mapping deep neural networks onto FPGAs with RTL-HLS hybrid templates (2017) Proc. IEEE 25th Annu. Int. Symp. Field-Program. Custom Comput. Mach. (FCCM), pp. 152-159. , Apr; DiCecco, R., Lacey, G., Vasiljevic, J., Chow, P., Taylor, G., Areibi, S., Caffeinated FPGAs: FPGA framework for convolutional neural net-works (2016) Proc. Int. Conf. Field-Program. Technol. (FPT), pp. 265-268. , Dec; Guo, K., Sui, L., Qiu, J., Yu, J., Wang, J., Yao, S., Han, S., Yang, H., Angel-eye: A complete design flow for mapping CNN onto embedded FPGA (2018) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 37 (1), pp. 35-47. , Jan; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Pro-cess. Syst., pp. 1097-1105; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., (2016) SqueezeNet: AlexNet-level accuracy with 50x fewer param-eters and <0.5MB model size, , http://arxiv.org/abs/1602.07360, arXiv:1602.07360; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) MobileNets: Efficient Convolutional Neu-ral Networks for Mobile Vision Applications, , http://arxiv.org/abs/1704.04861, arXiv:1704.04861; Ioffe, S., Szegedy, C., (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, , http://arxiv.org/abs/1502.03167, arXiv:1502.03167; Alyamkin, S., Low-power computer vision: Status, challenges, and opportunities (2019) IEEE J. Emerg. Sel. Topics Circuits Syst., 9 (2), pp. 411-421. , Jun; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., Automatic compilation of diverse CNNs onto high-performance FPGA accelerators (2020) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 39 (2), pp. 424-437. , Feb; Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., The Pascal visual object classes (VOC) challenge (2010) Int. J. Comput. Vis., 88 (2), pp. 303-338. , Jun; Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J., (2016) Prun-ing Convolutional Neural Networks for Resource Efficient Inference, , http://arxiv.org/abs/1611.06440, arXiv:1611.06440; (2016) ImageNet, , http://www.image-net.org/, ImageNet; https://www.bilibili.com/video/av62554595","Li, S.; VLSI Design and Automation Laboratory, United States; email: sli97@hawk.iit.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85086711993
"Chung H., Ko H., Lee H., Lee J.","57143278800;57190950665;57192917390;57314523000;","Deep Learning for Heart Rate Estimation from Reflectance Photoplethysmography with Acceleration Power Spectrum and Acceleration Intensity",2020,"IEEE Access","8",,"9042276","63390","63402",,11,"10.1109/ACCESS.2020.2981956","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083720033&doi=10.1109%2fACCESS.2020.2981956&partnerID=40&md5=8b5e545bd5457bc700b9ed507f2a1821","Department of Biomedical Engineering, Wonkwang University, College of Medicine, Iksan, 54538, South Korea","Chung, H., Department of Biomedical Engineering, Wonkwang University, College of Medicine, Iksan, 54538, South Korea; Ko, H., Department of Biomedical Engineering, Wonkwang University, College of Medicine, Iksan, 54538, South Korea; Lee, H., Department of Biomedical Engineering, Wonkwang University, College of Medicine, Iksan, 54538, South Korea; Lee, J., Department of Biomedical Engineering, Wonkwang University, College of Medicine, Iksan, 54538, South Korea","Objective: A wearable reflectance-type photoplethysmography (PPG) sensor can be incorporated in a watch or band to provide instantaneous heart rates (HRs) with minimum inconvenience to users. However, the sensor is sensitive to motion artifacts (MAs), which results in inaccurate HR estimation. To address this problem, we propose a new neural network for deep learning to ensure accurate HR estimation even during intensive exercise. Methods: We propose a new deep neural network based on multiclass and non-uniform multilabel classification for HR estimation. It comprises of two convolutional layers, two long short-term memory (LSTM) layers, one concatenation layer, and three fully connected layers including a softmax. The proposed model feeds the power spectra from the PPG and acceleration signals along with the acceleration intensity to the input layer. We also present a new scheme to evaluate the loss value by modifying the true HR value into a Gaussian distribution. Results: We used 48 training datasets and evaluated 23 isolated testing datasets. The proposed model exhibited average absolute error of less than 1.5 bpm for all the training and test datasets - 1.09 bpm for the training dataset and 1.46 bpm for the test dataset. Conclusion: The proposed model outperforms the state-of-the-art methods for accurate estimation of HR. Significance: It precisely estimates the HRs with robustness even during intensive physical exercise, as evidenced by the accuracy when PPG signals are severely corrupted by MAs. © 2013 IEEE.","convolutional layer; deep learning; instantaneous heart rate; long short-term memory (LSTM) layer; Reflectance-type photoplethysmography","Deep neural networks; Heart; Long short-term memory; Photoplethysmography; Power spectrum; Reflection; Statistical tests; Wearable sensors; Acceleration signals; Accurate estimation; Average absolute error; Instantaneous heart rates; Multi-label classifications; Photoplethysmography (PPG); State-of-the-art methods; Training data sets; Deep learning",,,,,"Ministry of Science, ICT and Future Planning, MSIP: NRF-2015M3A9D7067215, NRF-2020R1A2C1014829; National Research Foundation of Korea, NRF","This work was supported by the National Research Foundation of Korea (NRF), Ministry of Science, ICT, and Future Planning, through the Basic Science Research Program under Grant NRF-2020R1A2C1014829 and Grant NRF-2015M3A9D7067215.",,,,,,,,,,"Zhang, Z., Pi, Z., Liu, B., TROIKA: A general framework for heart rate monitoring using wrist-type photoplethysmographic signals during intensive physical exercise (2015) Ieee Trans. Biomed. Eng., 62 (2), pp. 522-531. , Feb; Zhang, Z., Photoplethysmography-based heart rate monitoring in physical activities via joint sparse spectrum reconstruction (2015) Ieee Trans. Biomed. Eng., 62 (8), pp. 1902-1910. , Aug; Salehizadeh, S., Dao, D., Bolkhovsky, J., Cho, C., Mendelson, Y., Chon, K., Anovel time-varying spectral filtering algorithm for reconstruction of motion artifact corrupted heart rate signals during intense physical activities using a wearable photoplethysmogram sensor (2016) Sensors, 16 (1), p. 10; Fallet, S., Vesin, J.-M., Robust heart rate estimation using wrist-type photoplethysmographic signals during physical exercise: An approach based on adaptive filtering (2017) Physiol. Meas., 38 (2), pp. 155-170. , Feb; Boloursaz Mashhadi, M., Asadi, E., Eskandari, M., Kiani, S., Marvasti, F., Heart rate tracking using wrist-type photoplethysmographic (PPG) signals during physical exercise with simultaneous accelerometry (2016) Ieee Signal Process. Lett., 23 (2), pp. 227-231. , Feb; Sun, B., Zhang, Z., Photoplethysmography-based heart rate monitoring using asymmetric least squares spectrum subtraction and Bayesian decision theory (2015) Ieee Sensors J., 15 (12), pp. 7161-7168. , Dec; Temko, A., Accurate heart rate monitoring during physical exercises using PPG (2017) Ieee Trans. Biomed. Eng., 64 (9), pp. 2016-2024. , Sep; Motin, M.A., Karmakar, C.K., Palaniswami, M., PPG derived heart rate estimation during intensive physical exercise (2019) Ieee Access, 7, pp. 56062-56069; Khan, E., Al Hossain, F., Uddin, S.Z., Alam, S.K., Hasan, M.K., A robust heart rate monitoring scheme using photoplethysmographic signals corrupted by intense motion artifacts (2016) Ieee Trans. Biomed. Eng., 63 (3), pp. 550-562. , Mar; Lee, H., Chung, H., Ko, H., Lee, J., Wearable multichannel photo-plethysmography framework for heart rate monitoring during intensive exercise (2018) Ieee Sensors J., 18 (7), pp. 2983-2993. , Apr; Nathan, V., Jafari, R., Particle filtering and sensor fusion for robust heart rate monitoring using wearable sensors (2018) Ieee J. Biomed. Health Informat., 22 (6), pp. 1834-1846. , Nov; Fujita, Y., Hiromoto, M., Sato, T., PARHELIA: Particle filter-based heart rate estimation from photoplethysmographic signals during physical exercise (2018) Ieee Trans. Biomed. Eng., 65 (1), pp. 189-198. , Jan; Galli, A., Narduzzi, C., Giorgi, G., Measuring heart rate during physical exercise by subspace decomposition and Kalman smoothing (2018) Ieee Trans. Instrum. Meas., 67 (5), pp. 1102-1110. , May; Chung, H., Lee, H., Lee, J., State-dependent Gaussian kernel-based power spectrum modification for accurate instantaneous heart rate estimation (2019) PLoS One, 14 (4); Chung, H., Lee, H., Lee, J., Finite state machine framework for instantaneous heart rate validation using wearable photoplethysmography during intensive exercise (2019) Ieee J. Biomed. Health Informat., 23 (4), pp. 1595-1606. , Jul; Lee, J., Chung, H., Lee, H., Multi-mode particle filtering methods for heart rate estimation from wearable photoplethysmography (2019) Ieee Trans. Biomed. Eng., 66 (10), pp. 2789-2799. , Oct; Biswas, D., Everson, L., Liu, M., Panwar, M., Verhoef, B.-E., Patki, S., Kim, C.H., Van Helleputte, N., CorNET: Deep learning framework for PPG-based heart rate estimation and biometric identification in ambulant environment (2019) Ieee Trans. Biomed. Circuits Syst., 13 (2), pp. 282-291. , Apr; Zhang, Z., (2019) Ieee Signal Processing Cup 2015: Heart Rate Monitoring during Physical Exercise Using Wrist-Type Photoplethysmo-graphic (PPG) Signals., , https://sites.google.com/site/researchbyzhang/ieeespcup2015, Accessed: Jan. 15 [Online]; Chung, H., Lee, H., Ko, H., Lee, J., (2019) CNN-LSTM Based Heart Rate Estimation from Ppg and Acceleration., , https://github.com/HeewonChung92/CNN_LSTM_HeartRateEstimation, Accessed: Jun. 15, [Online]; Lu, S., Zhao, H., Ju, K., Shin, K., Lee, M., Shelley, K., Chon, K.H., Can photoplethysmography variability serve as an alternative approach to obtain heart rate variability information? (2008) J. Clin. Monitor. Comput., 22 (1), pp. 23-29. , Jan; Selvaraj, N., Jaryal, A., Santhosh, J., Deepak, K.K., Anand, S., Assessment of heart rate variability derived from finger-tip photoplethysmography as compared to electrocardiography (2008) J. Med. Eng. Technol., 32 (6), pp. 479-484. , Jan; Mashhadi, M.B., Farhadi, M., Essalat, M., Marvasti, F., Low complexity heart rate measurement from wearable wrist-type photoplethysmographic sensors robust to motion artifacts (2018) Proc. Ieee Int. Conf. Acoust., Speech Signal Process. (ICASSP), pp. 921-924. , Calgary, AB, Canada, Apr; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1251-1258. , Jul; Shyam, A., Ravichandran, V., Preejith, S.P., Joseph, J., Sivaprakasam, M., PPGnet: Deep network for device independent heart rate estimation from photoplethysmogram (2019) Proc. 41st Annu. Int. Conf. Ieee Eng. Med. Biol. Soc. (EMBC), pp. 1899-1902. , Berlin, Germany, Jul; Essalat, M., Mashhadi, M.B., Marvasti, F., Supervised heart rate tracking using wrist-type photoplethysmographic (PPG) signals during physical exercise without simultaneous acceleration signals (2016) Proc. Ieee Global Conf. Signal Inf. Process. (GlobalSIP), pp. 1166-1170. , Washington, DC, USA, Dec; Reiss, A., Indlekofer, I., Schmidt, P., Van Laerhoven, K., Deep PPG: Large-scale heart rate estimation with convolutional neural networks (2019) Sensors, 19 (14), p. 3079; Tang, J., Sun, D., Liu, S., Gaudiot, J.-L., Enabling deep learning on IoT devices (2017) Computer, 50 (10), pp. 92-96","Lee, J.; Department of Biomedical Engineering, South Korea; email: gonasago@wku.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85083720033
"Han X., Ye J., Luo J., Zhou H.","57216205155;57198795447;57203554479;57216202936;","The effect of axis-wise triaxial acceleration data fusion in CNN-based human activity recognition",2020,"IEICE Transactions on Information and Systems","E103D","4",,"813","824",,2,"10.1587/transinf.2018EDP7409","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082831468&doi=10.1587%2ftransinf.2018EDP7409&partnerID=40&md5=b072b389a7ff487491fd1cfba18cc0d2","School of Data Science, North University of China, TaiYuan, 030051, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Beijing, 100000, China; College of Economics and Management, Beijing University of Technology, Beijing, 100124, China","Han, X., School of Data Science, North University of China, TaiYuan, 030051, China, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Ye, J., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China, Beijing Key Laboratory of Mobile Computing and Pervasive Device, Beijing, 100000, China; Luo, J., College of Economics and Management, Beijing University of Technology, Beijing, 100124, China; Zhou, H., School of Data Science, North University of China, TaiYuan, 030051, China","The triaxial accelerometer is one of the most important sensors for human activity recognition (HAR). It has been observed that the relations between the axes of a triaxial accelerometer plays a significant role in improving the accuracy of activity recognition. However, the existing research rarely focuses on these relations, but rather on the fusion of multiple sensors. In this paper, we propose a data fusion-based convolutional neural network (CNN) approach to effectively use the relations between the axes. We design a single-channel data fusion method and multichannel data fusion method in consideration of the diversified formats of sensor data. After obtaining the fused data, a CNN is used to extract the features and perform classification. The experiments show that the proposed approach has an advantage over the CNN in accuracy. Moreover, the single-channel model achieves an accuracy of 98.83% with the WISDM dataset, which is higher than that of state-of-the-art methods. © 2020 The Institute of Electronics, Information and Communication Engineers.","Convolutional neural network; Data fusion; Human activity recognition; Triaxial accelerometer","Accelerometers; Convolution; Convolutional neural networks; Data fusion; Pattern recognition; Acceleration data; Activity recognition; Data fusion methods; Human activity recognition; Multichannel data; Multiple sensors; State-of-the-art methods; Triaxial accelerometer; Sensor data fusion",,,,,,,,,,,,,,,,"Cook, D.J., Krishnan, N.C., Rashidi, P., Activity discovery and activity recognition: A new partnership (2013) IEEE Trans. Cybern., 43 (3), pp. 820-828; Wan, S., Liang, Y., Zhang, Y., Guizani, M., Deep multilayer perceptron classifier for behavior analysis to estimate parkinson's disease severity using smartphones (2018) IEEE Access, 6, pp. 36825-36833; Chen, L., Hoey, J., Nugent, C.D., Cook, D.J., Yu, Z., Sensor-based activity recognition (2012) IEEE Trans. Syst., Man, Cybern. C, Appl. Rev., 42 (6), pp. 790-808; Chen, Y., Shen, C., Performance analysis of smartphone-sensor behavior for human activity recognition (2017) IEEE Access, 5, pp. 3095-3110; Hnoohom, N., Mekruksavanich, S., Jitpattanakul, A., Human activity recognition using triaxial acceleration data from smartphone and ensemble learning (2017) 2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS), pp. 408-412. , IEEE; Wang, A., Chen, G., Yang, J., Zhao, S., Chang, C.-Y., A comparative study on human activity recognition using inertial sensors in a smartphone (2016) IEEE Sensors J., 16 (11), pp. 4566-4578; Singh, D., Merdivan, E., Psychoula, I., Kropf, J., Hanke, S., Geist, M., Holzinger, A., Human activity recognition using recurrent neural networks (2017) International Cross-Domain Conference for Machine Learning and Knowledge Extraction, pp. 267-274. , Springer; Zhang, L., Wu, X., Luo, D., Real-time activity recognition on smartphones using deep neural networks, "" (2015) 2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom), pp. 1236-1242. , IEEE; Zhang, L., Wu, X., Luo, D., Recognizing human activities from raw accelerometer data using deep neural networks (2015) 2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA), pp. 865-870. , IEEE; Gjoreski, H., Bizjak, J., Gjoreski, M., Gams, M., Comparing deep and classical machine learning methods for human activity recognition using wrist accelerometer (2016) Proc. IJCAI 2016Workshop on Deep Learning for Artificial Intelligence, New York, NY, USA; Yang, J., Nguyen, M.N., San, P.P., Li, X., Krishnaswamy, S., Deep convolutional neural networks on multichannel time series for human activity recognition (2015) IJCAI, pp. 3995-4001; Zeng, M., Nguyen, L.T., Yu, B., Mengshoel, O.J., Zhu, J., Wu, P., Zhang, J., Convolutional neural networks for human activity recognition using mobile sensors (2014) 2014 6th International Conference on Mobile Computing, Applications and Services (MobiCASE), pp. 197-205. , IEEE; Wang, J., Chen, Y., Hao, S., Peng, X., Hu, L., Deep learning for sensor-based activity recognition: A survey (2018) Pattern Recognition Letters; Jiang, W., Yin, Z., Human activity recognition using wearable sensors by deep convolutional neural networks (2015) Proc. 23rd ACM International Conference on Multimedia, pp. 1307-1310. , Acm; Wang, S., Yang, J., Chen, N., Chen, X., Zhang, Q., Human activity recognition with user-free accelerometers in the sensor networks (2005) 2005 International Conference on Neural Networks and Brain, pp. 1212-1217. , IEEE; Bao, L., Intille, S.S., Activity recognition from user-annotated acceleration data (2004) International Conference on Pervasive Computing, pp. 1-17. , Springer; Ravi, N., Dandekar, N., Mysore, P., Littman, M.L., Activity recognition from accelerometer data (2005) AAAI, pp. 1541-1546; Yang, J.-Y., Wang, J.-S., Chen, Y.-P., Using acceleration measurements for activity recognition: An effective learning algorithm for constructing neural classifiers (2008) Pattern Recognition Letters, 29 (16), pp. 2213-2220; He, Z.-Y., Jin, L.-W., Activity recognition from acceleration data using ar model representation and svm (2008) 2008 International Conference on Machine Learning and Cybernetics, pp. 2245-2250. , IEEE; Gu, T., Wang, L., Wu, Z., Tao, X., Lu, J., A pattern mining approach to sensor-based human activity recognition (2010) IEEE Trans. Knowl. Data Eng., 23 (9), pp. 1359-1372; Lu, Y., Wei, Y., Liu, L., Zhong, J., Sun, L., Liu, Y., Towards unsupervised physical activity recognition using smartphone accelerometers (2017) Multimedia Tools and Applications, 76 (8), pp. 10701-10719; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Ronao, C.A., Cho, S.B., Human activity recognition with smartphone sensors using deep learning neural networks (2016) Expert Systems with Applications, 59, pp. 235-244; Hammerla, N.Y., Halloran, S., Ploetz, T., (2016) Deep, Convolutional, and Recurrent Models for Human Activity Recognition Using Wearables; Ordónez, F.J., Roggen, D., Deep convolutional and lstm recurrent neural networks for multimodal wearable activity recognition (2016) Sensors, 16 (1), p. 115; Panwar, M., Dyuthi, S.R., Prakash, K.C., Biswas, D., Acharyya, A., Maharatna, K., Gautam, A., Naik, G.R., Cnn based approach for activity recognition using a wrist-worn accelerometer (2017) 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 2438-2441. , IEEE; Alsheikh, M.A., Selim, A., Niyato, D., Doyle, L., Lin, S., Tan, H.P., Deep activity recognition models with triaxial accelerometers (2016) AAAI Workshop: Artificial Intelligence Applied to Assistive Technologies and Smart Environments; Matsui, S., Inoue, N., Akagi, Y., Nagino, G., Shinoda, K., User adaptation of convolutional neural network for human activity recognition (2017) 2017 25th European Signal Processing Conference (EUSIPCO), pp. 753-757. , IEEE; Liu, L., Peng, Y., Wang, S., Liu, M., Huang, Z., Complex activity recognition using time series pattern dictionary learned from ubiquitous sensors (2016) Information Sciences, 340, pp. 41-57; Münzner, S., Schmidt, P., Reiss, A., Hanselmann, M., Stiefelhagen, R., Dürichen, R., Cnn-based sensor fusion techniques for multimodal human activity recognition (2017) Proc. 2017 ACM International Symposium on Wearable Computers, pp. 158-165. , ACM; Radu, V., Lane, N.D., Bhattacharya, S., Mascolo, C., Marina, M.K., Kawsar, F., Towards multimodal deep learning for activity recognition on mobile devices (2016) Proc. 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct, pp. 185-188. , ACM; Lee, S.-M., Yoon, S.M., Cho, H., Human activity recognition from accelerometer data using convolutional neural network (2017) 2017 IEEE International Conference on Big Data and Smart Computing (BigComp), pp. 131-134. , IEEE; Li, Y., Shi, D., Ding, B., Liu, D., Unsupervised feature learning for human activity recognition susing smartphone sensors (2014) Mining Intelligence and Knowledge Exploration, pp. 99-107. , Springer; Morales, F.J.O., Roggen, D., Deep convolutional feature transfer across mobile activity recognition domains, sensor modalities and locations (2016) Proc. 2016 ACM International Symposium on Wearable Computers, pp. 92-99. , ACM; Ha, S., Yun, J.-M., Choi, S., Multi-modal convolutional neural networks for activity recognition (2015) 2015 IEEE International Conference on Systems, Man, and Cybernetics (SMC), pp. 3017-3022. , IEEE; Chen, Y., Xue, Y., A deep learning approach to human activity recognition based on single accelerometer (2015) 2015 IEEE International Conference on Systems, Man, and Cybernetics (Smc), pp. 1488-1492. , IEEE; Kwapisz, J.R., Weiss, G.M., Moore, S.A., Activity recognition using cell phone accelerometers (2011) ACM SigKDD Explorations Newsletter, 12 (2), pp. 74-82; Anguita, D., Ghio, A., Oneto, L., Parra, X., Reyes-Ortiz, J.L., A public domain dataset for human activity recognition using smartphones (2013) ESANN; Catal, C., Tufekci, S., Pirmit, E., Kocabag, G., On the use of ensemble of classifiers for accelerometer-based activity recognition (2015) Applied Soft Computing, 37, pp. 1018-1022; Rav, D., A deep learning approach to on-node sensor data analytics for mobile or wearable devices (2017) IEEE J. Biomed. Health Inform., 21 (1), pp. 56-64; Rav, D., Deep learning for human activity recognition: A resource efficient implementation on low-power devices (2016) 2016 IEEE 13th International Conference on Wearable and Implantable Body Sensor Networks (BSN), pp. 71-76. , IEEE","Luo, J.; College of Economics and Management, China; email: jia.luo.bjut@hotmail.com",,,"Institute of Electronics, Information and Communication, Engineers, IEICE",,,,,09168532,,ITISE,,"English","IEICE Trans Inf Syst",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85082831468
"Yao Z., Huang K., Shen H., Ming Z.","57214144345;54581052800;13309317500;36447695600;","Deep Neural Network Acceleration with Sparse Prediction Layers",2020,"IEEE Access","8",,"8949362","6839","6848",,1,"10.1109/ACCESS.2020.2963941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078331488&doi=10.1109%2fACCESS.2020.2963941&partnerID=40&md5=ebfc5eabff69d3bb0057985de433cf45","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, 310012, China","Yao, Z., College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, 310012, China; Huang, K., College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, 310012, China; Shen, H., College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, 310012, China; Ming, Z., College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, 310012, China","The ever-increasing computation cost of Convolutional Neural Network (CNN) makes it imperative for real-world applications to accelerate the key steps especially the inference. In this work, we propose an efficient yet general scheme called Sparse Prediction Layer (SPL) which can predict and skip the trivial elements in the CNN layer. Pruned weights are used to predict the locations of maximum values in max-pooling kernels and those of positive values before Rectified Linear Units (ReLUs). Thereafter, the precise values of these predicted important elements are calculated selectively and the complete outputs are restored from them. Our experiments on ImageNet Large Scale Visual Recognition Competition (ILSVRC) 2012 show that SPL can reduce 68.3%, 58.6% and 59.5% Floating-point Operations (FLOPs) on AlexNet, VGG-16 and ResNet-50, respectively, within an accuracy loss of less than 1% without retraining. The proposed SPL scheme can further accelerate these networks pruned by other pruning-based methods, such as a FLOP reduction of 50.2% on the ResNet-50 which has been pruned by Channel Pruning (CP) before being applied with SPLs. A special matrix multiplication called Sparse Result Matrix Multiplication (SRMM) is proposed to support the implementation of SPL, and its acceleration effect is in line with expectations. © 2013 IEEE.","acceleration; Artificial intelligence; high performance computing; neural networks; sparse matrices","Acceleration; Artificial intelligence; Digital arithmetic; Forecasting; Matrix algebra; Multilayer neural networks; Neural networks; Acceleration effects; Computation costs; Convolutional neural network; Floating point operations; High performance computing; MAtrix multiplication; Sparse matrices; Visual recognition; Deep neural networks",,,,,"2019KC0AD02","This work was supported by the Major Scientific Research Project of Zhejiang Lab (No. 2019KC0AD02).",,,,,,,,,,"Lecun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D., Backpropagation applied to handwritten zip code recognition (1989) Neural Comput, 1 (4), pp. 541-551. , Dec; Denil, M., Shakibi, B., Dinh, L., Ranzato, M., De Freitas, N., Predicting parameters in deep learning (2013) Proc. Adv. Neural Inf. Process. Syst, pp. 2148-2156; LeCun, Y., Denker, J.S., Solla, S.A., Optimal brain damage (1990) Proc. Adv. Neural Inf. Process. Syst, pp. 598-605; Hassibi, B., Stork, D.G., Second order derivatives for network pruning: Optimal brain surgeon (1993) Proc. Adv. Neural Inf. Process. Syst, pp. 164-171; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Proc. Adv. Neural Inf. Process. Syst, pp. 1135-1143; Guo, Y., Yao, A., Chen, Y., Dynamic network surgery for efficient DNNs (2016) Proc. Adv. Neural Inf. Process. Syst, pp. 1379-1387; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning filters for efficient convnets (2016) Proc. Int. Conf. Learn. Represent; Hu, H., Peng, R., Tai, Y.-W., Tang, C.-K., (2016) Network Trimming: A Data-driven Neuron Pruning Approach towards Efficient Deep Architectures, , Hong Kong Univ. Sci. Technol., SenseTime Group Ltd., Hong Kong, Tech. Rep. arXiv, 1607.03250; Luo, J.-H., Wu, J., Lin, W., ThiNet: A filter level pruning method for deep neural network compression (2017) Proc. IEEE Int. Conf. Comput. Vis. ICCV, pp. 5068-5076. , Oct; He, Y., Zhang, X., Sun, J., Channel Pruning for Accelerating Very Deep Neural Networks (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV, pp. 1389-1397. , Oct; Zhuang, Z., Tan, M., Zhuang, B., Liu, J., Guo, Y., Wu, Q., Huang, J., Zhu, J., Discrimination-aware channel pruning for deep neural networks (2018) Proc. Adv. Neural Inf. Process. Syst, pp. 875-886; Yu, R., Li, A., Chen, C.-F., Lai, J.-H., Morariu, V.I., Han, X., Gao, M., Davis, L.S., NISP: Pruning networks using neuron importance score propagation (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit, pp. 9194-9203. , Jun; Figurnov, M., Ibraimova, A., Vetrov, D.P., Kohli, P., Perforatedcnns: Acceleration through elimination of redundant convolutions (2016) Proc. Adv. Neural Inf. Process. Syst, pp. 947-955; Gao, X., Zhao, Y., Dudziak, L., Mullins, R., Xu, C.-Z., Dynamic channel pruning: Feature boosting and suppression (2019) Proc. Int. Conf. Learn. Represent; Dong, X., Huang, J., Yang, Y., Yan, S., Moreisless: A more complicated network with less inference complexity (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. CVPR, pp. 5840-5848. , Jul; Park, J., Li, S., Wen, W., Tang, P.T.P., Li, H., Chen, Y., Dubey, P., Faster CNNs with direct sparse convolutions and guided pruning (2017) Proc. Int. Conf. Learn. Represent; Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J., Pruning convolu-tional neural networks for resource efficient inference (2017) Proc. Int. Conf. Learn. Represent; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst, pp. 1097-1105; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR, pp. 770-778. , Jun; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis, 115 (3), pp. 211-252. , Dec; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) Proc. Int. Conf. Learn. Represent; Abadi, M., (2015) TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, , https://www.tensorflow.org/, Online]; Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Lerer, A., Automatic differentiation in pytorch (2017) Proc. Adv. Neural Inf. Process. Syst. Workshops; Buluç, A., Fineman, J.T., Frigo, M., Gilbert, J.R., Leiserson, C.E., Parallel sparse matrix-vector and matrix-transpose-vector multiplication using compressed sparse blocks (2009) Proc. 21st Annu. Symp. Parallelism Algorithms Archit, pp. 233-244; Chellapilla, K., Puri, S., Simard, P., High performance convolutional neural networks for document processing (2006) Proc. 10th Int. Workshop Frontiers Handwriting Recognit; Goto, K., Geijn, R.A., Anatomy of high-performance matrix multiplication (2008) ACM Trans. Math. Softw, 34 (3), p. 12","Huang, K.; College of Information Science and Electronic Engineering, China; email: huangkejie@zju.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85078331488
"Yan L., Zhen T., Kong J.-L., Wang L.-M., Zhou X.-L.","56390997300;57214096303;57195225361;7409178039;57214098723;","Walking gait phase detection based on acceleration signals using voting-weighted integrated neural network",2020,"Complexity","2020",,"4760297","","",,13,"10.1155/2020/4760297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078118729&doi=10.1155%2f2020%2f4760297&partnerID=40&md5=a9d7584e1582ad5a75184c64910f11bb","Beijing Forestry University, Beijing, 100083, China; Beijing Technology and Business University, Beijing, 100048, China","Yan, L., Beijing Forestry University, Beijing, 100083, China; Zhen, T., Beijing Forestry University, Beijing, 100083, China; Kong, J.-L., Beijing Technology and Business University, Beijing, 100048, China; Wang, L.-M., Beijing Forestry University, Beijing, 100083, China; Zhou, X.-L., Beijing Forestry University, Beijing, 100083, China","Human gait phase recognition is a significant technology for rehabilitation training robot, human disease diagnosis, artificial prosthesis, and so on. The efficient design of the recognition method for gait information is the key issue in the current gait phase division and eigenvalues extraction research. In this paper, a novel voting-weighted integrated neural network (VWI-DNN) is proposed to detect different gait phases from multidimensional acceleration signals. More specifically, it first employs a gait information acquisition system to collect different IMU sensors data fixed on the human lower limb. Then, with dimensionality reduction and four-phase division preprocessing, key features are selected and merged as unified vectors to learn common and domain knowledge in time domain. Next, multiple refined DNNs are transferred to design a multistream integrated neural network, which utilizes the mixture-granularity information to exploit high-dimensional feature representative. Finally, a voting-weighted function is developed to fuse different submodels as a unified representation for distinguishing small discrepancy among different gait phases. The end-to-end implementation of the VWI-DNN model is fine-tuned by the loss optimization of gradient back-propagation. Experimental results demonstrate the outperforming performance of the proposed method with higher classification accuracy compared with the other methods, of which classification accuracy and macro-F1 is up to 99.5%. More discussions are provided to indicate the potential applications in combination with other works. © 2020 Lei Yan et al.",,"Backpropagation; Diagnosis; Eigenvalues and eigenfunctions; Signal detection; Time domain analysis; Acceleration signals; Artificial prosthesis; Classification accuracy; Dimensionality reduction; High dimensional feature; Information acquisition system; Recognition methods; Rehabilitation training; Pattern recognition",,,,,"National Natural Science Foundation of China, NSFC: 61673002; Beijing Municipal Commission of Education: KM201910011010; National Key Research and Development Program of China, NKRDPC: 2017YFC1600605; Fundamental Research Funds for the Central Universities: 2015ZCQGX- 03","This study was financially supported by the Fundamental Research Funds for the Central Universities (No. 2015ZCQGX- 03), National Key Research and Development Program of China (No. 2017YFC1600605), National Natural Science Foundation of China (No. 61673002), and Beijing Municipal Education Commission (No. KM201910011010).",,,,,,,,,,"Nazmi, N., Abdul Rahman, M.A., Yamamoto, S.-I., Ahmad, S.A., Walking gait event detection based on electromyography signals using artificial neural network (2019) Biomedical Signal Processing and Control, 47, pp. 334-343. , 2-s2.0-85053192544; Okubo, Y., Schoene, D., Lord, S.R., Step training improves reaction time, gait and balance and reduces falls in older people: A systematic review and meta-analysis (2017) British Journal of Sports Medicine, 51 (102), pp. 586-593. , 2-s2.0-84956639572; Tian, S., Li, M., Wang, Y., Chen, X., Application of an improved correlation method in electrostatic gait recognition of hemiparetic patients (2019) Sensors, 19 (11), p. 2529. , 2-s2.0-85067496139; Yan, T., Cempini, M., Oddo, C.M., Vitiello, N., Review of assistive strategies in powered lower-limb orthoses and exoskeletons (2015) Robotics and Autonomous Systems, 64, pp. 120-136. , 2-s2.0-84926163555; Vu, H., Gomez, F., Cherelle, P., Lefeber, D., Nowé, A., Vanderborght, B., ED-FNN: A new deep learning algorithm to detect percentage of the gait cycle for powered prostheses (2018) Sensors, 18 (7), p. 2389. , 2-s2.0-85050629915; Murray, S., Goldfarb, M., Towards the Use of A Lower Limb Exoskeleton for Locomotion Assistance in Individuals with Neuromuscular Locomotor Deficits, pp. 1912-1915. , Proceedings of the 2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society August 2012 San Diego, USA 2-s2.0-84880773579; Ounpuu, S., The biomechanics of walking and running (1994) Clinics in Sports Medicine, 13, pp. 4843-4863; Ferrari, A., Brunner, R., Faccioli, S., Gait analysis contribution to problems identification and surgical planning in CP patients: An agreement study (2015) European Journal of Physical & Rehabilitation Medicine, 51 (1), pp. 39-48; Taborri, J., Scalona, E., Rossi, S., Real-time Gait Detection Based on Hidden Markov Model: Is It Possible to Avoid Training Procedure?, pp. 141-145. , Proceedings of the 2015 IEEE International Symposium on Medical Measurements and Applications May 2015 Torino, Italy; Mukherjee, J., Chattopadhyay, P., Sural, S., Information fusion from multiple cameras for gait-based re-identification and recognition (2015) IET Image Processing, 9 (11), pp. 969-976; Rosati, S., Agostini, V., Knaflitz, M., Balestra, G., Muscle activation patterns during gait: A hierarchical clustering analysis (2017) Biomedical Signal Processing and Control, 31, pp. 1746-8094. , 2-s2.0-84989306796; Ding, S., Ouyang, X., Li, Z., Yang, H., Proportion-based fuzzy gait phase detection using the smart insole (2018) Sensors and Actuators A: Physical, 284. , 2-s2.0-85055128368; Shimada, Y., Ando, S., Matsunaga, T., Clinical application of acceleration sensor to detect the swing phase of stroke gait in functional electrical stimulation (2005) The Tohoku Journal of Experimental Medicine, 207 (3), pp. 197-202. , 2-s2.0-27744440187; Chia Bejarano, N., Ambrosini, E., Pedrocchi, A., Ferrigno, G., Monticone, M., Ferrante, S., A novel adaptive, real-time algorithm to detect gait events from wearable sensors (2015) IEEE Transactions on Neural Systems and Rehabilitation Engineering, 23 (3), pp. 413-422. , 2-s2.0-84929299073; Caldas, R., Mundt, M., Potthast, W., Buarque De Lima Neto, F., Markert, B., A systematic review of gait analysis methods based on inertial sensors and adaptive algorithms (2017) Gait & Posture, 57, pp. 204-210. , 2-s2.0-85021304346; Sánchez Manchola, M.D., Pinto Bernal, M.J., Munera, M., Cifuentes, C.A., Gait phase detection for lower-limb exoskeletons using foot motion data from a single inertial measurement unit in hemiparetic individuals (2019) Sensors, 19 (13). , 2-s2.0-85069429797; Yuwono, M., Su, S.W., Guo, Y., Moulton, B.D., Nguyen, H.T., Unsupervised nonparametric method for gait analysis using a waist-worn inertial sensor (2014) Applied Soft Computing, 14, pp. 72-80. , 2-s2.0-84888301694; Bai, Y., Jin, X., Wang, X., Su, T., Kong, J., Lu, Y., Compound autoregressive network for prediction of multivariate time series (2019) Complexity, 2019, p. 11. , 9107167 2-s2.0-85073162551; Taborri, J., Rossi, S., Palermo, E., Patanè, F., Cappa, P., A novel HMM distributed classifier for the detection of gait phases by means of a wearable inertial sensor network (2014) Sensors, 14 (9), pp. 16212-16234. , 2-s2.0-84907483910; Liu, R., Zhang, J., Wang, L., Zhang, M., Research on face recognition method based on combination of SVM and LDA-PCA (2014) The Proceedings of the Second International Conference on Communications, Signal Processing, and Systems, pp. 62-66. , Berlin, Germany Springer; Lu, X., Xu, X., Human behavior recognition based on acceleration and hga-bp neural network (2015) Computer Engineering, 41 (9), pp. 220-232; Ma, J., Yuan, Y., Dimension reduction of image deep feature using PCA (2019) Journal of Visual Communication and Image Representation, 63. , 2-s2.0-85069655616; Juri, T., Eduardo, P., Stefano, R., Gait partitioning methods: A systematic review (2016) Sensors, 16 (1), pp. 66-91; Kim, J., Hwang, S., Sohn, R., Lee, Y., Kim, Y., Development of an active ankle foot orthosis to prevent foot drop and toe drag in hemiplegic patients: A preliminary study (2011) Applied Bionics and Biomechanics, 8 (3-4), pp. 377-384; Bolus, N.B., Teague, C.N., Inan, O.T., Kogler, G.F., Instrumented ankle-foot orthosis: Towards a clinical assessment tool for patient-specific optimization of orthotic ankle stiffness (2017) IEEE/ASME Transactions on Mechatronics, 22 (6), pp. 2492-2501. , 2-s2.0-85031786993; Mummolo, C., Mangialardi, L., Kim, J.H., Quantifying dynamic characteristics of human walking for comprehensive gait cycle (2013) Journal of Biomechanical Engineering, 135, p. 91006. , 2-s2.0-84880856551; Jin, X., Yang, N., Wang, X., Bai, Y., Su, T., Kong, J., Integrated predictor based on decomposition mechanism for PM2.5 long-term prediction (2019) Applied Sciences, 9 (21), p. 4533; Zheng, Y.-Y., Kong, J.-L., Jin, X.-B., Wang, X.-Y., Su, T.-L., Wang, J.-L., Probability fusion decision framework of multiple deep neural networks for fine-grained visual classification (2019) IEEE Access, 7, pp. 122740-122757; Zheng, Y.Y., Kong, J.L., Jin, X.B., Wang, X.-Y., Zuo, M., Cropdeep: The crop vision dataset for deep-learning-based classification and detection in precision agriculture (2019) Sensors, 19 (5), p. 1058. , 2-s2.0-85062399371; Jaya Lakshmi, A.N.M., Krishna Kishore, K.V., Performance evaluation of DNN with other machine learning techniques in a cluster using Apache Spark and MLlib (2018) Journal of King Saud University Computer and Information Sciences, , 2-s2.0-85055258292; Liu, J., Xia, S., Yu, W., A neural network integrated incremental learning method for voting right value adjustment (2010) Signal Processing, 26 (1), pp. 46-50; Tommaso, N., Renzo, C., Claudio, A., An integrated artificial neural network-unscented Kalman filter vehicle sideslip angle estimation based on inertial measurement unit measurements (2019) Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering, 233 (7), pp. 1864-1878. , 2-s2.0-85052338395; Povey, D., Zhang, X., Khudanpur, S., (2014) Parallel Training of Deep Neural Networks with Natural Gradient and Parameter Averaging, , https://arxiv.org/abs/1410.7455; Zhou, G., Ge, S., Yang, L., Fault diagnosis method of nuclear power plant based on neural network and vote fusion (2010) Journal of Atomic Energy Science and Technology, 44 (B09), pp. 367-372; Zhu, J., Arbor, A., Hastie, T., Multi-class AdaBoost (2006) Statistics and Its Interface, 2 (3), pp. 349-360; Breiman, L., Bagging predictors (1996) Machine Learning, 24 (2), pp. 123-140; Rodrigo, W.W., Lopes, H.S., Neural networks for protein classification (2004) Applied Bioinformatics, 3 (1), pp. 41-48; Pinheiro, R.H.W., Cavalcanti, G.D.C., Correa, R.F., Ren, T.I., A global-ranking local feature selection method for text categorization (2012) Expert Systems with Applications, 39 (17), pp. 12851-12857. , 2-s2.0-84865003955; Lau, H.-Y., Tong, K.-Y., Zhu, H., Support vector machine for classification of walking conditions of persons after stroke with dropped foot (2009) Human Movement Science, 28 (4), pp. 504-514. , 2-s2.0-67650465278; Sanchez-Valdes, D., Alvarez-Alvarez, A., Trivino, G., Walking pattern classification using a granular linguistic analysis (2015) Applied Soft Computing, 33, pp. 100-113. , 2-s2.0-84928788619; Bartlett, J.L., Kram, R., Changing the demand on specific muscle groups affects the walk-run transition speed (2008) Journal of Experimental Biology, 211 (8), pp. 1281-1288. , 2-s2.0-44349168264; Taborri, J., Palermo, E., Rossi, S., Cappa, P., Gait partitioning methods: A systematic review (2016) Sensors, 66, pp. 1-20; Provost, F., Fawcett, T., Kohavi, R., Shavlik, J., The Case against Accuracy Estimation for Comparing Induction Algorithms, pp. 445-453. , Proceedings of the Fifteenth International Conference (ICML 98) 1998 San Francisco, CA, USA; Hanlon, M., Anderson, R., Real-time gait event detection using wearable sensors (2009) Gait & Posture, 30 (4), pp. 523-527. , 2-s2.0-70349251128","Yan, L.; Beijing Forestry UniversityChina; email: mark_yanlei@bjfu.edu.cn",,,"Hindawi Limited",,,,,10762787,,,,"English","Complexity",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85078118729
"Mahdiani H., Khadem A., Ghanbari A., Modarressi M., Fattahi-Bayat F., Daneshtalab M.","15925383200;57211395613;57211390663;13408135000;57214247418;23004285900;","ΔnN: Power-efficient neural network acceleration using differential weights",2020,"IEEE Micro","40","1","8877741","67","74",,3,"10.1109/MM.2019.2948345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073748116&doi=10.1109%2fMM.2019.2948345&partnerID=40&md5=e81bf880d3e6d5416e02bf5f28285451","University of Tehran, Iran; Mälardalen University, Sweden","Mahdiani, H., University of Tehran, Iran; Khadem, A., University of Tehran, Iran; Ghanbari, A., University of Tehran, Iran; Modarressi, M., University of Tehran, Iran; Fattahi-Bayat, F., University of Tehran, Iran; Daneshtalab, M., Mälardalen University, Sweden","The enormous and ever-increasing complexity of state-of-the-art neural networks has impeded the deployment of deep learning on resource-limited embedded and mobile devices. To reduce the complexity of neural networks, this article presents ΔNN, a power-efficient architecture that leverages a combination of the approximate value locality of neuron weights and algorithmic structure of neural networks. ΔNN keeps each weight as its difference (Δ) to the nearest smaller weight: each weight reuses the calculations of the smaller weight, followed by a calculation on the Δ value to make up the difference. We also round up/down the Δ to the closest power of two numbers to further reduce complexity. The experimental results show that ΔNN boosts the average performance by 14%-37% and reduces the average power consumption by 17%-49% over some state-of-the-art neural network designs. © 1981-2012 IEEE.","Deep neural network; Difierential computation; Hardware acceleration","Complex networks; Computer architecture; Computer hardware; Multiplexing; Network architecture; Neural networks; Neurons; Parallel processing systems; Quantization (signal); Algorithmic structure; Biological neural networks; Complexity theory; Embedded and mobile devices; Hardware acceleration; Power efficient; State of the art; Value locality; Deep neural networks",,,,,"Swedish Foundation for International Cooperation in Research and Higher Education, STINT","This work was supported by The Initiation Grant Program of Swedish Foundation for International Cooperation in Research and Higher Education (STINT).",,,,,,,,,,"Hedge, K., UCNN: Exploiting computational reuse in deep neural networks via weight repetition (2018) Proc. 45th Int. Symp. Comput. Archit., pp. 674-687; Yasoubi, A., Hojabr, R., Modarressi, M., Powerefficient accelerator design for neural networks using computation reuse (2017) IEEE Comput. Archit. Lett., 16 (1), pp. 72-75. , Jan.-Jun; Du, Z., Lingamneni, A., Chen, Y., Palem, K.V., Temam, O., Wu, C., Leveraging the error resilience of neural networks for designing highly energy efficient accelerators (2015) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 34 (8), pp. 1223-1235. , Aug; Albericio, J., Bit-pragmatic deep neural network computing (2017) Proc. 50th Annu. IEEE/ACM Int. Symp. Microarchit., pp. 382-394; Parashar, A., SCNN: An accelerator for compressed-sparse convolutional neural networks (2017) Proc. 44th Annu. Int. Symp. Comput. Archit., pp. 27-40; Akhlaghi, V., Yazdanbakhsh, A., Samadi, K., Gupta, R.K., Esmaeilzadeh, H., SnaPEA: Predictive early activation for reducing computation in deep convolutional neural networks (2018) Proc. 45th Annu. Int. Symp. Comput. Archit., pp. 662-673; Zhou, A., (2017) Incremental Quantization: Towards Lossless CNNs with Low-precision Weights; Mahmoud, M., Siu, K., Moshovos, A., Diffy: A deja vu-free differential deep neural network accelerator (2018) Proc. 51st Annu. IEEE/ACM Int. Symp. Microarchit., pp. 134-147; Jouppi, N., In-datacenter performance analysis of a tensor processing unit (2017) Proc. 44th Annu. Int. Symp. Comput. Archit., pp. 1-12; Chen, Y., Emer, J., Sze, V., Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks (2016) Proc. 43rd Annu. Int. Symp. Comput. Archit., pp. 367-379; Dua, D., Graff, C., (2019) UCI Machine Learning Repository, , http://archive.ics.uci.edu/ml; Tu, F., Yin, S., Ouyang, P., Tang, S., Liu, L., Wei, S., Deep convolutional neural network architecture with reconfigurable computation patterns (2017) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 25 (8), pp. 2220-2233. , Aug",,,,"IEEE Computer Society",,,,,02721732,,IEMID,,"English","IEEE Micro",Article,"Final","",Scopus,2-s2.0-85073748116
"Meister F., Passerini T., Mihalef V., Tuysuzoglu A., Maier A., Mansi T.","57213697687;26428298300;22935148900;25652249900;23392966100;24401117700;","Deep learning acceleration of Total Lagrangian Explicit Dynamics for soft tissue mechanics",2020,"Computer Methods in Applied Mechanics and Engineering","358",,"112628","","",,20,"10.1016/j.cma.2019.112628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072715847&doi=10.1016%2fj.cma.2019.112628&partnerID=40&md5=f33f8d6843e0d2e9b170a53394db51c5","Siemens Healthineers, Digital Technology & Innovation, 755 College Rd E, Princeton, NJ  08540, United States; Friedrich-Alexander University, Pattern Recognition Lab, Martensstr. 3, Erlangen, 91058, Germany","Meister, F., Siemens Healthineers, Digital Technology & Innovation, 755 College Rd E, Princeton, NJ  08540, United States, Friedrich-Alexander University, Pattern Recognition Lab, Martensstr. 3, Erlangen, 91058, Germany; Passerini, T., Siemens Healthineers, Digital Technology & Innovation, 755 College Rd E, Princeton, NJ  08540, United States; Mihalef, V., Siemens Healthineers, Digital Technology & Innovation, 755 College Rd E, Princeton, NJ  08540, United States; Tuysuzoglu, A., Siemens Healthineers, Digital Technology & Innovation, 755 College Rd E, Princeton, NJ  08540, United States; Maier, A., Friedrich-Alexander University, Pattern Recognition Lab, Martensstr. 3, Erlangen, 91058, Germany; Mansi, T., Siemens Healthineers, Digital Technology & Innovation, 755 College Rd E, Princeton, NJ  08540, United States","Simulating complex soft tissue deformations has been an intense research area in the fields of computer graphics or computational physiology for instance. A desired property is the ability to perform fast, if not real-time, simulations while being physically accurate. Numerical schemes have been explored to speed up finite element methods, like the Total Lagrangian Explicit Dynamics (TLED). However, real-time applications still come at the price of accuracy and fidelity. In this work, we explore the use of neural networks as function approximators to accelerate the time integration of TLED, while being generic enough to handle various geometries, motion and materials without having to retrain the neural network model. The method is evaluated on a set of experiment, showing promising accuracy at time steps up to 20 times larger than the “breaking” time step, as well as in a simple medical application. Such an approach could pave the way to very fast but accurate acceleration strategies for computational biomechanics. © 2019 Elsevier B.V.","Data-driven computational modeling; Deep learning; Finite element method; Soft tissue biomechanics; Total Lagrangian Explicit Dynamics","Biomechanics; Computer graphics; Dynamics; Finite element method; Lagrange multipliers; Medical applications; Numerical methods; Tissue; Acceleration strategies; Computational biomechanics; Computational model; Computational physiology; Explicit dynamics; Function approximators; Soft tissue biomechanics; Soft tissue deformation; Deep learning",,,,,,,,,,,,,,,,"Taylor, C.A., Figueroa, C., Patient-specific modeling of cardiovascular mechanics (2009) Annu. Rev. Biomed. Eng., 11, pp. 109-134; Cotin, S., Delingette, H., Ayache, N., Real-time elastic deformations of soft tissues for surgery simulation (1999) IEEE Trans. Vis. Comput. Graph., 5 (1), pp. 62-73; Hagemann, A., Rohr, K., Stiehl, H.S., Spetzger, U., Gilsbach, J.M., Biomechanical modeling of the human head for physically based, nonrigid image registration (1999) IEEE Trans. Med. Imaging, 18 (10), pp. 875-884; Zienkiewicz, O.C., Taylor, R.L., Zhu, J.Z., The Finite Element Method: Its Basis and Fundamentals (2005), Elsevier; Roewer-Despres, F., Khan, N., Stavness, I., Towards finite element simulation using deep learning (2018) 15th International Symposium on Computer Methods in Biomechanics and Biomedical Engineering; Miller, K., Joldes, G., Lance, D., Wittek, A., Total lagrangian explicit dynamics finite element algorithm for computing soft tissue deformation (2007) Int. J. Numer. Methods Biomed. Eng., 23 (2), pp. 121-134; Klawonn, A., Rheinbach, O., Highly scalable parallel domain decomposition methods with an application to biomechanics (2010) ZAMM-J. Appl. Math. Mech., 90 (1), pp. 5-32; Rama, R.R., Skatulla, S., Sansour, C., Real-time modelling of diastolic filling of the heart using the proper orthogonal decomposition with interpolation (2016) Int. J. Solids Struct., 96, pp. 409-422; Choi, M.G., Ko, H.-S., Modal warping: Real-time simulation of large rotational deformation and manipulation (2005) IEEE Trans. Vis. Comput. Graphics, 11 (1), pp. 91-101; Yang, Y., Li, D., Xu, W., Tian, Y., Zheng, C., Expediting precomputation for reduced deformable simulation (2015) ACM Trans. Graph. (TOG), 34 (6); Voulodimos, A., Doulamis, N., Doulamis, A., Protopapadakis, E., Deep learning for computer vision: A brief review (2018) Comput. Intell. Neurosci., 2018; Young, T., Hazarika, D., Poria, S., Cambria, E., Recent trends in deep learning based natural language processing (2018) IEEE Comput. Intell. Mag., 13 (3), pp. 55-75; Goodfellow, I., Bengio, Y., Courville, A., Deep Learning (2016), http://www.deeplearningbook.org, MIT Press; Lin, H., Tegmark, M., Rolnick, D., Why does deep and cheap learning work so well? (2017) J. Stat. Phys., 168 (6), pp. 1223-1247; Kim, B., Azevedo, V.C., Thuerey, N., Kim, T., Gross, M., Solenthaler, B., Deep fluids: A generative network for parameterized fluid simulations, arXiv preprint ; Ayed, I., Cedilnik, N., Gallinari, P., Sermesant, M., Ep-net: Learning cardiac electrophysiology models for physiology-based constraints in data-driven predictions (2019) Functional Imaging and Modeling of the Heart; Raissi, M., Karniadakis, G.E., Hidden physics models: Machine learning of nonlinear partial differential equations (2018) J. Comput. Phys., 357, pp. 125-141; Raissi, M., Perdikaris, P., Karniadakis, G., Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations (2019) J. Comput. Phys., 378, pp. 686-707; Oishi, A., Yagawa, G., Computational mechanics enhanced by deep learning (2017) Comput. Methods Appl. Mech. Engrg., 327, pp. 327-351; Luo, R., Shao, T., Wang, H., Xu, W., Zhou, K., Yang, Y., DeepWarp: DNN-based Nonlinear Deformation, arXiv preprint ; Mendizabal, A., Márquez-Neila, P., Cotin, S., Simulation of hyperelastic materials in real-time using deep learning, arXiv preprint ; Fulton, L., Modi, V., Duvenaud, D., Levin, D.I.W., Jacobson, A., Latent-space dynamics for reduced deformable simulation (2019) Comput. Graph. Forum; Ogden, R.W., Non-linear Elastic Deformations (1997), Courier Corporation; Holzapfel, G.A., Ogden, R.W., Constitutive modelling of passive myocardium: a structurally based framework for material characterization (2009) Phil. Trans. R. Soc. A, 367 (1902), pp. 3445-3475. , http://rsta.royalsocietypublishing.org/content/367/1902/3445, URL; Hanson, A., Ma, H., (1995), pp. 3-7. , Parallel transport approach to curve framing, Indiana University, Techreports-TR425, 11; Kingma, D.P., Ba, J., Adam: A Method for Stochastic Optimization, CoRR abs/1412.6980; Chollet, F., (2015), https://keras.io, Keras,; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Zheng, X., (2015), http://tensorflow.org/, TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, Software available from tensorflow.org,; Maas, S.A., Ellis, B.J., Ateshian, G.A., Weiss, J.A., Febio: finite elements for biomechanics (2012) J. Biomech. Eng., 134 (1), p. 011005","Meister, F.; Siemens Healthineers, 755 College Rd E, United States; email: meister.felix@siemens-healthineers.com",,,"Elsevier B.V.",,,,,00457825,,CMMEC,,"English","Comput. Methods Appl. Mech. Eng.",Article,"Final","",Scopus,2-s2.0-85072715847
"Shea C., Mohsenin T.","55388937300;23668732400;","Heterogeneous scheduling of deep neural networks for low-power real-time designs",2019,"ACM Journal on Emerging Technologies in Computing Systems","15","4","36","","",,7,"10.1145/3358699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077797445&doi=10.1145%2f3358699&partnerID=40&md5=4d04d5032e7007c54b724cda2019693b","University of Maryland, 1000 Hilltop Circle, Baltimore County, Catonsville, MD  21250, United States","Shea, C., University of Maryland, 1000 Hilltop Circle, Baltimore County, Catonsville, MD  21250, United States; Mohsenin, T., University of Maryland, 1000 Hilltop Circle, Baltimore County, Catonsville, MD  21250, United States","Deep neural networks have become the readiest answer to a range of application challenges including image recognition, stock analysis, natural language processing, and biomedical applications such as seizure detection. All while outperforming prior leading solutions that relied heavily on hand-engineered techniques. However, deployment of these neural networks often requires high-computational and memory-intensive solutions. These requirements make it challenging to deploy Deep Neural Networks (DNNs) in embedded, real-time low-power applications where classic architectures, GPUs and CPUs, still impose significant power burden. Systems-on-Chip (SoC) with Field-programmable Gate Arrays (FPGAs) can be used to improve performance and allow more fine-grain control of resources than CPUs or GPUs, but it is difficult to find the optimal balance between hardware and software to improve DNN efficiency. In the current research literature there have been few proposed solutions to address optimizing hardware and software deployments of DNNs in embedded low-power systems. To address the computation resource restriction and low-power needs for deploying these networks, we describe and implement a domain-specific metric model for optimizing task deployment on differing platforms, hardware and software. Next, we propose a DNN hardware accelerator called Scalable Low-power Accelerator for real-time deep neural Networks (SCALENet) that includes multithreaded software workers. Finally, we propose a heterogeneous aware scheduler that uses the DNN-specific metric models and the SCALENet accelerator to allocate a task to a resource based on solving a numerical cost for a series of domain objectives. To demonstrate the applicability of our contribution, we deploy nine modern deep network architectures, each containing a different number of parameters within the context of two different neural network applications: image processing and biomedical seizure detection. Utilizing the metric modeling techniques integrated into the heterogeneous aware scheduler and the SCALENet accelerator, we demonstrate the ability to meet computational requirements, adapt to multiple architectures, and lower power by providing an optimized task to resource allocation. Our heterogeneous aware scheduler improves power saving by decreasing power consumption by 10% of the total system power, does not affect the accuracy of the networks, and still meets the real-time deadlines. We demonstrate the ability to achieve parity with or exceed the energy efficiency of NVIDIA GPUs when evaluated against Jetson TK1 with embedded GPU SoC and with a 4× power savings in a power envelope of 2.0W. When compared to existing FPGA-based accelerators, SCALENet’s accelerator and heterogeneous aware scheduler achieves a 4.8× improvement in energy efficiency. © 2019 Copyright held by the owner/author(s).","Co-design; FPGA; Hardware; Machine learning; Real-time; Scheduling; Software","Acceleration; Computer hardware; Computer software; Embedded systems; Energy efficiency; Field programmable gate arrays (FPGA); Image processing; Image recognition; Learning algorithms; Learning systems; Low power electronics; Medical applications; Natural language processing systems; Network architecture; Program processors; Programmable logic controllers; Scheduling; System-on-chip; Biomedical applications; Co-designs; Computational requirements; Heterogeneous Scheduling; Multithreaded softwares; NAtural language processing; Neural network application; Real time; Deep neural networks",,,,,,,,,,,,,,,,"Abtahi, T., Kulkarni, A., Mohsenin, T., Accelerating convolutional neural network with FFT on tiny cores (2017) Proceedings of the IEEE International Symposium on Circuits and Systems (ISCAS’17), pp. 1-4. , https://doi.org/10.1109/ISCAS.2017.8050588; Abtahi, T., Shea, C., Kulkarni, A., Mohsenin, T., Accelerating convolutional neural network with FFT on embedded hardware (2018) IEEE Trans. Very Large Scale Integr., 26 (9), pp. 1737-1749. , https://doi.org/10.1109/TVLSI.2018.2825145, Sept. 2018; Rajendra Acharya, U., Oh, S.L., Hagiwara, Y., Tan, J.H., Adeli, H., Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals (2017) Comput. Biol. Med., 100. , https://doi.org/10.1016/j.compbiomed.2017.09.017, 2017; Berman, F., Wolski, R., Figueira, S., Schopf, J., Shao, G., Application-level scheduling on distributed heterogeneous networks (1996) Proceedings of the ACM/IEEE Conference on Supercomputing, p. 39. , https://doi.org/10.1109/SUPERC.1996.183541; Braun, T.D., Siegel, H.J., Beck, N., Bölöni, L.L., Maheswaran, M., Reuther, A.I., Robertson, J.P., Freund, R.F., A comparison of eleven static heuristics for mapping a class of independent tasks onto heterogeneous distributed computing systems (2001) J. Parallel Distrib. Comput., 61 (6), pp. 810-837. , https://doi.org/10.1006/jpdc.2000.1714, 2001; Chafi, H., Sujeeth, A.K., Brown, K.J., Lee, H., Atreya, A.R., Olukotun, K., A domain-specific approach to heterogeneous parallelism (2011) SIGPLAN Not, 46 (8), pp. 35-46. , https://doi.org/10.1145/2038037.1941561, Feb. 2011; Chakradhar, S., A dynamically configurable coprocessor for convolutional neural networks (2010) ACM SIGARCH Computer Architecture News; Chen, Y.H., Krishna, T., Emer, J., Sze, V., 14.5 eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2016) Proceedings of the IEEE International Solid-State Circuits Conference (ISSCC’16), 59, pp. 262-263. , https://doi.org/10.1109/ISSCC.2016.7418007, IEEE; DiCecco, R., Lacey, G., Vasiljevic, J., Chow, P., Taylor, G., Areibi, S., Caffeinated FPGAs: FPGA framework for convolutional neural networks (2016) Proceedings of the International Conference on Field-Programmable Technology (FPT’16), pp. 265-268. , https://doi.org/10.1109/FPT.2016.7929549; Ding, C., Liao, S., Wang, Y., Li, Z., Liu, N., Zhuo, Y., Wang, C., Yuan, B., CircNN: Accelerating and compressing deep neural networks using block-circulant weight matrices (2017) Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO’17), pp. 395-408. , https://doi.org/10.1145/3123939.3124552, ACM, New York, NY; Gokhale, V., Jin, J., Dundar, A., Martini, B., Culurciello, E., A 240 G-ops/s mobile coprocessor for deep neural networks (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 696-701. , https://doi.org/10.1109/CVPRW.2014.106; Goldberger, A.L., Amaral, L.A.N., Glass, L., Hausdorff, J.M., Ivanov, P.Ch., Mark, R.G., Mietus, J.E., Stanley, H.E., PhysioBank, physiotoolkit, and physionet: Components of a new research resource for complex physiologic signals (2000) Circulation, 101 (23), pp. e215-e220. , http://circ.ahajournals.org/content/101/23/e215.full, June 13. June 2000, Retrieved from PMID:1085218; Guo, K., Sui, L., Qiu, J., Yu, J., Wang, J., Yao, S., Han, S., Yang, H., Angel-Eye: A complete design flow for mapping CNN onto embedded FPGA (2018) IEEE Trans. Comput.-Aided Design Integr. Circ. Syst., 37 (1), pp. 35-47. , https://doi.org/10.1109/TCAD.2017.2705069, Jan. 2018; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2015) CoRR, , http://arxiv.org/abs/1512.03385; Hosseini, M., Horton, M., Paneliya, H., Kallakuri, U., Homayoun, H., Mohsenin, T., On the complexity reduction of dense layers from O(N2) to O(NloдN) with cyclic sparsely connected layers (2019) Proceedings of the 56th Annual Design Automation Conference, , ACM; Hosseini, M., Paneliya, H., Kallakuri, U., Khatwani, M., Mohsenin, T., Minimizing classification energy of binarized neural network inference for wearable devices (2019) Proceedings of the 20th International Symposium on Quality Electronic Design (ISQED’19), pp. 259-264. , IEEE; Iandola, F.N., Moskewicz, M.W., Ashraf, K., Han, S., Dally, W.J., Keutzer, K., (2016) Squeezenet: Alexnet-Level Accuracy with 50× Fewer Parameters and <1mb Model Size, , arXiv preprint 2016; Inggs, G., Thomas, D., Luk, W., A heterogeneous computing framework for computational finance (2013) Proceedings of the 42nd International Conference on Parallel Processing, pp. 688-697. , https://doi.org/10.1109/ICPP.2013.82; Jafari, A., Hosseini, M., Homayoun, H., Mohsenin, T., A scalable and low-power DCNN for multimodal data classification (2018) Proceedings of the International Conference on ReConFigurable Computing and FPGAs (ReConFig’18), pp. 1-6. , IEEE; Javaheripi, M., Samragh, M., Javidi, T., Koushanfar, F., ASCAI: Adaptive sampling for acquiring compact AI (2019) Proceedings of the AutoML Workshop at the 36th International Conference of Machine Learning (ICML’19); Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding, , arXiv Preprint; Kang, Q., He, H., Song, H., Task assignment in heterogeneous computing systems using an effective iterated greedy algorithm (2011) J. Syst. Softw., 84 (6), pp. 985-992. , https://doi.org/10.1016/j.jss.2011.01.051, June 2011; Khatwani, M., David Hairston, W., Waytowich, N., Mohsenin, T., A low complexity automated multi-channel EEG artifact detection using EEGNet (2019) Proceedings of the IEEE EMBS Conference on Neural Engineering, , IEEE; Khatwani, M., Hosseini, M., Paneliya, H., Mohsenin, T., David Hairston, W., Waytowich, N., Energy efficient convolutional neural networks for EEG artifact detection (2018) Proceedings of the IEEE Biomedical Circuits and Systems Conference (BioCAS’18), pp. 1-4. , IEEE; Liu, X., Pool, J., Han, S., Dally, W.J., Efficient sparse-winograd convolutional neural networks (2018) CoRR, , http://arxiv.org/abs/1802.06367; Lu, J., Young, S., Arel, I., Holleman, J., A 1 TOPS/W analog deep machine-learning engine with floating-gate storage in 0.13 μm CMOS (2015) IEEE J. Solid-State Circ., 50 (1), pp. 270-281. , 2015; Makrani, H.M., Sayadi, H., Mohsenin, T., Rafatirad, S., Sasan, A., Homayoun, H., XPPE: Cross-platform performance estimation of hardware accelerators using machine learning (2019) Proceedings of the 24th Asia and South Pacific Design Automation Conference (ASPDAC’19), pp. 727-732. , https://doi.org/10.1145/3287624.3288756, ACM, New York, NY; Neshatpour, K., Behnia, F., Homayoun, H., Sasan, A., ICNN: An iterative implementation of convolutional neural networks to enable energy and computational complexity aware dynamic approximation (2018) Proceedings of the Design, Automation Test in Europe Conference Exhibition (DATE’18), pp. 551-556. , https://doi.org/10.23919/DATE.2018.8342068; Neshatpour, K., Behnia, F., Homayoun, H., Sasan, A., Exploiting energy-accuracy trade-off through contextual awareness in multi-stage convolutional neural networks (2019) Proceedings of the 20th International Symposium on Quality Electronic Design (ISQED’19), pp. 265-270. , https://doi.org/10.1109/ISQED.2019.8697497; Ortega-Zamorano, F., Jerez, J.M., Franco, L., FPGA implementation of the c-mantec neural network constructive algorithm (2014) IEEE Trans. Industr. Inform., 10 (2), pp. 1154-1161. , 2014; Page, A., Attaran, N., Shea, C., Homayoun, H., Mohsenin, T., Low-power manycore accelerator for personalized biomedical applications (2016) Proceedings of the 26th Edition on Great Lakes Symposium on Very Large Scale Integration (GLSVLSI’16), pp. 63-68. , https://doi.org/10.1145/2902961.2902986, ACM, New York, NY; Page, A., Jafari, A., Shea, C., Mohsenin, T., SparcNet: A hardware accelerator for efficient deployment of sparse convolutional networks (2017) J. Emerg. Technol. Comput. Syst., 13, p. 3. , https://doi.org/10.1145/3005448, May 2017); Page, A., Sagedy, C., A flexible multichannel EEG feature extractor and classifier for seizure detection (2015) IEEE Trans. Circ. Syst. II: Express Briefs, 62 (2), pp. 109-113. , 2015; Page, A., Shea, C., Mohsenin, T., Wearable seizure detection using convolutional neural networks with transfer learning (2016) Proceedings of the IEEE International Symposium on Circuits and Systems (ISCAS’16); Park, S.W., Park, J., Bong, K., Shin, D., Lee, J., Choi, S., Yoo, H.J., An energy-efficient and scalable deep-learning/inference processor with tetra-parallel MIMD architecture for big data applications (2015) IEEE Trans. Biomed. Circ. Syst., 9 (6), pp. 838-848. , Dec. 2015; Samragh, M., Javaheripi, M., Koushanfar, F., AutoRank: Automated rank selection for effective neural network customization (2019) Proceedings of the ML-for-Systems Workshop at the 46th International Symposium on Computer Architecture (ISCA’19); Samragh, M., Javaheripi, M., Koushanfar, F., (2019) CodeX: Bit-Flexible Encoding for Streaming-Based FPGA Acceleration of DNNs, , arXiv Preprint; Sayadi, H., Patel, N., Sasan, A., Homayoun, H., Machine-learning-based approaches for energy-efficiency prediction and scheduling in composite cores architectures (2017) Proceedings of the IEEE International Conference on Computer Design (ICCD’17), pp. 129-136. , https://doi.org/10.1109/ICCD.2017.28; Shea, C., Page, A., Mohsenin, T., Scalenet: A scalable low-power accelerator for real-time embedded deep neural networks (2018) ACM Proceedings of the 28th Edition of the Great Lakes Symposium on Very Large Scale Integration (GLSVLSI’18), , ACM; Sim, J., A 1.42 TOPS/W deep convolutional neural network recognition processor for intelligent IoE systems 14.6 (2016) Proceedings of the International Solid-State Circuits Conference (ISSCC’16), , IEEE; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint 2014; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision (2015) CoRR, , http://arxiv.org/abs/1512.00567; Van Deursen, A., Klint, P., Visser, J., Domain-specific languages: An annotated bibliography (2000) SIGPLAN Not, 35 (6), pp. 26-36. , https://doi.org/10.1145/352029.352035, June 2000; Vasilache, N., Johnson, J., Mathieu, M., Chintala, S., Piantino, S., LeCun, Y., Fast convolutional nets with fbfft: A GPU Performance evaluation (2014) CoRR, , http://arxiv.org/abs/1412.7580; Vepakomma, P., De, D., Das, S.K., Bhansali, S., A-wristocracy: Deep learning on wrist-worn sensing for recognition of user complex activities (2015) Proceedings of the IEEE 12th International Conference on Wearable and Implantable Body Sensor Networks (BSN’15), pp. 1-6. , IEEE; (2011) Power Methodology Guide, , https://www.xilinx.com/support/documentation/sw_manuals/xilinx13_1/ug786_PowerMethodology.pdf, Retrieved on March 2011 from; Zhang, C., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proceedings of the International Symposium on Field-Programmable Gate Arrays (FPGA’15), , ACM; Zhong, G., Dubey, A., Tan, C., Mitra, T., Synergy: A HW/SW Framework for high throughput CNNs on embedded heterogeneous SoC (2018) CoRR, , http://arxiv.org/abs/1804.00706",,,,"Association for Computing Machinery",,,,,15504832,,,,"English","ACM J. Emerg. Technologies Comput. Syst.",Article,"Final","",Scopus,2-s2.0-85077797445
"Losh M., Llamocca D.","57212411188;24476114500;","A low-power spike-like neural network design",2019,"Electronics (Switzerland)","8","12","1479","","",,5,"10.3390/electronics8121479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076604172&doi=10.3390%2felectronics8121479&partnerID=40&md5=da8834cc1d6f1fddab1c9e5d33f3c14a","Electrical and Computer Engineering Department, Oakland University, Rochester, MI  48309, United States","Losh, M., Electrical and Computer Engineering Department, Oakland University, Rochester, MI  48309, United States; Llamocca, D., Electrical and Computer Engineering Department, Oakland University, Rochester, MI  48309, United States","Modern massively-parallel Graphics Processing Units (GPUs) and Machine Learning (ML) frameworks enable neural network implementations of unprecedented performance and sophistication. However, state-of-the-art GPU hardware platforms are extremely power-hungry, while microprocessors cannot achieve the performance requirements. Biologically-inspired Spiking Neural Networks (SNN) have inherent characteristics that lead to lower power consumption. We thus present a bit-serial SNN-like hardware architecture. By using counters, comparators, and an indexing scheme, the design effectively implements the sum-of-products inherent in neurons. In addition, we experimented with various strength-reduction methods to lower neural network resource usage. The proposed Spiking Hybrid Network (SHiNe), validated on an FPGA, has been found to achieve reasonable performance with a low resource utilization, with some trade-off with respect to hardware throughput and signal representation. © 2019, MDPI AG. All rights reserved.","Bit-serial architectures; FPGA; Spiking neural networks",,,,,,,,,,,,,,,,,"Chen, Y., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks (2017) IEEE J. Solid State Circuits, 52, pp. 127-138; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks (2015) Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 161-170. , Monterey, CA, USAACM: New York, NY, USA; Chakradhar, S., Sankaradas, M., Jakkula, V., Cadambi, S.A., Dynamically configurable coprocessor for convolutional neural networks ACM SIGARCH Comput (2010) Archit. News, 38, pp. 247-257; Hardieck, M., Kumm, M., Möller, K., Zipf, P., Reconfigurable Convolutional Kernels for Neural Networks on FPGAs (2019) Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 43-52. , Seaside, CA, USA, ACM: New York, NY, USA; Markidis, S., Chien, S., Laure, E., Pong, I., Vetter, J.S., NVIDIA Tensor Core Programmability, Performance & Precision (2018) Proceedings of the 2018 IEEE International Parallel and Distributed Processing Symposium Workshops, , Vancouver, BC, Canada; Misra, J., Saha, I., Artificial neural networks in hardware: A survey of two decades of progress (2010) Neurocomputing, 74, pp. 239-255; Renteria-Cedano, J., Rivera, J., Sandoval-Ibarra, F., Ortega-Cisneros, S., Loo-Yau, R., SoC Design Based on a FPGA for a Configurable Neural Network Trained by Means of an EKF (2019) Electronics, 8, p. 761; Nurvitadhi, E., Venkatesh, G., Sim, J., Marr, D., Huang, R., Hock, J.O.G., Liew, Y.T., Subhaschandra, S., Can FPGAs beat GPUs in accelerating next-generation Deep Neural Networks? (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 5-14. , Monterey, CA, USA, ACM: New York, NY, USA; Gomperts, A., Ukil, A., Zurfluh, F., Development and Implementation of Parameterized FPGA-Based General-Purpose Neural Networks for Online Applications (2011) IEEE Trans. Ind. Inform, 7, pp. 78-89; Himavathi, S., Anitha, D., Muthuramalingam, A., Feedforward Neural Network Implementation in FPGA using layer multiplexing for effective resource utilization (2007) IEEE Trans. Neural Netw, 18, pp. 880-888; Tavanaei, A., Ghodrati, M., Kheradpisheh, S.R., Masquelier, T., Maida, A.S., Deep Learning in Spiking Neural Networks (2019) Neural Netw, 111, pp. 47-63; Iakymchuk, T., Rosado, A., Frances, J.V., Batallre, M., Fast Spiking Neural Network Architecture for lowcost FPGA devices (2012) Proceedings of the 7Th International Workshop on Reconfigurable and Communication-Centric Systems-On-Chip (Recosoc), , York, UK; Rice, K., Bhuiyan, M.A., Taha, T.M., Vutsinas, C.N., Smith, M., FPGA Implementation of Izhikevich Spiking Neural Networks for Character Recognition (2009) Proceedings of the 2019 International Conference on Reconfigurable Computing and Fpgas, , Cancun, Mexico; Pearson, M.J., Pipe, A.G., Mitchinson, B., Gurney, K., Melhuish, C., Gilhespy, I., Nibouche, N., Implementing Spiking Neural Networks for Real-Time Signal Processing and Control Applications (2007) IEEE Trans. Neural Netw., 18, pp. 1472-1487; Belyaev, M., Velichko, A., A Spiking Neural Network Based on the Model of VO2-Neuron (2019) Electronics, 8, p. 1065; Arbib, M.A., (2002) The Handbook of Brain Theory and Neural Networks, , 2nd ed.; MIT Press: Cambridge, MA, USA; Nielsen, M.A., (2015) Neural Networks and Deep Learning, , Determination Press: San Francisco, CA, USA; Minsky, M.L., Papert, S.A., (2017) Perceptrons: An Introduction to Computational Geometry, , 3rd ed.; MIT Press: Cambridge, MA, USA; Glorot, X., Bordes, A., Bengio, Y., Deep sparse rectifier neural networks (2011) Proceedings of the 14Th International Conference on Artificial Intelligence and Statistics, pp. 315-323. , Ft. Lauderdale, FL, USA; Deng, L., The MNIST database of handwritten digit images for machine learning research [best of web] (2012) IEEE Signal Process. Mag, 29, pp. 141-142; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86, pp. 2278-2324; Llamocca, D., Self-Reconfigurable Architectures for HEVC Forward and Inverse Transform (2017) J. Parallel Distrib. Comput, 109, pp. 178-192; Reagen, B., Whatmough, P., Adolf, R., Rama, S., Lee, H., Lee, S., Hernandez-Lobato, J., Brooks, D., Minerva: Enabling Low-Power, Highly-Accurate Deep Neural Network Accelerators (2016) Proceedings of the 2016 ACM/IEEE 43Rd Annual International Symposium on Computer Architecture (ISCA), , Seoul, Korea; Gokhale, V., Jin, J., Dundar, A., Martini, B., Culurciello, E., A 240 G-Ops/s mobile coprocessor for deep neural networks (2014) Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops, , Columbus, OH, USA; Farabet, C., Martini, B., Akselrod, P., Talay, S., Lecun, Y., Culurciello, E., Hardware accelerated convolutional neural networks for synthetic vision systems (2010) Proceedings of the 2010 IEEE International Symposium on Circuits and Systems, , Paris, France; Umuroglu, Y., Fraser, N.J., Gambardella, G., Blott, M., Leong, P., Jahre, M., Vissers, K., A framework for Fast, Scalable Binarized Neural Network Interface (2017) Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 65-74. , Monterey, CA, USA, ACM: New York, NY, USA; Strigl, D., Kofler, K., Podlipnig, S., Performance and scalability of GPU-based convolutional neural networks (2010) Proceedings of the 2018 18Th Euromicro Conference on Parallel, Distributed and Networkbased Processing, , Pisa, Italy; Song, S., Su, C., Rountree, B., Cameron, K.W., A simplified and accurate model of power-performance efficiency on emergent GPU architectures (2013) Proceedings of the 2013 IEEE 27Th International Symposium on Parallel and Distributed Processing, , Boston, MA, USA; Hauswald, J., Kang, Y., Laurenzano, M.A., Chen, Q., Li, C., Mudge, T., Dreslinski, R., Tang, L., DjiNN and Tonic: DNN as a service and its implications for future warehouse scale computers (2015) Proceedings of the 2015 ACM/IEEE 42Nd Annual International Symposium on Computer Architecture (ISCA), , Portland, OR, USA","Llamocca, D.; Electrical and Computer Engineering Department, United States; email: llamocca@oakland.edu",,,"MDPI AG",,,,,20799292,,,,"English","Electronics (Switzerland)",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85076604172
"Eleftheriou E., Karunaratne G., Kersting B., Stanisavljevic M., Jonnalagadda V.P., Ioannou N., Kourtis K., Francese P.A., Sebastian A., Gallo M.L., Nandakumar S.R., Piveteau C., Boybat I., Joshi V., Khaddam-Aljameh R., Dazzi M., Giannopoulos I.","7006881122;57207605273;57202537506;57208971134;56820062900;35175785700;13408849900;6602489453;7005671728;55962114500;8595364000;57203746654;55747096300;57210477369;57207691345;57204778167;57202536008;","Deep learning acceleration based on in-memory computing",2019,"IBM Journal of Research and Development","63","6","8865099","","",,11,"10.1147/JRD.2019.2947008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075005732&doi=10.1147%2fJRD.2019.2947008&partnerID=40&md5=149fae4a32b68a94260f555f30ccad86","IBM Research - Zurich, Ruschlikon, 8803, Switzerland","Eleftheriou, E., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Karunaratne, G., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Kersting, B., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Stanisavljevic, M., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Jonnalagadda, V.P., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Ioannou, N., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Kourtis, K., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Francese, P.A., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Sebastian, A., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Gallo, M.L., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Nandakumar, S.R., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Piveteau, C., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Boybat, I., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Joshi, V., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Khaddam-Aljameh, R., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Dazzi, M., IBM Research - Zurich, Ruschlikon, 8803, Switzerland; Giannopoulos, I., IBM Research - Zurich, Ruschlikon, 8803, Switzerland","Performing computations on conventional von Neumann computing systems results in a significant amount of data being moved back and forth between the physically separated memory and processing units. This costs time and energy, and constitutes an inherent performance bottleneck. In-memory computing is a novel non-von Neumann approach, where certain computational tasks are performed in the memory itself. This is enabled by the physical attributes and state dynamics of memory devices, in particular, resistance-based nonvolatile memory technology. Several computational tasks such as logical operations, arithmetic operations, and even certain machine learning tasks can be implemented in such a computational memory unit. In this article, we first introduce the general notion of in-memory computing and then focus on mixed-precision deep learning training with in-memory computing. The efficacy of this new approach will be demonstrated by training the MNIST multilayer perceptron network achieving high accuracy. Moreover, we show how the precision of in-memory computing can be further improved through architectural and device-level innovations. Finally, we present system aspects, such as high-level system architecture, including core-to-core interconnect technologies, and high-level ideas and concepts of the software stack. © 1957-2012 IBM.",,"Computational methods; Arithmetic operations; Computational memory; High-level systems; Interconnect technology; Logical operations; Multi-layer perceptron networks; Non-volatile memory technology; Performance bottlenecks; Deep learning",,,,,,,,,,,,,,,,"Merolla, P.A., Arthur, J.V., Alvarez-Icaza, R., A million spiking-neuron integrated circuit with a scalable communication network and interface (2014) Science, 345 (6197), pp. 668-673; Sebastian, A., Le Gallo, M., Burr, G.W., Tutorial: Brain-inspired computing using phase-change memory devices (2018) J. Appl. Phys., 124; Burr, G.W., Brightsky, M.J., Sebastian, A., Recent progress in phase-change memory technology (2016) IEEE J. Emerg. Sel. Topics Circuits Syst., 6 (2), pp. 146-162. , Jun; Borghetti, J., Snider, G.S., Kuekes, P.J., 'Memristive' switches enable 'stateful' logic operations via material implication (2010) Nature, 464, pp. 873-876; Yang, J.J., Strukov, D.B., Stewart, D.R., Memristive devices for computing (2013) Nature Nanotechnol., 8, pp. 13-24; Di Ventra, M., Pershin, Y.V., The parallel approach (2013) Nature Phys., 9, pp. 200-202; Zidan, M.A., Strachan, J.P., Lu, W.D., The future of electronics based on memristive systems (2018) Nature Electron., 1, pp. 22-29; Ielmini, D., Wong, H.-S.P., In-memory computing with resistive switching devices (2018) Nature Electron., 1, pp. 333-343; Biswas, A., Chandrakasan, A.P., Conv-RAM: An energy-efficient SRAMwith embedded convolution computation for low-power CNN-based machine learning applications (2018) Proc. IEEE Int. Solid-State Circuits Conf., pp. 488-490; Cassinerio, M., Ciocchini, N., Ielmini, D., Logic computation in phase change materials by threshold and memory switching (2013) Adv. Mater., 25, pp. 5975-5980; Seshadri, V., Lee, D., Mullins, T., (2016) Buddy-RAM: Improving the Performance and Efficiency of Bulk Bitwise Operations Using DRAM, , arXiv:1611.09988; Wright, C.D., Hosseini, P., Diosdado, J.A.V., Beyond von-neumann computing with nanoscale phase-change memory devices (2013) Adv. Functional Mater., 23, pp. 2248-2254; Hosseini, P., Sebastian, A., Papandreou, N., Accumulationbased computing using phase-change memoriesWith FET access devices (2015) IEEE Electron Device Lett., 36 (9), pp. 975-977. , Sep; Sebastian, A., Tuma, T., Papandreou, N., Temporal correlation detection using computational phase-change memory (2017) Nature Commun., 8; Le Gallo, M., Sebastian, A., Cherubini, G., Compressed sensing recovery using computational memory (2017) Proc. IEEE Int. Electron Devices Meeting, pp. 2831-28342. , Dec; Le Gallo, M., Sebastian, A., Cherubini, G., Compressed sensing with approximate message passing using in-memory computing (2018) IEEE Trans. Electron Devices, 65 (10), pp. 4304-4312. , Oct; Hu, M., Graves, C.E., Li, C., Memristor-based analog computation and neural network classification with a dot product engine (2017) Adv. Mater., 30 (9); Merrikh-Bayat, F., Guo, X., Klachko, M., High-performance mixed-signal neurocomputing with nanoscale floating-gate memory cell arrays (2018) IEEE Trans. Neural Netw. Learn. Syst., 29 (10), pp. 4782-4790. , Oct; Sun, Z., Pedretti, G., Ambrosi, E., Solving matrix equations in one step with cross-point resistive arrays (2019) Proc. Nat. Acad. Sci. USA, 10 (116), pp. 4123-4128; Le Gallo, M., Sebastian, A., Mathis, R., Mixed-precision in-memory computing (2018) Nature Electron., 1, pp. 246-253; Nandakumar, S.R., LeGallo, M., Boybat, I., Mixed-precision architecture based on computational memory for training deep neural networks (2018) Proc. IEEE Int. Symp. Circuits Syst., pp. 1-5; Nandakumar, S.R., LeGallo, M., Boybat, I., (2017) Mixed-precision Training of Deep Neural Networks Using Computational Memory, , arXiv:1712.01192; Sebastian, A., Boybat, I., Dazzi, M., Computational memory-based inference and training of deep neural networks (2019) Proc. Symp. VLSI Technol., Kyoto, Japan, pp. T168-T169; Gupta, S., Agrawal, A., Gopalakrishnan, K., Deep learning with limited numerical precision (2015) Proc. 32nd Int. Conf. Mach. Learn., 37, pp. 1737-1746; Muller, L.K., Indiveri, G., (2015) Rounding Methods for Neural Networks with Low Resolution Synaptic Weights, , arXiv:1504.05767; Courbariaux, M., Bengio, Y., David, J.-P., BinaryConnect: Training deep neural networks with binary weights during propagations (2015) Proc. Advances Neural Inf. Process. Syst., pp. 3123-3131; Merolla, P., Appuswamy, R., Arthur, J., (2016) Deep Neural Networks Are Robust to Weight Binarization and Other Non-linear Distortions, , arXiv:1606.01981; Zhang, H., Li, J., Kara, K., ZipML: Training linear models with end-to-end low precision, and a little bit of deep learning (2017) Proc. 34th Int. Conf. Mach. Learn., 70, pp. 4035-4043; Gokmen, T., Vlasov, Y., Acceleration of deep neural network training with resistive cross-point devices: Design considerations (2016) Frontiers Neurosci., 10, p. 333; Burr, G.W., Experimental demonstration and tolerancing of a large-scale neural network (165 000 Synapses) using phase-change memory as the synaptic weight element (2015) IEEE Trans. Electron Devices, 62 (11), pp. 3498-3507. , Nov; Ambrogio, S., Narayanan, P., Tsai, H., Equivalent-accuracy accelerated neural-network training using analogue memory (2018) Nature, 558, pp. 60-67; Nandakumar, S.R., Le Gallo, M., Boybat, I., Mixed-precision deep learning based on computational memory To Be Published; Tuma, T., Pantazi, A., Le Gallo, M., Stochastic phase-change neurons (2016) Nature Nanotechnol., 11, pp. 693-699; Tuma, T., Le Gallo, M., Sebastian, A., Detecting correlations using phase-change neurons and synapses (2016) IEEE Electron Device Lett., 37 (9), pp. 1238-1241. , Sep; Sebastian, A., Le Gallo, M., Krebs, D., Crystal growth within a phase change memory cell (2014) Nature Commun., 5; Le Gallo, M., Tuma, T., Zipoli, F., Inherent stochasticity in phase-change memory devices (2016) Proc. 46th Eur. Solid-State Device Res. Conf., pp. 373-376; Nandakumar, S.R., Le Gallo, M., Boybat, I., A phase-change memory model for neuromorphic computing (2018) J. Appl. Phys., 124; Nandakumar, S.R., Boybat, I., Joshi, V., Phase-change memory models for deep learning training and inference (2019) Proc. IEEE Int. Conf. Electron., Circuits Syst., , Nov; (2018) IBM, , https://analog-ai-demo.mybluemix.net; Boybat, I., Le Gallo, M., Moraitis, T., Stochastic weight updates in phase-change memory-based synapses and their influence on artificial neural networks (2017) Proc. 13th Conf. Ph.D. Res. Microelectron. Electron., pp. 13-16; Boybat, I., Gallo, M.L., Nandakumar, S.R., Neuromorphic computing with multi-memristive synapses (2018) Nature Commun., 9; Boybat, I., Nandakumar, S.R., Gallo, M.L., Impact of conductance drift on multi-PCM synaptic architectures (2018) Proc. Non-Volatile Memory Technol. Symp., pp. 1-4; Boybat, I., Giovinazzo, C., Shahrabi, E., Multi-ReRAM synapses for artificial neural network training (2019) Proc. IEEE Int. Symp. Circuits Syst., pp. 1-5; Kim, S., Sosa, N., BrightSky, M., A phase change memory cell with metallic surfactant layer as a resistance drift stabilizer (2013) Proc. IEEE Int. Electron Devices Meeting, pp. 3071-3074; Koelmans, W.W., Sebastian, A., Jonnalagadda, V.P., Projected phase-changememory devices (2015) Nature Commun., 6; Giannopoulos, I., Sebastian, A., Le Gallo, M., 8-bit precision in-memory multiplication with projected phase-change memory (2018) Proc. EEE Int. Electron Devices Meeting, pp. 2771-2774; Le Gallo, M., Krebs, D., Zipoli, F., Collective structural relaxation in phase-change memory devices (2018) Adv. Electron. Mater., 4 (9); Abadi, M., Barham, P., Chen, J., TensorFlow: A system for large-scale machine learning (2016) Proc. 12th USENIX Symp. Operating Syst. Des. Implementation, pp. 265-283; Open Neural Network Exchange, 2017, , https://github.com/onnx/onnx; Lecun, Y., Bottou, L., Bengio, Y., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; Szegedy, C., Liu, W., Jia, Y., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 1-9; He, K., Zhang, X., Ren, S., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 770-778; Huang, G., Liu, Z., Maaten Der Van, L., Densely connected convolutional networks (2017) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 2736-2744; Dazzi, M., Sebastian, A., Francese, P.A., (2019) 5 Parallel Prism: A Topology for Communication-efficient Implementations of Convolutional Neural Networks on Computational Memory, , arXiv:1906.03474; Deng, J., Dong, W., Socher, R., Imagenet: A large-scale hierarchical image database (2009) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 248-255; Kim, S., Gokmen, T., Lee, H., Analog CMOS-based resistive processing unit for deep neural network training (2017) Proc. IEEE 60th Int. Midwest Symp. Circuits Syst., pp. 422-425; Xue, C., Chen, W., Liu, J., A 1Mb multibit ReRAM computing-in-memory macro with 14.6 ns parallel MAC computing time for CNN-Based AI Edge processors (2019) Proc. IEEE Int. Solid-State Circuits Conf., pp. 388-390; Hu, M., Graves, C.E., Li, C., Memristor-based analog computation and neural network classification with a dot product engine (2018) Adv. Mater., 30",,,,"IBM Corporation",,,,,00188646,,IBMJA,,"English","IBM J. Res. Dev.",Article,"Final","",Scopus,2-s2.0-85075005732
"Zhang C., Sun G., Fang Z., Zhou P., Pan P., Cong J.","57221300808;24588064300;38361266400;56430328700;7102504459;25931913900;","Caffeine: Toward uniformed representation and acceleration for deep convolutional neural networks",2019,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","38","11","8497058","2072","2085",,91,"10.1109/TCAD.2017.2785257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055214133&doi=10.1109%2fTCAD.2017.2785257&partnerID=40&md5=efd0ec4a34510dd965e28ad02576abc8","Center for Energy-Efficient Computing and Applications, Peking University, Beijing, 100871, China; Center for Domain-Specific Computing, University of California at Los Angeles, Los Angeles, CA  90095, United States; Falcon Computing Solutions Inc., Los Angeles, CA  95054, United States","Zhang, C., Center for Energy-Efficient Computing and Applications, Peking University, Beijing, 100871, China, Center for Domain-Specific Computing, University of California at Los Angeles, Los Angeles, CA  90095, United States; Sun, G., Center for Energy-Efficient Computing and Applications, Peking University, Beijing, 100871, China; Fang, Z., Center for Domain-Specific Computing, University of California at Los Angeles, Los Angeles, CA  90095, United States; Zhou, P., Center for Domain-Specific Computing, University of California at Los Angeles, Los Angeles, CA  90095, United States; Pan, P., Falcon Computing Solutions Inc., Los Angeles, CA  95054, United States; Cong, J., Center for Energy-Efficient Computing and Applications, Peking University, Beijing, 100871, China, Center for Domain-Specific Computing, University of California at Los Angeles, Los Angeles, CA  90095, United States, Falcon Computing Solutions Inc., Los Angeles, CA  95054, United States","With the recent advancement of multilayer convolutional neural networks (CNNs) and fully connected networks (FCNs), deep learning has achieved amazing success in many areas, especially in visual content understanding and classification. To improve the performance and energy efficiency of the computation-demanding CNN, the FPGA-based acceleration emerges as one of the most attractive alternatives. In this paper, we design and implement Caffeine, a hardware/software co-designed library to efficiently accelerate the entire CNN and FCN on FPGAs. First, we propose a uniformed convolutional matrix-multiplication representation for both computation-bound convolutional layers and communication-bound FCN layers. Based on this representation, we optimize the accelerator micro-architecture and maximize the underlying FPGA computing and bandwidth resource utilization based on a revised roofline model. Moreover, we design an automation flow to directly compile high-level network definitions to the final FPGA accelerator. As a case study, we integrate Caffeine into the industry-standard software deep learning framework Caffe. We evaluate Caffeine and its integration with Caffe by implementing VGG16 and AlexNet networks on multiple FPGA platforms. Caffeine achieves a peak performance of 1460 giga fixed point operations per second on a medium-sized Xilinx KU060 FPGA board; to our knowledge, this is the best published result. It achieves more than 100 × speed-up on FCN layers over prior FPGA accelerators. An end-to-end evaluation with Caffe integration shows up to 29 × and 150 × performance and energy gains over Caffe on a 12-core Xeon server, and 5.7 × better energy efficiency over the GPU implementation. Performance projections for a system with a high-end FPGA (Virtex7 690t) show even higher gains. © 1982-2012 IEEE.","Caffe; CNN FPGA engine; convolutional neural network (CNN); deep learning; hardware/software co-design","Acceleration; Bandwidth; Caffeine; Computer architecture; Computer graphics; Computer hardware; Convolution; Deep learning; Energy efficiency; Engines; Field programmable gate arrays (FPGA); Graphics processing unit; Green computing; Hardware; Hardware-software codesign; Integrated circuit design; Learning systems; Multilayer neural networks; Program processors; Caffe; Convolutional neural network; Convolutional Neural Networks (CNN); Deep convolutional neural networks; FPGA-based accelerations; Fully connected networks; Hardware software co-designed; Kernel; Deep neural networks",,,,,"National Science Foundation, NSF: 61572045; Intel Corporation; Mentor Graphics; Fujitsu; Huawei Technologies; National Engineering College, NEC","Manuscript received January 3, 2017; revised May 24, 2017 and September 18, 2017; accepted November 12, 2017. Date of publication October 18, 2018; date of current version October 16, 2019. This work was supported in part by the Center for Domain-Specific Computing Industrial Sponsors, including Fujitsu Labs, Huawei, Intel, Mentor Graphics, and NEC, in part by NSF China under Award 61572045, in part by UCLA/PKU Joint Research Institute, in part by the Chinese Scholarship Council, and in part by the AsiaInfo Inc. This paper was recommended by Associate Editor D. Chen. (Corresponding author: Chen Zhang.) C. Zhang is with the Center for Energy-Efficient Computing and Applications, Peking University, Beijing 100871, China, and also with the Center for Domain-Specific Computing, University of California at Los Angeles, Los Angeles, CA 90095 USA (e-mail: chen.ceca@pku.edu.cn).",,,,,,,,,,"Taigman, Y., Yang, M., Ranzato, M., Wolf, L., DeepFace: Closing the gap to human-level performance in face verification (2014) Proc. CVPR, pp. 1701-1708; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification (2015) Proc. ICCV, pp. 1026-1034; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc. CVPR, pp. 580-587; Ji, S., Xu, W., Yang, M., Yu, K., 3D convolutional neural networks for human action recognition (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (1), pp. 221-231. , Jan; Coates, A., Deep learning with COTS HPC systems (2013) Proc. ICML, pp. III1337-III1345; Zheng, Z., Jiang, W., Wu, G., Chang, E.Y., SpeeDO: Parallelizing stochastic gradient descent for deep convolutional neural network (2015) Proc. LearningSys, pp. 1-6; Yu, K., Large-scale deep learning at Baidu (2013) Proc. ACM CIKM, pp. 2211-2212; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. NIPS, pp. 1097-1105; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Proc. ECCV, pp. 818-833; Szegedy, C., Going deeper with convolutions (2015) Proc. CVPR, pp. 1-9; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. ICLR; Jia, Y.Q.C., (2013) An Open Source Convolutional Architecture for Fast Feature Embedding, , http://caffe.berkeleyvision.org; Zhang, C., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc. ACM FPGA, pp. 161-170; Chen, T., DianNao: A small-footprint high-throughput accelerator for ubiquitous machine-learning (2014) ACM SIGPLAN Notices, 49 (4), pp. 269-284; Zhang, C., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: Towards uniformed representation and acceleration for deep convolutional neural networks (2016) Proc. IEEE/ACM Int. Conf. Comput.-Aided Design (ICCAD), pp. 1-8; Farabet, C., Poulet, C., Han, J.Y., LeCun, Y., CNP: An FPGAbased processor for convolutional networks (2009) Proc. IEEE FPL, pp. 32-37; Chakradhar, S., A dynamically configurable coprocessor for convolutional neural networks (2010) ACM SIGARCH Comput. Archit. News, 38 (3), pp. 247-257; Aysegul, D., Accelerating deep neural networks on mobile processor with embedded programmable logic (2013) Proc. IEEE NIPS; Cadambi, S., Majumdar, A., Becchi, M., Chakradhar, S., Graf, H.P., A programmable parallel accelerator for learning and classification (2010) Proc. ACM PACT, pp. 273-284; Sankaradas, M., A massively parallel coprocessor for convolutional neural networks (2009) Proc. IEEE ASAP, pp. 53-60; Peemen, M., Setio, A.A.A., Mesman, B., Corporaal, H., Memorycentric accelerator design for convolutional neural networks (2013) Proc. IEEE ICCD, pp. 13-19; Ovtcharov, K., Accelerating deep convolutional neural networks using specialized hardware (2015) Microsoft Res. Whitepaper, 2 (11); Suda, N., Throughput-optimized openCL-based FPGA accelerator for large-scale convolutional neural networks (2016) Proc. ACM FPGA, pp. 16-25; Qiu, J., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proc. ACM FPGA, pp. 26-35; Wei, X., Automated systolic array architecture synthesis for high throughput CNN inference on FPGAS (2017) Proc. ACM DAC, pp. 1-6; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., Optimizing loop operation and dataflow in FPGA acceleration of deep convolutional neural networks (2017) Proc. ACM/SIGDA Int. Symp. Field Program. Gate Arrays, pp. 45-54; Zhao, R., Accelerating binarized convolutional neural networks with software-programmable FPGAS (2017) Proc. ACM FPGA, pp. 15-24; Zhang, J., Li, J., Improving the performance of openCL-based FPGA accelerator for convolutional neural network (2017) Proc. FPGA, pp. 25-34; Zhang, C., Prasanna, V., Frequency domain acceleration of convolutional neural networks on CPU-FPGA shared memory system (2017) Proc. ACM/SIGDA Int. Symp. Field Program. Gate Arrays, pp. 35-44; Choi, Y.-K., A quantitative analysis on microarchitectures of modern CPU-FPGA platforms (2016) Proc. DAC, pp. 1-6; Bergstra, J., Theano: A CPU and GPU math expression compiler (2010) Proc. SciPy, 4, p. 3; (2015) Ultrascale Architecture FPGAS Memory Interface Solutions v7.0, , Vivado Design Suite Xilinx, San Jose, CA, USA, Rep., Apr; Mittal, S., A survey of techniques for managing and leveraging caches in GPUs (2014) J. Circuits Syst. Comput., 23 (8); http://torch.ch; Abadi, M., (2016) TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems, , http://www.tensorflow.org; Rupnow, K., High level synthesis of stereo matching: Productivity, performance, and software constraints (2011) Proc. IEEE Int. Conf. Field Program. Technol. (FPT), pp. 1-8; Zuo, W., Improving high level synthesis optimization opportunity through polyhedral transformations (2013) Proc. ACM FPGA, pp. 9-18; Williams, S., Waterman, A., Patterson, D., Roofline: An insightful visual performance model for multicore architectures (2009) Commun. ACM, 52 (4), pp. 65-76; Yan, Z.-J., Huo, Q., Xu, J., A scalable approach to using DNNderived features in GMM-HMM based acoustic modeling for LVCSR (2013) Proc. Interspeech, pp. 104-108; Grézl, F., Karafiát, M., Kontár, S., Cernocky, J., Probabilistic and bottle-neck features for LVCSR of meetings (2007) Proc. IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), 4, pp. IV757-IV760; Gehring, J., Miao, Y., Metze, F., Waibel, A., Extracting deep bottleneck features using stacked auto-encoders (2013) Proc. IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), pp. 3377-3381; Yu, D., Seltzer, M.L., Improved bottleneck features using pretrained deep neural networks (2011) Proc. 12th Annu. Conf. Int. Speech Commun. Assoc., pp. 237-240; Hinton, G., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Process. Mag., 29 (6), pp. 82-97. , Nov; Jouppi, N.P., In-datacenter performance analysis of a tensor processing unit (2017) Proc. ACM/IEEE 44th Annu. Int. Symp. Comput. Archit. (ISCA), pp. 1-12","Zhang, C.; Center for Energy-Efficient Computing and Applications, China; email: chen.ceca@pku.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Final","",Scopus,2-s2.0-85055214133
"Lin J., Ma L., Yao Y.","57193241200;57217089227;56967360600;","A Fourier domain acceleration framework for convolutional neural networks",2019,"Neurocomputing","364",,,"254","268",,5,"10.1016/j.neucom.2019.06.080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069835328&doi=10.1016%2fj.neucom.2019.06.080&partnerID=40&md5=b6919259a3806bc07e555229b008ea4b","School of Computer Application Technology, Changchun University of Technology, Yan'an street No.2055, Changchun, China; Machinery & Electronics Engineering, University of Chinese Academy of Sciences, Yu Quan Road No. 19, Beijing, China; FAW Foundry Co., Ltd., DongFeng street No. 83, Changchun, China","Lin, J., School of Computer Application Technology, Changchun University of Technology, Yan'an street No.2055, Changchun, China, Machinery & Electronics Engineering, University of Chinese Academy of Sciences, Yu Quan Road No. 19, Beijing, China; Ma, L., FAW Foundry Co., Ltd., DongFeng street No. 83, Changchun, China; Yao, Y., School of Computer Application Technology, Changchun University of Technology, Yan'an street No.2055, Changchun, China","Acceleration of training and inference of convolutional neural networks (CNNs) plays a significant role in deep learning efforts for large-scale datasets. However, it is difficult to accelerate the training and inference of CNNs based on traditional Fourier domain acceleration frameworks because Fourier domain training and inference are related to many complicated factors, such as the architecture of Fourier domain propagation passes, the representation of the activation function and the design of downsampling operations. A conceptually intuitive, useful and general Fourier domain acceleration framework for CNNs is proposed in this paper. Taking the proposed Fourier domain rectified linear unit (FReLU) as an activation function and the proposed Fourier domain pooling function (FPool) as a downsampling function, a Fourier domain acceleration framework is established for CNNs, and the inverse activation function (FReLU−1) and inverse downsampling function (FPool−1) are further obtained for the backward propagation pass. Furthermore, a block decomposition pipeline is integrated into the Fourier domain forward/backward propagation passes of CNNs to accelerate the training and inference of CNNs. The results show that the proposed acceleration framework can accelerate the training and inference of CNNs by a significant factor without reducing the recognition precision. © 2019 Elsevier Ltd","Activation function; Convolutional neural networks; Deep learning; Downsampling operations; Forward/backward propagation passes","Acceleration; Backpropagation; Chemical activation; Convolution; Deep learning; Deep neural networks; Large dataset; Neural networks; Signal sampling; Activation functions; Backward propagation; Block decomposition; Convolutional neural network; Downsampling; Forward/backward propagation passes; Large-scale datasets; Learning efforts; Fourier transforms; acceleration; article; decomposition; deep learning; pipeline",,,,,"National Natural Science Foundation of China, NSFC: 51705032; National High-tech Research and Development Program: 2014AA7031010B","This work was supported by National Natural Science Foundation of China [grant number 51705032]; National High-tech R&D Program[grant number 2014AA7031010B].","This work was supported by National Natural Science Foundation of China [grant number 51705032 ]; National High-tech R&D Program [grant number 2014AA7031010B ].",,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolutional neural networks (2012) Adv. Neural Inf. Process. Syst., 25 (2), pp. 1097-1105; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: towards real-time object detection with region proposal networks (2015) IEEE Trans. Pattern Anal. Mach. Intell., 39 (6), pp. 1137-1149; Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., Kuksa, P., Natural language processing (almost) from scratch (2011) J. Mach. Learn. Res., 12 (1), pp. 2493-2537; Gu, J., Wang, Z., Kuen, J., Ma, L., Shahroudy, A., Shuai, B., Recent advances in convolutional neural networks (2018) Pattern Recognit., 77 (none), pp. 354-377; Yu, J., Rui, Y., Tao, D., Click prediction for web image reranking using multimodal sparse coding (2014) IEEE Trans. Image Process., 23 (5), pp. 2019-2032; Yu, J., Tao, D., Wang, M., Rui, Y., Learning to rank using user clicks and visual features for image retrieval (2015) IEEE Trans. Cybern., 45 (4), pp. 767-779; Yu, J., Yang, X., Gao, F., Tao, D., Deep multimodal distance metric learning using click constraints for image ranking (2016) IEEE Trans. Cybern., 47 (12), pp. 1-11; Hong, C., Yu, J., Wan, J., Tao, D., Wang, M., Multimodal deep autoencoder for human pose recovery (2015) IEEE Trans. Image Process., 24 (12), pp. 5659-5670; Hong, C., Yu, J., Tao, D., Wang, M., Image-based three-dimensional human pose recovery by multiview locality-sensitive sparse retrieval (2015) IEEE Trans. Indust. Electron., 62 (6), pp. 3742-3751; Zhang, Q., Zhang, M., Chen, T., Sun, Z., Ma, Y., Yu, B., Recent advances in convolutional neural network acceleration (2018) Neurocomputing, 323, pp. 37-51; Chetlur, Sharan, Woolley, Cliff, Vandermersch, Philippe, Cohen, Jonathan, Tran, John, Catanzaro, Bryan, and Shelhamer, Evan. cudnn: eEfficient primitives for deep learning. On line first; Filippone, S., Colajanni, M., Psblas:a library for parallel linear algebra computation on sparse matrices (2000) ACM Trans. Math. Softw., 26 (4), pp. 527-550; Cintra, R.J., Duffner, S., Garcia, C., Leite, A., Low-complexity approximate convolutional neural networks (2018) IEEE Trans. Neural Netw. Learn. Syst., 29 (12), pp. 5981-5992; Collobert, R., Kavukcuoglu, K., Farabet, C., Torch7: a Matlab-like environment for machine learning (2011) Proceedings of BigLearn NIPS Workshop, January 2011; Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Bengio, Y., Theano: a CPU and GPU math expression compiler (2010) Proceedings of the Python for Scientific Computing Conference (SciPy), , Oral Presentation; (2014), https://code.google.com/p/cudaconvnet2/, Krizhevsky, Alex. cudaCuda-convnet2 URL:; Jia, Yangqing, Shelhamer, Evan, Donahue, Jeff, Karayev, Sergey, Long, Jonathan, Girshick, Ross, Guadarrama, Sergio, and Darrell, Trevor. Caffe: cConvolutional architecture for fast feature embedding. On line first; Nickolls, J., Parallel computing experiences with cuda (2008) Micro IEEE, 28 (4), pp. 13-27; Bakhoda, A., Yuan, G.L., Fung, W.W.L., Wong, H., Aamodt, T.M., Analyzing cuda workloads using a detailed gpu simulator (2009) Proceedings of IEEE Intl Symp Performance Analysis of Systems & Software, Boston, MA, USA, pp. 163-174. , April 2009; Lavin, A., Gray, S., Fast algorithms for convolutional neural networks (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , On line first; Winograd, S., Arithmetic complexity of computations (1980) SIAM, 43 (2), pp. 625-633; Gall, F.L., Powers of tensors and fast matrix multiplication (2014) Proceedings of the 39th International Symposium on Symbolic and Algebraic Computation, Kobe, Japan, pp. 296-303. , July; Cong, J., Xiao, B., Minimizing computation in convolutional neural networks (2014) Proceedings of Artificial Neural Networks and Machine Learning, Hamburg, Germany, pp. 281-290. , September; Strassen, V., Gaussian elimination is not optimal (1969) Numer. Math., 13 (4), pp. 354-356; Ben-Yacoub, S., Fasel, B., Luttin, J., Fast face detection using mlp and fft (1999) Proceedings of Audio and Video-based Biometric Person Authentification, Washington, D. C., USA; Heideman, M.T., Johnson, D.H., Burrus, C.S., Gauss and the history of the fast Fourier transform (1984) IEEE ASSP Mag., 1 (4), pp. 14-21; Vetterli, P.D., Fast Fourier transforms: a tutorial review and a state of the art (1990) Signal Process., 19 (4), pp. 259-299; Mathieu, M., Henaff, M., Lecun, Y., (2013), Fast training of convolutional networks through ffts. Eprint Arxiv. On line first; (2012), https://docs.nvidia.com/cuda/cufft/; Cooley, J.W., Tukey, J.W., An algorithm for the machine calculation of complex Fourier series (1965) Math. Comput., 19 (90), pp. 297-301; Brosch, T., Tam, R., Efficient training of convolutional deep belief networks in the frequency domain for application to high-resolution 2d and 3d images (2015) Neural Comput., 27 (1), pp. 211-227; Wang, J., Yang, Y., Mao, J., Huang, Z., Huang, C., Xu, W., Cnn-rnn: a unified framework for multi-label image classification (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , On line first; Noord, N.V., Postma, E., Learning scale-variant and scale-invariant features for deep image classification (2017) Pattern Recognit., 61, pp. 583-592; Barat, C., Ducottet, C., String representations and distances in deep convolutional neural networks for image classification (2016) Pattern Recognit., 54 (100), pp. 104-115; Shin, J., Hall, M.W., Chame, J., Chen, C., Hovland, P.D., Speeding up Nek5000 with autotuning and specialization (2010) Proceedings of the 24th International Conference on Supercomputing, Tsukuba, Ibaraki, Japan, pp. 253-262. , June 2010; Vasilache, N., Johnson, J., Mathieu, M., Chintala, S., Piantino, S., Lecun, Y., Fast convolutional nets with fbfft: a gpu performance evaluation (2014) Proceedings of International Conference on Learning Representations, , On line first; Ragankelley, J., Barnes, C., Adams, A., Paris, S., Durand, F., Amarasinghe, S.P., Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines (2013) ACM SIGPLAN Not., 48 (6), pp. 519-530; Rippel, O., Snoek, J., Adams, R.P., Spectral representations for convolutional neural networks (2015) Proceedings of the 28th International Conference on Neural Information Processing Systems, Montreal, Canada, 2, pp. 2449-2457; Ko, J.H., Mudassar, B., Na, T., Mukhopadhyay, S., Design of an energy-efficient accelerator for training of convolutional neural networks using frequency-domain computation (2017) Proceedings of the 54th Annual Design Automation Conference, Austin, TX, USA; Ito, Y., Representation of functions by superpositions of a step or sigmoid function and their applications to neural network theory (1991) Neural Netw., 4 (3), pp. 385-394; Jones, L.K., Constructive approximations for neural networks by sigmoidal functions (1990) Proc. IEEE, 78 (10), pp. 1586-1589; Costarelli, D., Spigler, R., Approximation results for neural network operators activated by sigmoidal functions (2013) Neural Netw., 44 (8), pp. 101-106; Girshick, R., Fast R-CNN (2015) ICCV, , On line first; Lin, T.-Y., Doll´ar, P., Girshick, R., He, K., Hariharan, B., Belongie, S., Feature pyramid networks for object detection (2017) CVPR, , On line first; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: towards real-time object detection with region proposal networks (2015) International Conference on Neural Information Processing Systems, , On line first; Song, S., Xiao, J., Sliding shapes for 3D object detection in depth images (2014) European Conference on Computer Vision, 8694, pp. 634-651","Lin, J.; School of Computer Application Technology, Yan'an street No. 2055, China; email: 282765569@qq.com",,,"Elsevier B.V.",,,,,09252312,,NRCGE,,"English","Neurocomputing",Article,"Final","",Scopus,2-s2.0-85069835328
"Awaad T.A., Elbehery A.M., Abdelhamid A., Elsokkary S.K., Ali Y.M., Salah K., Abdel Salam M., El-Kharashi M.W.","57210990930;57210992263;57210994710;57210997855;57210998058;35617663600;56943118900;6603549157;","An ultrafast neural network-based hardware acceleration for nonlinear systems’ simulators",2019,"Computers and Electrical Engineering","79",,"106452","","",,,"10.1016/j.compeleceng.2019.106452","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072198898&doi=10.1016%2fj.compeleceng.2019.106452&partnerID=40&md5=ca02d08545ab95e48dae680a223ae964","Mentor, A Siemens Business, Cairo, Egypt; Department of Computer and Systems Engineering, Ain Shams University, Cairo, Egypt; Department of Electrical and Computer Engineering, University of Victoria, ictoria, BC, Canada","Awaad, T.A., Mentor, A Siemens Business, Cairo, Egypt; Elbehery, A.M., Department of Computer and Systems Engineering, Ain Shams University, Cairo, Egypt; Abdelhamid, A., Department of Computer and Systems Engineering, Ain Shams University, Cairo, Egypt; Elsokkary, S.K., Department of Computer and Systems Engineering, Ain Shams University, Cairo, Egypt; Ali, Y.M., Department of Computer and Systems Engineering, Ain Shams University, Cairo, Egypt; Salah, K., Mentor, A Siemens Business, Cairo, Egypt; Abdel Salam, M., Mentor, A Siemens Business, Cairo, Egypt; El-Kharashi, M.W., Department of Computer and Systems Engineering, Ain Shams University, Cairo, Egypt, Department of Electrical and Computer Engineering, University of Victoria, ictoria, BC, Canada","Nowadays, investigating new techniques to accelerate nonlinear systems’ simulations is a need because of their regular usage in industry. Systems’ simulators need to solve an enormous number of nonlinear equations. Software-based solutions cannot solve complex nonlinear equations in a reasonable time while maintaining scalability with the increase in the number of equations. The speedup of the process can be achieved by hardware accelerators. This research enhances a neural network architecture with a new hybrid-updating rule realized in hardware to solve nonlinear equations. A scalable hardware architecture is introduced to solve any number of nonlinear equations and achieve a high performance gain. Results show the increase in the performance gain between our proposed solution and software solvers. For example, our proposed architecture is able to solve 1000 sparse equations on Xilinx Virtex-7 with 400x speedup compared to other software methods. © 2019","Back propagation; Circuit devices simulators; Computational methods; Hardware acceleration; Neural networks; Solving nonlinear equations","Backpropagation; Computational methods; Network architecture; Neural networks; Nonlinear systems; Simulators; Complex nonlinear equations; Hardware acceleration; Hardware accelerators; Proposed architectures; Scalable hardware architecture; Software methods; Software-based solutions; Solving nonlinear equations; Nonlinear equations",,,,,,,,,,,,,,,,"Chapra, S.C., Canale, R., Numerical methods for engineers (2006), 5 McGraw-Hill, Inc. New York, NY, USA 9780073101569; Broyden, C., A class of methods for solving nonlinear simultaneous equations (1965) Math Comput, 19, pp. 577-593; Mor, J.J., The Levenberg–Marquardt algorithm: implementation and theory (1963) SIAM J Appl Math, 11, pp. 431-441; Allgower, E.L., Georg, K., Introduction to numerical continuation methods (2003), Society for Industrial and Applied Mathematics Philadelphia, PA, USA; Sturmfels, B., What is a Gróbner basis? (2005) Not Am Math Soc, 52 (10), pp. 1199-1200; Delvest, L.M., Lyness, J.N., A numerical method for locating the zeros of an analytic function (1967) Math Comput, 21, pp. 543-560; http://www.mentor.com/products/fv/emulation-systems/, Veloce emulation platform, Mentor, A Siemens Business corporation.; [Online; Last visited on August 31st, 2019]; Tarek Ibn Ziad, M., Hossam, M., Masoud, M.A., Nagy, M., Adel, H.A., Alkabani, Y., On kernel acceleration of electromagnetic solvers via hardware emulation (2015) Comput Electr Eng, 47, pp. 96-113; http://ngspice.sourceforge.net/, NGspice: an open source library for circuit simulations.; [Online; Last visited on August 31st, 2019]; http://www.linear.com/designtools/software/, LTspice: a high performance SPICE simulation software.; [Online; Last visited on August 31st, 2019]; Van Hentenryck, P., McAllester, D., Kapur, D., Solving polynomial systems using a branch and prune approach (1997) SIAM J Numer Anal, 34 (2), pp. 797-827; Kreyszig, E., Advanced engineering mathematics: maple computer guide (2000), 8th ed. John Wiley & Sons, Inc. New York, NY, USA; Arfken, G., Mathematical methods for physicists (1985), 3 Academic Press Orlando, FL 9780073101569; Goulianas, K., Margaris, A., Refanidis, I., Diamantaras, P.K.T., A back propagation-type neural network architecture for solving the complete n × n nonlinear algebraic system of equations (2016) Adv Pure Math, 6, pp. 455-480; Coleman, T., Li, Y., An interior, trust region approach for nonlinear minimization subject to bounds (1996) SIAM J Optim, 6, pp. 418-445; Adamopoulos, M., Margaris, A., Solving nonlinear algebraic systems using artificial neural network (2007) Proceedings of the 10th international conference on engineering applications of artificial neural networks, , Thessaloniki Greece; Goulianas, K., Margaris, A., Refanidis, I., Diamantaras, K., Solving polynomial systems using a fast adaptive back propagation-type neural network algorithm (2018) Eur J Appl Math, 29 (2), pp. 301-337; Kruse, R., Borgelt, C., Klawonn, F., Moewes, C., Steinbrecher, M., Held, P., Computational intelligence: a methodological introduction (2013), Springer Publishing Company, Incorporated 9781447150121; Kingma, D.P., Ba, J., Adam: a method for stochastic optimization (2014) Proceedings of the international conference on learning representations, abs/1412.6980; de Dinechin, F., Pasca, B., Designing custom arithmetic data paths with flopoco (2011) IEEE Des Test Comput, 28 (4), pp. 18-27; Shin, B.-C., Darvishi, M., Kim, C.-H., A comparison of the Newton–Krylov method with high order Newton-like methods to solve nonlinear systems (2010) Appl Math Comput, 217 (7), pp. 3190-3198; Yuan, G., Zhang, M., A three-terms Polak–Ribire–Polyak conjugate gradient algorithm for large-scale nonlinear equations (2015) J Comput Appl Math, 286 (100), pp. 186-195; Mamat, M., Muhammad, K., Waziri, M.Y., Trapezoidal Broyden's method for solving systems of nonlinear equations (2014) Appl Math Sci, 8, pp. 251-260; Ho, C.-W., Ruehli, A., Brennan, P., The modified nodal approach to network analysis (1975) IEEE Trans Circuits Syst, 22 (6), pp. 504-509; Moré, J.J., Garbow, B.S., Hillstrom, K.E., Testing unconstrained optimization software (1981) Trans Math Softw, 7 (1), pp. 17-41","El-Kharashi, M.W.; Department of Computer and Systems Engineering, Egypt; email: watheq.elkharashi@eng.asu.edu.eg",,,"Elsevier Ltd",,,,,00457906,,CPEEB,,"English","Comput Electr Eng",Article,"Final","",Scopus,2-s2.0-85072198898
"Agrawal A., Ankit A., Roy K.","57196356810;56192298100;57000621800;","Spare: Spiking neural network acceleration using rom-embedded rams as in-memory-computation primitives",2019,"IEEE Transactions on Computers","68","8","8447492","1190","1200",,8,"10.1109/TC.2018.2867048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052626945&doi=10.1109%2fTC.2018.2867048&partnerID=40&md5=1591e532ed982145f5e69336005b8e75","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN  47907, United States","Agrawal, A., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN  47907, United States; Ankit, A., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN  47907, United States; Roy, K., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN  47907, United States","From the little we know about the human brain, the inherent cognitive mechanism is very different from the de facto state-of-The-Art computing platforms. The human brain uses distributed, yet integrated memory and computation units, unlike the physically separate memory and computation cores in typical von Neumann architectures. Despite huge success of artificial intelligence, hardware systems running these algorithms consume orders of magnitude higher energy compared to the human brain, mainly due to heavy data movements between the memory unit and the computation cores. Spiking neural networks (SNNs) built using bio-plausible neuron and synaptic models have emerged as the power efficient choice for designing cognitive applications. These algorithms involve several lookup-Table (LUT) based function evaluations such as high-order polynomials and transcendental functions for solving complex neuro-synaptic models, that typically require additional storage and thus, bigger memories. To that effect, we propose 'SPARE'-An in-memory, distributed processing architecture built on ROM-embedded RAM technology, for accelerating SNNs. ROM-embedded RAMs allow storage of LUTs (for neuro-synaptic models), embedded within a typical memory array, without additional area overhead. Our proposed architecture consists of a 2-D array of Processing Elements (PEs), wherein each PE has its own ROM-embedded RAM structure and executes part of the SNN computation. Since most of the computations (including multiple math-Table evaluations) are done locally within each PE, unnecessary data transfers are restricted, thereby alleviating the problems arising due to physically separate remote memory unit and the computation core. SPARE thus leverages both, the hardware benefits of distributed, in-memory processing, and also the algorithmic benefits of SNNs. We evaluate SPARE for two different ROM-Embedded RAM structures-CMOS based ROM-Embedded SRAMs (R-SRAMs) and STT-MRAM based ROM-Embedded MRAMs (R-MRAMs). Moreover, we analyze trade-offs in terms of energy, area and performance, for using the two technologies on a range of image classification benchmarks. Furthermore, we leverage the additional storage density to implement complex neuro-synaptic functionalities. This enhances the utility of the proposed architecture by provisioning implementation of any neuron/synaptic behavior as necessitated by the application. Our results show up-To \sim\! 1.75\times∼1.75×, \sim\! 1.95\times∼1.95× and \sim \!1.95\times∼1.95× improvement in energy, iso-storage area, and iso-Area performance, respectively, by using neural network accelerators built on ROM-embedded RAM primitives. © 1968-2012 IEEE.","in-memory computing; ROM-embedded RAM; Spiking neural network (SNN); STT-MRAM","Benchmarking; Brain; Complex networks; Data transfer; Economic and social effects; Function evaluation; Hardware; Intelligent agents; Magnetic recording; Magnetic storage; Memory architecture; MRAM devices; Network architecture; Neural networks; Neurons; Static random access storage; Table lookup; Arrays; Biological neural networks; Embedded rams; Random access memory; Spiking neural network(SNN); STT-MRAM; ROM",,,,,"Semiconductor Research Corporation, SRC; Defense Advanced Research Projects Agency, DARPA; Intel Corporation","The research was funded in part by C-BRIC, one of six centers in JUMP, a Semiconductor Research Corporation (SRC) program sponsored by DARPA, the US National Science Foundation, Intel Corporation and Vannevar Bush Faculty Fellowship. Amogh Agrawal and Aayush Ankit are contributed equally to this work.",,,,,,,,,,"Bengio, Y., Learning deep architectures for AI (2009) Found. Trends Mach. Learn, 2 (1), pp. 1-127; Jones, N., The learning machines (2014) Nature, 505 (7482). , Art. no 146; Silver, D., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Diehl, P.U., Fast-classifying, high-Accuracy spiking deep networks through weight and threshold balancing (2015) Proc. Int. Joint Conf. Neural Netw, pp. 1-8; Krizhevsky, A., ImageNet classification with deep convolutional neural networks (2012) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 1097-1105; Han, S., Learning both weights and connections for efficient neural network (2015) Proc. Int. Conf. Neural Inf. Process. Syst, pp. 1135-1143; Chen, Y.-H., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks IEEE J. Solid-State Circuits, 52 (1), pp. 127-138. , Jan. 2017; Kang, M., An energy-efficient VLSI architecture for pattern recognition via deep embedding of computation in SRAM (2014) Proc IEEE Int. Conf. Acoust. Speech Signal Process, pp. 8326-8330. , May; Snelgrove, W.M., Stumm, M., Elliott, D., McKenzie, R., Cojocaru, C., Computational RAM: Implementing processors in memory (1999) IEEE Des. Test Comput, 16 (1), pp. 32-41. , Jan-Mar; Borghetti, J., Memristive switches enable stateful logic operations via material implication (2010) Nature, 464 (7290), pp. 873-876; Ankit, A., Sengupta, A., Panda, P., Roy, K., RESPARC: A reconfigurable and energy-efficient architecture with memristive crossbars for deep spiking neural networks (2017) Proc. 54th Annu. Des. Autom. Conf, , Art 27; Ankit, A., Sengupta, A., Roy, K., TraNNsformer: Neural network transformation for memristive crossbar based neuromorphic system design (2017) Proc. 36th Int. Conf. Comput.-Aided des, pp. 533-540; Lee, D., Area efficient ROM-embedded SRAM cache (2013) IEEE Trans. Very Large Scale Integr. Syst, 21 (9), pp. 1583-1595. , Sep; Fong, X., Embedding read-only memory in spin-Transfer torque MRAM-based on-chip caches (2016) IEEE Trans. Very Large Scale Integr. Syst, 24 (3), pp. 992-1002. , Mar; Clopath, C., Voltage and spike timing interact in STDP-A unified model Spike-Timing Dependent Plasticity, 2. , Jul 2010, Art 294; Bliss, T.V., A synaptic model of memory: Long-Term potentiation in the hippocampus (1993) Nature, 361 (6407). , Art. no 31; Harrison, J., Kubaska, T., Story, S., Labs, M.S., Corporation, I., The computation of transcendental functions on the IA-64 architecture (1999) Intel Technol. J, 4, pp. 234-251; Akopyan, F., TrueNorth: Design and tool flow of a 65 mW 1 Million neuron programmable neurosynaptic chip (2015) IEEE Trans. Comput-Aided Des. Integr. Circuits Syst, 34 (10), pp. 1537-1557. , Oct; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778. , Jun; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Hassabis, D., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529, pp. 484-489. , Jan; Dayan, P., (2001) Theoretical Neuroscience, 806. , Cambridge, MA, USA MIT Press; Izhikevich, E., Simple model of spiking neurons (2003) IEEE Trans. Neural Netw, 14 (6), pp. 1569-1572. , Nov; Hodgkin, A.L., A quantitative description of membrane current and its application to conduction and excitation in nerve (1952) The J. Physiology, 117, pp. 500-544. , Aug; Diehl, P.U., Cook, M., Unsupervised learning of digit recognition using spike-Timing-dependent plasticity Frontiers Comput. Neurosci, 9. , Aug 2015, Art 99; CACTI 6.0: A Tool to Understand Large Caches, , http://www.hpl.hp.com/research/cacti/; Dong, X., Xu, C., Xie, Y., Jouppi, N.P., NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory (2012) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst, 31 (7), pp. 994-1007. , Jul; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc IEEE, 86 (11), pp. 2278-2324. , Nov; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , Masters thesis, Dept. of Computer Science, University of Toronto; Han, B., Ankit, A., Sengupta, A., Roy, K., Cross-layer design exploration for energy-quality tradeoffs in spiking and non-spiking deep artificial neural networks (2017) IEEE Trans. Multi-Scale Comput. Syst; Goodman, D., Brian: A simulator for spiking neural networks in python (2008) Frontiers Neuroinformatics, 2. , Art 5; Sun, F., Wang, C., Gong, L., Xu, C., Zhang, Y., Lu, Y., Li, X., Zhou, X., A power-efficient accelerator for convolutional neural networks (2017) Proc IEEE Int. Conf. Cluster Comput., pp. 631-632. , Sep","Agrawal, A.; School of Electrical and Computer Engineering, United States; email: agrawa64@purdue.edu",,,"IEEE Computer Society",,,,,00189340,,ITCOB,,"English","IEEE Trans Comput",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85052626945
"Wei W., Deng D., Zeng L., Zhang C., Shi W.","57211747064;35204811700;24465796200;57212206839;37104951800;","Classification of foreign fibers using deep learning and its implementation on embedded system",2019,"International Journal of Advanced Robotic Systems","16","4",,"","",,6,"10.1177/1729881419867600","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070401608&doi=10.1177%2f1729881419867600&partnerID=40&md5=ba026b7ba061c3d8e35d7a38ab9674a0","School of Electronic Information, Wuhan University, Wuhan, China; School of Information Science and Engineering, Wuhan University of Science and Technology, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China","Wei, W., School of Electronic Information, Wuhan University, Wuhan, China; Deng, D., School of Electronic Information, Wuhan University, Wuhan, China; Zeng, L., School of Electronic Information, Wuhan University, Wuhan, China; Zhang, C., School of Information Science and Engineering, Wuhan University of Science and Technology, Wuhan, China; Shi, W., School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China","In recent years, the foreign fibers in cotton lint significantly affect the quality of the final cotton textile products. It remains a challenging task to accurately distinguish foreign fibers from cotton. This article proposes an embedded system based on field programmable gate array (FPGA) + digital signal processor (DSP) to recognize and remove foreign fibers mixed in cotton. With substantial tests of this system, we collect massive samples of foreign fibers and fake foreign fibers. Based on these samples, a convolution neural network mode is developed to validate the classification of the suspected targets from the detection subsystem, to improve the detection reliability. After training several model architectures, we find a model with the best balance between performance and computation. The high success rate (up to 96% in the validation set) demonstrates the effectiveness of the model. Moreover, the computation time (5 ms on a single image based on an eight-core DSP) indicates the efficiency of the detection, which ensures the real-time application of the system. © The Author(s) 2019.","Deep learning; embedded system; foreign fiber; TMS320C6678","Cotton; Digital signal processing; Digital signal processors; Embedded systems; Fibers; Field programmable gate arrays (FPGA); Computation time; Convolution neural network; Cotton textiles; Digital signal processors (DSP); Foreign fiber; Model architecture; Real-time application; TMS320C6678; Deep learning",,,,,,,,,,,,,,,,"Zhang, H., Li, D., Applications of computer vision techniques to cotton foreign matter inspection: a review (2014) Comput Electron Agr, 109, pp. 59-70; Brosnan, T., Sun, D.W., Inspection and grading of agricultural and food products by computer vision systems—a review (2002) Comput Electron Agr, 36, pp. 193-213; Yang, W.Z., Li, D.L., Zhu, L., A new approach for image processing in foreign fiber detection (2009) Comput Electron Agr, 68 (1), pp. 68-77; Yang, W., Li, D., Wei, X., An automated visual inspection system for foreign fiber detection in lint, 4, pp. 364-368. , Proceedings of the 2009 WRI global congress on intelligent systems, Xia Men, China, 19–21 May 2009, IEEE, In; Yang, W., Li, D., Wang, S., Lu, S., Saliency-based color image segmentation in foreign fiber detection (2013) Math Comput Model, 58, pp. 852-858; Zhao, X., Li, D., Yang, W., Feature selection for cotton foreign fiber objects based on improved ant colony algorithm (2011) Trans CSAM, 42 (4), pp. 168-173. , (in Chinese with English abstract); Wang, R., Liu, S., Wang, Q., Classification features of feather and hemp in cotton foreign fibers (2012) Trans CSAE, 28, pp. 202-207. , (in English with Chinese abstract); Tantaswadi, P., Vilainatre, J., Tamaree, N., Machine vision for automated visual inspection of cotton quality in textile industries using color isodiscrimination contour (1999) Comput Ind Eng, 37 (1), pp. 347-350; Qu, X., Ding, T., A fast feature extraction algorithm for detection of foreign fiber in lint cotton within a complex background (2010) Acta Automat Sinica, 36 (6), pp. 785-790; Rubio, J.J., Cruz, D.R., Elias, I., ANFIS system for classification of brain signals (2019) J Intell Fuzzy Syst, pp. 1-9; Soares, A.M., Fernandes, B.J.T., Bastos-Filho, C.J., Pyramidal neural networks with evolved variable receptive fields (2018) Neural Comput and Appl, 29 (12), pp. 1443-1453; de Jesús Rubio, J., A method with neural networks for the classification of fruits and vegetables (2017) Soft Comput, 21 (23), pp. 1-14; Liu, Y., Wang, Z., Yuan, Y., Partial-nodes-based state estimation for complex networks with unbounded distributed delays (2018) IEEE Trans Neural Netw Learn Syst, 29 (8), pp. 3906-3912; de Jesús Rubio, J., SOFMLS: online self-organizing fuzzy modified least-squares network (2009) IEEE Trans Fuzzy Syst, 17 (6), pp. 1296-1309; Li, X., Li, H., Sun, B., Assessing information security risk for an evolving smart city based on fuzzy and grey FMEA (2018) J Intell Fuzzy Syst, 34 (4), pp. 2491-2501; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Noh, H., Hong, S., Han, B., Learning deconvolution network for semantic segmentation, pp. 1520-1528. , Proceedings of the IEEE international conference on computer vision, 2015, In; Chen, Z., Shilei, S., Wenxuan, S., Design and test of foreign fiber removal machine based on embedded system (2017) Trans Chin Soc Agr Mach, 48, pp. 43-52; Pauwels, K., Tomasi, M., Diaz Alonso, J., A comparison of FPGA and GPU for real-time phase-based optical flow, stereo, and local image features (2012) IEEE Trans Comput, 61 (7), pp. 999-1012; LeCun, Y., Bottou, L., Bengio, Y., Gradient-based learning applied to document recognition (1998) Proc IEEE, 86, pp. 2278-2324; Russakovsky, O., Deng, J., Su, H., IMAGENET large scale visual recognition challenge (2015) Int J Comput Vis, 115 (3), pp. 211-252; Donahue, J., Jia, Y., Vinyals, O., Decaf: A deep convolutional activation feature for generic visual recognition; Oquab, M., Bottou, L., Laptev, I., Learning and transferring mid-level image representations using convolutional neural networks 2014 IEEE conference on computer vision and pattern recognition (CVPR), pp. 1717-1724. , Columbus, OH, USA, 23–28 June 2014, Washington, DC, USA, IEEE Computer Society, In; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Computer vision—ECCV 2014, pp. 818-833. , Fleet D., Pajdla T., Schiele B., Tuytelaars T., (eds), Zürich, Springer, In:, (eds; Fine, T.L., (2006) Feedforward neural network methodology, , Berlin, Springer Science Business Media; Bottou, L., Large-scale machine learning with stochastic gradient descent, pp. 177-186. , Proceedings of COMPSTAT’2010, 22–27 August 2010, Paris, Springer, In; Hawkins, D.M., The problem of over-fitting (2004) J Chem Inf Comput Sci, 44 (1), pp. 1-12; Kumar, V., Sbîrlea, A., Jayaraj, A., Heterogeneous workstealing across CPU and DSP cores, pp. 1-6. , 2015 IEEE high performance extreme computing conference (HPEC), Waltham, MA, USA, 15–17 September 2015, IEEE, In; Ramesh, B., Bhardwaj, A., Richardson, J., Optimization and evaluation of image-and signal-processing kernels on the TI C6678 multi-core DSP, pp. 1-6. , IEEE high performance extreme computing conference (HPEC), Waltham, MA, USA, 9–11 September 2014, IEEE, In; Coombs, J., Prabhu, R., OpenCV on TI’s DSP+ ARM Platforms: mitigating the challenges of porting OpenCV to embedded platforms (2011) White Paper, Texas Instruments; Castillo, M.I., Fernández, J.C., Igual, F.D., Hyperspectral unmixing on multicore DSPs: trading off performance for energy (2014) IEEE J Sel Top Appl, 7 (6), pp. 2297-2304; Kim, S.C., Bhattacharyya, S.S., An efficient GPU implementation of a multirate resampler for multi-carrier systems, pp. 751-755. , 2015 IEEE global conference on signal and information processing (GlobalSIP), Orlando, FL, USA, 14–16 December 2015, Hingham, MA, USA, Kluwer Academic Publishers, In; Chen, J., Alfred, C., So, H.K.H., Design considerations of real-time adaptive beamformer for medical ultrasound research using FPGA and GPU, pp. 198-205. , 2012 international conference on field-programmable technology, FPT 2012, Seoul, Korea (South), 10–12 December 2012, Seoul, IEEE, In; Pauwels, K., Tomasi, M., Alonso, J.D., A comparison of FPGA and GPU for real-time phase-based optical flow, stereo, and local image features (2012) IEEE Trans Comput, 61 (7), pp. 999-1012; TMS320C6678 multi-core fixed and floating-point digital signal processor, data sheet, , http://www.ti.com/cn/lit/ds/symlink/tms320c6678.pdf, accessed March 2014; Feng, T., Zou, L., Yan, J., Real-time fabric defect detection using accelerated small-scale over-completed dictionary of sparse coding (2016) Int J Adv Robot Syst, 13, pp. 1-9; Han, G., Zeng, H., Natale, M.D., Experimental evaluation and selection of data consistency mechanisms for hard real-time applications on multicore platforms (2014) IEEE Trans Ind Inform, 10 (2), pp. 903-918","Wei, W.; School of Electronic Information, China; email: ww_130@163.com",,,"SAGE Publications Inc.",,,,,17298806,,,,"English","Int. J. Adv. Rob. Syst.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85070401608
"Liu H., Ji Y., Han J., Zhang Y., Zheng W.","57196314740;57040305000;57208386360;8686316300;24451602300;","Training and Software Simulation for ReRAM-Based LSTM Neural Network Acceleration [面向阻变存储器的长短期记忆网络加速器的训练和软件仿真]",2019,"Jisuanji Yanjiu yu Fazhan/Computer Research and Development","56","6",,"1182","1191",,3,"10.7544/issn1000-1239.2019.20190113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072169029&doi=10.7544%2fissn1000-1239.2019.20190113&partnerID=40&md5=9102d191516a8a083d3cf0ca9c6ed135","Deparment of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Institute of Microelectronics, Tsinghua University, Beijing, 100084, China","Liu, H., Deparment of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Ji, Y., Deparment of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Han, J., Institute of Microelectronics, Tsinghua University, Beijing, 100084, China; Zhang, Y., Deparment of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Zheng, W., Deparment of Computer Science and Technology, Tsinghua University, Beijing, 100084, China","Long short-term memory (LSTM) is mostly used in fields of speech recognition, machine translation, etc., owing to its expertise in processing and predicting events with long intervals and long delays in time series. However, most of existing neural network acceleration chips cannot perform LSTM computation efficiently, as limited by the low memory bandwidth. ReRAM-based crossbars, on the other hand, can process matrix-vector multiplication efficiently due to its characteristic of processing in memory (PIM). However, a software tool of broad architectural exploration and end-to-end evaluation for ReRAM-based LSTM acceleration is still missing. This paper proposes a simulator for ReRAM-based LSTM neural network acceleration and a corresponding training algorithm. Main features (including imperfections) of ReRAM devices and circuits are reflected by the highly configurable tools, and the core computation of simulation can be accelerated by general-purpose graphics processing unit (GPGPU). Moreover, the core component of simulator has been verified by the corresponding circuit simulation of a real chip design. Within this framework, architectural exploration and comprehensive end-to-end evaluation can be achieved. © 2019, Science Press. All right reserved.","Long short-term memory (LSTM); Neural network; ReRAM; Simulation framework; Training algorithm","Brain; Circuit simulation; Computer aided software engineering; Computer graphics; Graphics processing unit; Image coding; Neural networks; Program processors; RRAM; Speech recognition; Speech transmission; Core components; Core computation; General purpose graphics processing unit (GPGPU); Machine translations; Processing in memory; Simulation framework; Software simulation; Training algorithms; Long short-term memory",,,,,,"This work was supported by the Science and Technology Innovation Special Zone Project.",,,,,,,,,,"Jouppi, N.P., Young, C., Patil, N., In-datacenter performance analysis of a tensor processing unit (2017) Proc of the 44th Annual Int Symp on Computer Architecture, pp. 1-12. , New York: ACM; Benchmarks: Deep Learning Nvidia P100 vs V100 GPU https://www.xcelerit.com/computing-benchmarks/insights/benchmarks-deep-learning-nvidia-p100-vs-v100-gpu/, [2017-11-27]; Han, S., Kang, J., Mao, H., ESE: Efficient speech recognition engine with sparse LSTM on FPGA (2017) Proc of the 2017 ACM/SIGDA Int Symp on Field-Programmable Gate Arrays, pp. 75-84. , New York: ACM; Wang, S., Li, Z., Ding, C., C-LSTM: Enabling efficient LSTM using structured compression techniques on FPGAs (2018) Proc of the 2018 ACM/SIGDA Int Symp on Field-Programmable Gate Arrays, pp. 11-20. , New York: ACM; Shafiee, A., Nag, A., Muralimanohar, N., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) Proc of the 43rd Annual Int Symp on Computer Architecture, pp. 14-26. , Piscataway, NJ: IEEE; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Evangelopoulos, G.N., Efficient hardware mapping of long short-term memory neural networks for automatic speech recognition (2016), Belgium: KU Leuven; Liu, B., Li, H., Chen, Y., Vortex: Variation-aware training for memristor x-bar (2015) Proc of the 52nd ACM/EDAC/IEEE Design Automation Conf (DAC), pp. 1-6. , Piscataway, NJ: IEEE; Tang, T., Xia, L., Li, B., Binary convolutional neural network on RRAM (2017) Proc of the 22nd Asia and South Pacific Design Automation Conf, pp. 782-787. , Piscataway, NJ: IEEE; Song, L., Qian, X., Li, H., PipeLayer: A pipelined ReRAM-based accelerator for deep learning (2017) Proc of 2017 IEEE Int Symp on High Performance Computer Architecture, pp. 541-552. , Piscataway, NJ: IEEE; Dong, X., Xu, C., Xie, Y., NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory (2012) IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 31 (7), pp. 994-1007; Xu, S., Chen, X., Wang, Y., PIMSim: A flexible and detailed processing-in-memory simulator (2018) IEEE Computer Architecture Letters, 18 (1), pp. 6-9; Chen, P., Peng, X., Yu, S., NeuroSim: A circuit-level macro model for benchmarking neuro-inspired architectures in online learning (2018) IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 37 (12), pp. 3067-3080; Xia, L., Li, B., Tang, T., MNSIM: Simulation platform for memristor-based neuromorphic computing system (2018) IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 37 (5), pp. 1009-1022; Yao, P., Wu, H., Gao, B., Face classification using electronic synapses (2017) Nature Communications, 8, p. 15199; Muralimanohar, N., Balasubramonian, R., Jouppi, N.P., Optimizing NUCA organizations and wiring alternatives for large caches with CACTI 6.0 (2007) Proc of the 40th Annual IEEE/ACM Int Symp on Microarchitecture (MICRO-402007), pp. 3-14. , Piscataway, NJ: IEEE; Long, Y., Na, T., Mukhopadhyay, S., ReRAM-based processing-in-memory architecture for recurrent neural network acceleration (2018) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 26 (12), pp. 2781-2794; Gu, P., Li, B., Tang, T., Technological exploration of RRAM crossbar array for matrix-vector multiplication (2016) Journal of Computer Science and Technology, 31 (1), pp. 3-19; Lee, S.R., Kim, Y.B., Chang, M., Multi-level switching of triple-layered TaOx RRAM with excellent reliability for storage class memory (2012) Proc of 2012 Symp on VLSI Technology, pp. 71-72. , Piscataway, NJ: IEEE","Zhang, Y.; Deparment of Computer Science and Technology, China; email: zyh02@tsinghua.edu.cn",,,"Science Press",,,,,10001239,,JYYFE,,"English; Chinese","Jisuanji Yanjiu yu Fazhan",Article,"Final","",Scopus,2-s2.0-85072169029
"Blanco-Filgueira B., Garcia-Lesta D., Fernandez-Sanjurjo M., Brea V.M., Lopez P.","26039004700;56784386800;57204679350;6602965095;7202454417;","Deep learning-based multiple object visual tracking on embedded system for IoT and mobile edge computing applications",2019,"IEEE Internet of Things Journal","6","3","8653851","5423","5431",,43,"10.1109/JIOT.2019.2902141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067882071&doi=10.1109%2fJIOT.2019.2902141&partnerID=40&md5=5138592d80a7b74e34374def68a7d046","Centro Singular de Investigación en Tecnoloxías da Información, Universidade de Santiago de Compostela, Santiago de Compostela, 15782, Spain","Blanco-Filgueira, B., Centro Singular de Investigación en Tecnoloxías da Información, Universidade de Santiago de Compostela, Santiago de Compostela, 15782, Spain; Garcia-Lesta, D., Centro Singular de Investigación en Tecnoloxías da Información, Universidade de Santiago de Compostela, Santiago de Compostela, 15782, Spain; Fernandez-Sanjurjo, M., Centro Singular de Investigación en Tecnoloxías da Información, Universidade de Santiago de Compostela, Santiago de Compostela, 15782, Spain; Brea, V.M., Centro Singular de Investigación en Tecnoloxías da Información, Universidade de Santiago de Compostela, Santiago de Compostela, 15782, Spain; Lopez, P., Centro Singular de Investigación en Tecnoloxías da Información, Universidade de Santiago de Compostela, Santiago de Compostela, 15782, Spain","Compute and memory demands of state-of-the-art deep learning methods are still a shortcoming that must be addressed to make them useful at Internet of Things (IoT) end-nodes. In particular, recent results depict a hopeful prospect for image processing using convolutional neural networks, CNNs, but the gap between software and hardware implementations is already considerable for IoT and mobile edge computing applications due to their high power consumption. This proposal performs low-power and real time deep learning-based multiple object visual tracking implemented on an NVIDIA Jetson TX2 development kit. It includes a camera and wireless connection capability and it is battery powered for mobile and outdoor applications. A collection of representative sequences captured with the on-board camera, dETRUSC video dataset, is used to exemplify the performance of the proposed algorithm and to facilitate benchmarking. The results in terms of power consumption and frame rate demonstrate the feasibility of deep learning algorithms on embedded platforms although more effort in the joint algorithm and hardware design of CNNs is needed. © 2014 IEEE.","Deep learning; Edge computing; Foreground segmentation; Internet of Things (IoT) node; Visual tracking","Application programs; Benchmarking; Cameras; Edge computing; Electric power utilization; Green computing; Image processing; Internet of things; Learning algorithms; Neural networks; Computing applications; Convolutional neural network; Foreground segmentation; High power consumption; Internet of Things (IOT); Software and hardwares; Visual Tracking; Wireless connection; Deep learning",,,,,"Ministerio de Ciencia e Innovación, MICINN; Consellería de Cultura, Educación e Ordenación Universitaria, Xunta de Galicia: ED431C 2017/69, ED431G/08; European Regional Development Fund, FEDER","Manuscript received July 31, 2018; revised February 1, 2019; accepted February 18, 2019. Date of publication February 27, 2019; date of current version June 19, 2019. This work was supported in part by the Spanish Government project RTI2018-097088-B-C32 MICINN (FEDER), in part by the Consellería de Cultura, Educación e Ordenación Universitaria (accreditation 2016-2019, ED431G/08, and reference competitive group 2017-2020, ED431C 2017/69), and in part by the European Regional Development Fund (ERDF). (Corresponding author: Beatriz Blanco-Filgueira.) The authors are with the Centro Singular de Investigación en Tecnoloxías da Información, Universidade de Santiago de Compostela, 15782 Santiago de Compostela, Spain (e-mail: blancofilgueira@edu.xunta.es). Digital Object Identifier 10.1109/JIOT.2019.2902141",,,,,,,,,,"Rusci, M., Rossi, D., Farella, E., Benini, L., A sub-mW IoT-endnode for always-on visual monitoring and smart triggering (2017) IEEE Internet Things J., 4 (5), pp. 1284-1295. , Oct; Shi, W., Cao, J., Zhang, Q., Li, Y., Xu, L., Edge computing: Vision and challenges (2016) IEEE Internet Things J., 3 (5), pp. 637-646. , Oct; LeCun, Y., Bengio, Y., Hilton, G., Deep learning (2015) Nature, 521, pp. 436-444. , May; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778; Shelhamer, E., Long, J., Darrell, T., Fully convolutional networks for semantic segmentation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (4), pp. 640-651. , Apr; Gundogdu, E., Alatan, A.A., Good features to correlate for visual tracking (2018) IEEE Trans. Image Process., 27 (5), pp. 2526-2540. , May; (2018), http://www.votchallenge.net/challenges.html, VOT Challenges. Accessed: Jul. 31; Nam, H., Han, B., Learning multi-domain convolutional neural networks for visual tracking (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 4293-4302; Bertinetto, L., Valmadre, J., Henriques, J.F., Vedaldi, A., Torr, P.H., Fully convolutional Siamese networks for object tracking (2016) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 850-865; Danelljan, M., Robinson, A., Khan, F.S., Felsberg, M., Beyond correlation filters: Learning continuous convolution operators for visual tracking (2016) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 472-488; Danelljan, M., Bhat, G., Khan, F.S., Felsberg, M., ECO: Efficient convolution operators for tracking (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 6638-6646; Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. IEEE, 105 (12), pp. 2295-2329. , Dec; Keckler, S.W., Dally, W.J., Khailany, B., Garland, M., Glasco, D., GPUs and the future of parallel computing (2011) IEEE Micro, 31 (5), pp. 7-17. , Sep./Oct; (2018), https://www.nvidia.com/enus/autonomous-machines/embedded-systems-dev-kits-modules/, NVIDIA Jetson. The Embedded Platform for Autonomous Everything. Accessed: Jul. 31; García-Lesta, D., López, P., Brea, V.M., Cabello, D., In-pixel analog memories for a pixel-based background subtraction algorithm on CMOS vision sensors (2018) Int. J. Circuit Theory Appl., 46 (9), pp. 1631-1647; Held, D., Thrun, S., Savarese, S., Learning to track at 100 f/s with deep regression networks (2016) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 749-765; (2018), https://citius.usc.es/investigacion/datasets/detrusc, dETRUSC Video Dataset. Accessed: Jul. 31; Nurvitadhi, E., Can FPGAS beat GPUs in accelerating nextgeneration deep neural networks? (2017) Proc. ACM/SIGDA Int. Symp. Field Program. Gate Arrays (FPGA), pp. 5-14; Guo, K., Angel-eye: A complete design flow for mapping CNN onto embedded FPGA (2018) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 37 (1), pp. 35-47. , Jan; Gokhale, V., Jin, J., Dundar, A., Martini, B., Culurciello, E., A 240 G-ops/s mobile coprocessor for deep neural networks (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 682-687; Qiu, J., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proc. ACM/SIGDA Int. Symp. Field Program. Gate Arrays (FPGA), pp. 26-35; Shah, N., Chaudhari, P., Varghese, K., Runtime programmable and memory bandwidth optimized FPGA-based coprocessor for deep convolutional neural network (2018) IEEE Trans. Neural Netw. Learn. Syst., 29 (12), pp. 5922-5934. , Dec; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.-S., Optimizing the convolution operation to accelerate deep neural networks on FPGA (2018) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 26 (7), pp. 1354-1367. , Jul; Wang, C., DLAU: A scalable deep learning accelerator unit on FPGA (2017) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 36 (3), pp. 513-517. , Mar; Zhang, C., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc. ACM/SIGDA Int. Symp. Field Program. Gate Arrays, pp. 161-170; Qiao, Y., FPGA-accelerated deep convolutional neural networks for high throughput and energy efficiency (2017) Concurrency Comput. Pract. Exp., 29 (20); Bettoni, M., Urgese, G., Kobayashi, Y., Macii, E., Acquaviva, A., A convolutional neural network fully implemented on FPGA for embedded platforms (2017) Proc. New Gener. CAS (NGCAS), pp. 49-52; Chen, Y.-H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2017) IEEE J. Solid-State Circuits, 52 (1), pp. 127-138. , Jan; Bang, S., 1.47 A 288μW programmable deep-learning processor with 270KB on-chip weight storage using non-uniform memory hierarchy for mobile intelligence (2017) Proc. IEEE Int. Solid-State Circuits Conf. (ISSCC), pp. 250-251; Du, Z., An accelerator for high efficient vision processing (2017) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 36 (2), pp. 227-240. , Feb; (2018), https://ark.intel.com/products/95831/Intel-Xeon-Phi-Processor-7290F-16GB-1_50-GHz-72-core, Intel Xeon Phi Processor 7290F. Accessed: Jul. 31; (2018), https://ark.intel.com/products/128690/Intel-Xeon-Phi-Processor-7295-16GB-1_5-GHz-72-Core, Intel Xeon Phi Processor 7295. Accessed: Jul. 31; (2018), https://www.nvidia.com/en-us/deep-learning-ai/developer/, Deep Learning AI Developer. Accessed: Jul. 31; (2018), https://code.facebook.com/posts/1687861518126048/facebook-to-open-source-ai-hardware-design/, Facebook to Open-Source AI Hardware Design. Accessed: Jul. 31; (2018), https://code.facebook.com/posts/1835166200089399/introducing-big-basin-our-next-generation-aihardware/, Introducing Big Basin: Our Next-Generation AI Hardware. Accessed: Jul. 31; Hofmann, M., Tiefenbacher, P., Rigoll, G., Background segmentation with feedback: The pixel-based adaptive segmenter (2012) Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 38-43; Suárez, M., Low-power CMOS vision sensor for Gaussian pyramid extraction (2017) IEEE J. Solid-State Circuits, 52 (2), pp. 483-495. , Feb; Kristan, M., The visual object tracking VOT2014 challenge results (2014) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 191-217; Jia, Y., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. ACM Multimedia Syst. Conf., pp. 675-678; Wu, Y., Lim, J., Yang, M.-H., Online object tracking: A benchmark (2013) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2411-2418; (2018), https://motchallenge.net/, The Multiple Object Tracking Challenge. Accessed: Jul. 31; Henschel, R., Cremers, L.L.-T.D., Rosenhahn, B., Fusion of head and full-body detectors for multi-object tracking (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1541-1550; Sze, V., Chen, Y.-H., Emer, J., Suleiman, A., Zhang, Z., Hardware for machine learning: Challenges and opportunities (2017) Proc. IEEE Custom Integr. Circuits Conf. (CICC) 2016. A Multi-Cut Formulation for Joint Segmentation and Tracking of Multiple Objects, 45, pp. 1-9. , https://arxiv.org/abs/1607.06317; Goyette, N., Jodoin, P.-M., Porikli, F., Konrad, J., Ishwar, P., Changedetection.net: A new change detection benchmark dataset (2012) Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 1-8; Kristan, M., The visual object tracking VOT2017 challenge results (2017) Proc. Int. Conf. Comput. Vis. (ICCV), pp. 1949-1972; Hanhirova, J., Latency and throughput characterization of convolutional neural networks for mobile computer vision (2018) Proc. ACM Multimedia Syst. Conf., pp. 204-215; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (6), pp. 1137-1149. , Jun; Dai, J., Li, Y., He, K., Sun, J., R-FCN: Object detection via regionbased fully convolutional networks (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 379-387","Blanco-Filgueira, B.; Centro Singular de Investigación en Tecnoloxías da Información, Spain; email: blancofilgueira@edu.xunta.es",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,23274662,,,,"English","IEEE Internet Things J.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85067882071
"Locharla G.R., Pogiri R.","57185790300;57209475498;","Hardware accelerator design approach for CNN-based low power applications",2019,"International Journal of Innovative Technology and Exploring Engineering","8","7",,"2061","2065",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067872760&partnerID=40&md5=8ce573ce0a5636fc90197f21fcae7966","Department of ECE, GMR Institute of Technology, Rajam, AP  532127, India; Department of ECE, Sri Venkateswara College of Engineering, Etcherla, Srikakulam, AP, India; JNTU, Kakinada, India; Department of VLSI System design, National Institute of Technology, Trichy, India; National Institute of Technology, Roukela, India; Department of Digital Electronics and Communication Systems, JNTU, Kakinada, India","Locharla, G.R., Department of ECE, GMR Institute of Technology, Rajam, AP  532127, India, JNTU, Kakinada, India, Department of VLSI System design, National Institute of Technology, Trichy, India, National Institute of Technology, Roukela, India; Pogiri, R., Department of ECE, Sri Venkateswara College of Engineering, Etcherla, Srikakulam, AP, India, Department of Digital Electronics and Communication Systems, JNTU, Kakinada, India","Field Programmable Gate Array (FPGA) based CNN accelerator is getting popular due to its high performance at lower power requirements. Since the convolution process requires the huge number of the multiply and accumulate (MAC) operations it costs more amount of area and power. In this paper, a generalized pipelined architecture for the CNN model is reported and the functionality of the key elements is quantitatively presented. This pipelined architecture employs the limited number of functional units and schedules the operation over the more number of clock cycles. This pipelined approach helps in achieving lesser hardware complexity, therefore, lesser power and area requirements at the cost of speed. The architecture presented in this paper can be customized for given CNN model by configuring Image size, Kernel sizes, Kernel buffer, pooling and activation type, etc. Finally, the hardware requirements of CNN architecture for LeNet-5 is reported as a case study and analyzed. © BEIESP.","ASIC; CNN; FPGA; GPU; LeNet; MAC",,,,,,,,,,,,,,,,,"Farabet, C., Poulet, C., Han, J.Y., Lecun, Y., CNP: An FPGA-based Processor for Convolutional Networks (2009) Proc. Field Programmable Logic and Applications, IEEE, pp. 32-37; Improving Photo Search: A Step across the Semantic Gap, , http://googleresearch.blogspot.com/2013/06/improving-photo-search-step-across.html; Holi, J.L., Hwang, J.-N., Finite precision error analysis of neural network hardware implementations (1993) IEEE Trans. Comput, 42 (3), pp. 281-290; Larochelle, H., Erhan, D., Courville, A., Bergstra, J., Bengio, Y., An Empirical Evaluation of Deep Architectures on Problems with Many Factors of Variation (2007) Proc. the 24Th Intern. Conf. on Machine Learning-07, pp. 473-480. , New York, ACM; Sankaradas, M., Jakkula, V., Cadambi, S., Chakradhar, S., Durdanovic, I., Cosatto, E., Graf, H.P., A Massively Parallel Coprocessor for Convolutional Neural Networks (2009) Proc. 20Th IEEE International Conference on Application-Specific Systems, Architectures and Processors, pp. 53-60; https://www.electronicspecifier.com/artificial-intelligence/cnn-hardware-accelerator-brings-improved-performance; Oskouei, S.S.L., “GPU-based Acceleration of Deep Convolutional Neural Networks on Mobile Platforms (2015) Distrib. Parallel Clust. Comput; Aysegul, D., Jonghoon, J., Vinayak, G., Bharadwaj, K., Alfredo, C., Berin, M., Eugenio, C., Accelerating Deep Neural Networks on Mobile Processor with Embedded Programmable Logic (2013) Proc. NIPS, , IEEE; Jung, S., Kim, S.S., Hardware Implementation of a Real-time Neural Network Controller with a DSP and an FPGA for Nonlinear Systems (2007) IEEE Trans. Ind. Informat, 54 (1), pp. 265-271; Chakradhar, S., Sankaradas, M., Jakkula, V., Cadambi, S., A Dynamically Configurable Coprocessor for Convolutional Neural Networks (2010) ACM SIGARCH Computer Architecture News, 38, pp. 247-257; Peemen, M., Memory-Centric Accelerator Design for Convolutional Neural Networks Proc. 31St International Conference on Computer Design (ICCD), pp. 13-19. , IEEE; Lindsey, C., Lindblad, T., “Review of Hardware Neural Networks: A Users Perspective (1994) Proc. 3Rd Workshop Neural Netw, pp. 26-30; Zhu, J., Sutton, P., “FPGA Implementations of Neural Networks-A Survey of a Decade of Progress (2003) Proc. 13Th Int. Conf. Field-Program. Logic Appl, pp. 1062-1066; Dias, F., Antunes, A., Mota, A., Artificial Neural Networks: A Review of Commercial Hardware (2004) Eng. Appl. Artif. Intell, 17, pp. 945-952; Boser, B.E., Sackinger, E., Bromley, J., Le Cun, Y., Jackel, L.D., An Analog Neural Network Processor with Programmable Topology (1991) IEEE J. Solid-State Circuits, 26 (12), pp. 2017-2025; Maeda, Y., Tada, T., FPGA Implementation of a Pulse Density Neural Network with Learning Ability Using Simultaneous Perturbation (2003) IEEE Trans. Neural Netw, 14 (3), pp. 688-695; Oh, K., Jung, K., GPU Implementation of Neural Networks (2004) Pattern Recognit, 37, pp. 1311-1314; Kim, M., Smaragdis, P., “Bitwise Neural Networks (2015) Proc. Int. Conf. Mach. Learn, pp. 6-11; Du, L., A Reconfigurable Streaming Deep Convolutional Neural Network Accelerator for Internet of Things (2018) IEEE Transactions on Circuits and Systems I: Regular Papers, 65 (1), pp. 198-208",,,,"Blue Eyes Intelligence Engineering and Sciences Publication",,,,,22783075,,,,"English","Int. J. Innov. Technol. Explor. Eng.",Article,"Final","",Scopus,2-s2.0-85067872760
"Eckert C., Wang X., Wang J., Subramaniyan A., Iyer R., Sylvester D., Blaauw D., Das R.","57191579162;57204516183;56412076200;56690072600;17434769300;7005550123;7006597968;22833936700;","Neural Cache: Bit-Serial In-Cache Acceleration of Deep Neural Networks",2019,"IEEE Micro","39","3","8676265","11","19",,5,"10.1109/MM.2019.2908101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063906560&doi=10.1109%2fMM.2019.2908101&partnerID=40&md5=84e8821e5bd488ead3b2a52749b02bf1","Department of Computer Science and Engineering, University of Michigan, United States; Intel Corporation, United States","Eckert, C., Department of Computer Science and Engineering, University of Michigan, United States; Wang, X., Department of Computer Science and Engineering, University of Michigan, United States; Wang, J., Department of Computer Science and Engineering, University of Michigan, United States; Subramaniyan, A., Department of Computer Science and Engineering, University of Michigan, United States; Iyer, R., Intel Corporation, United States; Sylvester, D., Department of Computer Science and Engineering, University of Michigan, United States; Blaauw, D., Department of Computer Science and Engineering, University of Michigan, United States; Das, R., Department of Computer Science and Engineering, University of Michigan, United States","This article presents Neural Cache architecture, which repurposes cache structures to transform them into massively parallel compute units capable of running inferences for deep neural networks. Techniques to do in situ arithmetic in SRAM arrays create efficient data mapping, and reducing data movement is proposed. Neural Cache architecture is capable of fully executing convolutional, fully connected, and pooling layers in cache. Our experimental results show that the proposed architecture can improve efficiency over a GPU by 128 × while requiring a minimal area overhead of 2%. © 2019 IEEE.",,"Convolution; Flip flop circuits; Network architecture; Static random access storage; Arrays; Cache architecture; Cache structure; Layout; Logic arrays; Massively parallels; Proposed architectures; Random access memory; Deep neural networks",,,,,"National Science Foundation, NSF: CAREER-1652294; Intel Corporation; National Sleep Foundation, NSF","The authors would like to thank members of the M-Bits research group for their feedback. This work was supported in part by the NSF CAREER-1652294 Award and the Intel Gift Award.",,,,,,,,,,"Eckert, C., Neural cache: Bit-serial in-cache acceleration of deep neural networks (2018) Proc. ACM/IEEE 45th Annu. Int. Symp. Comput. Archit., pp. 383-396. , Jun; Wang, J., A compute SRAM with bit-serial integer/floating-point operations for programmable inmemory vector acceleration (2019) Proc. IEEE Int. Solid- State Circuits Conf.; Patterson, D., A case for intelligent RAM (1997) IEEE Micro, 39 (2), pp. 34-44. , Mar./Apr; Seshadri, V., Ambit: In-memory accelerator for bulk bitwise operations using commodity DRAM technology (2017) Proc. 50th Annu. IEEE/ACM Int. Symp. Microarchit., pp. 273-287; Chi, P., PRIME: A novel processing-in-memory architecture for neural network computation in ReRAM-based main memory (2016) Proc. 43rd ACM/IEEE Annu. Int. Symp. Comput. Archit., pp. 27-39. , Seoul, South Korea, Jun. 18-22; Shafiee, A., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Architect., pp. 14-26; Jouppi, N.P., In-datacenter performance analysis of a tensor processing unit (2017) Proc. 44th Annu. Int. Symp. Comput. Archit., pp. 1-12; Aga, S., Jeloka, S., Subramaniyan, A., Narayanasamy, S., Blaauw, D., Das, R., Compute caches (2017) Proc. 23rd Int. Symp.High Perform. Comput. Archit., pp. 481-492; Jeloka, S., Akesh, N.B., Sylvester, D., Blaauw, D., A 28 nm configurable memory (TCAM/BCAM/SRAM) using push-rule 6t bit cell enabling logic-in-memory (2016) IEEE J. Solid-State Circuits, 51 (4), pp. 1009-1021. , Apr; Huang, M., Mehalel, M., Arvapalli, R., He, S., An energy efficient 32-nm 20-mb shared on-die L3 cache for Intel® Xeon® processor E5 family (2013) J. Solid-State Circuits, 48 (8), pp. 1954-1962; Chung, E., Accelerating persistent neural networks at datacenter scale (2017) Proc. Hot Chips: A Symp. High Perform. Chips; Srivastava, P., Promise: An end-to-end design of a programmable mixed-signal accelerator for machine-learning algorithms (2018) Proc. 45th Annu. Int. Symp. Comput. Archit., pp. 43-56. , https://doi.org/10.1109/ISCA.2018.00015, [Online]",,,,"IEEE Computer Society",,,,,02721732,,IEMID,,"English","IEEE Micro",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85063906560
"Lee S., Lee J.","35092639900;57209268867;","Compressed learning of deep neural networks for OpenCL-capable embedded systems",2019,"Applied Sciences (Switzerland)","9","8","1669","","",,1,"10.3390/app9081669","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067106643&doi=10.3390%2fapp9081669&partnerID=40&md5=fb662a13d2c71886c17bcb101bb464cb","Computer Science, Hanyang University ERICA, Ansan, 15588, South Korea; Computer Science and Engineering, Hanyang University ERICA, Ansan, 15588, South Korea","Lee, S., Computer Science, Hanyang University ERICA, Ansan, 15588, South Korea; Lee, J., Computer Science and Engineering, Hanyang University ERICA, Ansan, 15588, South Korea","Deep neural networks (DNNs) have been quite successful in solving many complex learning problems. However, DNNs tend to have a large number of learning parameters, leading to a large memory and computation requirement. In this paper, we propose a model compression framework for efficient training and inference of deep neural networks on embedded systems. Our framework provides data structures and kernels for OpenCL-based parallel forward and backward computation in a compressed form. In particular, our method learns sparse representations of parameters using ℓ1-based sparse coding while training, storing them in compressed sparse matrices. Unlike the previous works, our method does not require a pre-trained model as an input and therefore can be more versatile for different application environments. Even though the use of ℓ1-based sparse coding for model compression is not new, we show that it can be far more effective than previously reported when we use proximal point algorithms and the technique of debiasing. Our experiments show that our method can produce minimal learning models suitable for small embedded devices. © 2019 by the authors.","Compressed learning; Debiasing; Embedded systems; OpenCL; Proximal point algorithm; Regularization",,,,,,"Hanyang University, HYU: HY-2017-N","Funding: This work was supported by the research fund of Hanyang University (HY-2017-N).",,,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet Classification with Deep Convolutional Neural Networks (2012) Advances in Neural Information Processing Systems 25, pp. 1097-1105. , Curran Associates, Inc.: New York, NY, USA; Graves, A., Schmidhuber, J., Framewise phoneme classification with bidirectional LSTM and other neural network architectures (2005) Neural Netw, 18, pp. 5-6; Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., Kuksa, P., Natural Language Processing (Almost) from Scratch (2011) J. Mach. Learn. Res, 12, pp. 2493-2537; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86, pp. 2278-2324; Simonyan, K., Zisserman, A., Very Deep Convolutional Networks for Large-Scale Image Recognition (2015) Proceedings of the International Conference on Learning Representations, , San Diego, CA, USA, 7-9 May; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going Deeper with Convolutions (2015) Proceedings of the Computer Vision and Pattern Recognition (CVPR), , Boston, MA, USA, 7-12 June; Zeiler, M.D., Fergus, R., Visualizing and Understanding Convolutional Networks (2014) Proceedings of the Computer Vision (ECCV 2014), pp. 818-833. , Zurich, Switzerland, 6-12 September; Ioffe, S., Szegedy, C., Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (2015) Proceedings of the 32nd International Conference on Machine Learning, pp. 448-456. , Lille, France, 6-11 July; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the Inception Architecture for Computer Vision (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2818-02826. , Las Vegas, NV, USA, 26 June-1 July; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning (2017) Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, pp. 4278-4284. , San Francisco, CA, USA, 4-9 February; He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , Las Vegas, NV, USA, 27-30 June; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., DeepFace: Closing the Gap to Human-Level Performance in Face Verification (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Columbus, OH, USA, 23-28 June; Coates, A., Huval, B., Wang, T., Wu, D., Catanzaro, B., Andrew, N., Deep learning with COTS HPC systems (2013) Proceedings of the 30th International Conference on Machine Learning, pp. 1337-1345. , Atlanta, GA, USA, 16-21 June; Lawrence, S., Giles, C.L., Tsoi, A.C., Lessons in Neural Network Training: Overfitting May be Harder than Expected (1997) Proceedings of the Fourtheenth National Conference on Artificial Intelligence (AAAI'97), , Providence, RI, USA, 27-31 July; Buyya, R., Yeo, C.S., Venugopal, S., Broberg, J., Brandic, I., Cloud Computing and Emerging IT Platforms: Vision, Hype, and Reality for Delivering Computing As the 5th Utility (2009) Future Gener. Comput. Syst, 25, pp. 599-616; Jaderberg, M., Vedaldi, A., Zisserman, A., Speeding up Convolutional Neural Networks with Low Rank Expansions (2014) Proceedings of the British Machine Vision Conference, , Nottingham, UK, 1-5 September; Denton, E., Zaremba, W., Bruna, J., LeCun, Y., Fergus, R., Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation (2014) Advances in Neural Information Processing Systems 27, pp. 1269-1277. , Curran Associates, Inc.: New York, NY, USA; Ioannou, Y., Robertson, D.P., Shotton, J., Cipolla, R., Criminisi, A., Training cnns with low-rank filters for efficient image classification (2016) Proceedings of the International Conference on Learning Representations, , San Juan, PR, USA, 2-4 May; Tai, C., Xiao, T., Wang, X.E.W., Convolutional neural networks with low-rank regularization (2016) Proceedings of the International Conference on Learning Representations, , San Juan, PR, USA, 2-4 May; Hanson, S.J., Pratt, L.Y., Comparing Biases for Minimal Network Construction with Back-Propagation (1989) Advances in Neural Information Processing Systems 1, pp. 177-185. , Morgan-Kaufmann: Burlington, MA, USA; LeCun, Y., Denker, J.S., Solla, S.A., Optimal Brain Damage (1990) Advances in Neural Information Processing Systems 2, pp. 598-605. , Morgan-Kaufmann: Burlington, MA, USA; Hassibi, B., Stork, D.G., Second order derivatives for network pruning: Optimal Brain Surgeon (1993) Advances in Neural Information Processing Systems 5, pp. 164-171. , Morgan-Kaufmann: Burlington, MA, USA; Han, S., Pool, J., Tran, J., Dally, W.J., Learning BothWeights and Connections for Efficient Neural Networks (2015) Advances in Neural Information Processing Systems 28, pp. 1135-1143. , Curran Associates, Inc.: New York, NY, USA; Han, S., Mao, H., Dally, W.J., Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding (2016) Proceedings of the International Conference on Learning Representations, , San Juan, PR, USA, 2-4 May; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning Structured Sparsity in Deep Neural Networks (2016) Proceedings of the 30th International Conference on Neural Information Processing Systems (NIPS'16), pp. 2082-2090. , Barcelona, Spain, 5-10 December; Lebedev, V., Lempitsky, V., Fast ConvNets Using Group-Wise Brain Damage (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2554-2564. , Las Vegas, NV, USA, 27-30 June; Shalev-Shwartz, S., Tewari, A., Stochastic Methods for l1 Regularized Loss Minimization (2009) Proceedings of the 26th International Conference on Machine Learning (ICML), pp. 929-936. , Montreal, QC, Canada, 14-18 June; Duchi, J.C., Singer, Y., Efficient Learning using Forward-Backward Splitting (2009) Advances in Neural Information Processing Systems 22, pp. 495-503. , Curran Associates, Inc.: New York, NY, USA; Zhou, H., Alvarez, J.M., Porikli, F., Less Is More: Towards Compact CNNs (2016) Computer Vision (ECCV 2016), pp. 662-677. , Springer: New York, NY, USA; Parikh, N., Boyd, S., Proximal Algorithms (2014) Found. Trends Optim, 1, pp. 127-239; Hinton, G., CSC321 (2014) Introduction to Neural Networks and Machine Learning; Lecture 6e.; Toronto University: Toronto, ON, Canada, February; Kingma, D.P., Ba, J.L., Adam: A Method for Stochastic Optimization (2015) Proceedings of the International Conference on Learning Representations, , San Diego, CA, USA, 7-9 May; Carreira-Perpiñán, M.á., Idelbayev, Y., Learning-Compression Algorithms for Neural Net Pruning (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), , Salt Lake City, UT, USA, 18-22 June; Hestenes, M.R., Multiplier and gradient methods (1969) J. Optim. Theory Appl, 4, pp. 303-320; Powell, M.J.D., A method for nonlinear constraints in minimization problems (1969) Optimization, pp. 283-298. , Fletcher, R., Ed.; Academic Press: New York, NY, USA; Chen, C., Tung, F., Vedula, N., Mori, G., Constraint-Aware Deep Neural Network Compression (2018) Proceedings of the European Conference on Computer Vision (ECCV),Munich, , Germany, 8-14 September; Zoph, B., Le, Q.V., (2016) Neural Architecture Search with Reinforcement Learning, , arXiv; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., (2017) Learning Transferable Architectures for Scalable Image Recognition, , arXiv; He, Y., Lin, J., Liu, Z., Wang, H., Li, L.J., Han, S., AMC: AutoML for Model Compression and Acceleration on Mobile Devices (2018) Proceedings of the European Conference on Computer Vision (ECCV), , Munich, Germany, 8-14 September; Cheng, Y., Wang, D., Zhou, P., Zhang, T., Model Compression and Acceleration for Deep Neural Networks: The Principles, Progress, and Challenges (2018) IEEE Signal Process. Mag, 35, pp. 126-136; Lee, H., Battle, A., Raina, R., Ng, A.Y., Efficient sparse coding algorithms (2007) Advances in Neural Information Processing Systems 19, pp. 801-808. , MIT Press: Cambridge, MA, USA; Needell, D., Tropp, J., CoSaMP: Iterative signal recovery from incomplete and inaccurate samples (2009) Appl. Comput. Harmon. Anal, 26, pp. 301-321; Bao, C., Ji, H., Quan, Y., Shen, Z., Dictionary Learning for Sparse Coding: Algorithms and Convergence Analysis (2016) IEEE Trans. Pattern Anal. Mach. Intell, 38, pp. 1356-1369; Tibshirani, R., Regression Shrinkage and Selection via the Lasso (1996) J. R. Stat. Soc. (Ser. B), 58, pp. 267-288; Candes, E., Tao, T., The Dantzig Selector: Statistical Estimation When P Is Much Larger Than N (2007) Ann. Stat, 35, pp. 2313-2351; Candes, E.J., Tao, T., Decoding by linear programming (2005) IEEE Trans. Inf. Theory, 51, pp. 4203-4215; Donoho, D.L., Compressed sensing (2006) IEEE Trans. Inf. Theory, 52, pp. 1289-1306; Candes, E., Plan, Y., Matrix Completion with Noise (2010) Proc. IEEE, 98, pp. 925-936; Nemirovski, A., Juditsky, A., Lan, G., Shapiro, A., Robust Stochastic Approximation Approach to Stochastic Programming (2009) SIAM J. Optim, 19, pp. 1574-1609; Duchi, J., Hazan, E., Singer, Y., Adaptive Subgradient Methods for Online Learning and Stochastic Optimization (2011) J. Mach. Learn. Res, 12, pp. 2121-2159; Lee, S., Wright, S., Manifold Identification of Dual Averaging Methods for Regularized Stochastic Online Learning (2011) Proceedings of the 28th International Conference on Machine Learning (ICML), pp. 1121-1128. , Bellevue,WA, USA, 28 June-2 July; Auslender, A., Teboulle, M., Interior Gradient and Proximal Methods for Convex and Conic Optimization (2006) SIAM J. Optim, 16, pp. 697-725; Nitanda, A., Stochastic Proximal Gradient Descent with Acceleration Techniques (2014) Advances in Neural Information Processing Systems 27, pp. 1574-1582. , Curran Associates, Inc.: New York, NY, USA; Patrascu, A., Necoara, I., Nonasymptotic convergence of stochastic proximal point methods for constrained convex optimization (2018) J. Mach. Learn. Res, 18, pp. 1-42; Rosasco, L., Villa, S., Vu, B.C., (2014) Convergence of Stochastic Proximal Gradient Algorithm; Polyak, B.T., Somemethods of speeding up the convergence of iterationmethod.USSR Comput (1964) Math. Math. Phys, 4, pp. 1-17; Wright, S.J., Nowak, R.D., Figueiredo, M.A.T., Sparse reconstruction by separable approximation (2009) IEEE Trans. Signal Process, 57, pp. 2479-2493; Figueiredo, M., Nowak, R., Wright, S., Gradient projection for sparse reconstruction: application to compressed sensing and other inverse problems (2007) IEEE J. Sel. Top. Signal Process, 1, pp. 586-598; Donoho, D., De-noising by soft thresholding (1995) IEEE Trans. Inf. Theory, 41, pp. 6-18; https://github.com/amd/OpenCL-caffe, (accessed on 31 August 2018); Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding, , arXiv; http://viennacl.sourceforge.net, (accessed on 31 August 2018); Bell, N., Garland, M., (2008) Efficient Sparse Matrix-Vector Multiplication on CUDA, , NVIDIA Technical Report NVR-2008-004; NVIDIA Corporation: Santa Clara, CA, USA; Bell, N., Garland, M., Implementing Sparse Matrix-vector Multiplication on Throughput-oriented Processors (2009) In Proceedings of the Conference on High Performance Computing Networking, 18, pp. 1-11. , Storage and Analysis, Portland, OR, USA, 14-20 November; Krizhevsky, A., (2009) Learning Multiple Layers of Features from Tiny Images, , Technical Report; University of Toronto: Toronto, ON, Canada; He, K., Zhang, X., Ren, S., Sun, J., Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification (2015) Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV '15), pp. 1026-1034. , Santiago, Chile, 11-18 December","Lee, S.; Computer Science, South Korea; email: sangkyun@hanyang.ac.kr",,,"MDPI AG",,,,,20763417,,,,"English","Appl. Sci.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85067106643
"Moon H., Huo Y., Abramson R.G., Peters R.A., Assad A., Moyo T.K., Savona M.R., Landman B.A.","57204243708;56830058500;55218605000;7401442416;57193204561;36574155800;13103585500;16679175200;","Acceleration of spleen segmentation with end-to-end deep learning method and automated pipeline",2019,"Computers in Biology and Medicine","107",,,"109","117",,9,"10.1016/j.compbiomed.2019.01.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061774398&doi=10.1016%2fj.compbiomed.2019.01.018&partnerID=40&md5=3f2aebbd99d0a0f565e34ccbc9a62ecb","Department of Electrical Engineering, Vanderbilt University, 2301 Vanderbilt Pl, Nashville, TN  37235, United States; Department of Medicine, 250 25th Ave N, Suite 412, Nashville, TN  37203, United States; Vanderbilt University Institute of Imaging Science, 161 21st Avenue South, Nashville, TN  37232, United States; Incyte Corporation, 1801 Augustine Cut Off, Wilmington, DE  19803, United States; Vanderbilt Institute for Clinical and Translational Research, 2525 West End Ave, Nashville, TN  37235, United States; Vanderbilt-Ingram Cancer Center, 2220 Pierce Ave, Nashville, TN  37232, United States","Moon, H., Department of Electrical Engineering, Vanderbilt University, 2301 Vanderbilt Pl, Nashville, TN  37235, United States; Huo, Y., Department of Electrical Engineering, Vanderbilt University, 2301 Vanderbilt Pl, Nashville, TN  37235, United States; Abramson, R.G., Vanderbilt University Institute of Imaging Science, 161 21st Avenue South, Nashville, TN  37232, United States, Vanderbilt-Ingram Cancer Center, 2220 Pierce Ave, Nashville, TN  37232, United States; Peters, R.A., Department of Electrical Engineering, Vanderbilt University, 2301 Vanderbilt Pl, Nashville, TN  37235, United States; Assad, A., Incyte Corporation, 1801 Augustine Cut Off, Wilmington, DE  19803, United States; Moyo, T.K., Department of Medicine, 250 25th Ave N, Suite 412, Nashville, TN  37203, United States; Savona, M.R., Department of Medicine, 250 25th Ave N, Suite 412, Nashville, TN  37203, United States, Vanderbilt Institute for Clinical and Translational Research, 2525 West End Ave, Nashville, TN  37235, United States; Landman, B.A., Department of Electrical Engineering, Vanderbilt University, 2301 Vanderbilt Pl, Nashville, TN  37235, United States, Vanderbilt University Institute of Imaging Science, 161 21st Avenue South, Nashville, TN  37232, United States","Delineation of Computed Tomography (CT) abdominal anatomical structure, specifically spleen segmentation, is useful for not only measuring tissue volume and biomarkers but also for monitoring interventions. Recently, segmentation algorithms using deep learning have been widely used to reduce time humans spend to label CT data. However, the computerized segmentation has two major difficulties: managing intermediate results (e.g., resampled scans, 2D sliced image for deep learning), and setting up the system environments and packages for autonomous execution. To overcome these issues, we propose an automated pipeline for the abdominal spleen segmentation. This pipeline provides an end-to-end synthesized process that allows users to avoid installing any packages and to deal with the intermediate results locally. The pipeline has three major stages: pre-processing of input data, segmentation of spleen using deep learning, 3D reconstruction with the generated labels by matching the segmentation results with the original image dimensions, which can then be used later and for display or demonstration. Given the same volume scan, the approach described here takes about 50 s on average whereas the manual segmentation takes about 30 min on the average. Even if it includes all subsidiary processes such as preprocessing and necessary setups, the whole pipeline process requires on the average 20 min from beginning to end. © 2019","Clinical trial; Deep learning; DICOM; Docker; End-to-end automation; Image processing; Spleen segmentation","Automation; Computerized tomography; Data handling; Image processing; Image segmentation; Learning systems; Pipeline processing systems; Pipelines; Clinical trial; DICOM; Docker; End to end; Spleen segmentations; Deep learning; acceleration; article; automation; deep learning; digital imaging and communications in medicine; human; image processing; pipeline; spleen; algorithm; diagnostic imaging; procedures; spleen; three-dimensional imaging; time factor; x-ray computed tomography; Algorithms; Deep Learning; Humans; Imaging, Three-Dimensional; Spleen; Time Factors; Tomography, X-Ray Computed",,,,,"NIH Office of the Director, OD: S10OD020154; National Cancer Institute, NCI: P30CA068485; National Institute of Biomedical Imaging and Bioengineering, NIBIB: R01EB017230; National Center for Research Resources, NCRR: UL1RR024975; National Center for Advancing Translational Sciences, NCATS: UL1TR000445",,,,,,,,,,,"Bezerra, A.S., Determination of splenomegaly by CT: is there a place for a single measurement? (2005) Am. J. Roentgenol., 184 (5), pp. 1510-1513; Sharma, N., Aggarwal, L.M., Automated medical image segmentation techniques (2010) Journal of medical physics/Association of Medical Physicists of India, 35 (1), p. 3; Rosenkrantz, A.B., Clinical utility of quantitative imaging (2015) Acad. Radiol., 22 (1), pp. 33-49; Abramson, R.G., Methods and challenges in quantitative imaging biomarker development (2015) Acad. Radiol., 22 (1), pp. 25-32; Fred, H.L., Drawbacks and limitations of computed tomography: views from a medical educator (2004) Tex. Heart Inst. J., 31 (4), p. 345; Paley, M.R., Ros, P.R., Imaging of spleen disorders (2002) The Complete Spleen, pp. 259-280. , Springer; Redmond, H., Surgical anatomy of the human spleen (1989) Br. J. Surg., 76 (2), pp. 198-201; Linguraru, M.G., Assessing splenomegaly: automated volumetric analysis of the spleen (2013) Acad. Radiol., 20 (6), pp. 675-684; Yetter, E.M., Estimating splenic volume: sonographic measurements correlated with helical CT determination (2003) Am. J. Roentgenol., 181 (6), pp. 1615-1620; Huo, Y., Splenomegaly segmentation using global convolutional kernels and conditional generative adversarial networks (2018) Medical Imaging 2018: Image Processing, , International Society for Optics and Photonics; Gil, J.Y., Kimmel, R., Efficient dilation, erosion, opening, and closing algorithms (2002) IEEE Trans. Pattern Anal. Mach. Intell., 24 (12), pp. 1606-1617; Guenette, J.P., Automated versus manual segmentation of brain region volumes in former football players (2018) Neuroimage: clinical, 18, pp. 888-896; Ji, S., 3D convolutional neural networks for human action recognition (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (1), pp. 221-231; Merkel, D., Docker: lightweight Linux containers for consistent development and deployment (2014) Linux J., 2014 (239), p. 2; Cox, R.W., A (sort of) new image data format standard: nifti-1 (2004) Neuroimage, 22, p. e1440; Huo, Y., Robust multicontrast MRI spleen segmentation for splenomegaly using multi-atlas segmentation (2018) IEEE (Inst. Electr. Electron. Eng.) Trans. Biomed. Eng., 65 (2), pp. 336-343; Huo, Y., Adversarial synthesis learning enables segmentation without target modality ground truth (2018) Biomedical Imaging (ISBI 2018), 2018 IEEE 15th International Symposium on, , IEEE; Eichelberg, M., Onken, M., Thiel, A., OFFIS DCMTK-DICOM Toolkit (2014); Harrigan, R.L., Vanderbilt university institute of imaging science center for computational imaging XNAT: a multimodal data archive and processing environment (2016) Neuroimage, 124, pp. 1097-1101; Alshipli, M., Kabir, N.A., Effect of slice thickness on image noise and diagnostic content of single-source-dual energy computed tomography (2017) J. Phys. Conf., p. 851; Yung, K.T., Atlas‐based automated positioning of outer volume suppression slices in short‐echo time 3D MR spectroscopic imaging of the human brain (2011) Magn. Reson. Med., 66 (4), pp. 911-922; Huo, Y., Simultaneous total intracranial volume and posterior fossa volume estimation using multi‐atlas label fusion (2017) Hum. Brain Mapp., 38 (2), pp. 599-616; Szegedy, C., I (2017) nception-v4, Inception-Resnet and the Impact of Residual Connections on Learning, , AAAI; Serra, J., Image Analysis and Mathematical Morphology (1983), Academic Press, Inc; Eaton, H.A., Olivier, T.L., Learning coefficient dependence on training set size (1992) Neural Network., 5 (2), pp. 283-288; https://clinicaltrials.gov/ct2/show/NCT02493530, TGR-1202 + Ruxolitinib PMF PPV-MF PET-MF MDS/MPN Polycythemia Vera Resistant to Hydroxyurea","Moon, H.; Department of Electrical Engineering, 2301 Vanderbilt Pl, United States; email: hyeonsoo.moon@lgcns.com",,,"Elsevier Ltd",,,,,00104825,,CBMDA,"30798219","English","Comput. Biol. Med.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85061774398
"Yin S., Tang S., Lin X., Ouyang P., Tu F., Liu L., Wei S.","8376913500;57221028177;57191877390;55178121000;56938143800;8880228100;7401765431;","A High Throughput Acceleration for Hybrid Neural Networks with Efficient Resource Management on FPGA",2019,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","38","4","8328868","678","691",,19,"10.1109/TCAD.2018.2821561","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044737461&doi=10.1109%2fTCAD.2018.2821561&partnerID=40&md5=a4aee2ac92bc67a989a95f0ba0a8e78d","Institute of Microelectronics, Tsinghua University, Beijing, 100084, China","Yin, S., Institute of Microelectronics, Tsinghua University, Beijing, 100084, China; Tang, S., Institute of Microelectronics, Tsinghua University, Beijing, 100084, China; Lin, X., Institute of Microelectronics, Tsinghua University, Beijing, 100084, China; Ouyang, P., Institute of Microelectronics, Tsinghua University, Beijing, 100084, China; Tu, F., Institute of Microelectronics, Tsinghua University, Beijing, 100084, China; Liu, L., Institute of Microelectronics, Tsinghua University, Beijing, 100084, China; Wei, S., Institute of Microelectronics, Tsinghua University, Beijing, 100084, China","Deep learning is the amazing technology which has promoted the development of artificial intelligence and achieved many amazing successes in intelligent fields. Convolution-based layers (CLs), fully connected layers (FLs) and recurrent layers (RLs) are three types of layers in classic neural networks. Most intelligent tasks are implemented by the hybrid neural networks (hybrid-NNs), which are commonly composed of different layer-blocks (LBs) of CLs, FLs, and RLs. Because the CLs require the most computation in hybrid-NNs, many field-programmable gate array (FPGA)-based accelerators focus on CLs acceleration and have demonstrated great performance. However, the CLs accelerators lead to an underutilization of FPGA resources in the acceleration of the whole hybrid-NN. To fully exploit the logic resources and the memory bandwidth in the acceleration of CLs/FLs/RLs, we propose an FPGA resource efficient mapping mechanism for hybrid-NNs. The mechanism first improves the utilization of DSPs by integrating multiple small bit-width operations on one DSP. Then the LB-level spatial mapping is used to exploit the complementary features between different neural networks in the hybrid-NN. We evaluate the mapping mechanism by implementing four hybrid-NNs on Xilinx Virtex7 690T FPGA. The proposed mechanism achieves a peak performance of 1805.8 giga operations per second (GOPs). With the analysis on resource utilization and throughput, the proposed method exploits more computing power in FPGA and achieves up to 4.13 × higher throughput than the state-of-the-art acceleration. © 1982-2012 IEEE.","Field-programmable gate array (FPGA)-based accelerators; hybrid neural networks (hybrid-NNs); resource efficient mapping","Acceleration; Bandwidth; Computation theory; Convolution; Deep learning; Engines; Field programmable gate arrays (FPGA); Linear accelerators; Mapping; Neural networks; Quantization (signal); Throughput; Complementary features; Fully-connected layers; Hybrid neural networks; Intelligent fields; Mapping mechanism; Resource management; Resource utilizations; Resource-efficient; Recurrent neural networks",,,,,"2013ZX01033001-001-003; 2015AA016601; National Natural Science Foundation of China, NSFC: 61774094","Manuscript received October 19, 2017; revised February 23, 2018; accepted March 24, 2018. Date of publication March 30, 2018; date of current version March 19, 2019. This work was supported in part by NSFC under Grant 61774094, in part by the China National High Technologies Research Program under Grant 2015AA016601, and in part by the China Major S&T Project under Grant 2013ZX01033001-001-003. This paper was recommended by Associate Editor Y. Wang. (Corresponding author: Shaojun Wei.) The authors are with the Institute of Microelectronics, Tsinghua University, Beijing 100084, China (e-mail: wsj@tsinghua.edu.cn).",,,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst. (NIPS), pp. 1097-1105; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) CoRR, pp. 1-14. , http://arxiv.org/abs/1409.1556, Sep; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2015) CoRR, pp. 770-778. , http://arxiv.org/abs/1512.03385, Dec; Donahue, J., Long-term recurrent convolutional networks for visual recognition and description (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 2625-2634; Sainath, T.N., Vinyals, O., Senior, A., Sak, H., Convolutional, long short-term memory, fully connected deep neural networks (2015) Proc. IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), Brisbane, QLD, Australia, pp. 4580-4584; Wu, Z., Sivadas, S., Tan, Y.K., Bin, M., Goh, R.S.M., Multi-modal hybrid deep neural network for speech enhancement (2016) ArXiv: Learning, pp. 1-5; Fernando, C., PathNet: Evolution channels gradient descent in super neural networks (2017) CoRR, pp. 1-16. , http://arxiv.org/abs/1701.08734, Jan; Jouppi, N.P., In-datacenter performance analysis of a tensor processing unit (2017) Proc. Int. Symp. Comput. Architect. (ISCA), Toronto, ON, Canada, pp. 1-12; Zhang, C., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc. ACM Int. Symp. Field Program. Gate Arrays (FPGA), Monterey, CA, USA, pp. 161-170; Farabet, C., Poulet, C., Han, J.Y., LeCun, Y., CNP: An FPGAbased processor for convolutional networks (2009) Proc. IEEE Int. Conf. Field Program. Logic Appl. (FPGA), Prague, Czech Republic, pp. 32-37; Peemen, M., Setio, A.A.A., Mesman, B., Corporaal, H., Memorycentric accelerator design for convolutional neural networks (2013) Proc. IEEE Int. Conf. Comput. Design (ICCD), Asheville, NC, USA, pp. 13-19; Shen, Y., Ferdman, M., Milder, P., Overcoming resource underutilization in spatial CNN accelerators (2016) Proc. Int. Conf. Field Program. Logic Appl. (FPL), Lausanne, Switzerland, pp. 1-4; Cadambi, S., Majumdar, A., Becchi, M., Chakradhar, S., Graf, H.P., A programmable parallel accelerator for learning and classification (2010) Proc. Int. Conf. Parallel Architect. Compilation Techn. (PACT), Vienna, Austria, pp. 273-284; Ovtcharov, K., Accelerating deep convolutional neural networks using specialized hardware (2015) Microsoft Res. Whitepaper, 2 (11), pp. 1-4. , Feb; Rahman, A., Lee, J., Choi, K., Efficient FPGA acceleration of convolutional neural networks using logical-3D compute array (2016) Proc. IEEE Design Autom. Test Europe Conf. Exhibit. (DATE), Dresden, Germany, pp. 1393-1398; Zhang, C., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: Towards uniformed representation and acceleration for deep convolutional neural networks (2016) Proc. IEEE Int. Conf. Comput.-Aided Design (ICCAD), Austin, TX, USA, pp. 1-8; Suda, N., Throughput-optimized openCL-based FPGA accelerator for large-scale convolutional neural networks (2016) Proc. Int. Symp. Field Program. Gate Arrays (FPGA), Monterey, CA, USA, pp. 16-25; Gong, Y., Liu, L., Yang, M., Bourdev, L., Compressing deep convolutional networks using vector quantization (2014) CoRR, pp. 1-10. , http://arxiv.org/abs/1412.6115, Dec; Müller, L.K., Indiveri, G., Rounding methods for neural networks with low resolution synaptic weights (2015) CoRR, pp. 1-11. , http://arxiv.org/abs/1504.05767, Apr; Gysel, P., Ristretto: Hardware-oriented approximation of convolutional neural networks (2016) CoRR, pp. 1-63. , http://arxiv.org/abs/1605.06402, May; Jia, Y., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. ACM Multimedia, pp. 675-678; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Chakradhar, S., Sankaradas, M., Jakkula, V., Cadambi, S., A dynamically configurable coprocessor for convolutional neural networks (2010) Proc. Int. Symp. Comput. Architect. (ISCA), Saint-Malo, France, pp. 247-257; Qiu, J., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proc. ACM Int. Symp. Field Program. Gate Arrays (FPGA), Monterey, CA, USA, pp. 26-35; Williams, S., Waterman, A., Patterson, D., Roofline: An insightful visual performance model for multicore architectures (2009) Commun. ACM, 52 (4), pp. 65-76. , Apr; Wu, J., Leng, C., Wang, Y., Hu, Q., Cheng, J., Quantized convolutional neural networks for mobile devices (2016) Proc. Comput. Vis. Pattern Recognit., pp. 4820-4828; (2011) 7 Series DSP48E1 Slice User Guide, , UG479(v1.1), Xilinx, San Jose, CA, USA Mar","Wei, S.; Institute of Microelectronics, China; email: wsj@tsinghua.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Final","",Scopus,2-s2.0-85044737461
"Pilly P.K., Stepp N.D., Liapis Y., Payton D.W., Srinivasa N.","24081408000;24340253600;57194771065;6701696834;56028528300;","Hypercolumn sparsification for low-power convolutional neural networks",2019,"ACM Journal on Emerging Technologies in Computing Systems","15","2","20","","",,3,"10.1145/3304104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063950676&doi=10.1145%2f3304104&partnerID=40&md5=6a9203995b0965d5f3bb7e9fda2ad9a3","Center for Autonomy Computing, Information and Systems Sciences Laboratory, HRL Laboratories, LLC, Malibu, CA  90265, United States; Enthought, Inc., Austin, TX  78701, United States; Eta Compute, Westlake Village, CA  91362, United States","Pilly, P.K., Center for Autonomy Computing, Information and Systems Sciences Laboratory, HRL Laboratories, LLC, Malibu, CA  90265, United States; Stepp, N.D., Center for Autonomy Computing, Information and Systems Sciences Laboratory, HRL Laboratories, LLC, Malibu, CA  90265, United States; Liapis, Y., Enthought, Inc., Austin, TX  78701, United States; Payton, D.W., Center for Autonomy Computing, Information and Systems Sciences Laboratory, HRL Laboratories, LLC, Malibu, CA  90265, United States; Srinivasa, N., Eta Compute, Westlake Village, CA  91362, United States","We provide here a novel method, called hypercolumn sparsification, to achieve high recognition performance for convolutional neural networks (CNNs) despite low-precision weights and activities during both training and test phases. This method is applicable to any CNN architecture that operates on signal patterns (e.g., audio, image, video) to extract information such as class membership. It operates on the stack of feature maps in each of the cascading feature matching and pooling layers through the processing hierarchy of the CNN by an explicit competitive process (k-WTA, winner take all) that generates a sparse feature vector at each spatial location. This principle is inspired by local brain circuits, where neurons tuned to respond to different patterns in the incoming signals from an upstream region inhibit each other using interneurons, such that only the ones that are maximally activated survive the quenching threshold. We show this process of sparsification is critical for probabilistic learning of low-precision weights and bias terms, thereby making pattern recognition amenable for energy-efficient hardware implementations. Further, we show that hypercolumn sparsification could lead to more data-efficient learning as well as having an emergent property of significantly pruning down the number of connections in the network. A theoretical account and empirical analysis are provided to understand these effects better. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Convolutional neural networks; Embedded systems; Low energy; Low precision; Machine learning; Object recognition; Quantization; Sparse","Brain; Convolution; Embedded systems; Energy efficiency; Learning systems; Neural networks; Neurons; Object recognition; Convolutional neural network; Low energy; Low precision; Quantization; Sparse; Low power electronics",,,,,"Defense Advanced Research Projects Agency, DARPA: HR0011-13-C-0052","This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under contract No. HR0011-13-C-0052. The views expressed are those of the author and do not reflect the official policy or position of the Department of Defense or the U.S. Government. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of DARPA.",,,,,,,,,,"Courbariaux, M., Bengio, Y., David, J.-P., (2014) Training Deep Neural Networks With Low Precision Multiplications, , 2014; Courbariaux, M., Bengio, Y., David, J.-P., (2015) BinaryConnect: Training Deep Neural Networks With Binary Weights During Propagations, , 2015; Cover, T.M., Thomas, J.A., (2012) Elements of Information Theory, , John Wiley & Sons, New York, NY; Duda, R.O., Hart, P.E., Stork, D.G., (1973) Pattern Classification, 2. , Wiley Press, New York, NY; Ferster, D., Miller, K.D., Neural mechanisms of orientation selectivity in the visual cortex (2000) Annu. Rev. Neurosci., 23 (1), pp. 441-471. , 2000; Graham, B., (2013) Sparse Arrays of Signatures for Online Character Recognition, , 2013; Graham, B., (2014) Spatially-sparse Convolutional Neural Networks, , 2014; He, K., Zhang, X., Ren, S., Sun, J., Deepresidual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , (2016); Hoehfeld, M., Fahlman, S.E., Learning with limited numerical precision using the cascade-correlation algorithm (1992) IEEE Trans. Neur. Netw., 3 (4), pp. 602-611. , 1992; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., (2016) Quantized Neural Networks: Training Neural Networks With Low Precision Weights and Activations, , (2016); Kasturi, R., Goldgof, D.B., Ekambaram, R., Pratt, G., Krotkov, E., Hackett, D.D., Ran, Y., Anderson, M., Performance evaluation of neuromorphic-vision object recognition algorithms (2014) Proceedings of the International Conference on Pattern Recognition, pp. 2401-2406. , 2014; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105. , 2012; Liu, B., Wang, M., Foroosh, H., Tappen, M., Pensky, M., Sparse convolutional neural networks (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 806-814. , (2015); Mairal, J., Bach, F., Ponce, J., Sapiro, G., Online dictionary learning for sparse coding (2009) Proceedings of the International Conference on Machine Learning, pp. 689-696. , (2009); Makhzani, A., Frey, B., (2014) K-sparse Autoencoders, , (2014); Masci, J., Meier, U., Cireşan, D., Schmidhuber, J., Stacked convolutional auto-encoders for hierarchical feature extraction (2011) Proceedings of the International Conference on Artificial Neural Networks, pp. 52-59. , (2011); Miyashita, D., Lee, E.H., Murmann, B., (2016) Convolutional Neural Networks Using Logarithmic Data Representation, , (2016); Mutch, J., Lowe, D.G., Multiclass object recognition with sparse, localized features (2006) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 11-18. , (2006); Mutch, J., Lowe, D.G., Object class recognition and localization using sparse features with limited receptive fields (2008) Int. J. Comput. Vis., 80 (1), pp. 45-57. , 2008; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., (2016) XNOR-Net: Imagenet Classification Using Binary Convolutional Neural Networks, , (2016); Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., (2014) ImageNet Large Scale Visual Recognition Challenge, , (2014); Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y., (2013) Overfeat: Integrated Recognition, Localization and Detection Using Convolutional Networks, , (2013); Serre, T., Oliva, A., Poggio, T., A feedforward architecture accounts for rapid categorization (2007) Proc. Natl. Acad. Sci. U.S.A., 104 (15), pp. 6424-6429. , 2007; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning structured sparsityin deep neural networks (2016) Advances in Neural Information Processing Systems, pp. 2074-2082. , (2016); Wong, S.C., Stamatescu, V., Gatt, A., Kearney, D., Lee, I., McDonnell, M.D., (2017) Track Everything: Limiting Prior Knowledge in Online Multi-object Recognition, , (2017); Zhou, S., Ni, Z., Zhou, X., Wen, H., Wu, Y., Zou, Y., (2016) Training Low Bitwidth Convolutional Neural Networks With Low Bitwidth Gradients, , (2016)",,,,"Association for Computing Machinery",,,,,15504832,,,,"English","ACM J. Emerg. Technologies Comput. Syst.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85063950676
"Ghanavati B., Abiri E., Salehi M.R., Azhdari N.","24483225200;24463314100;7006812587;57202158540;","A low-power high-linear time-to-digital converter for measuring r-r intervals in ECG signal optimized by neural network and tlbo algorithm",2019,"Journal of Circuits, Systems and Computers","28","2","1950021","","",,1,"10.1142/S021812661950021X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047323351&doi=10.1142%2fS021812661950021X&partnerID=40&md5=78b7baa25412add752cf7580d18a60b1","Department of Electrical Engineering, Shiraz University of Technology, Shiraz, Iran","Ghanavati, B., Department of Electrical Engineering, Shiraz University of Technology, Shiraz, Iran; Abiri, E., Department of Electrical Engineering, Shiraz University of Technology, Shiraz, Iran; Salehi, M.R., Department of Electrical Engineering, Shiraz University of Technology, Shiraz, Iran; Azhdari, N., Department of Electrical Engineering, Shiraz University of Technology, Shiraz, Iran","In this paper, a two-stage time interpolation time-to-digital converter (TDC) is proposed to achieve adequate resolution and wide dynamic range for measuring R-R intervals in QRS detection. The architecture is based on a coarse counter and a couple of two-stage interpolator circuit in order to improve the conversion linearity. The proposed TDC is modeled with the neural network, while the teacher-learner-based optimization algorithm (TLBO) is used to optimize the integral nonlinearity (INL) of the proposed TDC. The proposed optimization method shows a characteristic close to the ideal output of the TDC behavior over a wide input range. Using the achieved results of the TLBO algorithm simulation results using CADENCE VIRTUOSO and standard 180nm CMOS technology shows 1.2s dynamic range, 100ns resolution, 0.19mW power consumption and area of 0.16mm2. The proposed circuit can find application in biomedical engineering systems and other fields where long and accurate time interval measurement is needed. © 2019 World Scientific Publishing Company.","Bio-medical circuit; Neural network; R-r interval measurement; Time interpolator tdc; Time-to-digital converter (tdc); Tlbo; Wide dynamic range","Biomedical engineering; Interpolation; Low power electronics; Neural networks; Signal processing; Teaching; Bio-medical; RR intervals; time interpolator TDC; Time to digital converters; TLBO; Wide dynamic range; Frequency converters",,,,,,,,,,,,,,,,"Ko, C.-T., Punn, K.-P., Gothenberg, A., A 5-ps vernIer sub-rangIng tIme-to-dIgItal converter with dnl calIbratIon (2015) MIcroelectron. J, 46, pp. 1469-1480; Guo, J., Sonkusale, S., A 22-bIt 110ps tIme-Interpolated tIme-to-dIgItal converter (2012) IEEE Int. Symp. CIrcuIts and Systems (ISCAS), pp. 3166-3169. , Seoul, South Korea, May; Cheng, Z., Deen, M.J., Peng, H., A low-power gateable vernIer rIng oscIllator tIme-todIgItal converter for bIomedIcal ImagIng applIcatIons (2015) IEEE Trans. BIomed. CIrcuIts Syst, 10 (2), pp. 445-454; Zhang, X.-J., Cui, K.-J., Zou, Z., Zheng, L.-R., A low-power coarse-fIne tIme-to-dIgItal converter in 65nm CMOS (2015) Int. Symp. SIgnals, CIrcuIts and Systems (ISSCS), pp. 1-4. , IasI, Romania, July; Keränen, P., Kostamovaara, J., A wIde range, 4.2 ps(rms) precIsIon CMOS tdc with cyclIc Interpolators based on swItched-frequency rIng oscIllators (2015) IEEE TransactIons on CIrcuIts and Systems, 62 (12), pp. 2795-2805; Markovic, B., Tisa, S., Villa, F.A., Tosi, A., Zappa, F., A hIgh-lInearIty 17 ps precIsIon tIme-to-dIgItal converter based on a sIngle-stage vernIer delay loop fIne InterpolatIon (2013) IEEE Trans CIrcuIts Syst, 60, pp. 557-569; Kanoun, M., Arpin, L., Rheaume, V.-P., Tétreault, M.-A., A 10-bIt 3 psrms precIsIon tImeto-dIgItal converter for dI®use optIcal tomography measurements 21st (2014) IEEE Int. Conf. ElectronIcs, CIrcuIts and Systems, pp. 554-557. , ICECS MarseIlle, France, December; Mino, K., Shin, W.-Y., Hong, G.-M., Park, J., Chae, J.-H., Xing, N., Woo, J.-K., Kim, S., HIgh-resolutIon and wIde-dynamIc range tIme-to-dIgItal converter with a multI-phase cyclIc VernIer delay lIne (2013) Proc. European SolId-State CIrcuIts Conf. (ESSCIRC), pp. 311-314. , September; Liu, S., Zheng, Y., A low-power and hIghly lInear 14-bIt parallel samplIng tdc with power gatIng and dem in 65-nm CMOS (2015) IEEE Trans. Very Large Scale Integr. (VLSI) Syst, 24 (3), pp. 1083-1091; Zhu, Z., Bai, W., A 0.5v 1.3 μw analog front-end CMOS cIrcuIt (2016) IEEE Trans. CIrcuIts Syst. II Exp. BrIefs, 63, pp. 253-257; Zanuso, M., Levantino, S., Puggelli, A., Samori, C., Lacaita, A.L., Tdc with 3-ps resolutIon and dIgItal lInearIzatIon algorIthm (2010) Proc. European SolId-State CIrcuIts Conf, pp. 262-265. , SevIlle, Spain, Sep; Zhaoxin, M., Xuefei, B., Lu, H., DesIgn of a delay-locked-loop-based tIme-to-dIgItal converter (2013) J. SemIcond, 34 (9), pp. 1-7; Yu, J., Dai, F.F., Jaeger, R.C., A 12-bIt vernIer rIng tIme-to-dIgItal converter in 0.13 μm CMOS technology (2010) IEEE J. SolId-State CIrcuIts, 45, pp. 830-842; Liu, Y., Vollenbruch, U., Chen, Y., Wicpalek, C., Maurer, L., Boos, Z., Weigel, R., MultIstage pulse shrInkIng tIme-to-dIgItal converter for tIme Interval measurements (2007) Proc. 2nd European MIcrowave Integrated CIrcuIts Conf, pp. 347-350. , October; Mäntyniemi, A., Rahkonen, T., Kostamovaara, J., A CMOS tIme-to-dIgItal converter (tdc) based on a cyclIc tIme domaIn successIve approxImatIon InterpolatIon method (2009) IEEE J. SolId-State CIrcuIts, 44, pp. 3067-3078; Lee, S.-K., Seo, Y.-H., Park, H.-J., Sim, J.-Y., A 1 GHz adpll with a 1.25 ps mInImumresolutIon sub-exponent tdc in 0.18 μm CMOS (2010) IEEE J. SolId-State CIrcuIts, 45, pp. 482-483; Uemori, S., Ishii, M., Kobayashi, H., Doi, Y., Kobayashi, O., Matsuura, T., Niitsu, K., Hirabayashi, D., MultI-bIt sIgma-delta tdc archItecture for dIgItal sIgnal tImIng measurement (2012) IEEE 18th Int. MIxed-SIgnal, Sensors, and Systems Test Workshop, pp. 62-72. , May; Kim, K.S., Yu, W.S., Cho, S.H., A 9 bIt, 1.12 ps resolutIon 2.5 b/stage pIpelIned tImeto-dIgItal converter in 65nm CMOS usIng tIme-regIster (2014) IEEE J. SolId-State CIrcuIts, 49, pp. 1007-1016; Yu, W., Kim, K.S., Cho, S.H., A 148fsrms Integrated noIse 4MHz bandwIdth alldIgItal second-order δ tIme-to-dIgItal converter usIng gated swItched-rIng oscIllator (2013) IEEE Custom Integrated CIrcuIts Conf. (CICC), pp. 1-4. , San Jose, CA, USA, September; Andersson, O., Chon, K.H., Sornmo, L., Rodrigues, J.N., A 290mv sub-vt ASIC for real-tIme atrIal fIbrIllatIon detectIon (2015) IEEE Trans. BIomed. CIrcuIts Syst, 9, pp. 377-386; Gish, H., Pierce, J., AsymptotIcally e±cIent quantIzIng (1968) IEEE Trans. Inf. Theory, 14, pp. 676-683; Boger, Z., Guterman, H., Knowledge extractIon from artIfIcIal neural network models (1997) IEEE Systems, Man, and CybernetIcs Conf, 4, pp. 3030-3035. , Orlando, FL, USA; Ghanavati, B., Abiri, E., Salehi, M.R., A hIgh-accurate exponentIal functIon generator based on a new pseudo-approxImatIon method by tlbo optImIzatIon algorIthm, cIrcuIts syst (2018) SIgnal Process, 37 (4), pp. 1407-1421; Chen, W., Papavassiliou, C., A low power 10-bIt tIme-to-dIgItal converter utIlIzIng vernIer delay lInes, 15th InternatIonal conf (2013) Computer ModellIng and SImulatIon, pp. 774-779. , Cambridge, AprIl; Atef, M., El-Nozahi, M., Hegazi, E., A second-order noIse-shapIng tIme-to-dIgItal converter usIng swItched-rIng oscIllator (2015) IEEE Int. Symp. CIrcuIts and Systems (ISCAS), pp. 1822-1825. , LIsbon, May; Park, Y.J., Yuan, F., A 12.88 ms/s 0.28 pj/conv.step 8-bitstage-interleaved pulseshrinking time-to-digital converter in 130nm CMOS (2015) IEEE 58th Int. MIdwest Symp. CIrcuIts and Systems (MWSCAS), pp. 1-4. , Fort CollIns, August","Ghanavati, B.; Department of Electrical Engineering, Iran; email: b.ghanavati@sutech.ac.ir",,,"World Scientific Publishing Co. Pte Ltd",,,,,02181266,,JCSME,,"English","J. Circuits Syst. Comput.",Article,"Final","",Scopus,2-s2.0-85047323351
"Huang H.-C., Lin S.-K.","24597566600;57205679871;","A Hybrid Metaheuristic Embedded System for Intelligent Vehicles Using Hypermutated Firefly Algorithm Optimized Radial Basis Function Neural Network",2019,"IEEE Transactions on Industrial Informatics","15","2","8267134","1062","1069",,24,"10.1109/TII.2018.2796556","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040988603&doi=10.1109%2fTII.2018.2796556&partnerID=40&md5=ef7251183e03e51eb55bb44e8503b17f","Department of Electrical Engineering, National Ilan University, Yilan, 260, Taiwan","Huang, H.-C., Department of Electrical Engineering, National Ilan University, Yilan, 260, Taiwan; Lin, S.-K., Department of Electrical Engineering, National Ilan University, Yilan, 260, Taiwan","This paper presents a hybrid metaheuristic embedded system for intelligent vehicles using hypermutated firefly algorithm (FA)-optimized radial basis function neural network (RBFNN), called FA-RBFNN. With the Mecanum vehicle's dynamic model, the FA with hypermutation is fused with RBFNN to develop a real-time optimal controller of the four-wheeled Mecanum vehicles in a field-programmable gate array (FPGA) chip. This hybrid metaheuristics takes the benefits of neural network, FA, real-time control, and FPGA realization. All the FA-RBFNN, dynamic controller, and hardware circuits are implemented in one FPGA chip using System-on-a-Programmable Chip methodology. Comparative works and experimental results clearly illustrate that the proposed FPGA-based FA-RBFNN optimal controller outperforms the conventional control methods. © 2005-2012 IEEE.","Metaheuristic; neural network; optimization; redundant control","Artificial intelligence; Bioluminescence; Controllers; Embedded systems; Field programmable gate arrays (FPGA); Functions; Hybrid vehicles; Intelligent robots; Intelligent vehicle highway systems; Logic gates; Mobile robots; Mobile telecommunication systems; Neural networks; Radial basis function networks; Real time control; Signal receivers; Metaheuristic; Mobile communications; Radial basis function neural networks; Redundant controllers; Redundant controls; Service robots; System on a programmable chips; Traditional approaches; Optimization",,,,,,,,,,,,,,,,"Tsai, C.C., Huang, H.C., Lin, S.C., FPGA-based parallel DNA algorithm for optimal configurations of an omnidirectional mobile service robot performing fire extinguishment (2011) IEEE Trans. Ind. Electron., 58 (3), pp. 1016-1026. , Mar; Dong, W., Zhou, M., Gaussian classifier-based evolutionary strategy for multimodal optimization (2014) IEEE Trans. Neural Netw. Learn. Syst., 25 (6), pp. 1200-1216. , Jun; Gong, Y.J., Shan, M., Zhang, J., Kaynak, O., Chen, W.N., Zhan, Z.H., Optimizing RFID network planning by using a particle swarm optimization algorithm with redundant reader elimination (2012) IEEE Trans. Ind. Informat., 8 (4), pp. 900-912. , Nov; Goharimanesh, M., Lashkaripour, A., Shariatnia, S., Akbari, A., Diabetic control using genetic fuzzy-PI controller (2014) Int. J. Fuzzy Syst., 16 (2), pp. 133-138; Yilmaz, S., Kucuksille, E.U., A new modification approach on bat algorithm for solving optimization problems (2015) Appl. Soft Comput., 28, pp. 259-275; Sharma, D., Chatterjee, A., Rakshit, A., A hybrid approach for design of stable adaptive fuzzy controllers employing Lyapunov theory and particle swarm optimization (2009) IEEE Trans. Fuzzy Syst., 17 (2), pp. 329-342. , Apr; Juang, C.F., Chang, Y.C., Evolutionary group-based particle swarmoptimized fuzzy controller with application to mobile robot navigation in unknown environments (2011) IEEE Trans. Fuzzy Syst., 19 (2), pp. 379-392. , Apr; Ghamisi, P., Feature selection based on hybridization of genetic algorithm and particle swarm optimization (2015) IEEE Geosci. Remote Sens. Lett., 12 (2), pp. 309-313. , Feb; Yang, X.S., Firefly algorithm, stochastic test functions and design optimisation (2010) Int. J. Bio-Inspired Comput., 2 (2), pp. 78-84; Fister, I., Fister, I., Jr., Yang, X.S., Brest, J., A comprehensive review of firefly algorithms (2013) Swarm Evol. Comput., 13, pp. 34-46; Darwish, S.M., Combining firefly algorithm and Bayesian classifier: New direction for automatic multilabel image annotation (2016) IET Image Process., 10 (10), pp. 763-772; Mishra, A., Nagesh, V., Gundavarapu, K., Bathina, V.R., Duvvada, D.C., Real power performance index and line stability index-based management of contingency using firefly algorithm (2016) IET Gener., Transmiss. Distrib., 10 (10), pp. 2327-2335; Su, H., Yong, B., Du, Q., Hyperspectral band selection using improved firefly algorithm (2016) IEEE Geosci. Remote Sens. Lett., 13 (1), pp. 68-72. , Jan; Klausen, A., Tordal, S.S., Karimi, H.R., Robbersmyr, K.G., Jecmenica, M., Melteig, O., Firefly optimization and mathematical modeling of a vehicle crash test based on single-mass (2014) J. Appl. Math., 2014, pp. 1-10; Broomhead, D.S., Lowe, D., Multivariable functional interpolation and adptive networks (1988) Complex Syst., 2, pp. 321-355; Khosravi, H., A novel structure for radial basis function networks-WRBF (2012) Neural Process. Lett., 35, pp. 177-186; Zapateiro, M., Luo, N., Karimi, H.R., Veh, J., Vibration control of a class of semiactive suspension system using neural network and backstepping techniques (2009) Mech. Syst. Signal Process., 23 (6), pp. 1946-1953; Kao, Y., Shi, L., Xieand, J., Karimi, H.R., Global exponential stability of delayed markovian jump fuzzy cellular neural networks with generally incomplete transition probability (2015) Neural Netw., 63, pp. 18-30; Dong, F., Lei, X., Chou, W., The adaptive radial basis function neural network for small rotary-wing unmanned aircraft (2014) IEEE Trans. Ind. Electron., 61 (9), pp. 4808-4815. , Sep; Gutiérrez, P.A., Hervas-Martinez, C., Martnez-Estudillo, F.J., Logistic regression by means of evolutionary radial basis function neural networks (2011) IEEE Trans. Neural Netw., 22 (2), pp. 246-263. , Feb; Karimi, H.R., Gao, H., New delay-dependent exponential H-; Synchronization for uncertain neural networks with mixed time delays (2010) IEEE Trans. Syst., Man, Cybern., B, Cybern., 40 (1), pp. 173-185. , Feb; Lin, L.C., Shih, H.Y., Modeling and adaptive control of an omni-Mecanum-wheeled robot (2013) Intell. Control Autom., 4, pp. 166-179; Han, K.L., Kim, H., Lee, J.S., The sources of position errors of omni-directional mobile robot with Mecanum wheel (2010) Proc. IEEE Int. Conf. Syst., Man Cybern., pp. 581-586; Siegwart, R., Nourbakhsh, I.R., Scaramuzza, D., (2011) Introduction to Autonomous Mobile Robots, , 2nd ed. London, U. K. : MIT Press; Fahmizal, Kuo, C.H., Development of a fuzzy logic wall following controller for steering mobile robots (2013) Proc. Int. Conf. Fuzzy Theory Appl., pp. 7-12; Park, J., Kim, S., Kim, J., Kim, S., Driving control of mobile robot with mecanum wheel using fuzzy inference system (2010) Proc. Int. Conf. Control, Autom. Syst., pp. 2519-2523; Tsai, C.C., Kuo, C.Z., Chan, C.C., Wang, X.C., Global path planning and navigation of an omnidirectional mecanum mobile robot (2013) Proc. CACS Int. Autom. Control Conf., pp. 85-90; Huang, H.C., FPGA-based hybrid GA-PSO algorithm and its application to global path planning for mobile robots (2012) Przeglad Elektrotechniczny (Elect. Rev.), 7, pp. 281-284. , Jul; Hamouda, M., Blanchette, H.F., Haddad, F., Fnaiech, F., An efficient DSP-FPGA-based real-time implementation method of SVM algorithms for an indirect matrix converter (2011) IEEE Trans. Ind. Electron., 58 (11), pp. 5024-5031. , Nov; Martinez, A., Ramos, A., Compean, I., Avila, R., Message concealment system of voice signals implemented on FPGA (2016) IEEE Latin Amer. Trans., 14 (8), pp. 3554-3559; Hany, M., Design optimization of PID controller in automatic voltage regulator system using taguchi combined genetic algorithmmethod (2013) IEEE Syst. J., 7 (4), pp. 825-831; Tsai, C.C., Huang, H.C., Chan, C.K., Parallel elite genetic algorithm and its application to global path planning for autonomous robot navigation (2011) IEEE Trans. Ind. Electron., 58 (10), pp. 4813-4821. , Oct; Hasanien, H.M., Design optimization of PID controller in automatic voltage regulator system using taguchi combined genetic algorithm method (2013) IEEE Syst. J., 7 (4), pp. 825-831. , Dec; Tang, Y., Xing, X., Karimi, H.R., Kocarev, L., Kurths, J., Tracking control of networked multi-agent systems under new characterizations of impulses and its applications in robotic systems (2016) IEEE Trans. Ind. Electron., 63 (2), pp. 1299-1307. , Feb; Karimi, H.R., Optimal vibration control of vehicle engine-body system using Haar functions (2006) Int. J. Control, Autom., Syst., 4 (6), pp. 714-724. , Dec","Huang, H.-C.; Department of Electrical Engineering, Taiwan; email: hchuang@niu.edu.tw",,,"IEEE Computer Society",,,,,15513203,,,,"English","IEEE Trans. Ind. Inf.",Article,"Final","",Scopus,2-s2.0-85040988603
"Zhang Q., Zhang M., Chen T., Sun Z., Ma Y., Yu B.","57206521211;55903835600;57112829000;57195412638;57198591067;54939654000;","Recent advances in convolutional neural network acceleration",2019,"Neurocomputing","323",,,"37","51",,130,"10.1016/j.neucom.2018.09.038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055032561&doi=10.1016%2fj.neucom.2018.09.038&partnerID=40&md5=3974d330a0ce54638239842193330118","National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, China; Department of Computer Science & Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong","Zhang, Q., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, China; Zhang, M., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, China; Chen, T., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, China, Department of Computer Science & Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Sun, Z., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, China; Ma, Y., Department of Computer Science & Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Yu, B., Department of Computer Science & Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong","In recent years, convolutional neural networks (CNNs) have shown great performance in various fields such as image classification, pattern recognition, and multi-media compression. Two of the feature properties, local connectivity and weight sharing, can reduce the number of parameters and increase processing speed during training and inference. However, as the dimension of data becomes higher and the CNN architecture becomes more complicated, the end-to-end approach or the combined manner of CNN is computationally intensive, which becomes limitation to CNN's further implementation. Therefore, it is necessary and urgent to implement CNN in a faster way. In this paper, we first summarize the acceleration methods that contribute to but not limited to CNN by reviewing a broad variety of research papers. We propose a taxonomy in terms of three levels, i.e. structure level, algorithm level, and implementation level, for acceleration methods. We also analyze the acceleration methods in terms of CNN architecture compression, algorithm optimization, and hardware-based improvement. At last, we give a discussion on different perspectives of these acceleration and optimization methods within each level. The discussion shows that the methods in each level still have large exploration space. By incorporating such a wide range of disciplines, we expect to provide a comprehensive reference for researchers who are interested in CNN acceleration. © 2018 Elsevier B.V.","Algorithm optimization; Convolutional neural network; Hardware acceleration; Model compression","Acceleration control; Convolution; Hardware; Network architecture; Neural networks; Pattern recognition; Acceleration method; Algorithm optimization; Convolutional neural network; Hardware acceleration; Local connectivity; Model compression; Optimization method; Processing speed; Acceleration; Article; calculation; compression; convolutional neural network; learning algorithm; mathematical computing; nerve cell network; priority journal; process optimization; taxonomy",,,,,"CUHK24209017; SJCX17_0048, SJCX18_0058; National Natural Science Foundation of China, NSFC: 61671148, 61750110529, 61850410535, BK20161147","This research work was partly supported by the Natural Science Foundation of China and Jiangsu (Project no. 61750110529, 61850410535, 61671148 , BK20161147 ), the Research and Innovation Program for Graduate Students in Universities of Jiangsu Province (Grant SJCX17_0048, SJCX18_0058), and the Research Grants Council of Hong Kong SAR (Project no. CUHK24209017).","This research work was partly supported by the Natural Science Foundation of China and Jiangsu (Project no. 61750110529, 61850410535, 61671148, BK20161147), the Research and Innovation Program for Graduate Students in Universities of Jiangsu Province (Grant SJCX17_0048, SJCX18_0058), and the Research Grants Council of Hong Kong SAR (Project no. CUHK24209017).",,,,,,,,,"Yu, S., Jia, S., Xu, C., Convolutional neural networks for hyperspectral image classification (2017) Neurocomputing, 219, pp. 88-98; Farabet, C., Couprie, C., Najman, L., LeCun, Y., Learning hierarchical features for scene labeling (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (8), pp. 1915-1929; Wang, K., Gou, C., Zheng, N., Rehg, J.M., Wang, F.Y., Parallel vision for perception and understanding of complex scenes: methods, framework, and perspectives (2017) Artif. Intell. Rev., 48 (3), pp. 299-329; Qin, P., Xu, W., Guo, J., An empirical convolutional neural network approach for semantic relation classification (2016) Neurocomputing, 190, pp. 1-9; Yu, B., Pan, D.Z., Matsunawa, T., Zeng, X., Machine learning and pattern matching in physical design (2015) Proceedings of the IEEE/ACM Asia and South Pacific Design Automation Conference (ASPDAC), pp. 286-293; Theis, L., Shi, W., Cunningham, A., Huszár, F., Lossy image compression with compressive autoencoders (2017) Proceedings of the International Conference on Learning Representations (ICLR); Zhang, M., Chen, T., Shi, X., Cao, P., Image arbitrary-ratio down-and up-sampling scheme exploiting DCT low frequency components and sparsity in high frequency components (2016) IEICE Trans. Inf. Syst., 99 (2), pp. 475-487; Chen, T., Zhang, M., Wu, J., Yuen, C., Tong, Y., Image encryption and compression based on Kronecker compressed sensing and elementary cellular automata scrambling (2016) Opt. Laser Technol., 84, pp. 118-133; Jothi, J.A.A., Rajam, V.M.A., A survey on automated cancer diagnosis from histopathology images (2017) Artif. Intell. Rev., 48 (1), pp. 31-81; Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Borchers, A., In-data center performance analysis of a tensor processing unit (2017) Proceedings of the IEEE/ACM International Symposium on Computer Architecture (ISCA), pp. 1-12; http://nvdla.org, NVDLA; https://www.intelnervana.com; Guo, Y., Liu, Y., Oerlemans, A., Lao, S., Wu, S., Lew, M.S., Deep learning for visual understanding: a review (2016) Neurocomputing, 187, pp. 27-48; Ghayoumi, M., A quick review of deep learning in facial expression (2017) J. Commun. Comput., 14, pp. 34-38; Carrio, A., Sampedro, C., Rodriguez-Ramos, A., Campoy, P., A review of deep learning methods and applications for unmanned aerial vehicles (2017) J. Sensors, 2017; Zhang, J., Zong, C., Deep neural networks in machine translation: an overview (2015) IEEE Intell. Syst., 30 (5), pp. 16-25; Singh, S.P., Kumar, A., Darbari, H., Singh, L., Rastogi, A., Jain, S., Machine translation using deep learning: an overview (2017) Proceedings of the International Conference on Computer, Communications and Electronics (Comptelix), pp. 162-167; Ling, Z.H., Kang, S.Y., Zen, H., Senior, A., Schuster, M., Qian, X.-J., Meng, H.M., Deng, L., Deep learning for acoustic modeling in parametric speech generation: a systematic review of existing techniques and future trends (2015) IEEE Signal Process. Mag., 32 (3), pp. 35-52; Schmidhuber, J., Deep learning in neural networks: an overview (2015) Neural Netw., 61, pp. 85-117; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Du, X., Cai, Y., Wang, S., Zhang, L., Overview of deep learning (2016) Proceedings of the Youth Academic Annual Conference of Chinese Association of Automation (YAC), pp. 159-164. , IEEE; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the Conference on Neural Information Processing Systems (NIPS), pp. 1097-1105; Lin, M., Chen, Q., Yan, S., (2013), 1312.4400 Network in network, arXiv; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proceedings of the International Conference on Learning Representations (ICLR); He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1-9; Chollet, F., Xception: deep learning with depthwise separable convolutions (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Aloysius, N., Geetha, M., A review on deep convolutional neural networks (2017) Proceedings of the International Conference on Communication and Signal Processing (ICCSP), 2017, pp. 0588-0592. , IEEE; Al-Saffar, A.A.M., Tao, H., Talab, M.A., Review of deep convolution neural network in image classification (2017) Proceedings of the International Conference on Radar, Antenna, Microwave, Electronics, and Telecommunications (ICRAMET), 2017, pp. 26-31. , IEEE; Rawat, W., Wang, Z., Deep convolutional neural networks for image classification: a comprehensive review (2017) Neural Comput., 29 (9), pp. 2352-2449; Bishop, C.M., (2006) Pattern Recognition and Machine Learning, , Springer New York; Nair, V., Hinton, G.E., Rectified linear units improve restricted Boltzmann machines (2010) Proceedings of the International Conference on Machine Learning (ICML), pp. 807-814; Maas, A.L., Hannun, A.Y., Ng, A.Y., Rectifier nonlinearities improve neural network acoustic models (2013) Proceedings of the International Conference on Machine Learning (ICML); He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: surpassing human-level performance on imagenet classification (2015) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 1026-1034; Xu, B., Wang, N., Chen, T., Li, M., Empirical evaluation of rectified activations in convolutional network (2015) Proceedings of the International Conference on Machine Learning Workshop; Clevert, D.-A., Unterthiner, T., Hochreiter, S., Fast and accurate deep network learning by exponential linear units (ELUS) (2016) Proceedings of the International Conference on Learning Representations (ICLR); Sermanet, P., Chintala, S., LeCun, Y., Convolutional neural networks applied to house numbers digit classification (2012) Proceedings of the IEEE International Conference on Pattern Recognition (ICPR), pp. 3288-3291; Zeiler, M.D., Fergus, R., Stochastic pooling for regularization of deep convolutional neural networks (2013) Proceedings of the International Conference on Learning Representations (ICLR); Yu, D., Wang, H., Chen, P., Wei, Z., Mixed pooling for convolutional neural networks (2014) Proceedings of the International Conference on Rough Sets and Knowledge Technology, pp. 364-375. , Springer; He, K., Zhang, X., Ren, S., Sun, J., Spatial pyramid pooling in deep convolutional networks for visual recognition (2015) IEEE Trans. Pattern Anal. Mach. Intell., 37 (9), pp. 1904-1916; Rippel, O., Snoek, J., Adams, R.P., Spectral representations for convolutional neural networks (2015) Proceedings of the Conference on Neural Information Processing Systems (NIPS), pp. 2449-2457; Gong, Y., Wang, L., Guo, R., Lazebnik, S., Multi-scale orderless pooling of deep convolutional activation features (2014) Proceedings of the European Conference on Computer Vision (ECCV), pp. 392-407. , Springer; Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y., Alsaadi, F.E., A survey of deep neural network architectures and their applications (2017) Neurocomputing, 234, pp. 11-26; Denil, M., Shakibi, B., Dinh, L., de Freitas, N., Predicting parameters in deep learning (2013) Proceedings of the Conference on Neural Information Processing Systems (NIPS), pp. 2148-2156; Sainath, T.N., Kingsbury, B., Sindhwani, V., Arisoy, E., Ramabhadran, B., Low-rank matrix factorization for deep neural network training with high-dimensional output targets (2013) Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6655-6659; Jaderberg, M., Vedaldi, A., Zisserman, A., Speeding up convolutional neural networks with low rank expansions (2014) Proceedings of the British Machine Vision Conference (BMVC); Denton, E.L., Zaremba, W., Bruna, J., LeCun, Y., Fergus, R., Exploiting linear structure within convolutional networks for efficient evaluation (2014) Proceedings of the Conference on Neural Information Processing Systems (NIPS), pp. 1269-1277; Lebedev, V., Ganin, Y., Rakhuba, M., Oseledets, I., Lempitsky, V., Speeding-up convolutional neural networks using fine-tuned CP-decomposition (2014) Proceedings of the International Conference on Learning Representations (ICLR); Tai, C., Xiao, T., Zhang, Y., Wang, X., W.E, Convolutional neural networks with low-rank regularization (2016) International Conference on Learning Representations (ICLR); Wang, P., Cheng, J., Accelerating convolutional neural networks for mobile applications (2016) Proceedings of the ACM International Multimedia Conference (MM), pp. 541-545; Kim, Y.-D., Park, E., Yoo, S., Choi, T., Yang, L., Shin, D., Compression of deep convolutional neural networks for fast and low power mobile applications (2016) Proceedings of the International Conference on Learning Representations; Ding, H., Chen, K., Yuan, Y., Cai, M., Sun, L., Liang, S., Huo, Q., A compact CNN-DBLSTM based character model for offline handwriting recognition with tucker decomposition (2017) Proceedings of the IAPR International Conference on Document Analysis and Recognition (ICDAR), 1, pp. 507-512. , IEEE; Le, Q., Sarlós, T., Smola, A., Fastfood-approximating kernel expansions in loglinear time (2013) Proceedings of the International Conference on Machine Learning (ICML), 85; Moczulski, M., Denil, M., Appleyard, J., de Freitas, N., ACDC: a structured efficient linear layer (2016) Proceedings of the International Conference on Learning Representations (ICLR); Ioannou, Y., Robertson, D., Shotton, J., Cipolla, R., Criminisi, A., Training CNNs with low-rank filters for efficient image classification (2016) Proceedings of the International Conference on Learning Representations (ICLR); Wen, W., Xu, C., Wu, C., Wang, Y., Chen, Y., Li, H., Coordinating filters for faster deep neural networks (2017) Proceedings of the IEEE International Conference on Computer Vision (ICCV); Sironi, A., Tekin, B., Rigamonti, R., Lepetit, V., Fua, P., Learning separable filters (2015) IEEE Trans. Pattern Anal. Mach. Intell., 37 (1), pp. 94-106; Zhang, X., Zou, J., He, K., Sun, J., Accelerating very deep convolutional networks for classification and detection (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (10), pp. 1943-1955; Han, S., Mao, H., Dally, W.J., Deep compression: compressing deep neural networks with pruning, trained quantization and Huffman coding (2016) Proceedings of the International Conference on Learning Representations (ICLR); Wang, H., Zhang, Q., Wang, Y., Hu, H., Structured probabilistic pruning for convolutional neural network acceleration (2018) British Machine Vision Conference (BMVC); Zhou, H., Alvarez, J.M., Porikli, F., Less is more: towards compact CNNs (2016) Proceedings of the European Conference on Computer Vision (ECCV), pp. 662-677. , Springer; Mariet, Z., Sra, S., Diversity networks (2016) Proceedings of the International Conference on Learning Representations (ICLR); Polyak, A., Wolf, L., Channel-level acceleration of deep face representations (2015) IEEE Access, 3, pp. 2163-2175; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning structured sparsity in deep neural networks (2016) Proceedings of the Conference on Neural Information Processing Systems (NIPS), pp. 2074-2082; He, Y., Zhang, X., Sun, J., Channel pruning for accelerating very deep neural networks (2017) Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2, p. 6; Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C., Learning efficient convolutional networks through network slimming (2017) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 2755-2763; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning filters for efficient convnets (2017) Proceedings of the International Conference on Learning Representations (ICLR); Vedaldi, A., Lenc, K., Matconvnet: convolutional neural networks for MATLAB (2015) Proceedings of the ACM International Multimedia Conference (MM), pp. 689-692; Oymak, S., Thrampoulidis, C., Hassibi, B., Near-optimal sample complexity bounds for circulant binary embedding (2017) Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6359-6363; Cheng, Y., Yu, F.X., Feris, R.S., Kumar, S., Choudhary, A., Chang, S.F., An exploration of parameter redundancy in deep networks with circulant projections (2015) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 2857-2865; Yang, Z., Moczulski, M., Denil, M., de Freitas, N., Smola, A., Song, L., Wang, Z., Deep fried ConvNets (2015) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 1476-1483; Ding, C., Liao, S., Wang, Y., Li, Z., Liu, N., Zhuo, Y., Wang, C., Yuan, G., CirCNN: accelerating and compressing deep neural networks using block-circulant weight matrices (2017) Proceedings of the IEEE/ACM International Symposium on Microarchitecture (MICRO), pp. 395-408; Caruana, R., Niculescu Mizil, A., Crew, G., Ksikes, A., Ensemble selection from libraries of models (2004) Proceedings of the International Conference on Machine Learning (ICML), p. 18; Bucilu, C., Caruana, R., Niculescu Mizil, A., Model compression (2006) Proceedings of the ACM International Conference on Knowledge Discovery and Data Mining (KDD), pp. 535-541; Xu, Z., Hsu, Y., Huang, J., Training student networks for acceleration with conditional adversarial networks (2018) British Machine Vision Conference (BMVC); Hinton, G., Vinyals, O., Dean, J., (2015), 1503.02531 Distilling the knowledge in a neural network, arXiv; Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y., Fitnets: hints for thin deep nets (2015) Proceedings of the International Conference on Learning Representations (ICLR); Hammerstrom, D., A VLSI architecture for high-performance, low-cost, on-chip learning (1990) Proceedings of the International Joint Conference on Neural Networks (IJCNN), pp. 537-544. , IEEE; Gupta, S., Agrawal, A., Gopalakrishnan, K., Narayanan, P., Deep learning with limited numerical precision. (2015) Proceedings of the International Conference on Machine Learning (ICML), pp. 1737-1746; Courbariaux, M., Bengio, Y., David, J.P., Training deep neural networks with low precision multiplications (2015) Proceedings of the International Conference on Learning Representations (ICLR); Courbariaux, M., Bengio, Y., David, J.P., Binaryconnect: Training deep neural networks with binary weights during propagations (2015) Proceedings of the Conference on Neural Information Processing Systems (NIPS), pp. 3123-3131; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., XNOR-Net: Imagenet classification using binary convolutional neural networks (2016) Proceedings of the European Conference on Computer Vision (ECCV), pp. 525-542. , Springer; Kim, M., Smaragdis, P., Bitwise neural networks (2016) Proceedings of the International Conference on Machine Learning (ICML); Zhou, S., Wu, Y., Ni, Z., Zhou, X., Wen, H., Zou, Y., (2018), 1606.06160 DoReFa-Net: training low bitwidth convolutional neural networks with low bitwidth gradients, arXiv; Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., Bengio, Y., Quantized neural networks: Training neural networks with low precision weights and activations (2017) J. Mach. Learn. Res., 18 (1), pp. 6869-6898; Kim, H., Sim, J., Choi, Y., Kim, L.-S., A kernel decomposition architecture for binary-weight convolutional neural networks (2017) Proceedings of the ACM/IEEE Design Automation Conference (DAC), p. 60; Li, F., Zhang, B., Liu, B., (2016), 1605.04711 Ternary weight networks, arXiv; Lin, Z., Courbariaux, M., Memisevic, R., Bengio, Y., Neural networks with few multiplications (2016) Proceedings of the International Conference on Learning Representations (ICLR); Alemdar, H., Leroy, V., Prost-Boucle, A., Pétrot, F., Ternary neural networks for resource-efficient AI applications (2017) Proceedings of the International Joint Conference on Neural Networks (IJCNN), pp. 2547-2554; Brown, B.D., Card, H.C., Stochastic neural computation. i. computational elements (2001) IEEE Trans. Comput., 50 (9), pp. 891-905; Li, Z., Ren, A., Li, J., Qiu, Q., Yuan, B., Draper, J., Wang, Y., Structural design optimization for deep convolutional neural networks using stochastic computing (2017) Proceedings of the IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE), pp. 250-253; Kim, K., Kim, J., Yu, J., Seo, J., Lee, J., Choi, K., Dynamic energy-accuracy trade-off using stochastic computing in deep neural networks (2016) Proceedings of the ACM/IEEE Design Automation Conference (DAC), pp. 1241-1246; Ji, Y., Ran, F., Ma, C., Lilja, D.J., A hardware implementation of a radial basis function neural network using stochastic logic (2015) Proceedings of the IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE), pp. 880-883; Ren, A., Li, Z., Ding, C., Qiu, Q., Wang, Y., Li, J., Qian, X., Yuan, B., SC-DCNN: highly-scalable deep convolutional neural network using stochastic computing (2017) Proceedings of the ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pp. 405-418; Li, J., Yuan, Z., Li, Z., Ren, A., Ding, C., Draper, J., Nazarian, S., Wang, Y., Normalization and dropout for stochastic computing-based deep convolutional neural networks (2017) Integr. VLSI J.; Li, G., Niu, P., Duan, X., Zhang, X., Fast learning network: a novel artificial neural network with a fast learning speed (2014) Neural Comput. Appl., 24 (7-8), pp. 1683-1695; Nawi, N.M., Khan, A., Rehman, M.Z., A new back-propagation neural network optimized with cuckoo search algorithm (2013) Proceedings of the International Conference on Computational Science and Its Applications, pp. 413-426. , Springer; Liu, Y.P., Wu, M.G., Qian, J.X., Evolving neural networks using the hybrid of ant colony optimization and bp algorithms (2006) Proceedings of the International Symposium on Neural Networks, pp. 714-722. , Springer; Pan, S.T., Lan, M.L., An efficient hybrid learning algorithm for neural network–based speech recognition systems on FPGA chip (2014) Neural Comput. Appl., 24 (7-8), pp. 1879-1885; Ding, S., Su, C., Yu, J., An optimizing bp neural network algorithm based on genetic algorithm (2011) Artif. Intell. Rev., 36 (2), pp. 153-162; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning internal representations by error propagation (1985) Technical Report; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) J. Mach. Learn. Res., 12 (Jul), pp. 2121-2159; Zeiler, M.D., (2012), 1212.5701 ADADELTA: an adaptive learning rate method, arXiv; Kingma, D., Ba, J., Adam: a method for stochastic optimization (2015) International Conference on Learning Representations (ICLR); Hamid, N.A., Nawi, N.M., Ghazali, R., Salleh, M.N.M., Accelerating learning performance of back propagation algorithm by using adaptive gain together with adaptive momentum and adaptive learning rate on classification problems (2011) Proceedings of the International Conference on Ubiquitous Computing and Multimedia Applications, pp. 559-570. , Springer; Nesterov, Y., Efficiency of coordinate descent methods on huge-scale optimization problems (2012) SIAM J. Optim., 22 (2), pp. 341-362; Richtárik, P., Takáč, M., Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function (2014) Math. Prog., 144 (1-2), pp. 1-38; http://docs.nvidia.com/cuda/cublas, cuBLAS; https://software.intel.com/en-us/intel-mkl, MLK; http://www.openblas.net, OpenBLAS; Cho, M., Brand, D., Mec: Memory-efficient convolution for deep neural network (2017) Proceedings of the International Conference on Machine Learning (ICML), pp. 815-824; Lavin, A., Gray, S., Fast algorithms for convolutional neural networks (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4013-4021; Park, H., Kim, D., Ahn, J., Yoo, S., Zero and data reuse-aware fast convolution for deep neural networks on GPU (2016) Proceedings of the International Conference on Hardware/Software Codesign and System Synthesis, pp. 1-10; Xiao, Q., Liang, Y., Lu, L., Yan, S., Tai, Y.-W., Exploring heterogeneous algorithms for accelerating deep convolutional neural networks on FPGAS (2017) Proceedings of the ACM/IEEE Design Automation Conference (DAC), pp. 1-6; Ben Yacoub, S., Fasel, B., Luettin, J., Fast face detection using MLP and FFT (1999) Proceedings of the International Conference on Audio and Video-based Biometric Person Authentication, pp. 31-36; Mathieu, M., Henaff, M., LeCun, Y., (2013), 1312.5851 Fast training of convolutional networks through ffts, arXiv; Brosch, T., Tam, R., Efficient training of convolutional deep belief networks in the frequency domain for application to high-resolution 2D and 3D images (2015) Neural Comput., 27 (1), pp. 211-227; Ko, J.H., Mudassar, B., Na, T., Mukhopadhyay, S., Design of an energy-efficient accelerator for training of convolutional neural networks using frequency-domain computation (2017) Proceedings of the ACM/IEEE Design Automation Conference (DAC), pp. 1-6; Wu, R., Yan, S., Shan, Y., Dang, Q., Sun, G., (2015) Deep image: Scaling up image recognition, , arXiv: 1501.02876; Coates, A., Huval, B., Wang, T., Wu, D., Catanzaro, B., Andrew, N., Deep learning with cots HPC systems (2013) Proceedings of the International Conference on Machine Learning (ICML), pp. 1337-1345; Imani, M., Peroni, D., Kim, Y., Rahimi, A., Rosing, T., Efficient neural network acceleration on GPGPU using content addressable memory (2017) Proceedings of the IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE), pp. 1026-1031; Izeboudjen, N., Larbes, C., Farah, A., A new classification approach for neural networks hardware: from standards chips to embedded systems on chip (2014) Artif. Intell. Rev., 41 (4), pp. 491-534; Peemen, M., Setio, A.A., Mesman, B., Corporaal, H., Memory-centric accelerator design for convolutional neural networks (2013) Proceedings of the IEEE International Conference on Computer Design (ICCD), pp. 13-19; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proceedings of the ACM Symposium on FPGAs, pp. 161-170; Martínez, J.J., Garrigós, J., Toledo, J., Ferrández, J.M., An efficient and expandable hardware implementation of multilayer cellular neural networks (2013) Neurocomputing, 114, pp. 54-62; Chakradhar, S., Sankaradas, M., Jakkula, V., Cadambi, S., A dynamically configurable coprocessor for convolutional neural networks (2010) Proceedings of the IEEE International Symposium on Circuits and Systems (ISCAS); Wang, Y., Li, H., Li, X., Re-architecting the on-chip memory sub-system of machine-learning accelerator for embedded devices (2016) Proceedings of the IEEE/ACM International Conference on Computer-Aided Design (ICCAD), p. 13; Zhang, C., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: towards uniformed representation and acceleration for deep convolutional neural networks (2016) Proceedings of the IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pp. 1-8; Rahman, A., Lee, J., Choi, K., Efficient FPGA acceleration of convolutional neural networks using logical-3D compute array (2016) Proceedings of the IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE), pp. 1393-1398; Alwani, M., Chen, H., Ferdman, M., Milder, P., Fused-layer CNN accelerators (2016) Proceedings of the IEEE/ACM International Symposium on Microarchitecture (MICRO), pp. 1-12; Gao, M., Pu, J., Yang, X., Horowitz, M., Kozyrakis, C., Tetris: scalable and efficient neural network acceleration with 3D memory (2017) Proceedings of the ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pp. 751-764; Luo, T., Liu, S., Li, L., Wang, Y., Zhang, S., Chen, T., Xu, Z., Chen, Y., Dadiannao: a neural network supercomputer (2017) IEEE Trans. Comput., 66 (1), pp. 73-88; Wang, S., Zhou, D., Han, X., Yoshimura, T., Chain-NN: an energy-efficient 1D chain architecture for accelerating deep convolutional neural networks (2017) Proceedings of the IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE), pp. 1032-1037; Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E., Hardware accelerated convolutional neural networks for synthetic vision systems (2010) IEEE International Symposium on Circuits and Systems (ISCAS), pp. 257-260; Zhang, S., Du, Z., Zhang, L., Lan, H., Liu, S., Li, L., Guo, Q., Chen, Y., Cambricon-X: an accelerator for sparse neural networks (2016) Proceedings of the IEEE/ACM International Symposium on Microarchitecture (MICRO), pp. 1-12; Kwon, H., Samajdar, A., Krishna, T., MAERI: enabling flexible dataflow mapping over DNN accelerators via reconfigurable interconnects (2018) Proceedings of the ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pp. 461-475; Gokmen, T., Vlasov, Y., Acceleration of deep neural network training with resistive cross-point devices: design considerations (2016) Front. Neurosci., 10, p. 333; Jackson, B.L., Rajendran, B., Corrado, G.S., Breitwisch, M., Burr, G.W., Cheek, R., Gopalakrishnan, K., Padilla, A., Nanoscale electronic synapses using phase change devices (2013) ACM J. Emerg. Technol. Comput. Syst. (JETC), 9 (2), p. 12; Saïghi, S., Mayr, C.G., Serrano Gotarredona, T., Schmidt, H., Lecerf, G., Tomas, J., Grollier, J., Querlioz, D., Plasticity in memristive devices for spiking neural networks (2015) Front. Neurosci., 9, p. 51; Seo, J., Lin, B., Kim, M., Chen, P.Y., Kadetotad, D., Xu, Z., Mohanty, A., Ye, J., On-chip sparse learning acceleration with CMOS and resistive synaptic devices (2015) IEEE Trans. Nanotechnol. (TNANO), 14 (6), pp. 969-979; Zeng, X., Wen, S., Zeng, Z., Huang, T., Design of memristor-based image convolution calculation in convolutional neural network (2016) Neural Comput. Appl., pp. 1-6; Shim, Y., Sengupta, A., Roy, K., Low-power approximate convolution computing unit with domain-wall motion based spin-memristor for image processing applications (2016) Proceedings of the ACM/IEEE Design Automation Conference (DAC), pp. 1-6; Ni, L., Huang, H., Yu, H., On-line machine learning accelerator on digital RRAM-crossbar (2016) Proceedings of the IEEE International Symposium on Circuits and Systems (ISCAS), pp. 113-116; Xu, Z., Mohanty, A., Chen, P.Y., Kadetotad, D., Lin, B., Ye, J., Vrudhula, S., Cao, Y., Parallel programming of resistive cross-point array for synaptic plasticity (2014) Procedia Comput. Sci., 41, pp. 126-133; Prezioso, M., Merrikh Bayat, F., Hoskins, B., Adam, G., Likharev, K.K., Strukov, D.B., Training and operation of an integrated neuromorphic network based on metal-oxide memristors (2015) Nature, 521 (7550), pp. 61-64; Cheng, M., Xia, L., Zhu, Z., Cai, Y., Xie, Y., Wang, Y., Yang, H., TIME: A training-in-memory architecture for memristor-based deep neural networks (2017) Proceedings of the ACM/IEEE Design Automation Conference (DAC), pp. 1-6; Song, L., Wang, Y., Han, Y., Li, H., Cheng, Y., Li, X., STT-RAM buffer design for precision-tunable general-purpose neural network accelerator (2017) IEEE Trans. Very Large Scale Integr. Syst. (TVLSI), 25 (4), pp. 1285-1296; Hu, M., Strachan, J.P., Li, Z., Grafals, E.M., Davila, N., Graves, C., Lam, S., Williams, R.S., Dot-product engine for neuromorphic computing: programming 1T1M crossbar to accelerate matrix-vector multiplication (2016) Proceedings of the ACM/IEEE Design Automation Conference (DAC), p. 19; Xia, L., Tang, T., Huangfu, W., Cheng, M., Yin, X., Li, B., Wang, Y., Yang, H., Switched by input: power efficient structure for RRAM-based convolutional neural network (2016) Proceedings of the ACM/IEEE Design Automation Conference (DAC), pp. 1-6; Ankit, A., Sengupta, A., Panda, P., Roy, K., RESPARC: a reconfigurable and energy-efficient architecture with memristive crossbars for deep spiking neural networks (2017) Proceedings of the ACM/IEEE Design Automation Conference (DAC), pp. 271-276; Liu, B., Wang, M., Foroosh, H., Tappen, M., Pensky, M., Sparse convolutional neural networks (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 806-814; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Proceedings of the Conference on Neural Information Processing Systems (NIPS), pp. 1135-1143; Courbariaux, M., Hubara, I., Soudry, D., El Yaniv, R., Bengio, Y., (2016), 1602.02830 Binarized neural networks: training deep neural networks with weights and activations constrained to+ 1 or-1, arXiv; Liew, S.S., Khalil Hani, M., Bakhteri, R., An optimized second order stochastic learning algorithm for neural network training (2016) Neurocomputing, 186, pp. 74-89; Cho, H., An, M.K., Co-clustering algorithm: batch, mini-batch, and online (2014) In. J. Inf. Electron. Eng., 4 (5), p. 340; Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Mao, M., Senior, A., Le, Q.V., Large scale distributed deep networks (2012) Proceedings of the Conference on Neural Information Processing Systems (NIPS), pp. 1223-1231; Meng, Q., Chen, W., Yu, J., Wang, T., Ma, Z.M., Liu, T.-Y., Asynchronous accelerated stochastic gradient descent (2016) Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI); Rippel, O., Snoek, J., Adams, R.P., Spectral representations for convolutional neural networks (2015) Proceedings of the Conference on Neural Information Processing Systems (NIPS), pp. 2449-2457; Du, Z., Liu, S., Fasthuber, R., Chen, T., Ienne, P., Li, L., Luo, T., Chen, Y., An accelerator for high efficient vision processing (2017) IEEE Trans. Comput.-Aid. Des. Integr. Circuits Syst. (TCAD), 36 (2), pp. 227-240; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: efficient inference engine on compressed deep neural network (2016) Proceedings of the IEEE/ACM International Symposium on Computer Architecture (ISCA), pp. 243-254; Qiu, J., Wang, J., Yao, S., Guo, K., Li, B., Zhou, E., Yu, J., Song, S., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proceedings of the ACM Symposium on FPGAs, pp. 26-35; Moons, B., Verhelst, M., An energy-efficient precision-scalable ConvNet processor in 40-nm CMOS (2017) IEEE J. Solid-State Circuits, 52 (4), pp. 903-914; Chen, Y.H., Krishna, T., Emer, J.S., Sze, V., EYERISS: an energy-efficient reconfigurable accelerator for deep convolutional neural networks (2017) IEEE J. Solid-State Circuits, 52 (1), pp. 127-138","Zhang, M.; National ASIC System Engineering Technology Research Center, China; email: zmeng@seu.edu.cn",,,"Elsevier B.V.",,,,,09252312,,NRCGE,,"English","Neurocomputing",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85055032561
"Awan M.J., Mohd Rahim M.S., Salim N., Ismail A.W., Shabbin H.","57213835764;57210569784;12790857000;34874868400;57214113838;","Acceleration of knee MRI cancellous bone classification on google colaboratory using convolutional neural network",2019,"International Journal of Advanced Trends in Computer Science and Engineering","8","1.6 Special Issue","13","83","88",,21,"10.30534/ijatcse/2019/1381.62019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078239551&doi=10.30534%2fijatcse%2f2019%2f1381.62019&partnerID=40&md5=77fa1584d773f3ae6c025925de51c3e9","School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia (UTM)Johor, Malaysia; Department of Software Engineering, University of Management and Technology, Pakistan","Awan, M.J., School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia (UTM)Johor, Malaysia, Department of Software Engineering, University of Management and Technology, Pakistan; Mohd Rahim, M.S., School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia (UTM)Johor, Malaysia; Salim, N., School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia (UTM)Johor, Malaysia; Ismail, A.W., School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia (UTM)Johor, Malaysia; Shabbin, H., Department of Software Engineering, University of Management and Technology, Pakistan","The field of Biomechanical engineering and Orth ology is related to knee bone tissue in which cancellous bone lies. The cancellous bone also called spongy bones has greater surface area for this it causes Osteoporosis (OP), Osteoarthritis (OA), and knee cartilage and knee replacement. The knee bone images are measured mostly by Magnetic Resonance Imaging (MRI).In this paper we presented deep learning model on cancellous bones (tiff type) MRI through Convolutional Neural Network (CNN) to predict the image classification which achieved 99.39 % accuracy. The sample size of images are 185 cancellous MRI and 185 tiff images. Further we trained our model on cloud service that is Google Colabaratory (Colab) which is Graphical Processing Unit (GPU). The accuracy of this model is same but the execution time per min decreases on GPU environment. We increased the no of epochs 20 then 50 its execution time is 10 times less than CPU. The execution time on GPU google Colab is 2.23 (mins) and on CPU its 24.23(mins). © 2019, World Academy of Research in Science and Engineering. All rights reserved.","Cancellous bone; Convolutional Neural Network; Deep learning; Google CoLab; Image Classification; MAgnetic REsonance Imaging",,,,,,,"This research is sponsored partially by the School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia.",,,,,,,,,,"Cowin, S.C., (2001) Bone Mechanics Handbook, , CRC press; Clarke, B., Normal bone anatomy and physiology (2008) Clinical Journal of the American Society of Nephrology, 3, pp. S131-S139. , https://doi.org/10.2215/CJN.04151206; Kotha, S.P., Guzelsu, N., Effect of bone mineral content on the tensile properties of cortical bone: Experiments and theory (2003) Journal of Biomechanical Engineering, 125 (6), pp. 785-793; Gibson, L., The mechanical behaviour of cancellous bone (1985) Journal of Biomechanics, 18 (5), pp. 317-328; Deng, L., Yu, D., Deep learning: Methods and applications (2014) Foundations and Trends® in Signal Processing, 7 (3-4), pp. 197-387; Liu, F., Zhou, Z., Samsonov, A., Blankenbaker, D., Larison, W., Kanarek, A., Lian, K., Kijowski, R., Deep learning approach for evaluating knee MR images: Achieving high diagnostic performance for cartilage lesion detection (2018) Radiology, 289 (1), pp. 160-169. , https://doi.org/10.1148/radiol.2018172986; Akkus, Z., Galimzianova, A., Hoogi, A., Rubin, D.L., Erickson, B.J., Deep learning for brain MRI segmentation: State of the art and future directions (2017) Journal of Digital Imaging, 30 (4), pp. 449-459; Teller, P., König, H., (2003) MRI Atlas of Orthopedics and Traumatology of the Knee, , Springer Science & Business Media; Liu, J., Pan, Y., Li, M., Chen, Z., Tang, L., Lu, C., Wang, J., Applications of deep learning to mri images: A survey (2018) Big Data Mining and Analytics, 1 (1), pp. 1-18. , https://doi.org/10.26599/BDMA.2018.9020001; Liu, F., Zhou, Z., Samsonov, A., Blankenbaker, D., Larison, W., Kanarek, A., Lian, K., Kijowski, R., Deep learning approach for evaluating knee MR images: Achieving high diagnostic performance for cartilage lesion detection (2018) Radiology, 289 (1), pp. 160-169; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) Comput. Sci., 1409 (1556); Xiao, C., Choi, E., Sun, J., Opportunities and challenges in developing deep learning models using electronic health records data: A systematic review (2018) Journal of the American Medical Informatics Association, 25 (10), pp. 1419-1428; https://colab.research.google.com/notebooks/welcome.ipynb?hl=pt; Erickson, B.J., Korfiatis, P., Akkus, Z., Kline, T.L., Machine learning for medical imaging (2017) Radiographics, 37 (2), pp. 505-515; Wernick, M.N., Yang, Y., Brankov, J.G., Yourganov, G., Strother, S.C., Machine learning in medical imaging (2010) IEEE Signal Processing Magazine, 27 (4), pp. 25-38; Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A., Ciompi, F., Ghafoorian, M., Sánchez, C.I., A survey on deep learning in medical image analysis (2017) Medical Image Analysis, 42, pp. 60-88. , https://doi.org/10.1016/j.media.2017.07.005; Ker, J., Wang, L., Rao, J., Lim, T., Deep learning applications in medical image analysis (2018) Ieee Access, 6, pp. 9375-9389; Lundervold, A.S., Lundervold, A., An overview of deep learning in medical imaging focusing on MRI (2018) Zeitschrift für Medizinische Physik; Ambellan, F., Tack, A., Ehlke, M., Zachow, S., Automated segmentation of knee bone and cartilage combining statistical shape knowledge and convolutional neural networks: Data from the Osteoarthritis Initiative (2019) Medical Image Analysis, 52, pp. 109-118; Antony, J., McGuinness, K., O’Connor, N.E., Moran, K., Quantifying radiographic knee osteoarthritis severity using deep convolutional neural networks (2016) Pattern Recognition (ICPR), pp. 1195-1200. , 2016 23rd International Conference on (pp.). IEEE; Smistad, E., Falch, T.L., Bozorgi, M., Elster, A.C., Lindseth, F., Medical image segmentation on GPUs–A comprehensive review (2015) Medical Image Analysis, 20 (1), pp. 1-18. , https://doi.org/10.1109/ACCESS.2018.2874767; Carneiro, T., da Nóbrega, R.V.M., Nepomuceno, T., Bian, G.B., de Albuquerque, V.H.C., Reboucas Filho, P.P., Performance Analysis of Google Colaboratory as a Tool for Accelerating Deep Learning Applications (2018) IEEE Access, 6, pp. 61677-61685; (2018) Google Colab Free GPU Tutorial, , https://medium.com/deep-learning-turkey/googlecolab-free-gpu-tutorial-e113627b9f5d, Access: 6-25-2018.[Online]. Available; Rampasek, L., Goldenberg, A., Tensorflow: Biology’s gateway to deep learning? (2016) Cell Systems, 2 (1), pp. 12-14. , https://doi.org/10.1016/j.cels.2016.01.009",,,,"World Academy of Research in Science and Engineering",,,,,22783091,,,,"English","Int. J. Adv. Trends Comput. Sci. Eng.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85078239551
"Liu B., Wang Z., Zhu W., Sun Y., Shen Z., Huang L., Li Y., Gong Y., Ge W.","57223712922;56547665700;57209778083;57216366540;57213689816;57226040128;7402670756;57188715247;54980718500;","An ultra-low power always-on keyword spotting accelerator using quantized convolutional neural network and voltage-domain analog switching network-based approximate computing",2019,"IEEE Access","7",,"8936893","186456","186469",,11,"10.1109/ACCESS.2019.2960948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077956442&doi=10.1109%2fACCESS.2019.2960948&partnerID=40&md5=d8d18cc4705979ee340c47eb6a975d56","National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, 210096, China; Nanjing Prochip Electronic Technology Company Ltd., Nanjing, 210001, China","Liu, B., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, 210096, China; Wang, Z., Nanjing Prochip Electronic Technology Company Ltd., Nanjing, 210001, China; Zhu, W., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, 210096, China; Sun, Y., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, 210096, China; Shen, Z., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, 210096, China; Huang, L., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, 210096, China; Li, Y., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, 210096, China; Gong, Y., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, 210096, China; Ge, W., National ASIC System Engineering Technology Research Center, Southeast University, Nanjing, 210096, China","An ultra-low power always-on keyword spotting (KWS) accelerator is implemented in 22nm CMOS technology, which is based on an optimized convolutional neural network (CNN). To reduce the power consumption while maintaining the system recognition accuracy, we first perform a bit-width quantization method on the proposed CNN to reduce the data/weight bit width required by the hardware computing unit without reducing the recognition accuracy. Then, we propose an approximate computing architecture for the quantized CNN using voltage-domain analog switching network based multiplication and addition unit. Implementation results show that this accelerator can support 10 keywords real time recognition under different noise types and SNRs, while the power consumption can be significantly reduced to 52 μW. © 2013 IEEE.","approximate computing; bit-width quantization; spotting","Computer architecture; Convolution; Electric power utilization; Green computing; Neural networks; Switching networks; approximate computing; Bit-Width; Computing architecture; Convolutional neural network; Hardware computing; Real time recognition; Recognition accuracy; spotting; Low power electronics",,,,,"National Natural Science Foundation of China, NSFC: 61404028, 61574033; National Major Science and Technology Projects of China: 2018ZX01031101-005","This work was supported in part by the National Science and Technology Major Project under Grant 2018ZX01031101-005, and in part by the National Natural Science Foundation of China under Grant 61404028 and Grant 61574033.",,,,,,,,,,"Shah, M., Arunachalam, S., Wang, J., Blaauw, D., Sylvester, D., Kim, H.-S., Seo, J.-S., Chakrabarti, C., A fixed-point neural network architecture for speech applications on resource constrained hardware (2018) J. Signal Pro-cess. Syst., 90 (5), pp. 727-741; Price, M., Glass, J., Chandrakasan, A.P., A scalable speech recognizer with deep-neural-network acoustic models and voice-activated power gating (2017) IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, pp. 244-245. , San Francisco, CA, USA, Feb; Bang, S., Wang, J., Li, Z., Gao, C., Kim, Y., Dong, Q., Chen, Y.-P., Sylvester, D., A 288 W programmable deep-learning processor with 270kb on-chip weight storage using non-uniform memory hierarchy for mobile intelligence (2017) IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, pp. 250-251. , San Francisco, CA, USA, Feb; Giraldo, J.S.P., Lauwereins, S., Badami, K., Van Hamme, H., Verhelst, M., 18 w soc for near-microphone keyword spotting and speaker verification (2019) Proc. IEEE Symp. VLSI Circuits, pp. C52-C53. , Jun; Yin, S., Ouyang, P., Tang, S., Tu, F., Li, X., Zheng, S., Lu, T., Wei, S., A high energy efficient reconfigurable hybrid neural network processor for deep learning applications (2018) IEEE J. Solid-State Circuits, 53 (4), pp. 968-982. , Apr; Yin, S., Ouyang, P., Zheng, S., Song, D., Li, X., Liu, L., Wei, S., A 141 w, 2.46 pj/neuron binarized convolutional neural network based self-learning speech recognition processor in 28nm CMOS (2018) Proc. IEEE Symp. VLSI Circuits, pp. 139-140. , Honolulu, HI, USA, Jun; Seltzer, M.L., Yu, D., Wang, Y., An investigation of deep neural networks for noise robust speech recognition (2013) Proc. ICASSP, pp. 7398-7402. , May; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding (2016) Proc. ICLR, pp. 3-7; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: Efficient inference engine on compressed deep neural network (2016) Proc. ISCA, pp. 243-254. , Jun; Salehinejad, H., Valaee, S., Ising-dropout: A regularization method for training and compression of deep neural networks (2019) Proc. ICASSP, pp. 3602-3606. , May; Wang, Z., Xia, M., Liu, B., Ruan, X., Gong, Y., Yang, J., Ge, W., Yang, J., Eera-dnn: An energy-efficient reconfigurable architecture for dnns with hybrid bit-width and logarithmic multiplier (2018) IEICE Electron. Express, 15 (8), pp. 1-10; Liu, B., Ruan, X., Xia, M., Gong, Y., Yang, J., Ge, W., Yang, J., An energy-efficient accelerator for hybrid bit-width DNNs (2018) Proc. IEEE Symp. Comput. Intell., pp. 1-8. , Nov./Dec; Liu, B., Wang, Z., Fan, H., Yang, J., Liu, B., Zhu, W., Huang, L., Shi, L., Eera-kws: A 163 tops/w always-on keyword spotting accelerator in 28nm CMOS using binary weight network and precision self-adaptive approximate computing (2019) IEEE Access, 7, pp. 82453-82465; Yin, P., Zhang, S., Qi, Y., Xin, J., Quantization and training of low bit-width convolutional neural networks for object detection (2018) J. Comput. Math., 37 (3), pp. 349-359; Pietras, M., Error analysis in the hardware neural networks applications using reduced floating-point numbers representation (2015) Proc. AIP Conf. Proc., 1648, pp. 239-255; Horowitz, M., Computing's energy problem (and what we can do about it) (2014) IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, pp. 10-14. , Feb; Gong, Y., Liu, B., Ge, W., Shi, L., ARA: Cross-Layer approximate computing framework based reconfigurable architecture for CNNs (2019) Microelectron. J., 87, pp. 33-44. , May; Liu, B., Dong, W., Xu, T., Gong, Y., Ge, W., Yang, J., Shi, L., E-era: An energy-efficient reconfigurable architecture for rnns using dynamically adaptive approximate computing (2017) IEICE Electron. Express, 14 (15), pp. 1-11; Babi, Z., Avramovi, A., Buli, P., An iterative logarithmic multiplier (2011) Microprocess. Microsyst., 35 (1), pp. 23-33. , Feb; Gupta, H., Gupta, D., Lpc and lpcc method of feature extraction in speech recognition system (2016) Proc. 6th Int. Conf.-Cloud Syst. Big Data Eng. (Confluence), pp. 498-502; Hermansky, H., Perceptual linear predictive (PLP) analysis of speech (1990) J. Acoust. Soc. Amer., 87 (4), pp. 1738-1752; Hermansky, H., Morgan, N., Bayya, A., Kohn, P., The challenge of inverse-e: The rasta-plp method (1991) Proc. ACSSC, pp. 800-804. , Nov; Veton, Z.K., Hussien, A.E., Robust speech recognition system using conventional and hybrid features of mfcc, lpcc, plp, rasta-plp and hidden markov model classifier in noisy conditions (2015) J. Comput. Chem. Commun., 3 (6), pp. 1-9; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., Xnor-net: Imagenet classification using binary convolutional neural networks (2016) Proc. Eur. Conf. Comput. Vis., pp. 525-542; Arik, S.O., Kliegl, M., Child, R., Hestness, J., Gibiansky, A., Fougner, C., Prenger, R., Coates, A., Convolutional recurrent neural networks for small-footprint keyword spotting (2017) Proc. INTERSPEECH, pp. 1606-1610; Warden, P., (2018) Speech Commands: A Dataset for Limited-vocabulary Speech Recognition, , https://arxiv.org/abs/1804.03209","Liu, B.; National ASIC System Engineering Technology Research Center, China; email: liubo_cnasic@seu.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85077956442
"Yan S., Liu Q., Li J., Han L.","57213268456;57001376500;56285989200;57213264357;","Heterogeneous Acceleration of Hybrid PSO-QN Algorithm for Neural Network Training",2019,"IEEE Access","7",,"8892465","161499","161509",,9,"10.1109/ACCESS.2019.2951710","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077730963&doi=10.1109%2fACCESS.2019.2951710&partnerID=40&md5=2911aeb8f1a0fdf88f20729db70c61a7","School of Microelectronics, Tianjin University, Tianjin, China; Alibaba Group, Sunnyvale, CA, United States","Yan, S., School of Microelectronics, Tianjin University, Tianjin, China; Liu, Q., School of Microelectronics, Tianjin University, Tianjin, China; Li, J., School of Microelectronics, Tianjin University, Tianjin, China; Han, L., Alibaba Group, Sunnyvale, CA, United States","Artificial neural network (ANN) has successfully provided solutions to many practical problems. One of the difficulties in training ANNs is finding the ideal solution to the network weights quickly. This paper designs an implementation of the hybrid particle swarm optimization (PSO) and quasi-Newton (QN) algorithm on CPU-GPU platform using OpenCL to accelerate ANN training. The PSO-QN implementation combines the strength of the PSO algorithm in global search and the advantage of the QN algorithm in fast convergence rate. A configurable parallel line search implementation and an efficient parallel reinitialization implementation are proposed to improve the performance and reduce data transmission. Experiments show the PSO-QN hybrid parallel implementation on CPU-GPU platform can achieve up to 362× and 8.9× acceleration compared with the C++ implementations of PSO and BFGS-QN on CPU, respectively. Compared with the PSO and BFGS-QN parallel implementations, the training loss of the PSO-QN hybrid implementation at given training time is reduced by 15.16% and 3.97%, and the testing error is reduced by 13.66% and 6.86%, respectively. © 2019 IEEE.","Heterogeneous computing; neural network training; PSO algorithm; quasi-Newton algorithm","Neural networks; Fast convergence rate; Heterogeneous computing; Hybrid implementation; Hybrid Particle Swarm Optimization; Neural network training; Parallel implementations; PSO algorithms; Quasi-newton algorithm; Particle swarm optimization (PSO)",,,,,"2017B-40; National Natural Science Foundation of China, NSFC: 61574099","This work was supported in part by the National Natural Science Foundation of China under Grant 61574099, the Tianjin Municipal Transportation Science and Technology Development Plan Project under Grant 2017B-40 and Alibaba Group through Alibaba Innovative Research (AIR) Program.",,,,,,,,,,"Olanrewaju, R.F., Sahari, N.S., Musa, A.A., Hakiem, N., Application of neural networks in early detection and diagnosis of Parkinson's disease (2014) Proc. Int. Conf. Cyber IT Service Manage. (CITSM), pp. 78-82. , Nov; Kabir, H., Wang, Y., Yu, M., Zhang, Q.-J., High-dimensional neuralnetwork technique and applications to microwave filter modeling (2010) IEEE Trans. Microw. Theory Techn., 58 (1), pp. 145-156. , Jan; Lin, C.-W., Yang, Y.-T.C., Wang, J.-S., Yang, Y.-C., A wearable sensor module with a neural-network-based activity classification algorithm for daily energy expenditure estimation (2012) IEEE Trans. Inf. Technol. Biomed., 16 (5), pp. 991-998. , Sep; Barzilai, J., Borwein, J.M., Two-point step size gradient methods (1988) IMA J. Numer. Anal., 8 (1), pp. 141-148; Caliskan, A., Yuksel, M.E., Badem, H., Basturk, A., Performance improvement of deep neural network classifiers by a simple training strategy (2018) Eng. Appl. Artif. Intell., 67, pp. 14-23. , Jan; Kennedy, J., Particle swarm optimization (2011) Encyclopedia of Machine Learning, pp. 760-766. , New York, NY, USA: Springer; Birgin, E.G., Krejić, N., Martínez, J.M., Globally convergent inexact quasi-Newton methods for solving nonlinear systems (2003) Numer. Algorithms, 32 (2-4), pp. 249-260. , Apr; Qu, X., Bo, L., Li, Z., Duan, W., Ran, Z., Wei, Z., Li, H., Anovel improved teaching-learning based optimization for functional optimization (2016) Proc. IEEE Int. Conf. Control Autom., pp. 939-943. , Jun; Plevris, V., Papadrakakis, M., A hybrid particle swarm-Gradient algorithm for global structural optimization (2011) Comput.-Aided Civil Infrastruct. Eng., 26 (1), pp. 48-68. , Jan; Ghaffari-Miab, M., Farmahini-Farahani, A., Faraji-Dana, R., Lucas, C., An efficient hybrid swarm intelligence-gradient optimization method for complex time green's functions of multilayer media (2007) Prog. Electromagn. Res., 77, pp. 181-192; Ouyang, A., Tang, Z., Li, K., Sallam, A., Sha, E., Estimating parameters of Muskingum model using an adaptive hybrid PSO algorithm (2014) Int. J. Pattern Recognit. Artif. Intell., 28 (1); Li, S., Tan, M., Tuning SVM parameters by using a hybrid CLPSO-BFGS algorithm (2010) Neurocomputing, 73 (10-12), pp. 2089-2096. , Jun; Nezhad, A.M., Shandiz, R.A., Jahromi, A.E., A particle swarm-BFGS algorithm for nonlinear programming problems (2013) Comput. Oper. Res., 40 (4), pp. 963-972. , Apr; Munshi, A., Gaster, B., Mattson, T.G., Ginsburg, D., (2011) OpenCL Programming Guide, , London, U.K.: Pearson; Bansal, J.C., Singh, P., Saraswat, M., Verma, A., Jadon, S.S., Abraham, A., Inertia weight strategies in particle swarm optimization (2011) Proc. 3rd World Congr. Nature Biologically Inspired Comput., pp. 633-640. , Oct; Li, S., Tan, M., Tsang, I.W., Kwok, J.T.-Y., A hybrid PSO-BFGS strategy for global optimization of multimodal functions (2011) IEEE Trans. Syst., Man, Cybern. B, Cybern., 41 (4), pp. 1003-1014. , Aug; Munshi, A., (2011) The OpenCL Specification Version: 1.2 Document Revision: 15, , https://www.khronos.org/registry/OpenCL/specs/opencl-1.2.pdf, [Online]; Peng, H., Zhang, X., Huang, L., An energy efficient approach for C4.5 algorithm using OpenCL design flow (2017) Proc. Int. Conf. Field Program. Technol. (ICFPT), pp. 144-151. , Dec; Zhou, Y., Tan, Y., GPU-based parallel particle swarm optimization (2009) Proc. IEEE Congr. Evol. Comput., pp. 1493-1500. , May; Ding, K., Tan, Y., Comparison of random number generators in particle swarm optimization algorithm (2014) Proc. IEEE Congr. Evol. Comput. (CEC), pp. 2664-2671. , Jul; Li, J., Liu, Q., Neural network training acceleration with PSO algorithm on a GPU using Open CL (2017) Proc. 8th Int. Symp. Highly Efficient Accel. Reconfigurable Technol., p. 17. , Jun; Feng, F., Zhang, C., Ma, J., Zhang, Q.-J., Parametric modeling of em behavior of microwave components using combined neural networks and pole-residue-based transfer functions (2016) IEEE Trans. Microw. Theory Techn., 64 (1), pp. 60-77. , Jan; Zhang, Q.-J., Gupta, K.C., (2000) Neural Networks for RF and Microwave Design, , Norwood, MA, USA: Artech House; Olorunda, O., Engelbrecht, A.P., Measuring exploration/exploitation in particle swarms using swarm diversity (2008) Proc. IEEE Congr. Evol. Comput., pp. 1128-1134. , Jun","Liu, Q.; School of Microelectronics, China; email: qiangliu@tju.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85077730963
"Markiewicz M., Wielgosz M., Bochenski M., Tabaczynski W., Konieczny T., Kowalczyk L.","35987547400;24451414700;57212621936;57212621551;57211511410;57212621064;","Predictive maintenance of induction motors using ultra-low power wireless sensors and compressed recurrent neural networks",2019,"IEEE Access","7",,"8935226","178891","178902",,6,"10.1109/ACCESS.2019.2953019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077238105&doi=10.1109%2fACCESS.2019.2953019&partnerID=40&md5=f7193eaad809c64ef831bffdc4580d9a","Faculty of Mathematics and Computer Science, Jagiellonian University, Cracow, Poland; Centre for Advanced Materials and Technologies CEZAMAT PW Sp. Z O.o., Warsaw, Poland; Faculty of Computer Science, Electronics and Telecommunications, AGH University of Science and Technology, Cracow, Poland","Markiewicz, M., Faculty of Mathematics and Computer Science, Jagiellonian University, Cracow, Poland, Centre for Advanced Materials and Technologies CEZAMAT PW Sp. Z O.o., Warsaw, Poland; Wielgosz, M., Faculty of Computer Science, Electronics and Telecommunications, AGH University of Science and Technology, Cracow, Poland; Bochenski, M., Centre for Advanced Materials and Technologies CEZAMAT PW Sp. Z O.o., Warsaw, Poland; Tabaczynski, W., Centre for Advanced Materials and Technologies CEZAMAT PW Sp. Z O.o., Warsaw, Poland; Konieczny, T., Centre for Advanced Materials and Technologies CEZAMAT PW Sp. Z O.o., Warsaw, Poland; Kowalczyk, L., Centre for Advanced Materials and Technologies CEZAMAT PW Sp. Z O.o., Warsaw, Poland","In real-world applications-to minimize the impact of failures-machinery is often monitored by various sensors. Their role comes down to acquiring data and sending it to a more powerful entity, such as an embedded computer or cloud server. There have been attempts to reduce the computational effort related to data processing in order to use edge computing for predictive maintenance. The aim of this paper is to push the boundaries even further by proposing a novel architecture, in which processing is moved to the sensors themselves thanks to decrease of computational complexity given by the usage of compressed recurrent neural networks. A sensor processes data locally, and then wirelessly sends only a single packet with the probability that the machine is working incorrectly. We show that local processing of the data on ultra-low power wireless sensors gives comparable outcomes in terms of accuracy but much better results in terms of energy consumption that transferring of the raw data. The proposed ultra-low power hardware and firmware architecture makes it possible to use sensors powered by harvested energy while maintaining high confidentiality levels of the failure prediction previously offered by more powerful mains-powered computational platforms. © 2013 IEEE.","bearing faults; compressed recurrent neural networks; edge computing; electric motors; induction motors; Internet of Things; IoT; predictive maintenance; RNN; smart sensors; vibration signature","Data handling; Edge computing; Electric motors; Energy utilization; Firmware; Induction motors; Internet of things; Low power electronics; Maintenance; Network architecture; Smart sensors; Bearing fault; Computational effort; Computational platforms; Embedded computers; Failure prediction; Novel architecture; Predictive maintenance; Vibration signature; Recurrent neural networks",,,,,"692519","This work was supported by ECSEL JU (Electronic Component Systems for European Leadership Joint Undertaking) under Grant 692519 – PRIME (Ultra-Low Power Technologies and Memory Architectures for IoT).",,,,,,,,,,"Sudhakar, I., Adi Narayana, S., Anilprakash, M., Condition monitoring of a 3-O induction motor by vibration spectrum anaylsis using Fft analyser-A case study (2017) Mater. Today: Proc, 4 (2), pp. 1099-1105. , http://www.sciencedirect.com/science/article/pii/S2214785317301256; Goyal, D., Vanraj, B.S.P., Dhami, S.S., Condition monitoring parameters for fault diagnosis of fixed axis gearbox: A review (2017) Arch. Comput. Methods Eng, 24 (3), pp. 543-556; Zhang, W., Jia, M.-P., Zhu, L., Yan, X.-A., Comprehensive overview on computational intelligence techniques for machinery condition monitoring and fault diagnosis Chin. J. Mech. Eng, 30 (4), pp. 782-795. , Jul. 2017; Palmero, G.I.S., Santamaria, J.J., De La Torre, E.M., Gonzalez, J.P., Fault detection and fuzzy rule extraction in AC motors by a neuro-fuzzy ART-based system (2005) Eng. Appl. Artif. Intell, 18 (7), pp. 867-874. , http://www.sciencedirect.com/science/article/pii/S0952197605000321; Gindy, N., Al-Habaibeh, A., (1997) Condition Monitoring of Cutting Tools Using Artificial Neural Networks, pp. 299-304. , London, U.K Macmillan; Hwang, Y.-R., Jen, K.-K., Shen, Y.-T., Application of cepstrum and neural network to bearing fault detection (2009) J. Mech. Sci. Technol, 23 (10), p. 2730. , Oct; Sugumaran, V., Ramachandran, K.I., Effect of number of features on classification of roller bearing faults using SVM and PSVM (2011) Expert Syst. Appl, 38 (4), pp. 4088-4096. , Apr; Milne, R., Artificial intelligence for online diagnosis (1987) IEE Proc. D, Control Theory Appl, 134 (4), pp. 238-244. , https://digital-library.theiet.org/content/journals/10.1049/ipd.1987.0040, Jul; Rao, B.K.N., Pai, P.S., Nagabhushana, T.N., Failure diagnosis and prognosis of rolling Element bearings using artificial neural networks: A critical overview in Proc. J. Phys., Conf. ser, 364. , May 2012, Art 012023; Bose, S.K., Kar, B., Roy, M., Gopalakrishnan, P.K., Basu, A., ADEPOS: Anomaly detection based power saving for predictive maintenance using edge computing in (2019) Proc. 24th Asia South Pacific Design Automat. Conf, pp. 597-602. , New York, NY, USA; Choudhary, A., Goyal, D., Shimi, S.L., Akula, A., Condition monitoring and fault diagnosis of induction motors: A review Arch. Comput. Methods Eng, 26 (4), pp. 1221-1238. , Sep. 2019; Liu, J., Shao, Y., Overview of dynamic modelling and analysis of rolling element bearings with localized and distributed faults Nonlinear Dyn, 93 (4), pp. 1765-1798. , Sep. 2018; Sunnersjö, C., Rolling bearing vibrations the effects of geometrical imperfections and wear (1985) J. Sound Vib, 98 (4), pp. 455-474. , http://www.sciencedirect.com/science/article/pii/0022460X85902561; Tandon, N., Choudhury, A., A review of vibration and acoustic measurement methods for the detection of defects in rolling element bearings (1999) Tribology Int, 32 (8), pp. 469-480. , http://www.sciencedirect.com/science/article/pii/S0301679X99000778; El-Thalji, I., Jantunen, E., A summary of fault modelling and predictive health monitoring of rolling element bearings (2015) Mechanical Sys-Tems and Signal Processing, 60-61, pp. 252-272. , Aug; Lipton, Z.C., The Mythos of Model Interpretability 2016, , https://arxiv.org/abs/1606.03490, arXiv:1606 03490; Zadeh, L.A., Fuzzy logic (1988) Computer, 21 (4), pp. 83-93. , Apr; Hochreiter, S., Schmidhuber, J., Long short-Term memory (1997) Neural Comput, 9 (8), pp. 1735-1780. , Nov; Graves, A., (2012) Neural Networks, , Berlin, Germany Springer; Lipton, Z.C., Berkowitz, J., Elkan, C., A Critical Review of Recurrent Neural Networks for Sequence Learning 2015, , https://arxiv.org/abs/1506.00019, arXiv:1506 00019; Greff, K., Srivastava, R.K., Koutník, J., Steunebrink, B.R., Schmidhuber, J., LSTM: A search space odyssey IEEE Trans. Neural Netw. Learn. Syst, 28 (10), pp. 2222-2232. , Oct. 2017; Djebala, A., Ouelaa, N., Hamzaoui, N., Detection of rolling bearing defects using discrete wavelet analysis (2008) Meccanica, 43 (3), pp. 339-348. , Jun; Wielgosz, M., Karwatowski, M., Mapping neural networks to FPGAbased IoT devices for ultra-low latency processing (2019) Sensors, 19 (13), p. 2981. , https://www.mdpi.com/1424-8220/19/13/2981; Lecun, Y., Denker, J.S., Solla, S.A., Optimal brain damage in (1990) Advances in Neural Information Processing Systems, pp. 598-605. , D. S. Touretzky, Eds. San Mateo, CA, USA: Morgan Kaufmann; Hassibi, B., Stork, D.G., Second order derivatives for network pruning: Optimal Brain Surgeon in (1993) Proc. Adv. Neural Inf. Process. Syst, pp. 164-171; Han, S., Pool, J., Tran, J., Dally, W.J., Learning both weights and connections for efficient neural networks in (2015) Proc. 28th Int. Conf. Neural Inf. Process. Syst, 1, pp. 1135-1143. , Cambridge, MA, USA; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning structured sparsity in deep neural networks in (2016) Proc. 30th Int. Conf. Neural Inf. Process. Syst, pp. 2082-2090. , New York, NY, USA; Luo, J.-H., Wu, J., Lin, W., Thi Net: A filter level pruning method for deep neural network compression in (2017) Proc IEEE Int. Conf. Comput. Vis. (ICCV), pp. 5058-5066. , Oct; Raghunathan, V., Schurgers, C., Park, S., Srivastava, M.B., Energyaware wireless microsensor networks (2002) IEEE Signal Process. Mag, 19 (2), pp. 40-50. , Mar; Kuorilehto, M., Kohvakka, M., Suhonen, J., Hämäläinen, P., Hännikäinen, M., Hamalainen, T.D., (2008) Ultra-Low Energy Wireless Sensor Networks in Practice: Theory, Realization and Deployment, , Hoboken, NJ, USA Wiley; Lu, G., Krishnamachari, B., Raghavendra, C.S., An adaptive energyef ficient and low-latency MAC for data gathering in wireless sensor networks in (2004) Proc. 18th Int. Parallel Distrib. Process. Symp, p. 224. , Apr; Mannion, P., (2017) Comparing Low-Power Wireless Technologies, , https://www.digikey.com/en/articles/techzone/2017/oct/comparing-low-power-wireless-Technologies; (2015) IEEE Standard for Low-Rate Wireless Networks, , https://standards.ieee.org/standard/802-15-4-2015.html, IEEE Standard 802.15.4-2015; Varga, L.-O., Rom-Aniello, G., Vucinic, M., Favre, M., Banciu, A., Guizzetti, R., Planat, C., Duda, A., Greennet: An energy-harvesting ip-enabled wireless sensor network (2015) IEEE Internet Things J, 2 (5), pp. 412-426. , Oct; MKW41Z/31Z/21Z Data Sheet, NXP Semiconductors, 3 2018, Rev, 4. , https://www.nxp.com/docs/en/data-sheet/MKW41Z512.pdf, Accessed: Jul 6 2019; Dunkels, A., Gronvall, B., Voigt, T., Contiki A lightweight and fiexible operating system for tiny networked sensors in (2004) Proc. 29th Annu IEEE Int. Conf. Local Comput. Netw, pp. 455-462. , Washington, DC, USA Nov; (2018) Lithium Coin Handbook and Application Manual Lithium/Manganese Dioxide Coin (Li/Mno2), , http://data.energizer.com/pdfs/lithiumcoin_appman.pdf, Energizer Brands LLC; Dziurdzia, P., Modelling and Simulation of Thermoelectric energy harvesting processes (2011) Sustainable Energy Harvesting Technologies: Past, Present and Future, pp. 109-116. , Kraków, Poland: AGH Univ. Science Technology; (2007) Amorphous Silicon Solar Cells, , https://media.digikey.com/pdf/Data%20Sheets/Sanyo%20Energy/Amorphous_Br.pdf, Sanyo; Tensor Ow, , https://www.tensor_ow.org/, Accessed: Jul 6 2019; Chollet, F., (2015) Keras, , https://keras.io/, Accessed: Jul 6 2019; Wielgosz, M., Analysta Data Analysis and Anomaly Detection, , https://bitbucket.org/macie.kwielgosz/anomaly_detection, Accessed: Jul 6 2019","Markiewicz, M.; Faculty of Mathematics and Computer Science, Poland; email: markiewicz@ii.uj.edu.pl",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85077238105
"Wang Z., Lin S., Xie J., Lin Y.","24082022800;57191847788;57212529261;56192613000;","Pruning Blocks for CNN Compression and Acceleration via Online Ensemble Distillation",2019,"IEEE Access","7",,"8918410","175703","175716",,13,"10.1109/ACCESS.2019.2957203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076971079&doi=10.1109%2fACCESS.2019.2957203&partnerID=40&md5=13a558c1e6623c8eb3c795c80955f3ce","Computer Engineering College, Jimei University, Xiamen, 361021, China; Department of Computer Science, National University of Singapore, Singapore, 117417, Singapore; Department of Automation, Xiamen University, Xiamen, 361005, China; Computer Engineering College, Jimei University, Xiamen, China","Wang, Z., Computer Engineering College, Jimei University, Xiamen, 361021, China; Lin, S., Department of Computer Science, National University of Singapore, Singapore, 117417, Singapore; Xie, J., Department of Automation, Xiamen University, Xiamen, 361005, China; Lin, Y., Computer Engineering College, Jimei University, Xiamen, China","In this paper, we propose an online ensemble distillation (OED) method to automatically prune blocks/layers of a target network by transferring the knowledge from a strong teacher in an end-to-end manner. To accomplish this, we first introduce a soft mask to scale the output of each block in the target network and enforce the sparsity of the mask by sparsity regularization. Then, a strong teacher network is constructed online by replicating the same target networks and ensembling the discriminative features from each target as its new features. Cooperative learning between multiple target networks and the teacher network is further conducted in a closed-loop form, which improves their performance. To solve the optimization problem in an end-to-end manner, we employ the fast iterative shrinkage-thresholding algorithm to fast and reliably remove the redundant blocks, in which the corresponding soft masks are equal to zero. Compared to other structured pruning methods with iterative fine-tuning, the proposed OED is trained more efficiently in one training cycle. Extensive experiments demonstrate the effectiveness of OED, which can not only simultaneously compress and accelerate a variety of CNN architectures but also enhance the robustness of the pruned networks. © 2013 IEEE.","Fast iterative shrinkage-thresholding algorithm; model compression and acceleration; network pruning; online ensemble distillation","Distillation; Shrinkage; Cooperative learning; Discriminative features; Iterative shrinkage-thresholding algorithms; Model compression; Multiple targets; Network pruning; Optimization problems; Sparsity regularizations; Iterative methods",,,,,"2017H6015; Xiamen Municipal Bureau of Science and Technology: 3502Z20183032; National Natural Science Foundation of China, NSFC: 61701191; Natural Science Foundation of Fujian Province: 2018J05108; National Basic Research Program of China (973 Program): 2016YFC0502902","This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFC0502902, in part by the National Natural Science Foundation of China under Grant 61701191, in part by the Key Technical Project of Fujian Province under Grant 2017H6015, in part by the Natural Science Foundation of Fujian Province under Grant 2018J05108, and in part by the Foundation of Xiamen Science and Technology Bureau under Grant 3502Z20183032.",,,,,,,,,,"Ahn, S., Hu, S.X., Damianou, A., Lawrence, N.D., Dai, Z., Variational information distillation for knowledge transfer (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 9163-9171; Alvarez, J.M., Salzmann, M., Learning the number of neurons in deep networks (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 2270-2278; Anil, R., Pereyra, G., Passos, A., Ormandi, R., Dahl, G.E., Hinton, G.E., Large scale distributed neural network training through online distillation (2018) Proc. Int. Conf. Learn. Represent., pp. 1-12; Ba, J., Caruana, R., Do deep nets really need to be deep? (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 2654-2662; Beck, A., Teboulle, M., A fast iterative shrinkage-thresholding algorithm for linear inverse problems (2009) SIAM J. Imag. Sci., 2 (1), pp. 183-202; Bucilua, C., Caruana, R., Niculescu-Mizil, A., Model compression (2006) Proc. 12th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 535-541; Chen, Z., Li, Y., Bengio, S., Si, S., You look twice: GaterNet for dynamic filter selection in CNNs (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 9172-9180; Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., Bengio, Y., (2016) Bina-rized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or-1, , https://arxiv.org/abs/1602.02830, [Online]; Courbariaux, M., Bengio, Y., David, J.-P., Binaryconnect: Training deep neural networks with binary weights during propagations (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 3123-3131; Dai, J., Li, Y., He, K., Sun, J., R-FCN: Object detection via region-based fully convolutional networks (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 379-387; Denton, E.L., Zaremba, W., Bruna, J., LeCun, Y., Fergus, R., Exploiting linear structure within convolutional networks for efficient evaluation (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 1269-1277; Gao, X., Zhao, Y., Dudziak, L., Mullins, R., Xu, C.-Z., Dynamic channel pruning: Feature boosting and suppression (2019) Proc. Int. Conf. Learn. Represent., pp. 1-14; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 580-587; Goldstein, T., Studer, C., Baraniuk, R., (2014) A Field Guide to Forward-backward Splitting with a FASTA Implementation, , https://arxiv.org/abs/1411.3406, [Online]; Gong, Y., Liu, L., Yang, M., Bourdev, L., (2014) Compressing Deep Con-volutional Networks Using Vector Quantization, , https://arxiv.org/abs/1412.6115, [Online]; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , https://arxiv.org/abs/1412.6572, [Online]; Gordon, A., Eban, E., Nachum, O., Chen, B., Wu, H., Yang, T.-J., Choi, E., MorphNet: Fast & simple resource-constrained structure learning of deep networks (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 1586-1595; Guo, Y., Yao, A., Chen, Y., Dynamic network surgery for efficient DNNs (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 1379-1387; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: Efficient inference engine on compressed deep neural network (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit. (ISCA), Jun., pp. 243-254; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding (2016) Proc. Int. Conf. Learn. Represent., pp. 1-14; Han, S., Pool, J., Tran, J., Dally, W., Learning both weights and connections for efficient neural network (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 1135-1143; Hassibi, B., Stork, D.G., Second order derivatives for network pruning: Optimal brain surgeon (1993) Proc. Adv. Neural Inf. Process. Syst., pp. 164-171; He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask R-CNN (2017) Proc. IEEE Int. Conf. Comput. Vis., Oct., pp. 2980-2988; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 770-778; He, Y., Kang, G., Dong, X., Fu, Y., Yang, Y., Soft filter pruning for accelerating deep convolutional neural networks (2018) Proc. Int. Joint Conf. Artif. Intell., pp. 2234-2240; He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., Han, S., AMC: AutoML for model compression and acceleration on mobile devices (2018) Proc. Eur. Conf. Comput. Vis, pp. 784-800. , Sep; He, Y., Zhang, X., Sun, J., Channel pruning for accelerating very deep neural networks (2017) Proc. IEEE Int. Conf. Comput. Vis., Oct., pp. 1389-1397; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in a Neural Network, , https://arxiv.org/abs/1503.02531, [Online]; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , https://arxiv.org/abs/1704.04861, [Online]; Hu, H., Peng, R., Tai, Y.-W., Tang, C.-K., (2016) Network Trimming: A Data-driven Neuron Pruning Approach towards Efficient Deep Architectures, , https://arxiv.org/abs/1607.03250, [Online]; Huang, Z., Wang, N., Data-driven sparse structure selection for deep neural networks (2018) Proc. Eur. Conf. Comput. Vis, pp. 304-320. , Sep; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5 MB model size (2017) Proc. Int. Conf. Learn. Represent., pp. 1-13; Ioffe, S., Szegedy, C., (2015) Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, , https://arxiv.org/abs/1502.03167, [Online]; Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., Kalenichenko, D., Quantization and training of neural networks for efficient integer-arithmetic-only inference (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 2704-2713; Jaderberg, M., Vedaldi, A., Zisserman, A., (2014) Speeding up Convolu-tional Neural Networks with Low Rank Expansions, , https://arxiv.org/abs/1405.3866, [Online]; Kim, Y.-D., Park, E., Yoo, S., Choi, T., Yang, L., Shin, D., Compression of deep convolutional neural networks for fast and low power mobile applications (2016) Proc. Int. Conf. Learn. Represent., pp. 1-15; Koratana, A., Kang, D., Bailis, P., Zaharia, M., LIT: Learned intermediate representation training for model compression (2019) Proc. 36th Int. Conf. Mach. Learn., pp. 3509-3518; Krizhevsky, A., Hinton, G., (2009) Learning Multiple Layers of Features from Tiny Images, , Univ. Toronto, Toronto, ON, Canada, Tech. Rep. TR-2009; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World, , arXiv preprint; Lebedev, V., Ganin, Y., Rakhuba, M., Oseledets, I., Lempitsky, V., Speeding-up convolutional neural networks using fine-tuned CP-decomposition (2015) Proc. Int. Conf. Learn. Represent., pp. 1-10; Lebedev, V., Lempitsky, V., Fast convnets using group-wise brain damage (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 2554-2564; LeCun, Y., Denker, J.S., Solla, S.A., Howard, R.E., Jackel, L.D., Optimal brain damage (1989) Proc. Adv. Neural Inf. Process. Syst., 2, pp. 598-605; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning filters for efficient convnets (2017) Proc. Int. Conf. Learn. Represent., pp. 1-9; Li, J., Qi, Q., Wang, J., Ge, C., Li, Y., Yue, Z., Sun, H., OICSR: Out-in-channel sparsity regularization for compact deep neural networks (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 7046-7055; Liang, L., Deng, L., Zeng, Y., Hu, X., Ji, Y., Ma, X., Li, G., Xie, Y., Crossbar-aware neural network pruning (2018) IEEE Access, 6, pp. 58324-58337; Lin, J., Rao, Y., Lu, J., Zhou, J., Runtime neural pruning (2017) Proc. Adv. Neural Inf. Process. Syst., pp. 2181-2191; Lin, M., Chen, Q., Yan, S., (2013) Network in Network, , https://arxiv.org/abs/1312.4400, [Online]; Lin, S., Ji, R., Chen, C., Tao, D., Luo, J., Holistic CNN com-pression via low-rank decomposition with knowledge transfer (2019) IEEE Trans. Pattern Anal. Mach. Intell., 41 (12), pp. 2889-2905. , Dec; Lin, S., Ji, R., Guo, X., Li, X., Towards convolutional neural networks compression via global error reconstruction (2016) Proc. Int. Joint Conf. Artif. Intell., pp. 1753-1759; Lin, S., Ji, R., Li, Y., Deng, C., Li, X., Toward compact convnets via structure-sparsity regularized filter pruning IEEE Trans. Neural Netw. Learn. Syst, , to be published; Lin, S., Ji, R., Li, Y., Wu, Y., Huang, F., Zhang, B., Accelerating convolutional networks via global & dynamic filter pruning (2018) Proc. Int. Joint Conf. Artif. Intell., pp. 2425-2432; Lin, S., Ji, R., Yan, C., Zhang, B., Cao, L., Ye, Q., Huang, F., Doermann, D., Towards optimal structured cnn pruning via generative adversarial learning (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 2790-2799; Lin, Y.-H., Chou, C.-N., Chang, E.Y., MBS: Macroblock scaling for CNN model reduction (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 9117-9125; Liu, B., Wang, M., Foroosh, H., Tappen, M., Pensky, M., Sparse con-volutional neural networks (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 806-814; Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C., Learning efficient convolutional networks through network slimming (2017) Proc. IEEE Int. Conf. Comput. Vis., Oct., pp. 2755-2763; Liu, Z., Mu, H., Zhang, X., Guo, Z., Yang, X., Cheng, T.K.-T., Sun, J., (2019) Metapruning: Meta Learning for Automatic Neural Network Channel Pruning, , https://arxiv.org/abs/1903.10258, [Online]; Luo, J., Wu, J., Lin, W., ThiNet: A filter level pruning method for deep neural network compression (2017) Proc. IEEE Int. Conf. Comput. Vis., Oct., pp. 2790-2799; Ma, N., Zhang, X., Zheng, H.-T., Sun, J., ShuffleNet V2: Practical guidelines for efficient cnn architecture design (2018) Proc. Eur. Conf. Com-put. Vis, pp. 116-131. , Sep; Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J., Pruning convolu-tional neural networks for resource efficient inference (2017) Proc. Int. Conf. Learn. Represent., pp. 1-17; Nair, V., Hinton, G., Rectified linear units improve restricted Boltz-mann machines (2010) Proc. Int. Conf. Mach. Learn., pp. 807-814; Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Lerer, A., Automatic differentiation in pytorch (2017) Proc. Adv. Neural Inf. Process. Syst. Workshops, pp. 1-4; Rao, Y., Lu, J., Lin, J., Zhou, J., Runtime network routing for efficient image classification (2019) IEEE Trans. Pattern Anal. Mach. Intell., 41 (10), pp. 2291-2304. , Oct; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., XNOR-Net: Imagenet classification using binary convolutional neural networks (2016) Proc. Eur. Conf. Comput. Vis., pp. 525-542; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 91-99; Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y., Fitnets: Hints for thin deep nets (2015) Proc. Int. Conf. Learn. Represent., pp. 1-15; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252. , Dec; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C., MobileNetV2: Inverted residuals and linear bottlenecks (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 4510-4520; Shelhamer, E., Long, J., Darrell, T., Fully convolutional networks for semantic segmentation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (4), pp. 640-651. , Apr; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proc. Int. Conf. Learn. Represent., pp. 1-10; Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey (2017) Proc. IEEE, 105 (12), pp. 2295-2329. , Dec; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 1-9; Veit, A., Belongie, S., Convolutional networks with adaptive inference graphs (2018) Proc. Eur. Conf. Comput. Vis, pp. 3-18. , Sep; Veit, A., Wilber, M.J., Belongie, S., Residual networks behave like ensembles of relatively shallow networks (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 550-558; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning structured sparsity in deep neural networks (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 2074-2082; Wu, Z., Nagarajan, T., Kumar, A., Rennie, S., Davis, L.S., Grauman, K., Feris, R., Blockdrop: Dynamic inference paths in residual net-works (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 8817-8826; Xie, S., Girshick, R., Dollár, P., Tu, Z., He, K., Aggregated residual transformations for deep neural networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jul., pp. 5987-5995; Ye, J., Lu, X., Lin, Z., Wang, J.Z., Rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers (2018) Proc. Int. Conf. Learn. Represent., pp. 1-11; Yim, J., Joo, D., Bae, J., Kim, J., A gift from knowledge dis-tillation: Fast optimization, network minimization and transfer learning (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jul., pp. 4133-4141; Yoon, J., Hwang, S.J., Combined group and exclusive sparsity for deep neural networks (2017) Proc. 34th Int. Conf. Mach. Learn., 70, pp. 3958-3966; Yu, R., Li, A., Chen, C.-F., Lai, J.-H., Morariu, V.I., Han, X., Gao, M., Davis, L.S., NISP: Pruning networks using neuron importance score propagation (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recog-nit., Jun., pp. 9194-9203; Zagoruyko, S., Komodakis, N., (2016) Wide Residual Networks, , https://arxiv.org/abs/1605.07146, [Online]; Zagoruyko, S., Komodakis, N., Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer (2017) Proc. Int. Conf. Learn. Represent., pp. 1-13; Zhang, Q., Zhang, M., Wang, M., Sui, W., Meng, C., Yang, J., Kong, W., Lin, W., Efficient deep learning inference based on model compression (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 1695-1702; Zhang, X., Zhou, X., Lin, M., Sun, J., Shufflenet: An extremely efficient convolutional neural network for mobile devices (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 2074-2082; Zhang, X., Zou, J., Ming, X., He, K., Sun, J., Efficient and accurate approximations of nonlinear convolutional networks (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 1984-1992; Zhang, Y., Xiang, T., Hospedales, T.M., Lu, H., Deep mutual learning (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 4320-4328; Zhou, W., Niu, Y., Zhang, G., Sensitivity-oriented layer-wise acceleration and compression for convolutional neural network (2019) IEEE Access, 7, pp. 38264-38272","Lin, S.; Department of Computer Science, Singapore; email: shaohuilin007@gmail.com",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85076971079
"Roukhami M., Lazarescu M.T., Gregoretti F., Lahbib Y., Mami A.","57194648504;7005603621;57215571662;8894658300;6602619622;","Very low power neural network FPGA accelerators for tag-less remote person identification using capacitive sensors",2019,"IEEE Access","7",,"2931392","102217","102231",,7,"10.1109/ACCESS.2019.2931392","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070482507&doi=10.1109%2fACCESS.2019.2931392&partnerID=40&md5=20fdc58d1e4cdd10a9cff702c5246cfa","UR-LAPER, Faculty of Sciences of Tunis, University of Tunis El-Manar, Tunis, 2092, Tunisia; Department of Electronics and Telecommunications, Politecnico di Torino, Torin, 10129, Italy; LR-EµE, ENICarthage, University of Carthage, Tunis, 2035, Tunisia","Roukhami, M., UR-LAPER, Faculty of Sciences of Tunis, University of Tunis El-Manar, Tunis, 2092, Tunisia; Lazarescu, M.T., Department of Electronics and Telecommunications, Politecnico di Torino, Torin, 10129, Italy; Gregoretti, F., Department of Electronics and Telecommunications, Politecnico di Torino, Torin, 10129, Italy; Lahbib, Y., LR-EµE, ENICarthage, University of Carthage, Tunis, 2035, Tunisia; Mami, A., UR-LAPER, Faculty of Sciences of Tunis, University of Tunis El-Manar, Tunis, 2092, Tunisia","Human detection, identification, and monitoring are essential for many applications aiming to make smarter the indoor environments, where most people spend much of their time (like home, office, transportation, or public spaces). The capacitive sensors can meet stringent privacy, power, cost, and unobtrusiveness requirements, they do not rely on wearables or specific human interactions, but they may need significant on-board data processing to increase their performance. We comparatively analyze in terms of overall processing time and energy several data processing implementations of multilayer perceptron neural networks (NNs) on board capacitive sensors. The NN architecture, optimized using augmented experimental data, consists of six 17-bit inputs, two hidden layers with eight neurons each, and one four-bit output. For the software (SW) NN implementation, we use two STMicroelectronics STM32 low-power ARM microcontrollers (MCUs): one MCU optimized for power and one for performance. For hardware (HW) implementations, we use four ultralow-power field-programmable gate arrays (FPGAs), with different sizes, dedicated computation blocks, and data communication interfaces (one FPGA from the Lattice iCE40 family and three FPGAs from the Microsemi IGLOO family). Our shortest SW implementation latency is 54.4 µs and the lowest energy per inference is 990 nJ, while the shortest HW implementation latency is 1.99 µs and the lowest energy is 39 nJ (including the data transfer between MCU and FPGA). The FPGAs active power ranges between 6.24 and 34.7 mW, while their static power is between 79 and 277 µW. They compare very favorably with the static power consumption of Xilinx and Altera low-power device families, which is around 40 mW. The experimental results show that NN inferences offloaded to external FPGAs have lower latency and energy than SW ones (even when using HW multipliers), and the FPGAs with dedicated computational blocks (multiply-accumulate) perform best. © 2019 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Capacitive sensing; Embedded design optimization; Hardware acceleration; Hardware design; Indoor person identification; Neural networks; Ultra-low power FPGAs","Data handling; Data transfer; Field programmable gate arrays (FPGA); Low power electronics; Microcontrollers; Multilayer neural networks; Neural networks; Wearable sensors; Capacitive sensing; Embedded designs; Hardware acceleration; Hardware design; Person identification; Ultra low power; Capacitive sensors",,,,,,,,,,,,,,,,"Iqbal, J., Lazarescu, M.T., Tariq, O.B., Arif, A., Lavagno, L., Capacitive sensor for tagless remote human identification using body frequency absorption signatures (2018) IEEE Trans. Instrum. Meas., 67 (4), pp. 789-797. , Apr; Xiao, J., Zhou, Z., Yi, Y., Ni, L.M., A survey on wireless indoor localization from the device perspective (2016) ACM Comput. Surv., 49 (2), p. 25. , Oct; Wang, C., Chen, S., Yang, Y., Hu, F., Liu, F., Wu, J., Literature review on wireless sensing-Wi-Fi signal-based recognition of human activities (2018) Tsinghua Sci. Technol., 23 (2), pp. 203-222. , Apr; Sharma, S., Ghose, A., Analysis of analog signal from PIR-sensors for human analytics in an IOTized environment (2018) Proc. 3rd IEEE Int. Conf. Internet Things, Smart Innov. Usages (IoT-SIU), pp. 1-6. , Feb; Fang, J.S., Hao, Q., Brady, D.J., Guenther, B.D., Hsu, K.Y., Real-time human identification using a pyroelectric infrared detector array and hidden Markov models (2006) Opt. Express, 14 (15), pp. 6643-6658. , Jul; Khalil, N., Benhaddou, D., Gnawali, O., Subhlok, J., Nonintrusive occupant identification by sensing body shape and movement (2016) Proc. ACM Int. Conf. Syst. Energy-Efficient Built Environ. (ACM BuildSys), pp. 1-10; Mokhtari, G., Zhang, Q., Hargrave, C., Ralston, J.C., Non-wearable UWB sensor for human identification in smart home (2017) IEEE Sensors J, 17 (11), pp. 3332-3340. , Jun; Pan, S., Yu, T., Mirshekari, M., Fagert, J., Bonde, A., Mengshoel, O.J., Noh, H.Y., Zhang, P., Footprintid: Indoor pedestrian identification through ambient structural vibration sensing (2017) Proc. ACM Interact. Mobile Wearable Ubiquitous Technol., 1 (3), pp. 891-8931. , Sep; Puppendahl, T.G., Dellangnol, X., Hatzfeld, C., Fu, B., Kupnik, M., Kuijper, A., Hastall, M., Gruteser, M., PlatyPus: Indoor localization and identification through sensing of electric potential changes in human bodies (2016) Proc. 14th Int. Conf. MobiSys. ACM, pp. 17-30; Braun, A.W., Wichert, R., Kuijper, A., Fellner, D.W., Capacitive proximity sensing in smart environments (2015) J. Ambient Intell. Smart Environ., 7 (4), pp. 483-510; Grosse-Puppendahl, T., Holz, C., Cohn, G., Wimmer, R., Bechtold, O., Hodges, S., Reynolds, M.S., Smith, J.R., Finding common ground: A survey of capacitive sensing in human-computer interaction (2017) Proc. SIGCHI Conf. Hum. Factors Comput. Syst. (CHI), pp. 3293-3315; Iqbal, J., Arif, A., Tariq, O.B., Lazarescu, M.T., Lavagno, L., A contact-less sensor for human body identification using RF absorption signatures (2017) Proc. IEEE Sensors Appl. Symp. (SAS), pp. 1-6. , Mar; Arshad, A., Khan, S., Alam, A.H.M.Z., Tasnim, R., Gunawan, T.S., Ahmad, R., Nataraj, C., An activity monitoring system for senior citizens living independently using capacitive sensing technique (2016) Proc. Instrum. Meas. Technol. Conf. Proc. (I2MTC), pp. 1-6. , May; Akhmareh, A.R., Lazarescu, M.T., Tariq, O.B., Lavagno, L., A tagless indoor localization system based on capacitive sensing technology (2016) Sensors, 16 (9), p. 1448; Iqbal, J., Lazarescu, M.T., Tariq, O.B., Lavagno, L., Long range, high sensitivity, low noise capacitive sensor for tagless indoor human localization (2017) Proc. 7th IEEE Int. Workshop Adv. Sensors Int. (IWASI), pp. 189-194. , Vieste, Italy, Jun; Iqbal, J., Lazarescu, M.T., Arif, A., Lavagno, L., High sensitivity, low noise front-end for long range capacitive sensors for tagless indoor human localization (2017) Proc. 3rd IEEE Int. Forum Res. Technol. Soc. Ind. (RTSI), pp. 189-194. , Modena, Italy, Sep; Abiodun, O.I., Jantan, A., Omolara, A.E., Dada, K.V., Mohamed, N., Arshad, H., State-of-the-art in artificial neural network applications: A survey (2018) Heliyon, 4 (11). , Nov; Tariq, O.B., Lazarescu, M.T., Iqbal, J., Lavagno, L., Performance of machine learning classifiers for indoor person localization with capacitive sensors (2017) IEEE Access, 5, pp. 12913-12926. , Jul; Lavi, B., Serj, M.F., Ullah, I., Survey on deep learning techniques for person re-identification task (2018) Proc. CVPR, , https://arxiv.org/abs/1807.05284, Jun. Online; Guo, K., Zeng, S., Yu, J., Yang, Y., Yang, H., A survey of FPGA based neural network accelerator (2017) ACM Trans. Reconfigurable Technol. Syst., 9 (4), p. 11. , Dec; Braga, A.L.S., Llanos, C.H., Gohringer, D., Obie, J., Performance, accuracy, power consumption and resource utilization analysis for hardware/software realized artificial neural networks (2010) Proc. IEEE 5th Int. Conf. Bio-Inspired Comput., Theories Appl. (BIC-TA), pp. 1629-1636. , Sep; Blaiech, A.G., Khalifa, K.B., Boubaker, M., Bedoui, M.H., Multi-width fixed-point coding based on reprogrammable hardware implementation of a multi-layer perceptron neural network for alertness classification (2010) Proc. 10th Int. Conf. Intell. Syst. Design Appl. (ISDA), pp. 610-614. , Dec; Bahoura, M., Park, C.-W., FPGA-implementation of high-speed MLP neural network (2011) Proc. 18th IEEE Int. Conf. Electron., Circuits Syst. (ICECS), pp. 426-429. , Dec; Zhai, X., Ali, A.A.S., Amira, A., Bensaali, F., MLP neural network based gas classification system on Zynq SoC (2016) IEEE Access, 4, pp. 8138-8146; Latino, C., Moreno-Armendariz, M.A., Hagan, M., Realizing general MLP networks with minimal FPGA resources (2009) Proc. Int. Joint Conf. Neural Netw., pp. 1722-1729. , Jun; Hariprasath, S., Prabakar, T.N., A pipelined approach for FPGA implementation of multi modal biometric pattern recognition using prototype based supervised neural network (2014) Proc. Int. Conf. Commun. Signal Process., pp. 1837-1843. , Nov; Bettoni, M., Urgese, G., Kobayashi, Y., Macii, E., Acquaviva, A., A convolutional neural network fully implemented on FPGA for embedded platforms (2017) Proc. New Gener. CAS (NGCAS), pp. 49-52. , Genoa, Italy, Sep; Abbas, S.A., Vicithra, G., Actualization of face detection in FPGA using neural network (2016) Proc. Int. Conf. Wireless Commun., Signal Process. Netw. (WiSPNET), pp. 634-638. , Chennai, India; Dawwd, S.A., Mahmood, B.S., Video-based face recognition via convolutional neural networks (2011) New Approaches to Characterization and Recognition of Faces, pp. 131-152. , Croatia, Rijeka: InTech; Gabriel, G., Jara, C., Pomares, J., Alabdo, A., Poggi, L., Torres, F., A survey on FPGA-based sensor systems: Towards intelligent and reconfigurable low-power sensors for computer vision, control and signal processing (2014) Sensors, 14 (4), pp. 6247-6278. , https://www.mdpi.com/1424-8220/14/4/6247, Online; De La Piedra, A., Braeken, A., Touhafi, A., Sensor systems based on FPGAs and their applications: A survey (2012) Sensors, 12 (9), pp. 12235-12264; Klauenberg, B.J., Miklavčič, D., (2012) Radio Frequency Radiation Dosimetry and Its Relationship to the Biological Effects of Electromagnetic Fields, 82. , Springer; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444. , May; Lemley, J., Bazrafkan, S., Corcoran, P., Smart augmentation learning an optimal data augmentation strategy (2017) IEEE Access, 4, pp. 5858-5869. , Apr; Sola, J., Sevilla, J., Importance of input data normalization for the application of neural networks to complex industrial problems (1997) IEEE Trans. Nucl. Sci., 44 (3), pp. 1464-1468. , Jun; Jayalakshmi, T., Santhakumaran, A., Statistical normalization and back propagation for classification (2011) Int. J. Comput. Theory Eng., 3 (1), pp. 89-93; Tiwari, V., Khare, N., Hardware implementation of neural network with sigmoidal activation functions using CORDIC (2015) Microprocess. Microsyst., 39 (6), pp. 373-381; Sahin, I., Koyuncu, I., Design and implementation of neural networks neurons with radBas, logsig, and tansig activation functions on FPGA (2012) Elektronika Ir Elektrotechnika, 120 (4), pp. 51-54; Lavagno, L., Lazarescu, M.T., Papaefstathiou, L., Brokalakis, A., Walters, J., Kienhuis, B., Schäfer, F., HEAP: A highly efficient adaptive multi-processor framework (2013) Microprocess. Microsyst., 37 (8), pp. 1050-1062; Arif, A., Barrigon, F.A., Gregoretti, F., Iqbal, J., Lavagno, L., Lazarescu, M.T., Ma, L., Segura, J.L.L., Performance and energy-efficient implementation of a smart city application on FPGAs (2018) J. Real-Time Image Process., pp. 1-15. , Jun; Sayyah, P., Lazarescu, M.T., Bocchio, S., Ebeid, E., Palermo, G., Quaglia, D., Rosti, A., Lavagno, L., Virtual platform-based design space exploration of power-efficient distributed embedded applications (2015) ACM Trans. Embedded Comput. Syst., 14 (3), p. 49; Qiu, J., Wang, J., Yao, S., Guo, K., Li, B., Zhou, E., Yu, J., Yang, H., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays ACM, pp. 26-35; Jiao, L., Luo, C., Cao, W., Zhou, X., Wang, L., Accelerating low bit-width convolutional neural networks with embedded FPGA (2017) Proc. IEEE 27th Int. Conf. Field Program. Logic Appl. (FPL), pp. 1-4. , Sep; Lemieux, G.G., Edwards, J., Vandergriendt, J., Severance, A., De Iaco, R., Raouf, A., Osman, H., Singh, S., (2019) TinBiNN: Tiny Bina-Rized Neural Network Overlay in about 5,000 4-LUTs and 5mW, , https://arxiv.org/abs/1903.06630, Online; (2016) STM32L15x6/8/B, , DocID17659 Rev 12, Rev12, STMicroelectron., Geneva, Switzerland, Apr; (2015) STM32F103x8, , DocID13587 Rev 17, Rev17, STMicroelectron., Geneva, Switzerland, Aug; Síma, J., Orponen, P., General-purpose computation with neural networks: A survey of complexity theoretic results (2003) Neural Comput, 15 (12), pp. 2727-2778; (2017) iCE40 UltraPlus Family: Data Sheet, Lattice Semicond, , Hillsboro, OR, USA, Aug; (2016) IGLOO Low Power Flash FPGAs with Flash∗ Freeze Technology, Data Sheet, , DS0095: Microsemi, Aliso Viejo, CA, USA, May; Qamar, A., Muslim, F.B., Gregoretti, F., Lavagno, L., Lazarescu, M.T., High-level synthesis for semi-global matching: Is the juice worth the squeeze? (2016) IEEE Access, 5, pp. 8419-8432","Roukhami, M.; UR-LAPER, Tunisia; email: marwen.roukhami@fst.utm.tn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85070482507
"Lei P., Liang J., Guan Z., Wang J., Zheng T.","55066403400;57210177404;57191897502;57200022394;57203092940;","Acceleration of FPGA Based Convolutional Neural Network for Human Activity Classification Using Millimeter-Wave Radar",2019,"IEEE Access","7",,"8753553","88917","88926",,16,"10.1109/ACCESS.2019.2926381","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069765470&doi=10.1109%2fACCESS.2019.2926381&partnerID=40&md5=1f9421926f6ef0ed838654744986310c","School of Electronic and Information Engineering, Beihang University, Beijing, 100191, China; School of Cyber Science and Technology, Beihang University, Beijing, 100191, China","Lei, P., School of Electronic and Information Engineering, Beihang University, Beijing, 100191, China; Liang, J., School of Electronic and Information Engineering, Beihang University, Beijing, 100191, China; Guan, Z., School of Cyber Science and Technology, Beihang University, Beijing, 100191, China; Wang, J., School of Electronic and Information Engineering, Beihang University, Beijing, 100191, China; Zheng, T., School of Electronic and Information Engineering, Beihang University, Beijing, 100191, China","Deep learning techniques have attracted much attention in the radar automatic target recognition. In this paper, we investigate an acceleration method of the convolutional neural network (CNN) on the field-programmable gate array (FPGA) for the embedded application of the millimeter-wave (mmW) radar-based human activity classification. Considering the micro-Doppler effect caused by a person's body movements, the spectrogram of mmW radar echoes is adopted as the CNN input. After that, according to the CNN architecture and the properties of the FPGA implementation, several parallel processing strategies are designed as well as data quantization and optimization of classification decision to accelerate the CNN execution. Finally, comparative experiments and discussions are carried out based on a measured dataset of nine individuals with four different actions by using a 77-GHz mmW radar. The results show that the proposed method not only maintains the high classification accuracy but also improves its execution speed, memory requirement, and power consumption. Specifically, compared with the implementation of the same network model on a graphics processing unit, it could achieve the speedup of about 30.42% at the cost of the classification accuracy loss of only 0.27%. © 2013 IEEE.","acceleration; convolutional neural network; field-programmable gate array; Human activity classification; millimeter-wave radar","Acceleration; Automatic target recognition; Computer graphics; Convolution; Deep learning; Field programmable gate arrays (FPGA); Graphics processing unit; Logic gates; Millimeter waves; Neural networks; Program processors; Radar; Radar target recognition; Classification accuracy; Classification decision; Comparative experiments; Convolutional neural network; FPGA implementations; Human activities; Millimeter wave radar; Radar automatic target recognition; Radar measurement",,,,,"National Natural Science Foundation of China, NSFC: 61501011, 61671035","This work was supported in part by the National Natural Science Foundation of China under Grant 61501011 and Grant 61671035.",,,,,,,,,,"Barton, D.K., Leonov, S.A., (1997) Radar Technology Encyclopedia, , Boston, MA, USA: Artech House; Kishida, M., Ohguchi, K., Shono, M., 79 GHz-band high-resolution millimeter-wave radar (2015) FUJITSU Sci. Tech. J., 51 (4), pp. 55-59. , Oct; Lien, J., Gillian, N., Karagozler, M.E., Amihood, P., Schwesig, C., Olson, E., Raja, H., Poupyrev, I., Soli: Ubiquitous gesture sensing with millimeter wave radar (2016) ACM Trans. Graph., 35 (4). , Jul; (2019), https://www.infineon.com/cms/en/product/sensor/radar-sensor-ics/77ghz-front-end-radar-ics/, Infineon Technologies AG. 77 GHz Front-End Radar ICs. Accessed: Feb. 25; (2018), http://www.ti.com/sensors/mmwave/overview.html, Texas Instruments Incorporated. MmWave Sensors. Accessed: Dec. 3; (2019), https://www.continental-automotive.com/en-gl/Passenger-Cars/Chassis-Safety/Advanced-Driver-Assistance-Systems/Radars, Continental AG. Radars. Accessed: Jan. 8; Dickmann, J., Klappstein, J., Hahn, M., Appenrodt, N., Bloecher, H.-L., Werber, K., Sailer, A., Automotive radar the key technology for autonomous driving: From detection and ranging to environmental understanding (2016) Proc. IEEE Radar Conf., pp. 1-6. , Philadelphia, PA, USA, May; Mazouni, K., Zeitler, A., Lanteri, J., Pichot, C., Dauvignac, J.-Y., Migliaccio, C., Yonemoto, N., Futatsumori, S., 76.5 GHz millimeterwave radar for foreign objects debris detection on airport runways (2012) Int. J. Microw. Wireless Technol., 4 (3), pp. 317-326. , Jun; Amin, M.G., Zhang, Y.D., Ahmad, F., Ho, K.C.D., Radar signal processing for elderly fall detection: The future for in-home monitoring (2016) IEEE Signal Process. Mag., 33 (2), pp. 71-80. , Mar; Vandersmissen, B., Knudde, N., Jalalvand, A., Couckuyt, I., Bourdoux, A., Neve, W.D., Dhaene, T., Indoor person identification using a lowpower FMCW radar (2018) IEEE Trans. Geosci. Remote Sens., 56 (7), pp. 3941-3952. , Jul; Patel, J.S., Fioranelli, F., Ritchie, M., Griffiths, H., Multistatic radar classification of armed vs unarmed personnel using neural networks (2018) Evolving Syst., 9 (2), pp. 135-144. , Jun; Chen, V.C., Li, F., Ho, S.-S., Wechsler, H., Micro-Doppler effect in radar: Phenomenon, model, and simulation study (2006) IEEE Trans. Aerosp. Electron. Syst., 42 (1), pp. 2-21. , Jan; Kim, Y., Ling, H., Human activity classification based on micro-Doppler signatures using a support vector machine (2009) IEEE Trans. Geosci. Remote Sens., 47 (5), pp. 1328-1337. , May; Kim, Y., Choudhury, S., Kong, H.-J., Application of micro-Doppler signatures for estimation of total energy expenditure in humans for walking/ running activities (2016) IEEE Access, 4, pp. 1548-1557; Nanzer, J.A., Rogers, R.L., Bayesian classification of humans and vehicles using micro-Doppler signals from a scanning-beam radar (2009) IEEE Microw. Wireless Compon. Lett., 19 (5), pp. 338-340. , May; Kim, Y., Moon, T., Human detection and activity classification based on micro-Doppler signatures using deep convolutional neural networks (2016) IEEE Geosci. Remote Sens. Lett., 13 (1), pp. 8-12. , Jan; Le, H.T., Phung, S.L., Bouzerdoum, A., Tivive, F.H.C., Human motion classification with micro-Doppler radar and Bayesian-optimized convolutional neural networks (2018) Proc. IEEE Int. Conf. Acoust., pp. 2961-2965. , Speech Signal Process., Calgary, AB, Canada, Apr; Jokanovi, B., Amin, M., Fall detection using deep learning in range-Doppler radars (2018) IEEE Trans. Aerosp. Electron. Syst., 54 (1), pp. 180-189. , Feb; Qiu, J., Wang, J., Yao, S., Guo, K., Li, B., Zhou, E., Yu, J., Yang, H., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays (FPGA), pp. 26-35. , Monterey, CA, USA, Feb; Suda, N., Chandra, V., Dasika, G., Mohanty, A., Ma, Y., Vrudhula, S., Seo, J.-S., Cao, Y., Throughput-optimized OpenCL-based FPGA accelerator for large-scale convolutional neural networks (2016) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays (FPGA), pp. 16-25. , Monterey, CA, USA, Feb; Venieris, S.I., Bouganis, C.-S., Latency-driven design for FPGA-based Convolutional Neural Networks (2017) Proc. 27th Int. Conf. Field Program. Logic Appl., pp. 1-8. , Ghent, Belgium, Sep; Chen, V.C., Doppler signatures of radar backscattering from objects with micro-motions (2008) IET Signal Process., 2 (3), pp. 291-300. , Sep; Hinz, J.O., Zölzer, U., A MIMO FMCW radar approach to HFSWR (2011) Adv. Radio Sci., 9, pp. 159-163. , Jul; Chen, V.C., Ling, H., (2002) Time-Frequency Transforms for Radar Imaging and Signal Analysis, , Boston, MA, USA: Artech House; Nair, V., Hinton, G.E., Rectified linear units improve restricted Boltzmann machines (2010) Proc. 27th Int. Conf. Int. Conf. Mach. Learn., pp. 807-814. , Haifa, Israel, Aug; Collobert, R., Large scale machine learning (2004) Ph.D. Dissertation, , Dept. Comput. Sci., Univ. Paris VI, Pairs, France; Ramachandran, P., Zoph, B., Le, Q.V., Searching for activation functions (2018) Proc. Int. Conf. Learn. Represent., pp. 1-13. , Vancouver, BC, Canada, Apr; Bishop, C.M., (2006) Pattern Recognition and Machine Learning, , New York, NY, USA: Springer; Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E., Hardware accelerated convolutional neural networks for synthetic vision systems (2010) Proc. IEEE Int. Symp. Circuits Syst., pp. 257-260. , Pairs, France, May; (2019), http://www.ti.com/tool/AWR1443BOOST, Texas Instruments Incorporated. AWR1443 Single-Chip 76-GHz to 81-GHz Automotive Radar Sensor Evaluation Module. Accessed: Feb. 26; https://www.xilinx.com/support/documentation/boards_and_kits/zc706/ug954-zc706-eval-board-xc7z045-ap-soc.pdf, Xilinx Incorporated. ZC706 Evaluation Board for the Zynq-7000 XC7Z045 SoC. Accessed: Mar. 12, 2019; (2018), https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080-ti/, NVIDIA Corporation. Geforce GTX 1080 Ti. Accessed: Nov. 5","Guan, Z.; School of Cyber Science and Technology, China; email: guanzhenyu@buaa.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85069765470
"Medus L.D., Iakymchuk T., Frances-Villora J.V., Bataller-Mompean M., Rosado-Munoz A.","57204595828;49963384800;7003499546;57211149886;57200000359;","A Novel Systolic Parallel Hardware Architecture for the FPGA Acceleration of Feedforward Neural Networks",2019,"IEEE Access","7",,"8731886","76084","76103",,22,"10.1109/ACCESS.2019.2920885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068255313&doi=10.1109%2fACCESS.2019.2920885&partnerID=40&md5=c7f44b0b29947b13cd207168b40536d1","Department of Electronic Engineering, Group for Processing and Digital Design, Universitat de Valencia, Burjassot, 46100, Spain","Medus, L.D., Department of Electronic Engineering, Group for Processing and Digital Design, Universitat de Valencia, Burjassot, 46100, Spain; Iakymchuk, T., Department of Electronic Engineering, Group for Processing and Digital Design, Universitat de Valencia, Burjassot, 46100, Spain; Frances-Villora, J.V., Department of Electronic Engineering, Group for Processing and Digital Design, Universitat de Valencia, Burjassot, 46100, Spain; Bataller-Mompean, M., Department of Electronic Engineering, Group for Processing and Digital Design, Universitat de Valencia, Burjassot, 46100, Spain; Rosado-Munoz, A., Department of Electronic Engineering, Group for Processing and Digital Design, Universitat de Valencia, Burjassot, 46100, Spain","New chips for machine learning applications appear, they are tuned for a specific topology, being efficient by using highly parallel designs at the cost of high power or large complex devices. However, the computational demands of deep neural networks require flexible and efficient hardware architectures able to fit different applications, neural network types, number of inputs, outputs, layers, and units in each layer, making the migration from software to hardware easy. This paper describes novel hardware implementing any feedforward neural network (FFNN): multilayer perceptron, autoencoder, and logistic regression. The architecture admits an arbitrary input and output number, units in layers, and a number of layers. The hardware combines matrix algebra concepts with serial-parallel computation. It is based on a systolic ring of neural processing elements (NPE), only requiring as many NPEs as neuron units in the largest layer, no matter the number of layers. The use of resources grows linearly with the number of NPEs. This versatile architecture serves as an accelerator in real-time applications and its size does not affect the system clock frequency. Unlike most approaches, a single activation function block (AFB) for the whole FFNN is required. Performance, resource usage, and accuracy for several network topologies and activation functions are evaluated. The architecture reaches 550 MHz clock speed in a Virtex7 FPGA. The proposed implementation uses 18-bit fixed point achieving similar classification performance to a floating point approach. A reduced weight bit size does not affect the accuracy, allowing more weights in the same memory. Different FFNN for Iris and MNIST datasets were evaluated and, for a real-time application of abnormal cardiac detection, a-0.112em ×-0.112em 256 acceleration was achieved. The proposed architecture can perform up to 1980 Giga operations per second (GOPS), implementing the multilayer FFNN of up to 3600 neurons per layer in a single chip. The architecture can be extended to bigger capacity devices or multi-chip by the simple NPE ring extension. © 2013 IEEE.","deep neural networks; Feedforward neural networks-FFNN; FPGA implementation; neural network acceleration; systolic hardware architecture","Application programs; Chemical activation; Clocks; Deep neural networks; Digital arithmetic; Feedforward neural networks; Field programmable gate arrays (FPGA); Matrix algebra; Multilayers; Network architecture; Parallel architectures; Topology; Classification performance; Computational demands; Feedforward neural networks (FFNN); FPGA implementations; Giga-operations per seconds; Hardware architecture; Machine learning applications; Proposed architectures; Multilayer neural networks",,,,,,,,,,,,,,,,"Zhang, C., Wu, D., Sun, J., Sun, G., Luo, G., Cong, J., Energy-efficient CNN implementation on a deeply pipelined FPGA cluster (2016) Proc. Int. Symp. Low Power Electron. Design, New York, NY, USA, pp. 326-331. , Aug; Zhu, J., Sutton, P., (2003) FPGA Implementations of Neural Networks-A Survey of a Decade of Progress, pp. 1062-1066. , Berlin Heidelberg: Springer; Clemente, J.A., Mansour, W., Ayoubi, R.A., Serrano, R., Mecha, H., Ziade, H., El Falou, W., Velazco, R., Hardware implementation of a fault-tolerant hopfield neural network on FPGAs (2016) Neurocomputing, 171, pp. 1606-1609. , Jan; Nedjah, N., Da Silva, F.P., De Sa, A.O., De Mourelle MacEdo, L., Bonilla, D.A., A massively parallel pipelined reconfigurable design for M-PLN based neural networks for efficient image classification (2016) Neurocomputing, 183, pp. 39-55. , Mar; Messalti, S., Harrag, A., Loukriz, A., A new variable step size neural networks MPPT controller: Review, simulation and hardware implementation (2017) Renew. Sustain. Energy Rev., 68, pp. 221-233. , Feb; Tang, Z.-L., Li, S.-M., Yu, L.-J., Implementation of deep learning-based automatic modulation classifier on FPGA SDR platform (2018) Electronics, 7 (7), p. 122. , Jul; Iranpour, E., Sharifian, S., An FPGA implemented brain emotional learning intelligent admission controller for SaaS cloud servers (2017) Trans. Inst. Meas. Control, 39 (10), pp. 1522-1536. , Oct; Ortega-Zamorano, F., Jerez, J.M., Muñoz, D.U., Luque-Baena, R.M., Franco, L., Efficient implementation of the backpropagation algorithm in FPGAs and microcontrollers (2016) IEEE Trans. Neural Netw. Learn. Syst., 27 (9), pp. 1840-1850. , Sep; Juang, C.-F., Chen, C.-Y., An interval type-2 neural fuzzy chip with on-chip incremental learning ability for time-varying data sequence prediction and system control (2014) IEEE Trans. Neural Netw. Learn. Syst., 25 (1), pp. 216-228. , Jan; Kim, L.-W., Deepx: Deep learning accelerator for restricted Boltzmann machine artificial neural networks (2017) IEEE Trans. Neural Netw. Learn. Syst., 29 (5), pp. 1441-1453. , May; Dundar, A., Jin, J., Martini, B., Culurciello, E., Embedded streaming deep neural networks accelerator with applications (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (7), pp. 1572-1583. , Jul; Kyrkou, C., Bouganis, C.S., Theocharides, T., Polycarpou, M.M., Embedded hardware-efficient real-time classification with cascade support vector machines (2016) IEEE Trans. Neural Netw. Learn. Syst., 27 (1), pp. 99-112. , Jan; Soleimani, H., Bavandpour, M., Ahmadi, A., Abbott, D., Digital implementation of a biological astrocyte model and its application (2015) IEEE Trans. Neural Netw., 26 (1), pp. 127-139. , Jan; Bataller-Mompeán, M., Martínez-Villena, J.M., Rosado-Muñoz, A., Francés-Víllora, J.V., Guerrero-Martínez, J.F., Wegrzyn, M., Adamski, M., Support tool for the combined software/hardware design of on-chip ELM training for SLFF neural networks (2016) IEEE Trans Ind. Informat., 12 (3), pp. 1114-1123. , Jun; Tisan, A., Chin, J., An end-user platform for FPGA-based design and rapid prototyping of feedforward artificial neural networks with on-chip backpropagation learning (2016) IEEE Trans. Ind. Informat., 12 (3), pp. 1124-1133. , Jun; Zhou, Y., Wang, W., Huang, X., FPGA design for PCANet deep learning network (2015) Proc. IEEE 23rd Annu. Int. Symp. Field-Program. Custom Comput. Mach., May, p. 232; Wang, R., Thakur, C.S., Cohen, G., Hamilton, T.J., Tapson, J., Van Schaik, A., Neuromorphic hardware architecture using the neural engineering framework for pattern recognition (2017) IEEE Trans. Biomed. Circuits Syst., 11 (3), pp. 574-584. , Jun; Huynh, T.V., Deep neural network accelerator based on FPGA (2017) Proc. 4th NAFOSTED Conf. Inf. Comput. Sci, pp. 254-257. , Nov; Frances-Villora, J.V., Rosado-Munoz, A., Bataller-Mompean, M., Barrios-Aviles, J., Guerrero-Martinez, J.F., Moving learning machine towards fast real-time applications: A high-speed FPGA-based implemen-tation of the OS-ELM training algorithm (2018) Electronics, 7 (11), p. 308. , Nov; Frances-Villora, J.V., Rosado-Muñoz, A., Martínez-Villena, J.M., Bataller-Mompean, M., Guerrero, J.F., Wegrzyn, M., Hardware imple-mentation of real-time Extreme Learning Machine in FPGA: Analysis of precision, resource occupation and performance (2016) Comput. Electr. Eng., 51, pp. 139-156. , Apr; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Netw., 61, pp. 85-117. , Jan; Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.-A., Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010) J. Mach. Learn. Res., 11 (12), pp. 3371-3408. , Dec; Xing, C., Ma, L., Yang, X., Stacked denoise autoencoder based feature extraction and classification for hyperspectral images (2016) J. Sensors, 2016. , Jun; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning internal representations by error propagation (1986) Parallel Distributed Processing: Explorations in the Microstructure of Cognition, 1, pp. 318-362. , D. E. Rumelhart, J. L. McClelland, and C. PDP Research Group, Eds. Cambridge, MA, USA: MIT Press; Kingma, D.P., Welling, M., Auto-encoding variational Bayes (2014) Proc. Int. Conf. Learn. Represent. (ICLR), pp. 14-16. , Apr; Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2007) Proc. Adv. Neural Inf. Process. Syst. (NIPS), pp. 153-160; Tan, C.C., (2009) Autoencoder Neural Networks: A Performance Study Based on Image Reconstruction, Recognition and Compression, , Berlin, Germany: LAP Lambert Academic; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Comput., 18 (7), pp. 1527-1554; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Bengio, Y., LeCun, Y., Scaling learning algorithms towards AI (2007) Large-Scale Kernel Mach., 34 (5), pp. 1-41. , Aug; Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., Bengio, S., Why does unsupervised pre-training help deep learning? (2010) J. Mach. Learn. Res., 11, pp. 625-660. , Feb; Dreiseitl, S., Ohno-Machado, L., Logistic regression and artificial neural network classification models: A methodology review (2002) J. Biomed. Inform., 35 (5-6), pp. 352-359; Harshvardhan, G., Venkateswaran, N., Padmapriya, N., Assessment of glaucoma with ocular thermal images using glcm techniques and logistic regression classifier (2016) Proc. Int. Conf. Wireless Commun., Signal Process. Netw. (WiSPNET), pp. 1534-1537. , Mar; Maas, A., Rottensteiner, F., Heipke, C., Using label noise robust logistic regression for automated updating of topographic geospatial databases (2016) ISPRS Ann. Photogramm., Remote Sens. Spatial Inf. Sci., III-7, pp. 133-140. , https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/III-7/133/2016/, [Online]; Zhu, X., Nie, Y., Jin, S., Li, A., Jia, Y., Spammer detection on online social networks based on logistic regression (2015) Proc. Int. Conf. Web-Age Inf. Manage, pp. 29-40. , Cham, Switzerland: Springer; Bishop, C., (2006) Pattern Recognition and Machine Learning 1st Ed, , New York NY USA: Springer-Verlag; Reynolds, P.D., (2005) Algorithm Implementation in FPGAs Demonstrated through Neural Network Inversion on the SRC-6e, , Waco, TX, USA: Baylor Univ; Zhang, M., Vassiliadis, S., Delgado-Frias, J.G., Sigmoid generators for neural computing using piecewise approximations (1996) IEEE Trans. Comput., 45 (9), pp. 1045-1049. , Sep; Kwan, H.K., Simple sigmoid-like activation function suitable for digital hardware implementation (1992) Electron. Lett., 28 (15), pp. 1379-1380. , Jul; Rosado-Muñoz, A., Soria-Olivas, E., Gomez-Chova, L., Vila Francés, J., An IP core and gui for implementing multilayer perceptron with a fuzzy activation function on configurable logic devices (2008) J. Universal Comput. Sci., 14 (10), pp. 1678-1694. , May; Greenwald, S.D., (1986) The Development and Analysis of a Ventricular Fibrillation Detector, , http://hdl.handle.net/1721.1/92988, M.S. thesis, Dept. Elect. Eng. Comput. Sci., Massachusetts Inst. Technol., Cambridge, MA, USA, [Online]; Goldberger, A.L., Amaral, L.A.N., Glass, L., Hausdorff, J.M., Ivanov, P.C., Mark, R.G., Mietus, J.E., Stanley, H.E., PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals (2000) Circulation, 101 (23), pp. e215-e220. , Jun; Cortina, A., Mjahad, A., Rosado, A., Bataller, M., Francés, J.V., Dutta, M.K., Vyas, G., Ventricular fibrillation detection from ECG surface electrodes using different filtering techniques, window length and artificial neural networks (2017) Proc. Int. Conf. Emerg. Trends Comput. Commun. Technol. (ICETCCT), pp. 1-5. , Nov; Mjahad, A., Rosado-Muñoz, A., Bataller-Mompeán, M., Francés-Víllora, J.V., Guerrero-Martínez, J.F., Ventricular fibrillation and tachycardia detection from surface ECG using time-frequency representation images as input dataset for machine learning (2017) Comput. Methods Programs Biomed., 141, pp. 119-127. , Apr; Palm, R.B., (2012) Prediction As a Candidate for Learning Deep Hierarchical Models of Data, , M.S. thesis, Dept. Inform. Math. Model., Tech. Univ. Denmark, Lyngby, Denmark; Ott, J., Lin, Z., Zhang, Y., Liu, S.-C., Bengio, Y., (2016) Recurrent Neural Networks with Limited Numerical Precision, , http://arxiv.org/abs/1608.06902, CoRR, vol. abs/1608.06902, [Online]; Gupta, S., Agrawal, A., Gopalakrishnan, K., Narayanan, P., Deep learning with limited numerical precision (2015) Proc. 32nd Int. Conf. Mach. Learn. (ICML), Lille, France, 37, pp. 1737-1746. , http://dl.acm.org/citation.cfm?id=3045118.3045303, [Online]; (2015) ARM Cortex M4 Processor Technical Reference Manual Revision r0p1 Sec. 3.3.1, , ARM Limited, Cambridge, U.K; Do A Ferreira, A.P., Da S Barros, E.N., A high performance full pipelined arquitecture of MLP neural networks in FPGA (2010) Proc. 17th IEEE Int. Conf. Electron., Circuits Syst., Dec., pp. 742-745; Vranjkovic, V., Struharik, R., Coarse-grained reconfigurable hardware accelerator of machine learning classifiers (2016) Proc. Int. Conf. Syst., Signals Image Process. (IWSSIP), pp. 1-5. , May; Suzuki, A., Morie, T., Tamukoh, H., A shared synapse architecture for efficient FPGA implementation of autoencoders (2018) PLoS ONE, 13 (3). , Mar; Nedjah, N., Da Silva, R.M., De Mourelle MacEdo, L., Compact yet efficient hardware implementation of artificial neural networks with customized topology (2012) Expert Syst. Appl., 39 (10), pp. 9191-9206. , Aug; Oliveira, J.G.M., Moreno, R.L., De Dutra Oliveira, O., Pimenta, T.C., Implementation of a reconfigurable neural network in FPGA (2017) Proc. Int. Caribbean Conf. Devices, Circuits Syst. (ICCDCS), pp. 41-44. , Jun; Zhai, X., Ali, A.A.S., Amira, A., Bensaali, F., MLP neural network based gas classification system on Zynq SoC (2016) IEEE Access, 4, pp. 8138-8146; Iakymchuk, T., Rosado-Muñoz, A., Mompéan, M.B., Víllora, J.V.F., Osimiry, E.O., Versatile direct and transpose matrix multiplication with chained operations: An optimized architecture using circulant matrices (2016) IEEE Trans. Comput., 65 (11), pp. 3470-3479. , Nov","Rosado-Munoz, A.; Department of Electronic Engineering, Spain; email: alfredo.rosado@uv.es",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85068255313
"Zhou W., Niu Y., Zhang G.","56939509600;57192666495;55643462500;","Sensitivity-Oriented Layer-Wise Acceleration and Compression for Convolutional Neural Network",2019,"IEEE Access","7",,"6287639","38264","38272",,3,"10.1109/ACCESS.2019.2905138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065180703&doi=10.1109%2fACCESS.2019.2905138&partnerID=40&md5=28f9bf086f571662bf623db0b15273f1","School of Electronics and Information, Northwestern Polytechnical University, Xi'an, 710072, China","Zhou, W., School of Electronics and Information, Northwestern Polytechnical University, Xi'an, 710072, China; Niu, Y., School of Electronics and Information, Northwestern Polytechnical University, Xi'an, 710072, China; Zhang, G., School of Electronics and Information, Northwestern Polytechnical University, Xi'an, 710072, China","Convolutional neural networks (CNNs) have achieved excellent performance improvement in image processing and other machine learning tasks. However, tremendous computation and memory consumption for most classical CNN models pose a great challenge to the deployment in portable and power-limited devices. In this paper, by analyzing the sensitivity of the rank in each layer of the network accuracy, we propose a sensitivity-oriented layer-wise low-rank approximation algorithm. With specific compression and acceleration requirement, the convolutional layer with higher sensitivity keeps more kernels than that with lower sensitivity. In addition, we also demonstrated that global optimization can obtain a better classification performance than layer-wise fine-tuning. The experimental results show that the proposed method can achieve 20% acceleration ratio gaining compared with the traditional rank-reducing methods. When deployed on the VGGNet-16 model, the proposed method can achieve 2.7\times compression/acceleration ratio on convolutional layers and 10.9\times compression/acceleration ratio on fully connected (FC) layers with 0.05% top-1 accuracy loss and 0.01% top-5 accuracy loss. © 2013 IEEE.","acceleration; CNN; compression; layer-wise sensitivity","Acceleration; Approximation algorithms; Approximation theory; Compaction; Convolution; Global optimization; Image enhancement; Learning systems; Neural networks; Acceleration ratio; Accuracy loss; Classification performance; Convolutional neural network; Layer-wise; Limited devices; Memory consumption; Network accuracy; Network layers",,,,,"2017JQ6019, 2018JQ6016; National Natural Science Foundation of China, NSFC: 61602383, 61702418, 61772424","This work was supported in part by the National Natural Science Foundation of China under Grant 61602383, Grant 61772424, and Grant 61702418, and in part by the Fundamental Natural Science Research Funds of Shaanxi Province under Grant 2017JQ6019 and Grant 2018JQ6016.",,,,,,,,,,"Hearst, M.A., Dumais, S.T., Osuna, E., Platt, J., Scholkopf, B., Support vector machines (1998) IEEE Intell. Syst. Appl., 13 (4), pp. 18-28. , Jul; Hinton, G., Krizhevsky, A., Sutskever, I., Imagenet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1-9; Karen, S., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , https://arxiv.org/abs/1409.1556; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778. , Jun; Christian, S., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Proc. 31st AAAI Conf. Artif. Intell., pp. 1-7. , Feb; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 580-587. , Jun; Ren, S.Q., He, K.M., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 91-99; Liu, W., Ssd: Single shot multibox detector (2016) Proc. Eur. Conf. Comput. Vis., pp. 21-37. , Sep; Jonathan, L., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 3431-3440. , Jun; Clement, F., Couprie, C., Najman, L., LeCun, Y., Learning hierarchical features for scene labeling (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (8), pp. 1915-1929. , Aug; Mao, Q., Dong, M., Huang, Z., Zhan, Y., Learning salient features for speech emotion recognition using convolutional neural networks (2014) IEEE Trans. Multimedia, 16 (8), pp. 2203-2213. , Dec; Zhang, G., Kato, J., Wang, Y., Mase, K., A novel approach for annotation-based image retrieval using deep architecture (2018) J. Multiple-Valued Logic Soft Comput., 30 (4-6), pp. 541-558; Zhang, S., Zhang, S., Huang, T., Gao, W., Speech emotion recognition using deep convolutional neural network and discriminant temporal pyra-mid matching (2017) IEEE Trans. Multimedia, 20 (6), pp. 1576-1590. , Oct; Zhang, T., Zheng, W., Cui, Z., Zong, Y., Yan, J., Yan, K., A deep neural network-driven feature learning method for multi-view facial expression recognition (2016) IEEE Trans. Multimedia, 18 (12), pp. 2528-2536. , Dec; Lu, X., Lin, Z., Jin, H., Yang, J., Wang, J.Z., Rating image aes-thetics using deep learning (2015) IEEE Trans. Multimedia, 17 (11), pp. 2021-2034. , Nov; Yoon, K., (2014) Convolutional Neural Networks for Sentence Classifica-tion, , https://arxiv.org/abs/1408.5882; Van Hasselt, H., Guez, A., Silver, D., Deep reinforcement learning with double Q-learning (2016) Proc. 30th AAAI Conf. Artif. Intell., pp. 2094-2100. , Feb; Babak, H., Stork, D.G., Second order derivatives for network pruning: Optimal brain surgeon (1993) Proc. Adv. Neural Inf. Process. Syst., pp. 164-171; Han, S., Mao, H., Dally, W.J., (2015) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding, , https://arxiv.org/abs/1510.00149; Zhou, A., Yao, A., Guo, Y., Xu, L., Chen, Y., (2017) Incremental Net-work Quantization: Towards Lossless CNNs with Low-precision Weights, , https://arxiv.org/abs/1702.03044; Wenlin, C., Wilson, J., Tyree, S., Weinberger, K., Chen, Y.X., Com-pressing neural networks with the hashing trick (2015) Proc. Int. Conf. Mach. Learn., pp. 2285-2294. , Jun; Khan, I., Non-rigid structure-from-motion with uniqueness constraint and low rank matrixfitting factorization (2014) IEEE Trans. Multimedia, 16 (5), pp. 1350-1357. , Aug; Wang, H., Cen, Y., He, Z., Zhao, R., Cen, Y., Zhang, F., Robust generalized low-rank decomposition of multimatrices for image recovery (2017) IEEE Trans. Multimedia, 19 (5), pp. 969-983. , May; Max, J., Andrea, V., Andrew, Z., (2014) Speeding Up Convolu-tional Neural Networks with Low Rank Expansions, , https://arxiv.org/abs/1405.3866; Zhang, X., Zou, J., Ming, X., He, K., Sun, J., Efficient and accurate approximations of nonlinear convolutional networks (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1984-1992. , Jun; Vadim, L., Yaroslav, G., Maksim, R., Ivan, O., Victor, L., (2014) Speeding-up Convolutional Neural Networks Usingfine-tuned CP-decomposition, , https://arxiv.org/abs/1412.6553; Wang, P., Cheng, J., Accelerating convolutional neural networks for mobile applications (2016) Proc. ACM Multimedia Conf., pp. 541-545. , Oct; Qiu, J.T., Going deeper with embedded FPGA platform for convo-lutional neural network (2016) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays, pp. 25-36. , Feb; Chen, Z., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc. ACM/SIGDA Int. Symp. Field-Program. Gate Arrays, pp. 161-170. , Feb; Peemen, M., Setio, A.A.A., Mesman, B., Corporaal, H., Memory-centric accelerator design for convolutional neural networks (2013) Proc. IEEE 31st Int. Conf. Comput. Des. (ICCD), pp. 13-19. , Oct; Figurnov, M., Ibraimova, A., Vetrov, D., Kohli, P., PerforatedCNNs: Acceleration through elimination of redundant convolutions (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 947-955; Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y., (2013) OverFeat: Integrated Recognition, Localization and Detection Using Convolutional Networks, , https://arxiv.org/abs/1312.6229; Denil, M., Shakibi, B., Ranzato, M., De Freitas, N., Predicting param-eters in deep learning (2013) Proc. Adv. Neural Inf. Process. Syst., pp. 2148-2156; Alex, B., Deng, J., Li, F.F., (2010) Large Scale Visual Recognition Chal-lenge, , www.imagenet.org/challenges, Accessed: Nov. 2017; Jia, Y., Caffe: Convolutional architecture for fast feature embed-ding (2014) Proc. 22nd ACM Int. Conf. Multimedia, pp. 675-678. , Nov; Collobert, R., Farabet, C., Kavukcuoglu, K., Torch: A Scientific Com-puting Framework for Luajit, , http://torch.ch, Accessed: Nov. 2017; Pierre, S., Eigen, D., Zhang, X., OverFeat: Object Recognizer, Fea-ture Extractor, , https://cilvr.nyu.edu/doku.php?id=software:overfeat:start, Accessed: Nov. 2017","Zhou, W.; School of Electronics and Information, China; email: zhouwei@nwpu.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85065180703
"Liu H., Han J., Zhang Y.","57196314740;57208386360;8686316300;","A Unified Framework for Training, Mapping and Simulation of ReRAM-Based Convolutional Neural Network Acceleration",2019,"IEEE Computer Architecture Letters","18","1","8676276","63","66",,5,"10.1109/LCA.2019.2908374","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064701583&doi=10.1109%2fLCA.2019.2908374&partnerID=40&md5=42257217eaa98b16258b6bb263f9f6ba","Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Institute of Microelectronics, Tsinghua University, Beijing, 100084, China","Liu, H., Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Han, J., Institute of Microelectronics, Tsinghua University, Beijing, 100084, China; Zhang, Y., Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China","ReRAM-based neural network accelerators (RNAs) could outshine their digital counterparts in terms of computational efficiency and performance remarkably. However, some open software tool for broad architectural exploration and end-to-end evaluation are still missing. We present a simulation framework of RNA for CNN inference that encompasses a ReRAM-aware NN training tool, a CNN-oriented mapper and a micro-architecture simulator. Main characteristics of ReRAM and circuits are reflected by the configurable simulator, as well as by the customized training algorithm. The function of the simulator's core components is verified by the corresponding circuit simulation of a real chip design. This framework enables comprehensive architectural exploration and end-to-end evaluation, and it's preliminary version is available at https://github.com/CRAFT-THU/XB-Sim. © 2002-2011 IEEE.","accelerator; Deep neural network; processing-in-memory; ReRAM; simulation","Bioinformatics; Computational efficiency; Computer aided software engineering; Computer architecture; Deep neural networks; Neural networks; Nucleic acids; Particle accelerators; Rhenium compounds; RRAM; Simulators; Convolutional neural network; Customized training; Digital counterparts; Efficiency and performance; Micro architectures; Processing in memory; simulation; Simulation framework; Circuit simulation",,,,,"Beijing Innovation Center for Future Chip, ICFC","Thanks for the support from Beijing Innovation Center for Future Chip, the support of the Science and Technology Innovation Special Zone project, China, and the support of HUAWEI project.",,,,,,,,,,"Prezioso, M., Merrikh-Bayat, F., Hoskins, B., Training and operation of an integrated neuromorphic network based on metal-oxide memristors (2015) Nature, 521 (7550); Snider, G., Amerson, R., Carter, D., From synapses to circuitry: Using memristive memory to explore the electronic brain (2011) Comput., 44 (2), pp. 21-28; Hu, M., Strachan, J.P., Li, Z., Dot-product engine for neuromorphic computing: Programming 1T1M crossbar to accelerate matrix-vector multiplication (2016) Proc. 53nd ACM/EDAC/IEEE Des. Autom. Conf., pp. 1-6; Chua, L., Memristor\-The missing circuit element (1971) IEEE Trans. Circuit Theory, 18 (5), pp. 507-519. , Sep; Li, B., Xia, L., Gu, P., MErging the interface: Power, area and accuracy co-optimization for RRAM crossbar-based mixed-signal computing system (2015) Proc. 52nd ACM/EDAC/IEEE Des. Autom. Conf., pp. 1-6; Chi, P., Li, S., Xu, C., PRIME: A novel processing-in-memory architecture for neural network computation in ReRAM-based main memory (2016) Proc. 43rd Int. Symp. Comput. Archit., pp. 27-39; Shafiee, A., Nag, A., Muralimanohar, N., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) Proc. 43rd Int. Symp. Comput. Archit., pp. 14-26; Song, L., Qian, X., Li, H., Chen, Y., PipeLayer: A pipelined ReRAMbased accelerator for deep learning (2017) Proc. 23rd IEEE Symp. High Perform. Comput. Archit., pp. 541-552; Dong, X., Xu, C., Xie, Y., Jouppi, N.P., NVSim: A circuit-level performance, energy, and area model for emerging nonvolatile memory (2012) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst., 31 (7), pp. 994-1007. , Jul; Chen, P.-Y., Peng, X., Yu, S., NeuroSim+: An integrated device-toalgorithm framework for benchmarking synaptic devices and array architectures (2017) Proc. IEEE Int. ElectronDevices Meeting, pp. 611-614; Xia, L., Li, B., Tang, T., MNSIM: Simulation platform for memristorbased neuromorphic computing system (2018) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst., 37 (5), pp. 1009-1022. , May; Lee, S.R., Kim, Y.-B., Chang, M., Multi-level switching of triplelayered taOx RRAM with excellent reliability for storage class memory (2012) Proc. Symp. VLSI Technol., pp. 71-72; Li, B., Gu, P., Shan, Y., RRAM-based analog approximate computing (2015) IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst., 34 (12), pp. 1905-1917. , Dec; Liu, B., Li, H., Chen, Y., Reduction and IR-drop compensations techniques for reliable neuromorphic computing systems (2014) Proc. IEEE/ACM Int. Conf. Comput.-Aided Des., pp. 63-70; Xia, L., Gu, P., Li, B., Technological exploration of RRAM crossbar array for matrix-vector multiplication (2016) J. Comput. Sci. Technol., 31 (1), pp. 3-19; Yao, P., Wu, H., Gao, B., Face classification using electronic synapses (2017) Nature Commun., 8; Gysel, P., Ristretto: Hardware-oriented approximation of convolutional neural networks (2016) CoRR, , http://arxiv.org/abs/1605.06402; Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Lerer, A., Automatic differentiation in PyTorch (2017) NIPS-W; Muralimanohar, N., Balasubramonian, R., Jouppi, N.P., CACTI 6.0: A tool to model large caches (2009) HP Laboratories, pp. 22-31; Long, Y., Na, T., Mukhopadhyay, S., ReRAM-based processing-inmemory architecture for recurrent neural network acceleration (2018) IEEE Trans. Very Large Scale Integr. Syst., 26 (12), pp. 2781-2794. , Dec; Alibart, F., Gao, L., Hoskins, B.D., Strukov, D.B., High precision tuning of state for memristive devices by adaptable variation-tolerant algorithm (2012) Nanotechnol., 23 (7); Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2016) Proc. 4th Int. Conf. Learn. Representations, , San Juan, Puerto Rico, May 2-4","Zhang, Y.; Department of Computer Science and Technology, China; email: zyh02@tsinghua.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,15566056,,,,"English","IEEE Comput. Archit. Lett.",Article,"Final","",Scopus,2-s2.0-85064701583
"Wang K.L., Xu J.","57141103900;57205679810;","A speed regression using acceleration data in a deep convolutional neural network",2019,"IEEE Access","7",,"8603675","9351","9356",,4,"10.1109/ACCESS.2019.2890967","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061092070&doi=10.1109%2fACCESS.2019.2890967&partnerID=40&md5=f72b2bcc5102acf879baf8a8662c2875","Electrical and Computer Engineering Department, International Technological University, San Jose, CA  95134, United States","Wang, K.L., Electrical and Computer Engineering Department, International Technological University, San Jose, CA  95134, United States; Xu, J., Electrical and Computer Engineering Department, International Technological University, San Jose, CA  95134, United States","A speed estimation method using the acceleration data measured by a wearable device during exercising on a treadmill is described in this paper. The moving speed is estimated by a regression algorithm that implements a deep convolutional neural network (CNN) model. This model is trained on a set of test speeds for walking and running conditions. The mean square error between the inferred speeds and test speeds is minimized during the training to optimize the internal model parameters. The speed inference mean error is shown to be accurate within 7% and 18% of the actual running and walking test speeds, respectively. The deep CNN model parameters, e.g., data sample size, convolution kernel size, and fully connected layer sizes, are optimized for inference accuracy and sized to enable a compact hardware design. The feasibility of designing a wearable device that can infer speed from the acceleration measurement for wearable applications is demonstrated by device simulation. © 2013 IEEE.","Acceleration; convolution; neural networks; regression analysis; velocity measurements","Acceleration; Convolution; Mean square error; Neural networks; Regression analysis; Speed; Velocity measurement; Wearable technology; Acceleration data; Convolution kernel; Convolutional neural network; Device simulations; Internal modeling; Regression algorithms; Running conditions; Wearable applications; Deep neural networks",,,,,"International Technological University, ITU","This work was supported by the International Technological University.",,,,,,,,,,"Yang, S., Yeh, Y.-C., Ladasky, J.J., Schmidt, D.J., Algorithm to calculate human calorie expenditure based on a predicted heat strain model (2016) Proc. IEEE-EMBS Int. Conf. Biomed. Health Informat. (BHI), pp. 545-548. , Feb; Masurier, G.L., Tudor-Locke, C., Comparison of pedometer and accelerometer accuracy under controlled conditions (2003) Med. Sci. Sports Exerc., 35 (5), pp. 867-871; Yeoh, W.-S., Pek, I., Yong, Y.-H., Chen, X., Waluyo, A.B., Ambulatory monitoring of human posture and walking speed using wearable accelerometer sensors (2008) Proc. 30th Annu. Int. IEEE EMBS Conf., pp. 5184-5187. , Aug; Shaque, M.A., Hato, E., Use of acceleration data for transportation mode prediction (2015) Transportation, 42 (1), pp. 163-188; Géron, A., (2017) Hands-on Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, , Newton, MA, USA: O'Reilly Media; Karpathy, A., Fei-Fei, L., Deep visual-semantic alignments for generating image descriptions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3128-3137. , Jun; LeCun, Y., Backpropagation applied to handwritten zip code recognition (1989) Neural Comput., 1 (4), pp. 541-551; Zhang, J., Liu, P., Zhang, F., Song, Q., CloudNet: Ground-based cloud classification with deep convolutional neural network (2018) Geophys. Res. Lett., 45 (16), pp. 8665-8672. , Aug; Szegedy, C., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1-9. , Jun; (2016), https://www.st.com/resource/en/datasheet/lis3dh.pdf, MEMS Digital Output Motion Sensor: Ultra-Low-Power High-Performance 3-Axis Nano' Accelerometer, LIS3DH Data Sheet. Accessed: Dec","Wang, K.L.; Electrical and Computer Engineering Department, United States; email: kwang@itu.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,21693536,,,,"English","IEEE Access",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85061092070
"Meloni P., Capotondi A., Deriu G., Brian M., Conti F., Rossi D., Raffo L., Benini L.","36785027100;55825787600;57190223539;57205143936;56866491400;7103169675;7003651730;35556997000;","Neuraghe: Exploiting CPU-FPGA synergies for efficient and flexible CNN inference acceleration on zynQ SoCs",2018,"ACM Transactions on Reconfigurable Technology and Systems","11","3","18","","",,33,"10.1145/3284357","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058815973&doi=10.1145%2f3284357&partnerID=40&md5=0107c76a32bcd72b37e312a5baa8ce8d","Università degli Studi di Cagliari, via Marengo 2, Cagliari, 09123, Italy; Università di Bologna, viale del Risorgimento, Bologna, 240136, Italy; T3Lab, via Sario Bassanelli, 9/11, Bologna, 40129, Italy; Università di Bologna, viale del Risorgimento, Bologna, 240136, Italy; ETH Zurich, Rämistrasse 101, Zürich, 8092, Italy","Meloni, P., Università degli Studi di Cagliari, via Marengo 2, Cagliari, 09123, Italy; Capotondi, A., Università di Bologna, viale del Risorgimento, Bologna, 240136, Italy; Deriu, G., Università degli Studi di Cagliari, via Marengo 2, Cagliari, 09123, Italy, T3Lab, via Sario Bassanelli, 9/11, Bologna, 40129, Italy; Brian, M., T3Lab, via Sario Bassanelli, 9/11, Bologna, 40129, Italy; Conti, F., Università di Bologna, viale del Risorgimento, Bologna, 240136, Italy, ETH Zurich, Rämistrasse 101, Zürich, 8092, Italy; Rossi, D., Università di Bologna, viale del Risorgimento, Bologna, 240136, Italy; Raffo, L., Università degli Studi di Cagliari, via Marengo 2, Cagliari, 09123, Italy; Benini, L., Università di Bologna, viale del Risorgimento, Bologna, 240136, Italy, ETH Zurich, Rämistrasse 101, Zürich, 8092, Italy","Deep convolutional neural networks (CNNs) obtain outstanding results in tasks that require human-level understanding of data, like image or speech recognition. However, their computational load is significant, motivating the development of CNN-specialized accelerators. This work presents NEURAghe, a flexible and efficient hardware/software solution for the acceleration of CNNs on Zynq SoCs. NEURAghe leverages the synergistic usage of Zynq ARM cores and of a powerful and flexible Convolution-Specific Processor deployed on the reconfigurable logic. The Convolution-Specific Processor embeds both a convolution engine and a programmable soft core, releasing the ARM processors from most of the supervision duties and allowing the accelerator to be controlled by software at an ultra-fine granularity. This methodology opens the way for cooperative heterogeneous computing: While the accelerator takes care of the bulk of the CNN workload, the ARM cores can seamlessly execute hard-to-accelerate parts of the computational graph, taking advantage of the NEON vector engines to further speed up computation. Through the companion NeuDNN SW stack, NEURAghe supports end-to-end CNN-based classification with a peak performance of 169GOps/s, and an energy efficiency of 17GOps/W. Thanks to our heterogeneous computing model, our platform improves upon the state-of-the-art, achieving a frame rate of 5.5 frames per second (fps) on the end-to-end execution of VGG-16 and 6.6fps on ResNet-18. © 2018 Association for Computing Machinery.","Convolutional neural networks; FPGAS; HW accelerator; Image classification","Acceleration; ARM processors; Computation theory; Convolution; Deep neural networks; Energy efficiency; Engines; Field programmable gate arrays (FPGA); Image classification; Neural networks; Speech recognition; Computational graph; Computational loads; Convolutional neural network; Deep convolutional neural networks; Frames per seconds; Heterogeneous computing; Reconfigurable logic; Specific processor; Reconfigurable hardware",,,,,"Horizon 2020 Framework Programme, H2020: 732631, 780788","This project has received funding from the European Union’s HORIZON 2020 Research and Innovation programme under Grants No. 780788 (https://www.aloha-h2020.eu/) and No. 732631 (http://oprecomp.eu/). Authors’ addresses: P. Meloni and L. Raffo, Università degli Studi di Cagliari, via Marengo 2, 09123 Cagliari, Italy; emails: {paolo.meloni, luigi}@diee.unica.it; A. Capotondi and D. Rossi, Università di Bologna, viale del Risorgimento, 240136 Bologna, Italy; emails: {alessandro.capotondi, davide.rossi}@unibo.it; G. Deriu, Università degli Studi di Cagliari, via Marengo 2, 09123 Cagliari, Italy and T3Lab, via Sario Bassanelli, 9/11, 40129 Bologna, Italy; emails: gianfranco.deriu@ unica.it, gianfranco.deriu@t3lab.it; M. Brian, T3Lab, via Sario Bassanelli, 9/11, 40129 Bologna, Italy; email: michele.brian@ t3lab.it; F. Conti and L. Benini, Università di Bologna, viale del Risorgimento, 240136 Bologna; emails: {f.conti, luca.benini}@unibo.it; ETH Zurich, Rämistrasse 101, 8092 Zürich, Switzerland, Italy; emails: {fconti, lbenini}@iis.ee.ethz.ch. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2018 Association for Computing Machinery. 1936-7406/2018/12-ART18 $15.00 https://doi.org/10.1145/3284357",,,,,,,,,,"(2017) Altera Arria 10, , https://www.altera.com/products/fpga/arria-series/arria-10/overview.html, Retrieved from; Azarkhish, E., Rossi, D., Loi, I., Benini, L., Neurostream: Scalable and energy-efficient deep learning with smart memory cubes (2017) IEEE Trans. Parallel Distrib. Syst. PP, 99, p. 1. , https://doi.org/10.1109/TPDS.2017.2752706, 2017; Capotondi, A., Marongiu, A., Benini, L., Runtime support for multiple offload-based programming models on clustered manycore accelerators (2018) IEEE Trans. Emerg. Topics Comput., 6 (3), pp. 330-342. , 2018; Cavigelli, L., Benini, L., A 803GOp/s/W convolutional network accelerator (2016) IEEE Trans. Circ. Syst. Video Technol., 99, p. 1. , https://doi.org/10.1109/TCSVT.2016.2592330, 2016; Chen, Y.H., Emer, J., Sze, V., Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks (2016) Proceedings of The ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA'16), pp. 367-379. , https://doi.org/10.1109/ISCA.2016.40; Conti, F., Benini, L., A ultra-low-energy convolution engine for fast brain-inspired vision in multicore clusters (2015) Proceedings of The Design, Automation & Test in Europe Conference & Exhibition (DATE'15), pp. 683-688. , EDA Consortium; Conti, F., Schilling, R., Schiavone, P.D., Pullini, A., Rossi, D., Gürkaynak, F.K., Muehlberghuber, M., Benini, L., An IoT endpoint system-on-chip for secure and energy-efficient near-sensor analytics (2017) IEEE Trans. Circ. Syst. I: Reg. Papers, 64 (9), pp. 2481-2494. , https://doi.org/10.1109/TCSI.2017.2698019, Sept. 2017; Courbariaux, M., Bengio, Y., David, J., BinaryConnect: Training deep neural networks with binary weights during propagations (2015) Advances in Neural Information Processing Systems 28 (NIPS'15), pp. 3123-3131. , Curran Associates Inc; Du, Z., Fasthuber, R., Chen, T., Ienne, P., Li, L., Luo, T., Feng, X., Temam, O., Shidiannao: Shifting vision processing closer to the sensor (2015) Proceedings of The ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA'15), pp. 92-104. , https://doi.org/10.1145/2749469.2750389; Gautschi, M., Schiavone, P.D., Traber, A., Loi, I., Pullini, A., Rossi, D., Flamand, E., Benini, L., Near-threshold RISC-V core with DSP extensions for scalable IoT endpoint devices (2017) IEEE Trans. Very Large Scale Integr. Syst., 25 (10), pp. 2700-2713. , https://doi.org/10.1109/TVLSI.2017.2654506, Oct. 2017; Girshick, R., Fast R-CNn (2015) Proceedings of The International Conference on Computer Vision (ICCV'15); Gokhale, V., Zaidy, A., Chang, A.X.M., Culurciello, E., Snowflake: An efficient hardware accelerator for convolutional neural networks (2017) Proceedings of The IEEE International Symposium on Circuits and Systems (ISCAS'17), pp. 1-4. , https://doi.org/10.1109/ISCAS.2017.8050809; (2017) Build and Train Machine Learning Models on Our New Google Cloud TPUs, , https://www.blog.google/topics/google-cloud/google-cloud-offer-tpus-machine-learning/, Retrieved from; Hannun, A., (2014) Deep Speech: Scaling up End-to-End Speech Recognition; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Iandola, F.N., Moskewicz, M.W., Ashraf, K., Han, S., Dally, W.J., Keutzer, K., SqueezeNet: AlexNet-level accuracy with 50× fewer parameters and <1MB model size (2016) CoRR, , http://dblp.uni-trier.de/db/journals/corr/corr1602.html#IandolaMAHDK16, abs/1602.07360 (2016); (2017) Large Scale Visual Recognition Challenge, , http://image-net.org/, Retrieved from; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) CoRR, , http://arxiv.org/abs/1502.03167, abs/1502.03167 (2015); Jouppi, N., In-datacenter performance analysis of a tensor processing unit (2017) Proceedings of The 44th Annual International Symposium on Computer Architecture (ISCA'17), pp. 1-12. , https://doi.org/10.1145/3079856.3080246, ACM, New York, NY; Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems 25 (NIPS'12), pp. 1097-1105. , Curran Associates Inc; Ma, Y., Cao, Y., Vrudhula, S., Seo, J.S., An automatic RTL compiler for high-throughput FPGA implementation of diverse deep convolutional neural networks (2017) Proceedings of The 27th International Conference on Field Programmable Logic and Applications (FPL'17), pp. 1-8. , https://doi.org/10.23919/FPL.2017.8056824; Meloni, P., Deriu, G., Conti, F., Loi, I., Raffo, L., Benini, L., Curbing the roofline: A scalable and flexible architecture for CNNs on FPGA (2016) Proceedings of The ACM International Conference on Computing Frontiers (CF'16), pp. 376-383. , https://doi.org/10.1145/2903150.2911715, ACM, New York, NY; Mnih, V., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), pp. 529-533. , Feb. 2015, Letter; Mousouliotis, P.G., Petrou, L.P., (2018) SqueezeJet: High-Level Synthesis Accelerator Design for Deep Convolutional Neural Networks, , e-prints; (2017) Movidius Neural Compute Stick: Accelerate Deep Learning Development at The Edge, , https://developer.movidius.com/, Retrieved from; (2017) NVIDIA Deep Learning Accelerator (NVDLA), , http://nvdla.org/, Retrieved from; (2017) NVIDIA Tegra K1, , http://www.nvidia.com/object/tegra-k1-processor.html, Retrieved from; (2017) NVIDIA Tegra X1, , http://www.nvidia.com/object/tegra-x1-processor.html, Retrieved from; Prost-Boucle, A., Bourge, A., Petrot, F., Alemdar, H., Caldwell, N., Leroy, V., Scalable high-performance architecture for convolutional ternary neural networks on FPGA (2017) Proceedings of The 27th International Conference on Field Programmable Logic and Applications (FPL'17), pp. 1-7. , https://doi.org/10.23919/FPL.2017.8056850; Qiu, J., Wang, J., Yao, S., Guo, K., Li, B., Zhou, E., Yu, J., Yang, H., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proceedings of The ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA'16), pp. 26-35. , https://doi.org/10.1145/2847263.2847265, ACM, New York, NY; Rahimi, A., Loi, I., Kakoee, M.R., Benini, L., A fully synthesizable single-cycle interconnection network for Shared-L1 processor clusters (2011) Proceedings of The Design, Automation Test in Europe, pp. 1-6. , https://doi.org/10.1109/DATE.2011.5763085; Rossi, D., Loi, I., Haugou, G., Benini, L., Ultra-low-latency lightweight DMA for tightly coupled multi-core clusters (2014) Proceedings of The 11th ACM Conference on Computing Frontiers (CF'14), , https://doi.org/10.1145/2597917.2597922, ACM, New York, NY; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., DeepFace: Closing the gap to human-level performance in face verification (2014) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition (CVPR'14), pp. 1701-1708. , https://doi.org/10.1109/CVPR.2014.220; Umuroglu, Y., Fraser, N., Gambardella, G., Blott, M., Leong, P., Jahre, M., Vissers, K., Finn: A framework for fast, scalable binarized neural network inference (2017) Proceedings of The ACM/SIGDA International Symposium on FieldProgrammable Gate Arrays (FPGA'17), pp. 65-74. , https://doi.org/10.1145/3020078.3021744, ACM, New York, NY; Venieris, S.I., Bouganis, C.S., Latency-driven design for FPGA-based convolutional neural networks (2017) Proceedings of The 27th International Conference on Field Programmable Logic and Applications (FPL'17), pp. 1-8. , https://doi.org/10.23919/FPL.2017.8056828; Ren, W., Shengen, Y., Yi, S., Qingqing, D., Gang, S., (2015) Deep Image: Scaling up Image Recognition; Weston, J., (2016) Dialog-Based Language Learning; Weston, J., Chopra, S., Bordes, A., (2014) Memory Networks; (2017) Xilinx Zynq-7000 All Programmable SoC, , https://www.xilinx.com/products/silicondevices/soc/zynq-7000.html, Retrieved from; (2017) Zynq UltraScale+ All Programmable Heterogeneous MPSoC, , https://www.xilinx.com/products/silicon-devices/soc/zynq-ultrascale-mpsoc.html, Retrieved from; Zastrow, M., Machine outsmarts man in battle of the decade (2016) New Sci, 229 (3065), p. 21. , https://doi.org/10.1016/S0262-4079(16)30458-4, 2016; Zhang, C., Fang, Z., Zhou, P., Pan, P., Cong, J., Caffeine: Toward uniformed representation and acceleration for deep convolutional neural networks (2016) Proceedings of The IEEE/ACM International Conference on Computer-Aided Design (ICCAD'16), pp. 1-8. , https://doi.org/10.1145/2966986.2967011; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proceedings of The ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA'15), pp. 161-170. , https://doi.org/10.1145/2684746.2689060, ACM, New York, NY",,,,"Association for Computing Machinery",,,,,19367406,,,,"English","ACM Trans. Reconfigurable Technol. Syst.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85058815973
"Long Y., Na T., Mukhopadhyay S.","57192659670;57189643082;8330116700;","ReRAM-Based Processing-in-Memory Architecture for Recurrent Neural Network Acceleration",2018,"IEEE Transactions on Very Large Scale Integration (VLSI) Systems","26","12","8402126","2781","2794",,50,"10.1109/TVLSI.2018.2819190","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049469562&doi=10.1109%2fTVLSI.2018.2819190&partnerID=40&md5=4e5a44499b7de4be259aea815bc46707","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States","Long, Y., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States; Na, T., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States; Mukhopadhyay, S., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA  30332, United States","We present a recurrent neural network (RNN) accelerator design with resistive random-access memory (ReRAM)-based processing-in-memory (PIM) architecture. Distinguished from prior ReRAM-based convolutional neural network accelerators, we redesign the system to make it suitable for RNN acceleration. We measure the system throughput and energy efficiency with the detailed circuit and device characterization. Reprogrammability is enabled with our design, and an RNN friendly pipeline is employed to increase the system throughput. We observe that on average the proposed system achieves 79 × improvement of computing efficiency compared with graphics processing unit baseline. Our simulation also indicates that to maintain high accuracy and computing efficiency, the read noise standard deviation should be less than 0.2, the device resistance should be at least 1 M Ω, and the device writes latency should be minimized. © 1993-2012 IEEE.","Gated recurrent unit (GRU); human activity recognition (HAR); long short-term memory (LSTM); processing in memory (PIM); recurrent neural network (RNN); resistive random-access memory (ReRAM)","Acceleration; Computation theory; Computer architecture; Computer graphics; Energy efficiency; Graphics processing unit; Image coding; Logic gates; Memory architecture; Network architecture; Nonvolatile storage; Program processors; Recurrent neural networks; RRAM; Switches; Throughput; Gated recurrent unit (GRU); Human activity recognition; Processing in memory; Recurrent neural network (RNN); Resistive Random Access Memory (ReRAM); Long short-term memory",,,,,"National Science Foundation, NSF; Semiconductor Research Corporation, SRC; Directorate for Computer and Information Science and Engineering, CISE: 1740197","Manuscript received September 7, 2017; revised January 17, 2018; accepted February 28, 2018. Date of publication July 3, 2018; date of current version November 30, 2018. This work was supported in part by the National Science Foundation under Grant 1740197 and in part by the Semiconductor Research Corporation. (Corresponding author: Yun Long.) The authors are with the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332 USA (e-mail: yunlong@gatech.edu; taesik.na@gatech.edu; saibal@ece.gatech.edu).",,,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst, pp. 1097-1105; Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L., Large-scale video classification with convolutional neural networks (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 1725-1732; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proc. IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), May, pp. 6645-6649; Hassabis, D., Artificial intelligence: Chess match of the century (2017) Nature, 544 (7651), pp. 413-444; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun., pp. 248-255; Eryilmaz, S.B., Kuzum, D., Yu, S., Wong, H.-S.P., Device and system level design considerations for analog-non-volatile-memory based neuromorphic architectures (2015) IEDM Tech. Dig, p. 411414. , Dec; Farmahini-Farahani, A., Ahn, J.H., Morrow, K., Kim, N.S., NDA: Near-DRAM acceleration architecture leveraging commodity DRAM devices and standard memory modules (2015) Proc. IEEE 21st Int. Symp. High Perform. Comput. Archit. (HPCA), pp. 283-295. , Feb; Chi, P., PRIME: A novel processing-in-memory architecture for neural network computation in ReRAM-based main memory (2016) Proc. 43rd Int. Symp. Comput. Archit, pp. 27-39; Song, L., Qian, X., Li, H., Chen, Y., PipeLayer: A pipelined ReRAM-based accelerator for deep learning (2017) Proc. IEEE Int. Symp. High Perform. Comput. Archit. (HPCA), Feb., pp. 541-552; Yu, S., Binary neural network with 16 Mb RRAM macro chip for classification and online training (2016) IEDM Tech. Dig, pp. 1621-1624. , Dec; Shafiee, A., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) Proc. 43rd Int. Symp. Comput. Archit., pp. 14-26; Greff, K., Srivastava, R.K., Koutník, J., Steunebrink, B.R., Schmidhuber, J., LSTM: A search space odyssey (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (10), pp. 2222-2232. , Oct; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, , https://arxiv.org/abs/1412.3555, [Online]; Kung, J., Kim, D., Mukhopadhyay, S., Dynamic approximation with feedback control for energy-efficient recurrent neural network hardware (2016) Proc. Int. Symp. Low Power Electron. Design, pp. 168-173; Long, Y., Jung, E.M., Kung, J., Mukhopadhyay, S., ReRAM Crossbar based Recurrent Neural Network for human activity detection (2016) Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 939-946. , Jul; Donahue, J., Long-term recurrent convolutional networks for visual recognition and description (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 2625-2634; Sak, H., Senior, A., Beaufays, F., (2014) Long Short-term Memory Based Recurrent Neural Network Architectures for Large Vocabulary Speech Recognition, , https://arxiv.org/abs/1402.1128, [Online]; Han, S., ESE: Efficient speech recognition engine with sparse LSTM on FPGA (2017) Proc. FPGA, pp. 75-84; Na, T., Ko, J.H., Kung, J., Mukhopadhyay, S., On-chip training of recurrent neural networks with limited numerical precision (2017) Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 3716-3723. , May; Sak, H., Senior, A., Beaufays, F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling (2014) Proc. 15 Annu. Conf. Int. Speech Commun. Assoc., pp. 338-342; Nurvitadhi, E., Sim, J., Sheffield, D., Mishra, A., Krishnan, S., Marr, D., Accelerating recurrent neural networks in analytics servers: Comparison of FPGA, CPU, GPU, and ASIC (2016) Proc. 26th Int. Conf. Field Program. Logic Appl. (FPL), pp. 1-4. , Aug; Shin, D., Lee, J., Lee, J., Yoo, H.-J., DNPU: An 8.1 TOPS/W reconfigurable CNN-RNN processor for general-purpose deep neural networks (2017) IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, Feb., pp. 240-241; Han, S., EIE: Efficient inference engine on compressed deep neural network (2016) Proc. 43rd Int. Symp. Comput. Archit, pp. 243-254. , Jun; Gao, B., Ultra-low-energy three-dimensional oxide-based elec-tronic synapses for implementation of robust high-accuracy neuromor-phic computation systems (2014) ACS Nano, 8 (7), pp. 6998-7004; Gao, B., Oxide-based RRAM switching mechanism: A new ion-transport-recombination model (2008) IEDM Tech. Dig, pp. 1-4. , Dec; Russo, U., Conductive-filament switching analysis and self-accelerated thermal dissolution model for reset in NiO-based RRAM (2007) IEDM Tech. Dig, pp. 775-778. , Dec; Park, S., RRAM-based synapse for neuromorphic system with pattern recognition function (2012) IEDM Tech. Dig, pp. 1021-1024. , Dec; Huang, P., A physical based analytic model of RRAM operation for circuit simulation (2012) IEDM Tech. Dig, pp. 2661-2664. , Dec; Guan, X., Yu, S., Wong, H.-S.P., A SPICE compact model of metal oxide resistive switching memory with variations (2012) IEEE Electron Device Lett., 33 (10), pp. 1405-1407. , Oct; Burr, G.W., Experimental demonstration and tolerancing of a large-scale neural network (165 000 synapses) using phase-change memory as the synaptic weight element (2015) IEEE Trans. Electron Devices, 62 (11), pp. 3498-3507. , Nov; Vincent, A.F., Spin-transfer torque magnetic memory as a stochastic memristive synapse for neuromorphic systems (2015) IEEE Trans. Biomed. Circuits Syst., 9 (2), pp. 166-174. , Apr; Park, S., Neuromorphic speech systems using advanced ReRAM-based synapse (2013) IEDM Tech. Dig, pp. 2561-2564. , Dec; Xu, C., Overcoming the challenges of crossbar resistive memory architectures (2015) Proc. IEEE 21st Int. Symp. High Perform. Comput. Archit. (HPCA), Feb., pp. 476-488; Prezioso, M., Merrikh-Bayat, F., Hoskins, B.D., Adam, G.C., Likharev, K.K., Strukov, D.B., Training and operation of an integrated neuromorphic network based on metal-oxide memristors (2015) Nature, 521, pp. 61-64. , May; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Trans. Neural Netw., 5 (2), pp. 157-166. , Mar; Wu, X., Saxena, V., Zhu, K., A CMOS spiking neuron for dense memristor-synapse connectivity for brain-inspired computing (2015) Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-6. , Jul; Kull, L., A 3.1 mW 8b 1.2 GS/s single-channel asynchronous SAR ADC with alternate comparators for enhanced speed in 32 nm digital SOI CMOS (2013) IEEE J. Solid-State Circuits, 48 (12), pp. 3049-3058. , Dec; Goldman, R., Bartleson, K., Wood, T., Kranen, K., Melikyan, V., Babayan, E., 32/28 nm educational design kit: Capabilities, deployment and future (2013) Proc. IEEE Asia-Pacific Conf. Postgraduate Res. Microelectron. Electron. (PrimeAsia), Dec., pp. 284-288; Zhao, W., Cao, Y., New generation of predictive technology model for sub-45 nm early design exploration (2006) IEEE Trans. Electron Devices, 53 (11), pp. 2816-2823. , Nov; Alibart, F., Gao, L., Hoskins, B.D., Strukov, D.B., High precision tuning of state for memristive devices by adaptable variation-tolerant algorithm (2012) Nanotechnology, 23 (7), pp. 075201-107520120; Gao, L., Fully parallel write/read in resistive synaptic array for accelerating on-chip learning (2015) Nanotechnology, 26, p. 455204. , Nov; Snoeij, M.F., Theuwissen, A.J.P., Makinwa, K.A.A., Huijsing, J.H., Multiple-ramp column-parallel ADC architectures for CMOS image sensors (2007) IEEE J. Solid-State Circuits, 42 (12), pp. 2968-2977. , Dec; Hu, M., Dot-product engine for neuromorphic computing: Programming 1T1M crossbar to accelerate matrix-vector multiplication (2016) Proc. 53nd ACM/EDAC/IEEE Design Autom. Conf. (DAC), Jun., pp. 1-6; Jouppi, N.P., (2017) In-datacenter Performance Analysis of a Tensor Processing Unit, , https://arxiv.org/abs/1704.04760, [Online]; Price, M., Glass, J., Chandrakasan, A.P., A scalable speech recognizer with deep-neural-network acoustic models and voice-activated power gating (2017) IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, Feb., pp. 244-245; Chen, Y., Dadiannao: A machine-learning supercomputer (2014) Proc. 47th Annu. IEEE/ACM Int. Symp. Microarchit., Dec., pp. 609-622; Atienza, R., (2017) LSTM by Example Using Tensorflow, , https://github.com/roatienza/Deep-Learning-Experiments, [Online]; Anguita, D., Ghio, A., Oneto, L., Parra, X., Reyes-Ortiz, J.L., A public domain dataset for human activity recognition using smartphones (2013) Proc. ESANN, pp. 437-442; Abadi, M., (2016) TensorFlow: Large-scale Machine Learning on Heterogeneous Distributed Systems, , https://arxiv.org/abs/1603.04467, [Online]","Long, Y.; School of Electrical and Computer Engineering, United States; email: yunlong@gatech.edu",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,10638210,,IEVSE,,"English","IEEE Trans Very Large Scale Integr VLSI Syst",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85049469562
"Nourazar M., Rashtchi V., Azarpeyvand A., Merrikh-Bayat F.","55354656100;13805245700;36056132800;24481647100;","Code Acceleration Using Memristor-Based Approximate Matrix Multiplier: Application to Convolutional Neural Networks",2018,"IEEE Transactions on Very Large Scale Integration (VLSI) Systems","26","12","8374046","2684","2695",,12,"10.1109/TVLSI.2018.2837908","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048192163&doi=10.1109%2fTVLSI.2018.2837908&partnerID=40&md5=1c978124084d1492aaf43a2905ddd0b5","Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, 45371-38791, Iran","Nourazar, M., Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, 45371-38791, Iran; Rashtchi, V., Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, 45371-38791, Iran; Azarpeyvand, A., Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, 45371-38791, Iran; Merrikh-Bayat, F., Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, 45371-38791, Iran","In this paper, we demonstrate the feasibility of building a memristor-based approximate accelerator to be used in cooperation with general-purpose × 86 processors. First, an integrated full system simulator is developed for simultaneous simulation of any multicrossbar architecture as an accelerator for × 86 processors, which is performed by coupling a cycle accurate Marss × 86 processor simulator with the Ngspice mixed-level/mixed-signal circuit simulator. Then, a novel mixed-signal memristor-based architecture is presented for multiplying floating-point signed complex numbers. The presented multiplier is extended for accelerating convolutional neural networks and finally, it is tightly integrated with the pipeline of a generic × 86 processor. To validate the accelerator, first it is utilized for multiplying different matrices that vary in size and distribution. Then, it is used as an accelerator for accelerating the tiny-dnn, an open-source C++ implementation of deep learning neural networks. The memristor-based accelerator provides more than 100 × speedup and energy saving for a 64 × 64 matrix-matrix multiplication, with an accuracy of 90%. Using the accelerated tiny-dnn for the MNIST database classification more than 10 × speedup and energy saving along with 95.51% pattern recognition accuracy is achieved. © 1993-2012 IEEE.","Analog accelerator; approximate computing; convolutional neural network (CNN); matrix multiplier; memristor crossbar","Acceleration; C++ (programming language); Circuit simulation; Classification (of information); Computer architecture; Convolution; Deep learning; Digital arithmetic; Energy conservation; Matrix algebra; Memristors; Network architecture; Network coding; Neural networks; Pattern recognition; Simulators; Approximate computing; Convolutional neural network; Convolutional Neural Networks (CNN); Full system simulators; Learning neural networks; Matrix matrix multiplications; Memristor crossbars; Pattern Recognition accuracies; Pipeline processing systems",,,,,,,,,,,,,,,,"Esmaeilzadeh, H., Blem, E., St Amant, R., Sankaralingam, K., Burger, D., Dark silicon and the end of multicore scaling (2011) Proc. 38th Annu. Int. Symp. Comput. Archit, pp. 365-376. , New York, NY, USA: ACM; Esmaeilzadeh, H., Blem, E., Amant, R.S., Sankaralingam, K., Burger, D., Power challenges may end the multicore era (2013) Commun. ACM, 56 (2), pp. 93-102; Williams, R.S., What's next? (2017) Comput. Sci. Eng., 19 (2), pp. 7-13. , Mar/Apr; Shalf, J.M., Leland, R., Computing beyond Moore's Law (2015) Computer, 48 (12), pp. 14-23. , Dec; Esmaeilzadeh, H., Sampson, A., Ceze, L., Burger, D., Neural acceleration for general-purpose approximate programs (2012) Proc. 45th Annu. IEEE/ACM Int. Symp. Microarchit. (MICRO), pp. 449-460. , Washington, DC, USA: IEEE Computer Society, Dec; St Amant, R., General-purpose code acceleration with limited-precision analog computation (2014) Proc. 41st Annu. Int. Symp. Comput. Archit. (ISCA), pp. 505-516. , Piscataway, NJ, USA: IEEE Press; Hu, M., Dot-product engine for neuromorphic computing: Pro-gramming 1T1M crossbar to accelerate matrix-vector multiplication (2016) Proc. 53rd ACM/EDAC/IEEE Design Autom. Conf. (DAC), Jun., pp. 1-6; Esmaeilzadeh, H., (2013) Approximate Acceleration for a Post Multicore Era, , Ph.D. dissertation, Dept. Comput. Sci. Eng., Univ. Washington, Seattle, WA, USA, Nov; Mittal, S., A survey of techniques for approximate computing (2016) ACM Comput. Surv., 48 (4), p. 62. , Mar; Sampson, A., Dietl, W., Fortuna, E., Gnanapragasam, D., Ceze, L., Grossman, D., EnerJ: Approximate data types for safe and general low-power computation (2011) Proc. 32nd ACM SIGPLAN Conf. Programm. Lang. Design Implementation (PLDI), pp. 164-174. , New York, NY, USA: ACM; Esmaeilzadeh, H., Sampson, A., Ceze, L., Burger, D., Architec-ture support for disciplined approximate programming (2012) Proc. 17th Int. Conf. Archit. Support Programm. Lang. Oper. Syst. (ASPLOS), pp. 301-312. , New York, NY, USA: ACM; St Amant, R.M., (2014) Enabling High-performance, Mixed-signal Approximate Computing, , Ph.D. dissertation, Dept. Comput. Sci., Univ. Texas Austin, Austin, TX, USA, May; Gao, L., Digital-to-analog and analog-to-digital conversion with metal oxide memristors for ultra-low power computing (2013) Proc. IEEE/ACM Int. Symp. Nanoscale Archit. (NANOARCH), pp. 19-22. , Piscataway, NJ, USA: IEEE Press, Jul; Yazdanbakhsh, A., Toward general-purpose code acceleration with analog computation (2014) Proc. Workshop Approx. Comput. Across Syst. Stack, pp. 1-7; Vourkas, I., Sirakoulis, G., (2016) Memristor-Based Nanoelectronic Computing Circuits and Architectures, 1st Ed, , New York, NY, USA: Springer-Verlag; Adamatzky, A., Chua, L., (2014) Memristor Networks 1st Ed, , Basel Switzerland: Springer-Verlag; Strukov, D.B., Snider, G.S., Stewart, D.R., Williams, R.S., The missing memristor found (2008) Nature, 453, pp. 80-83. , May; Sah, M.P., Kim, H., Chua, L.O., Brains are made of memristors (2014) IEEE Circuits Syst. Mag., 14 (1), pp. 12-36. , 1st Quart; Thomas, A., Memristor-based neural networks (2013) J. Phys. D, Appl. Phys., 46 (9), p. 093001; Starzyk, J.A., Basawaraj, B., Memristor crossbar architecture for synchronous neural networks (2014) IEEE Trans. Circuits Syst. I, Reg. Papers, 61 (8), pp. 2390-2401. , Aug; Merrikh-Bayat, F., Merrikh-Bayat, F., Shouraki, S.B., The neuro-fuzzy computing system with the capacity of implementation on a memristor crossbar and optimization-free hardware training (2014) IEEE Trans. Fuzzy Syst, 22 (5), pp. 1272-1287. , Oct; Liu, X., A heterogeneous computing system with memristor-based neuromorphic accelerators (2014) Proc. IEEE High Perform. Extreme Comput. Conf. (HPEC), Sep., pp. 1-6; Chakrabarti, B., A multiply-add engine with monohfhically integrated 3D memristor crossbar/CMOS hybrid circuit (2017) Sci. Rep., 7. , Feb; Cui, J., Qiu, Q., Towards memristor based accelerator for sparse matrix vector multiplication (2016) Proc. IEEE Int. Symp. Circuits Syst (ISCAS), May, pp. 121-124; Gu, P., Technological exploration of RRAM crossbar array for matrix-vector multiplication (2015) Proc. 20th Asia South Pacific Design Autom. Conf, pp. 106-111. , Jan; Adam, G.C., Hoskins, B.D., Prezioso, M., Merrikh-Bayat, F., Chakrabarti, B., Strukov, D.B., 3-D memristor crossbars for analog and neuromorphic computing applications (2017) IEEE Trans. Electron Devices, 64 (1), pp. 312-318. , Jan; Nourazar, M., Rashtchi, V., Azarpeyvand, A., Merrikh-Bayat, F., Memristor-based approximate matrix multiplier (2017) Analog Integr. Circuits Signal Process., 93 (2), pp. 363-373. , Nov; Lastras-Montano, M.A., Chakrabarti, B., Strukov, D.B., Cheng, K.-T., 3D-DPE: A 3D high-bandwidth dot-product engine for high-performance neuromorphic computing (2017) Proc. Design Autom. Test Eur. Conf. Exhib. (DATE), pp. 1257-1260. , Mar; Mirebrahimi, S.-N., Merrikh-Bayat, F., Programmable discrete-time type I and type II FIR filter design on the memristor crossbar structure (2014) Analog Integr. Circuits Signal Process., 79 (3), pp. 529-541. , Jun; Bayat, F.M., Alibart, F., Gao, L., Strukov, D.B., (2016) A Reconfigurable FIR Filter with Memristor-based Weights, , https://arxiv.org/abs/1608.05445, Aug., [Online]; Hong, Y., Lian, Y., A memristor-based continuous-time digital FIR filter for biomedical signal processing (2015) IEEE Trans. Circuits Syst. I, Reg. Papers, 62 (5), pp. 1392-1401. , May; Patel, A., Afram, F., Chen, S., Ghose, K., MARSS: A full system simulator for multicore x86 CPUs (2011) Proc. 48th ACM/EDAC/IEEE Design Autom. Conf. (DAC), Jun., pp. 1050-1055; www.ngspice.org, Ngspice Circuit Simulator. Accessed: Aug. 21, 2017. [Online]; https://github.com/tiny-dnn/tiny-dnn, Tiny-Dnn. Accessed: Aug. 21, 2017. [Online]; Chi, P., PRIME: A novel processing-in-memory architecture for neural network computation in ReRAM-based main memory (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit. (ISCA), Jun., pp. 27-39; Cheng, M., TIME: A training-in-memory architecture for memristor-based deep neural networks (2017) Proc. 54th ACM/EDAC/IEEE Design Autom. Conf. (DAC), Jun., pp. 1-6; Shafiee, A., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit. (ISCA), Jun., pp. 14-26; Song, L., Qian, X., Li, H., Chen, Y., PipeLayer: A pipelined ReRAM-based accelerator for deep learning (2017) Proc. IEEE Int. Symp. High. Perform. Comput. Archit. (HPCA), Feb., pp. 541-552; Merced-Grafals, E.J., Dávila, N., Ge, N., Williams, R.S., Strachan, J.P., Repeatable, accurate, and high speed multi-level programming of memristor 1T1R arrays for power efficient analog com-puting applications (2016) Nanotechnology, 27 (36), p. 365202; Strukov, D.B., Endurance-write-speed tradeoffs in nonvolatile memories (2016) Appl. Phys. A, Solids Surf., 122, p. 302. , Apr; Alibart, F., Gao, L., Hoskins, B.D., Strukov, D.B., High precision tuning of state for memristive devices by adaptable variation-tolerant algorithm (2012) Nanotechnology, 23 (7), p. 075201; Nasri, B., Sebastian, S.P., You, K.-D., RanjithKumar, R., Shahrjerdi, D., (2016) A 700uw 1 GS/s 4-bit Folding-flash ADC in 65 Nm CMOS for Wideband Wireless Communications, , https://arxiv.org/abs/1612.04855, Dec., [Online]; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; http://yann.lecun.com/exdb/mnist, MNIST Handwritten Digit Database Yann LeCun, Corinna Cortes and Chris Burges. Accessed: Aug. 22, 2017. [Online]; Li, S., Ahn, J.H., Strong, R.D., Brockman, J.B., Tullsen, D.M., Jouppi, N.P., McPAT: An integrated power, area, and timing modeling framework for multicore and manycore architectures (2009) Proc. 42nd Annu. IEEE/ACM Int. Symp. Microarchit. (MICRO), Dec., pp. 469-480; http://www.hpl.hp.com/research/cacti, CACTI. Accessed: Sep. 1, 2017. [Online]; Merrikh-Bayat, F., Hoskins, B., Strukov, D.B., Phenomenological modeling of memristive devices (2014) Appl. Phys. A, Solids Surf., 118 (3), pp. 779-786. , http://arxiv.org/abs/1406.4219, Jun., [Online]; Prezioso, M., Merrikh-Bayat, F., Hoskins, B.D., Adam, G.C., Likharev, K.K., Strukov, D.B., Training and operation of an integrated neuromorphic network based on metal-oxide memristors (2015) Nature, 521, pp. 61-64. , May; Yi, W., Feedback write scheme for memristive switching devices (2011) Appl. Phys. A, 102 (4), pp. 973-982. , Mar","Rashtchi, V.; Department of Electrical and Computer Engineering, Iran; email: rashtchi@znu.ac.ir",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,10638210,,IEVSE,,"English","IEEE Trans Very Large Scale Integr VLSI Syst",Article,"Final","",Scopus,2-s2.0-85048192163
"Wang Y., Li H., Li X.","56104472600;8904472100;56103276300;","A Case of On-Chip Memory Subsystem Design for Low-Power CNN Accelerators",2018,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","37","10","8165964","1971","1984",,8,"10.1109/TCAD.2017.2778060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037596245&doi=10.1109%2fTCAD.2017.2778060&partnerID=40&md5=ef427228b16ec927965b0e0272d071e0","State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China","Wang, Y., State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Li, H., State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Li, X., State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China","The rapid development of machine learning is enabling a plenty of novel applications, such as image and speech recognition for embedded and mobile devices. However, state-of-the-art deep learning models like convolutional neural networks (CNNs) are demanding so much on-chip storage and compute resources that they cannot be smoothly handled by low-power mobile or embedded systems. In order to fit large CNN models into mobile or more cutting-edge devices for IoT or cyberphysics applications, we proposed an efficient on-chip memory architecture for CNN inference acceleration, and showed its application to in-house single-instruction multiple-data structure machine learning processor. The redesigned on-chip memory subsystem, Memsqueezer, includes an active weight buffer and data buffer set that embraces specialized compression methods to reduce the footprint of CNN parameters (weights) and activation data, respectively. Memsqueezer buffer can compress the data and weight set according to the dataflow in computation, and it also includes a built-in redundancy detection mechanism that actively scans through the working-set of CNNs to boost their inference performance by eliminating the computation redundancy in CNN models. In our experiments, it is shown that the CNN processors with Memsqueezer buffers achieve more than 2× performance improvement and reduces 85% energy consumption on average over the conventional buffer design with the same area budget. © 2017 IEEE.","Convolutional neural network (CNN); deep learning; low power; memory subsystem","Acceleration; Bandwidth; Budget control; Computer architecture; Data flow analysis; Deep learning; Digital storage; Embedded systems; Energy utilization; Integrated circuit design; Low power electronics; Network architecture; Neural networks; Redundancy; Speech recognition; System-on-chip; Computational model; Kernel; Low Power; Memory subsystems; Two-dimensional displays; Memory architecture",,,,,"National Natural Science Foundation of China, NSFC: 61402146, 61432017, 61504153, 61521092, 61532017; National Basic Research Program of China (973 Program): 2016YFF0203500","Manuscript received March 18, 2017; revised June 30, 2017; accepted August 17, 2017. Date of publication December 4, 2017; date of current version September 18, 2018. This work was supported in part by the National Natural Science Foundation of China under Grant 61432017, Grant 61504153, Grant 61532017, Grant 61402146, and Grant 61521092, and in part by the National Key Research and Development Program of China under Grant 2016YFF0203500. This paper was recommended by Associate Editor Y. Wang. (Corresponding authors: Huawei Li; Xiaowei Li.) The authors are with the State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China (e-mail: lihuawei@ict.ac.cn; lxw@ict.ac.cn).",,,,,,,,,,"Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning structured sparsity in deep neural networks (2016) Proc. NIPS, pp. 2074-2082; Van Nguyen, H., Zhou, K., Vemulapalli, R., Cross-domain synthesis of medical images using efficient location-sensitive deep network (2015) Medical Image Computing and Computer-Assisted Intervention - MICCAI., , Cham, Switzerland: Springer; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2016) Proc. Int. Conf. Learn. Represent. (ICLR), , May; Chen, Y., DaDianNao: A machine-learning supercomputer (2014) Proc. MICRO, pp. 609-622; Cadambi, S., Majumdar, A., Becchi, M., Chakradhar, S., Graf, H.P., A programmable parallel accelerator for learning and classification (2010) Proc. PACT, pp. 273-283; Farabet, C., NeuFlow: A runtime reconfigurable dataflow processor for vision (2011) Proc. CVPR Workshop, pp. 109-116; Zhang, C., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc. FPGA, pp. 161-170; Wang, Y., Low power convolutional neural networks on a chip (2016) Proc. ISCAS, pp. 129-132; Ji, Y., NEUTRAMS: Neural network transformation and codesign under neuromorphic hardware constraints (2016) Proc. MICRO, pp. 1-13; Sharma, H., From high-level deep neural models to FPGAs (2016) Proc. MICRO, pp. 1-12; Chen, T., DianNao: A small-footprint high-throughput accelerator for ubiquitous machine-learning (2014) ACM SIGPLAN Notices, 49 (4), pp. 269-284; Liu, D., PuDianNao: A polyvalent machine learning accelerator (2015) Proc. ASPLOS, pp. 369-381; Duranton, M., Brain-inspired computing for advanced image and pattern recognition (2016) Proc. Leti Devices Workshop; Han, S., EIE: Efficient inference engine on compressed deep neural network (2016) Proc. Int. Symp. Comput. Archit. (ISCA), , Jun; Albericio, J., Cnvlutin: Ineffectual-neuron-free deep neural network computing (2016) Proc. ISCA, pp. 1-13; Chen, Y., Krishna, T., Emer, J., Sze, V., 14.5 eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2016) Proc. ISSCC, pp. 262-263; Song, L., C-Brain: A deep learning accelerator that tames the diversity of CNNs through adaptive data-level parallelization (2016) Proc. DAC, pp. 1-6; Shi, Y.Q., Sun, H., (2008) Image and Video Compression for Multimedia Engineering: Fundamentals, Algorithms, and Standards., , Boca Raton, FL, USA: CRC Press; Gustafsson, O., Dempster, A.G., Wanhammar, L., Extended results for minimum-adder constant integer multipliers (2002) Proc. IEEE Int. Symp. Circuits Syst., 1, pp. I73-I76; Alameldeen, A.R., Wood, D.A., Adaptive cache compression for high-performance processors (2004) Proc. ISCA, pp. 212-223; Lin, D.D., Talathi, S., Annapureddy, V.S., Fixed point quantization of deep convolutional networks (2016) Proc. ICML, pp. 2849-2858; The Nangate Open Cell Library, 45nm FreePDK., , https://www.si2.org/openeda.si2.org/projects/nangatelib/, [Online]; Jia, Y., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. Multimedia, pp. 675-678; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. NIPS, pp. 1097-1105; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252; Pekhimenko, G., Base-delta-immediate compression: Practical data compression for on-chip caches (2012) Proc. PACT, pp. 377-388; Cacti 6.5., , http://www.hpl.hp.com/research/cacti/, [Online]; Kim, Y., Yang, W., Mutlu, O., Ramulator: A fast and extensible DRAM simulator (2016) IEEE Comput. Archit. Lett., 15 (1), pp. 45-49. , Jan./Jun; Zhang, Q., Wang, T., Tian, Y., Yuan, F., Xu, Q., ApproxANN: An approximate computing framework for artificial neural network (2015) Proc. DATE, pp. 701-706; Chakradhar, S., Sankaradas, M., Jakkula, V., Cadambi, S., A dynamically configurable coprocessor for convolutional neural networks (2010) ACM SIGARCH Comput. Archit. News, 38 (3), pp. 247-257; Tu, F., Deep convolutional neural network architecture with reconfigurable computation patterns (2017) IEEE Trans. Very Large Scale Integr. (VLSI) Syst., 25 (8), pp. 2220-2233. , Aug; Tu, F., Yin, S., Ouyang, P., Liu, L., Wei, S., RNA: A reconfigurable architecture for hardware neural acceleration (2015) Proc. DATE, pp. 694-700; Wang, Y., Li, H., Li, X., Re-architecting the on-chip memory subsystem of machine-learning accelerator for embedded devices (2016) Proc. ICCAD","Li, H.; State Key Laboratory of Computer Architecture, China; email: lihuawei@ict.ac.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Final","",Scopus,2-s2.0-85037596245
"Vardhana M., Arunkumar N., Lasrado S., Abdulhay E., Ramirez-Gonzalez G.","57193253346;24330633400;57201375603;23388143900;36603157500;","Convolutional neural network for bio-medical image segmentation with hardware acceleration",2018,"Cognitive Systems Research","50",,,"10","14",,85,"10.1016/j.cogsys.2018.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044526146&doi=10.1016%2fj.cogsys.2018.03.005&partnerID=40&md5=d35bdb72ea77472d5b99f5ab2b78d17e","NMAM Institute of Technology, Nitte, India; Sastra University, Tanjore, India; Dept. of ECE, NMAM Institute of Technology, Nitte, India; Jordan University of Science and Technology, Jordan; Universidad del Cauca, Colombia","Vardhana, M., NMAM Institute of Technology, Nitte, India; Arunkumar, N., Sastra University, Tanjore, India; Lasrado, S., Dept. of ECE, NMAM Institute of Technology, Nitte, India; Abdulhay, E., Jordan University of Science and Technology, Jordan; Ramirez-Gonzalez, G., Universidad del Cauca, Colombia","Application of artificial intelligence in Bio-Medical image processing is gaining more and more importance in the field of Medical Science. The bio medical images, has to go through several steps before the diagnosis of the disease. Firstly, the images has to be acquired and preprocessing has to be done and the data has to be stored in memory. It requires huge amount of memory and processing time. Among the preprocessing steps, edge detection is one of the major step. Edge detection filters the unwanted details in the image, and preserves the edges of the image, which describe the boundary of the image. In biomedical application, for the detection of the diseases, it is very essential to have the boundary detail of the acquired image of the organ under observation. Thus it is very essential to extract the edges of the images. Power is one of the main parameters that have to be considered while dealing with biomedical instruments. The biomedical signal processing instruments should be capable of operating at low power and also at high speed. In order to segregate the images into different levels or stage, we use convolutional neural networks for classification. By having a hardware architecture for image edge detection, the computational time for pre-processing of the image can be reduced, and the hardware can be a part of acquisition device itself. In this paper a low-power architecture for edge detection to detect the biomedical images are presented. The edge detection output are given to the system, which will diagnose the diseases using image classification using convolutional neural network. In this paper, Sobel and Prewitt, algorithms are used for edge detection using 180 nm technology. The edge detection algorithms are implemented using VLSI, and digital IC design of the architecture is presented. The algorithms for edge detection is co-simulated using MATLAB and Modelsim. The architecture is first simulated using CMOS logic and new method using domino logic is presented for low power consumption. © 2018 Elsevier B.V.","Convolutional neural network; Domino; Prewitt; RTL; Sobel","Computation theory; Convolution; Diagnosis; Digital integrated circuits; Edge detection; Hardware; Image acquisition; Image segmentation; Medical applications; Medical imaging; Memory architecture; Network architecture; Neural networks; Bio-medical image processing; Biomedical applications; Convolutional neural network; Domino; Edge detection algorithms; Low power architecture; Prewitt; Sobel; Medical image processing; Article; artificial intelligence; artificial neural network; bone radiography; brain radiography; brain tumor; classification algorithm; computer assisted tomography; convolutional neural network; image analysis; image processing; image segmentation; mathematical computing; priority journal; signal processing; simulation; thorax radiography",,,,,,,,,,,,,,,,"Aggarwal, P., Sardana, H.K., Vig, R., (2010), An efficient visualization and segmentation of lung CT scan images for early diagnosis of cancer. In National Conference on Computational Instrumentation CSIO Chandigarh, India (pp. 100–104); Al-Tamimi, M.S.H., Sulong, G., Tumor brain detection through Mr images: A review of literature (2014) Journal of Theoretical and Applied Information Technology, 62; Dhanwani, D.C., Bartere, M.M., Survey on various techniques of brain tumor detection from MRI images (2014) IJCER, 4, pp. 24-26; Gupta, G., Tiwari, S., Boundary extraction of biomedical images using edge operators (2015) International Journal of Innovative Research in Computer and Communication Engineering, 3, pp. 11135-11141; Joshi, M.A., Shah, D., (2015), H. (2015). Survey of brain tumor detection techniques through MRI images. AIJRFANS, March-May; Kavitkar, S.G., Paikrao, P.L., FPGA based image feature extraction using xilinx system generator (2014) International Journal of Computer Science and Information Technologies, 5, pp. 3743-3747; Mankar, D., Mungona, S.S., A review on implementation of image processing algorithms using hardware software co-simulation (2015) International Journal on Recent and Innovation Trends in Computing and Communication, 3, pp. 14-17; Panigrahi, M., Mahakud, R., Samantaray, M., Mohapatra, S.K., (2014), Comparitive Analysis of different Edge detection techniques for bio medical images using MATLAB (Vol. 1, pp. 23–28); Rahebi, J., Tajik, H.R., Biomedical image edge detection using an ant colony optimization based on artificial neural networks (2011) International Journal of Engineering Science and Technology, 3, pp. 8211-8218; Verma, K., Mehrotra, A., Pandey, V., Singh, S., Image processing techniques for the enhancement of brain tumor patterns (2013) International Journal of Advanced Research in Electrical, Electronics and Instrumentation Engineering, 2, pp. 1611-1615","Arunkumar, N.; Sastra UniversityIndia; email: arun.nura@gmail.com",,,"Elsevier B.V.",,,,,13890417,,CSROA,,"English","Cogn. Sys. Res.",Article,"Final","",Scopus,2-s2.0-85044526146
"Yu H., Langari R.","56762994900;7006275578;","A neural network-based detection and mitigation system for unintended acceleration",2018,"Journal of the Franklin Institute","355","10",,"4315","4335",,1,"10.1016/j.jfranklin.2018.04.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046653158&doi=10.1016%2fj.jfranklin.2018.04.014&partnerID=40&md5=bd7b1efe2a97415227311a4f9470f7bb","Department of Mechanical Engineering, Texas A&M University, College Station, TX  77840, United States","Yu, H., Department of Mechanical Engineering, Texas A&M University, College Station, TX  77840, United States; Langari, R., Department of Mechanical Engineering, Texas A&M University, College Station, TX  77840, United States","Modern vehicles are equipped with a growing number of electronic devices, which significantly improve the driving experience. However, the complicated architecture of electronic systems also increases the difficulty of fault diagnosis since process models are often unavailable. This paper presents a novel detection and mitigation system for vehicle related anomalies originating in unintended acceleration (UA), which has become one of the most complained-about vehicle problems in recent history. The detection system consists of several neural network-based models, which are created by analyzing historical vehicle data at specific moments such as acceleration peaks and gear shifting. These data-driven models describe the boundary of normal vehicle behavior in the data space. A priori knowledge of complete vehicle structures is not necessary for building them. The detection system combines these models to decide if a UA event has occurred. When a UA event is detected, a mitigation system cuts the engine power and adjusts the braking force accordingly. The whole system was validated in the Simulink/dSPACE environment. UA errors were simulated so that they occurred randomly when human subjects drove virtual cars in a simulated environment. Random noise of sensors were also considered and incorporated to add realism. Various traffic scenarios were included in tests. Test results show that the integrated system is capable of detecting UA in one second with high accuracy and reducing the risk of accidents. © 2018 The Franklin Institute",,"Fault detection; Virtual reality; Data-driven model; Driving experiences; Electronic device; Electronic systems; Integrated systems; Mitigation systems; Simulated environment; Vehicle structures; Automobile electronic equipment",,,,,"Toyota Motor Corporation, Toyota","This work is supported by Toyota Motor Corporation. This paper is an extension of work originally reported in ASME 2015 Dynamic Systems and Control Conference [35] .",,,,,,,,,,"Barr, M., (2013), http://www.safetyresearch.net/Library/BarrSlides_FINAL_SCRUBBED.pdf, 2005 Camry L4 Software Analysis. Retrieved from; Bevly, D.M., Global positioning system (GPS): a low-cost velocity sensor for correcting inertial sensor errors on ground vehicles (2004) J. Dyn. Syst. Meas. Control, 126 (2), pp. 255-264; Bishop, C.M., Pattern Recognition and Machine Learning (2006), Springer New York; Chen, D., Lo, P., Swan, W., Zero-lag exponential moving average for real-time control and noisy data processing (2007) Hydrocarb. Process., 86 (10). , 61-61; Ding, S., Model-based Fault Diagnosis techniques: Design schemes, algorithms, and Tools (2008), Springer Science & Business Media; Duda, R.O., Hart, P.E., Stork, D.G., Pattern Classification (2012), John Wiley & Sons; Herrera, J.C., Work, D.B., Herring, R., Ban, X.J., Jacobson, Q., Bayen, A.M., Evaluation of traffic data obtained via GPS-enabled mobile phones: the mobile century field experiment (2010) Transp. Res. Part C: Emerg. Technol., 18 (4), pp. 568-583; Hwang, I., Kim, S., Kim, Y., Seah, C.E., A survey of fault detection, isolation, and reconfiguration methods (2010) IEEE Trans. Control Syst. Technol., 18 (3), pp. 636-653; Isermann, R., Diagnosis methods for electronic controlled vehicles (2001) Veh. Syst. Dyn., 36 (2-3), pp. 77-117; Isermann, R., Model-based fault-detection and diagnosis–status and applications (2005) Ann. Rev. Control, 29 (1), pp. 71-85; Jeppesen, B., Cebon, D., Application of observer-based fault detection in vehicle roll control (2009) Veh. Syst. Dyn., 47 (4), pp. 465-495; Kane, S., Liberman, E., DiViesti, T., Click, F., Toyota sudden unintended acceleration (2010) Rehoboth (MA): Safety Research & Strategies, p. 180; Kennel, M.B., Brown, R., Abarbanel, H.D., Determining embedding dimension for phase-space reconstruction using a geometrical construction (1992) Phys. Rev. A, 45 (6), p. 3403; Koopman, P., https://www.slideshare.net/PhilipKoopman/toyota-unintended-acceleration, “A case study of toyota unintended acceleration and software safety,” Public seminar, September 2014. Retrieved from; LeBlanc, D.J., Sivak, M., Bogard, S., (2010), Using naturalistic driving data to assess variations in fuel efficiency among individual drivers, Report No. UMTRI-2010-34, University of Michigan Transportation Research Institute, Ann Arbor, Michigan; MacIsaac, B., Langton, R., (2011) Gas Turbine Propulsion Systems, 49. , John Wiley & Sons; Meinguet, F., Sandulescu, P., Kestelyn, X., Semail, E., A method for fault detection and isolation based on the processing of multiple diagnostic indices: application to inverter faults in AC drives (2013) IEEE Trans. Veh. Technol., 62 (3), pp. 995-1009; Miller, W.T., Werbos, P.J., Sutton, R.S., Neural Networks For Control (1995), MIT press; Mitchell, T.M., Machine learning. WCB (1997), McGraw-Hill Boston, MA; Moseler, O., Isermann, R., Application of model-based fault detection to a brushless DC motor (2000) IEEE Trans. Ind. Electron., 47 (5), pp. 1015-1020; Kirsch, M.T., Regenie, V.A., Aguilar, M.L., Gonzalez, O., Bay, M., Davis, M.L., Null, C.H., Kichak, R.A., Technical support to the national highway traffic safety administration (NHTSA) on the reported Toyota Motor Corporation (TMC) unintended acceleration (UA) investigation. NASA Engineering and Safety Center Technical Assessment Report (January 2011); (2012) The Safety Promise and Challenge of Automotive Electronics: Insights from Unintended Acceleration, 308. , Transportation Research Board; (2011), https://www.nhtsa.gov/staticfiles/nvs/pdf/NHTSA-UA_report.pdf, Technical Assessment of Toyota Electronic Throttle Control (ETC) Systems. Retrieved from; Ogorevc, J., Geršak, G., Novak, D., Drnovšek, J., Metrological evaluation of skin conductance measurements (2013) Measurement, 46 (9), pp. 2993-3001; Ohnishi, H., Ishii, J., Kayano, M., Katayama, H., A study on road slope estimation for automatic transmission control (2000) JSAE Rev., 21 (2), pp. 235-240; Pollard, J., Sussman, E.D., An Examination of Sudden Acceleration (1989), National Highway Traffic Safety Administratyion; Purwandini Sutarto, A., Abdul Wahab, M.N., Mat Zin, N., Resonant breathing biofeedback training for stress reduction among manufacturing operators (2012) Int. J. Occup. Saf. Ergon., 18 (4), pp. 549-561; Vehicle Dynamics Terminology (2008), SAE Standard J670; Samy, I., Postlethwaite, I., Gu, D.-W., Survey and application of sensor fault detection and isolation schemes (2011) Control Eng. Pract., 19 (7), pp. 658-674; Sebsadji, Y., Glaser, S., Mammar, S., Dakhlallah, J., Road slope and vehicle dynamics estimation (2008) Proceedings of Paper presented at the American Control Conference, 2008; Su, X., Shi, P., Wu, L., Song, Y.-D., Fault detection filtering for nonlinear switched stochastic systems (2016) IEEE Trans. Autom. Control, 61 (5), pp. 1310-1315; Su, X., Wu, L., Shi, P., Sensor networks with random link failures: distributed filtering for T-S fuzzy systems (2013) IEEE Trans. Ind. Inform., 9 (3), pp. 1739-1750; Takens, F., Detecting Strange Attractors in Turbulence (1981), Springer; Wang, J., H∞ fault-tolerant controller design for networked control systems with time-varying actuator faults (2015) Int. J. Innov. Comput., Inf. Control, 11 (4), pp. 1471-1481; Yu, H., Langari, R., A detection and warning system for unintended acceleration (2015) Proceedings of Paper presented at the ASME 2015 Dynamic Systems and Control Conference; Yu, H., Langari, R., Detection of unintended acceleration in longitudinal car following (2015) SAE Int. J. Passeng. Cars-Electron. Electr. Syst., 8, pp. 306-313. , (2015-01-0208); Zhang, M., Shen, X., Li, T., Fault tolerant attitude control for cubesats with input saturation based on dynamic adaptive neural network (2016) Int. J. Innov. Comput. Inf. Control, 12 (2), pp. 651-663","Yu, H.; Department of Mechanical Engineering, United States; email: hzy5046@tamu.edu",,,"Elsevier Ltd",,,,,00160032,,JFINA,,"English","J Franklin Inst",Article,"Final","",Scopus,2-s2.0-85046653158
"Chen X., Yu Z.","57201451722;7404346340;","A Flexible and Energy-Efficient Convolutional Neural Network Acceleration With Dedicated ISA and Accelerator",2018,"IEEE Transactions on Very Large Scale Integration (VLSI) Systems","26","7",,"1408","1412",,6,"10.1109/TVLSI.2018.2810831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044864893&doi=10.1109%2fTVLSI.2018.2810831&partnerID=40&md5=139336e3d249112cad52033a8ad2e9d5","School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, 510006, China","Chen, X., School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, 510006, China; Yu, Z., School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, 510006, China","State-of-the-art convolutional neural networks (CNNs) usually have a large number of layers and filter weights which bring huge computation and communication overheads. A general purpose instruction set architecture (ISA) is flexible but has low code density and high power consumption. The existing CNN-specific accelerators are much more efficient but usually are inflexible or require a complex controller to handle the computation and data transfer of different CNNs. In this brief, we propose a new CNN-specific ISA which embeds the parallel computation and data reuse parameters in the instructions. An instruction generator deploys the instruction parameters according to the feature of CNNs and hardware's computation and storage resources. In addition, a reconfigurable accelerator with 225 multipliers and 24 adder trees is realized to obtain efficient parallel computation and data transfer. Compared with x86 processors, our design has 392 times better energy efficiency and 16 times higher code density. Compared with other state-of-the-art accelerators, our solution has a higher flexibility to support all popular CNNs and a higher energy efficiency. © 2018 IEEE.","Accelerator; convolutional neural network (CNN); data reuse; energy efficiency; flexibility; instruction set architecture (ISA); parallel computation","Acceleration; Adders; Computer architecture; Computer hardware; Convolution; Data transfer; Digital storage; Engines; Hardware; Network architecture; Neural networks; Parameter estimation; Particle accelerators; Trees (mathematics); Convolutional Neural Networks (CNN); Data reuse; flexibility; Instruction set architecture; Parallel Computation; Registers; Energy efficiency",,,,,"National Natural Science Foundation of China, NSFC: 61674173","This work was supported in part by the National Nature Science Foundation of China under Grant 61674173.",,,,,,,,,,"Le Cun, Y., Handwritten digit recognition: Applications of neural net chips and automatic learning (1989) IEEE Commun. Mag., 27 (11), pp. 41-46. , Nov; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , https://arxiv.org/abs/1409.1556, [Online]; Szegedy, C., Going deeper with convolutions (2015) Proc. IEEE Comput. Vis. Pattern Recognit, pp. 1-9. , Jun; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Comput. Vis. Pattern Recognit, pp. 770-778. , Jun; Liu, S., Cambricon: An instruction set architecture for neural networks (2016) Proc. ACM/IEEE Int. Symp. Comput. Archit., pp. 393-405. , Jun; Moons, B., Verhelst, M., An energy-efficient precision-scalable ConvNet processor in 40-nm CMOS (2017) IEEE J. Solid-State Circuits, 52 (4), pp. 903-914. , Apr; Suda, N., Throughput-optimized OpenCL-based FPGA accelerator for large-scale convolutional neural networks (2016) Proc. ACM/SIGDA Int. Symp. FPGA, pp. 16-25; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks (2015) Proc. ACM/SIGDA Int. Symp. Field-Programm. Gate Arrays, pp. 161-170; Qiu, J., Going deeper with embedded FPGA platform for convolutional neural network (2016) Proc. ACM/SIGDA Int. Symp. Field-Programm. Gate Arrays, pp. 26-35; Chen, Y.H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energyefficient reconfigurable accelerator for deep convolutional neural networks (2017) IEEE J. Solid-State Circuits, 52 (1), pp. 127-138. , Jan; Chen, Y., DaDianNao: A machine-learning supercomputer (2014) Proc. IEEE/ACM Int. Symp. Microarchitecture, pp. 609-622; Chakradhar, S., Sankaradas, M., Jakkula, V., Cadambi, S., A dynamically configurable coprocessor for convolutional neural networks (2010) ACM SIGARCH Comput. Archit. News, 38 (3), pp. 247-257","Yu, Z.; School of Electronics and Information Technology, China; email: yuzhiyi@mail.sysu.edu.cn",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,10638210,,IEVSE,,"English","IEEE Trans Very Large Scale Integr VLSI Syst",Article,"Final","",Scopus,2-s2.0-85044864893
"Bai Y., Fan D., Lin M.","55217532900;55778301000;14035959400;","Stochastic-based synapse and soft-limiting neuron with spintronic devices for low power and robust artificial neural networks",2018,"IEEE Transactions on Multi-Scale Computing Systems","4","3","8240945","463","476",,9,"10.1109/TMSCS.2017.2787109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040038360&doi=10.1109%2fTMSCS.2017.2787109&partnerID=40&md5=e7c1658d16f7ea29fe709cd7b5c96cf4","Department of Engineering and Computer Science, California State University, Fullerton, CA  92831, United States; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL  32817, United States","Bai, Y., Department of Engineering and Computer Science, California State University, Fullerton, CA  92831, United States; Fan, D., Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL  32817, United States; Lin, M., Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL  32817, United States","We propose an innovative stochastic-based computing architecture to implement low-power and robust artificial neural network (S-ANN) with both magnetic tunneling junction (MTJ) and Domain Wall (DW) devices. Our mixed-model HSPICE simulation results have shown that, for a well-known pattern recognition task, a 34-neuron S-ANN implementation achieves more than 1.5 orders of magnitude lower energy consumption and 2.5 orders of magnitude less hidden layer chip area, when compared with its deterministic-based ANN counterparts which are implemented with digital and analog CMOS circuits. We believe that our S-ANN architecture achieves such a remarkable performance gain by leveraging two key ideas. First, because all neural signals are encoded as random bit streams, the standard weighted-sum synapses can be accomplished by stochastic bit writing and reading procedure. Second, we designed and implemented a novel multiple-phase pumping circuit structure to effectively realize the soft-limiting neural transfer function that is essential to improve the overall ANN capability and reduce its network complexity. © 2015 IEEE.","artificial neural network; domain wall motion; Magnetic tunneling junction; soft-limiting neuron; stochastic computing","Computer architecture; Computer hardware; Domain walls; Energy utilization; Magnetic devices; Network architecture; Neural networks; Neurons; Pattern recognition; Random processes; SPICE; Stochastic systems; Transfer functions; Analog CMOS circuit; Biological neural networks; Computing architecture; Domain wall motion; Magnetic tunneling junctions; Neural transfer functions; Orders of magnitude; Stochastic computing; Low power electronics",,,,,,,,,,,,,,,,"Fan, D., Sharad, M., Sengupta, A., Roy, K., Hierarchical temporal memory based on spin-neurons and resistive memory for energy-efficient brain-inspired computing (2016) IEEE Trans. Neural Netw. Learning Syst., 27 (9), pp. 1907-1919; Fan, D., Sharad, M., Roy, K., Design and synthesis of ultralow energy spin-memristor threshold logic (2014) IEEE Trans. Nanotechnol., 13 (3), pp. 574-583. , May; Fan, D., (2015) Boolean and Brain-inspired Computing Using Spintransfer Torque Devices, , PhD thesis, Dept. Elect. Comput. Eng., Purdue Univ., West Lafayette, IN, USA; Fan, D., Maji, S., Yogendra, K., Sharad, M., Roy, K., Injectionlocked spin hall-induced coupled-oscillators for energy efficient associative computing (2015) IEEE Trans. Nanotechnol., 14 (6), pp. 1083-1093. , Nov; Basheer, I., Hajmeer, M., Artificial neural networks: Fundamentals, computing, design, and application (2000) J. Microbiological Methods, 43 (1), pp. 3-31; Hopfield, J.J., Artificial neural networks (1988) IEEE Circuits Devices Mag., 4 (5), pp. 3-10. , Sep; Chua, L., Yang, L., Cellular neural networks: Theory (1988) IEEE Trans. Circuits Syst., 35 (10), pp. 1257-1272. , Oct; Fan, D., Shim, Y., Raghunathan, A., Roy, K., STT-SNN: A spintransfer-torque based soft-limiting non-linear neuron for lowpower artificial neural networks (2015) IEEE Trans. Nanotechnology, 14 (6), pp. 1013-1023; Nedjah, N., Mourelle Macedo De, L., Stochastic reconfigurable hardware for neural networks (2003) Proc. Euromicro Symp. Digit. Syst. Des., pp. 438-442. , Sep; Ordoñez Cardenas, E., Romero-Troncoso, R.D.J., MLP neural network and on-line backpropagation learning implementation in a low-cost FPGA (2008) Proc. 18th ACM Great Lakes Symp. VLSI, pp. 333-338; Ebong, I.E., Mazumder, P., CMOS and memristor-based neural network design for position detection (2012) Proc. IEEE, 100 (6), pp. 2050-2060. , Jun; Kolasa, M., Dlugosz, R., An advanced software model for optimization of self-organizing neural networks oriented on implementation in hardware (2015) Proc. 22nd Int. Conf. Mixed Des. Integr. Circuits Syst., pp. 266-271. , Jun; Li, H., Zhang, D., Foo, S., A stochastic digital implementation of a neural network controller for small wind turbine systems (2006) IEEE Trans. Power Electron., 21 (5), pp. 1502-1507. , Sep; Ji, Y., Ran, F., Ma, C., Lilja, D., A hardware implementation of a radial basis function neural network using stochastic logic (2015) Proc. Des. Autom. Test Eur. Conf. Exhib., pp. 880-883. , Mar; Gadea, R., Cerda, J., Ballester, F., Mocholí, A., Artificial neural network implementation on a single FPGA of a pipelined on-line backpropagation (2000) Proc. 13th Int. Symp. Syst. Synthesis, pp. 225-230; Kung, S., (1993) Digital Neural Networks, , Englewood Cliffs, NJ, USA: Prentice Hall; Ienne, P., Digital hardware architectures for neural networks (1995) Speedup J., 1 (9); Bermak, A., Martinez, D., A compact 3D VLSI classifier using bagging threshold network ensembles (2003) IEEE Trans. Neural Netw., 14 (5), pp. 1097-1109. , Sep; Dobes, J., Pospisil, L., Yadav, A., Precise characterization of memristive systems by cooperative artificial neural networks (2012) Proc. Joint 6th Int. Conf. Soft Comput. Intell. Syst. 13th Int. Symp. Adv. Intell. Syst., pp. 2130-2133. , Nov; Starzyk, J.A., Basawaraj, Memristor crossbar architecture for synchronous neural networks (2014) IEEE Trans. Circuits Syst. I: Reg. Papers, 61 (8), pp. 2390-2401. , Aug; Bayraktaroglu, I., Ögrenci, A.S., Dündar, G., Balkir, S., Alpaydin, E., ANNSyS: An analog neural network synthesis system (1999) Neural Netw., 12 (2), pp. 325-338; Alippi, C., Selecting accurate, robust, and minimal feedforward neural networks (2002) IEEE Trans. Circuits Syst. I: Fundam. Theory Appl., 49 (12), pp. 1799-1810. , Dec; Dlugosz, R., Talaska, T., Pedrycz, W., Current-mode analog adaptive mechanism for ultra-low-power neural networks (2011) IEEE Trans. Circuits Syst. II: Exp. Briefs, 58 (1), pp. 31-35. , Jan; Belli, M., Conti, M., Crippa, P., Turchetti, C., Artificial neural networks as approximators of stochastic processes (1999) Neural Netw., 12 (45), pp. 647-658; Windecker, R., Stochastic artificial neural networks and random walks (2011) Proc. Int. Joint Conf. Neural Netw., pp. 1134-1140. , Jul; Palma, G., Suri, M., Querlioz, D., Vianello, E., De Salvo, B., Stochastic neuron design using conductive bridge RAM (2013) Proc. IEEE/ACM Int. Symp. Nanoscale Archit., pp. 95-100. , Jul; Kosel, T., Jeavons, P., Shawe-Taylor, J., Emergent activation functions from a stochastic bit-stream neuron (1994) Electron. Lett., 30, pp. 331-333. , Feb; Brown, B.D., Card, H.C., Stochastic neural computation. II. Soft competitive learning (2001) IEEE Trans. Comput., 50 (9), pp. 906-920. , Sep; Chun, S., Lee, S.-B., Hara, M., Park, W., Kim, S.-J., High-density physical random number generator using spin signals in multidomain ferromagnetic layer (2015) Advances Condensed Matter Physics, 2015. , Art. no. 251819; Gaines, B.R., Stochastic computing systems (1969) Advances Inf. Syst. Sci., 2 (2), pp. 37-172; Kim, K.-H., A functional hybrid memristor crossbar-array/CMOS system for data storage and neuromorphic applications (2011) Nano Lett., 12 (1), pp. 389-395; Borghetti, J., Snider, G.S., Kuekes, P.J., Yang, J.J., Stewart, D.R., Williams, R.S., Memristiveswitches enable statefullogic operations via material implication (2010) Nature, 464 (7290), pp. 873-876; Yu, S., Guan, X., Wong, H.-S., On the stochastic nature of resistive switching in metal oxide RRAM: Physical modeling, monte carlo simulation, and experimental characterization (2011) Proc. IEEE Int. Electron Devices Meet., , Dec; Rajendran, J., Manem, H., Karri, R., Rose, G., An energyefficient memristive threshold logic circuit (2012) IEEE Trans. Comput., 61 (4), pp. 474-487. , Apr; Choi, W.H., A magnetic tunnel junction based true random number generator with conditional perturb and real-time output probability tracking (2014) Proc. IEEE Int. Electron Devices Meet., , Dec; Zhang, Y., Compact modeling of perpendicular-anisotropy CoFeB/MgO magnetic tunnel junctions (2012) IEEE Trans. Electron Devices, 59 (3), pp. 819-826. , Mar; Vincent, A., Spin-transfer torque magnetic memory as a stochastic memristive synapse for neuromorphic systems (2015) IEEE Trans. Biomed. Circuits Syst., 9 (2), pp. 166-174. , Apr; Fong, X., Chen, M.-C., Roy, K., Generating true random numbers using on-chip complementary polarizer spin-transfer torque magnetic tunnel junctions (2014) Proc. 72nd Annu. Device Res. Conf., pp. 103-104. , Jun; Onizawa, N., Matsunaga, S., Hanyu, T., A compact soft-error tolerant asynchronous TCAM based on a transistor/magnetictunnel-junction hybrid dual-rail word structure (2014) Proc. 20th IEEE Int. Symp. Asynchronous Circuits Syst., pp. 1-8. , May; Zhu, J.-G.J., Park, C., Magnetic tunnel junctions (2006) Mater. Today, 9 (11), pp. 36-45; Yagami, K., Tulapurkar, A., Fukushima, A., Suzuki, Y., Inspection of intrinsic critical currents for spin-transfer magnetization switching (2005) IEEE Trans. Magn., 41 (10), pp. 2615-2617. , Oct; Fukushima, A., Spin dice: A scalable truly random number generator based on spintronics (2014) Appl. Physics Exp., 7 (8). , Art. no. 083001; Fukami, S., 20-nm magnetic domain wall motion memory with ultralow-power operation (2013) Proc. IEEE Int. Electron Devices Meet., , Dec; Feigenson, M., Reiner, J.W., Klein, L., Efficient currentinduced domain-wall displacement in SrRuO3 (2007) Phys. Rev. Lett., 98. , Jun. Art. no. 247204; Fong, X., Gupta, S., Mojumder, N., Choday, S., Augustine, C., Roy, K., KNACK: A hybrid spin-charge mixed-mode simulator for evaluating different genres of spin-transfer torque MRAM bitcells (2011) Proc. Int. Conf. Simul. Semicond. Processes Devices, pp. 51-54. , Sep; Chanthbouala, A., Vertical-current-induced domain-wall motion in MgO-based magnetic tunnel junctions with low current densities (2011) Nature Physics, 7 (8), pp. 626-630. , Dec; Sengupta, A., Shim, Y., Roy, K., Simulation studies of an allspin artificial neural network: Emulating neural and synaptic functionalities through domain wall motion in ferromagnets (2016) IEEE Trans. Biomed. Circuits Syst., 10 (6), pp. 1152-1160; Sentovich, E., (1992) SIS: A System for Sequential Circuit Synthesis, , EECS Dept., Univ. California, Berkeley, CA, USA, Tech. Rep. UCB/ERL M92/41; Sharad, M., Fan, D., Roy, K., Spin-neurons: A possible path to energy-efficient neuromorphic computers (2013) J. Appl. Physics, 114 (23). , Art. no. 234906; Sharad, M., Augustine, C., Panagopoulos, G., Roy, K., Spinbased neuron model with domain-wall magnets as synapse (2012) IEEE Trans. Nanotechnol., 11 (4), pp. 843-853. , Jul; Ramasubramanian, S., Venkatesan, R., Sharad, M., Roy, K., Raghunathan, A., Spindle: Spintronic deep learning engine for large-scale neuromorphic computing (2014) Proc. IEEE/ACM Int. Symp. Low Power Electron. Des., pp. 15-20. , Aug; Wang, S., Hybrid VC-MTJ/CMOS non-volatile stochastic logic for efficient computing (2017) Proc. Des. Autom. Test Eur. Conf. Exhib., pp. 1438-1443; Li, H., Zhang, D., Foo, S.Y., A stochastic digital implementation of a neural network controller for small wind turbine systems (2006) IEEE Trans. Power Electron., 21 (5), pp. 1502-1507. , Sep; Brown, B.D., Card, H.C., Stochastic neural computation. I. Computational elements (2001) IEEE Trans. Comput., 50 (9), pp. 891-905. , Sep; Li, Z., Ren, A., Li, J., Qiu, Q., Wang, Y., Yuan, B., DSCNN: Hardware-oriented optimization for stochastic computing based deep convolutional neural networks (2016) Proc. IEEE 34th Int. Conf. Comput. Des., pp. 678-681. , Oct; Li, P., Lilja, D.J., Qian, W., Bazargan, K., Riedel, M., The synthesis of complex arithmetic computation on stochastic bit streams using sequential logic (2012) Proc. Int. Conf. Comput.-Aided Des., pp. 480-487; Kim, Y., Fong, X., Kwon, K.-W., Chen, M.-C., Roy, K., Multilevel spin-orbit torque MRAMs (2015) IEEE Trans. Electron Devices, 62 (2), pp. 561-568. , Feb; Yakopcic, C., Taha, T.M., Hasan, R., Hybrid crossbar architecture for a memristor based memory (2014) Proc. IEEE Nat. Aerosp. Electron. Conf., pp. 237-242; Chen, E., Lottis, D., Driskill-Smith, A., Druist, D., Nikitin, V., Watts, S., Tang, X., Apalkov, D., Non-volatile spin-transfer torque RAM (STT-RAM) (2010) 68th Device Res. Conf., pp. 249-252. , Jun; Chen, T.-H., Alaghi, A., Hayes, J.P., Behavior of stochastic circuits under severe error conditions (2014) It-Inf. Technol., 56 (4), pp. 182-191; Bai, Y., Lin, M., Stochastic-based spin-programmable gate array with emerging MTJ device technology (2016) J. Low Power Electron. Appl., 6 (3). , Art. no. 15; Sengupta, A., Parsa, M., Han, B., Roy, K., Probabilistic deep spiking neural systems enabled by magnetic tunnel junction (2016) IEEE Trans. Electron Devices, 63 (7), pp. 2963-2970. , Jul; Metaxas, P.J., High domain wall velocities via spin transfer torque using vertical current injection (2013) Sci. Rep., 3. , Art. no. 1829; Lacour, D., Experimental evidence of multiple stable locations for a domain wall trapped by a submicron notch (2004) Appl. Physics Lett., 84 (11), pp. 1910-1912; Büttner, F., Krüger, B., Eisebitt, S., Kläui, M., Accurate calculation of the transverse anisotropy of a magnetic domain wall in perpendicularly magnetized multilayers (2015) Phys. Rev. B, 92. , Aug. Art. no. 054408; Drews, A., Selke, G., Möller, D.P.F., Multi-physical simulations of current-induced domain wall motion using graphics processing units (2010) Proc. Conf. Grand Challenges Model. Simul., pp. 152-157; Prezioso, M., Merrikh-Bayat, F., Hoskins, B.D., Adam, G., Likharev, K.K., Strukov, D.B., Training and operation of an integrated neuromorphic network based on metal-oxide memristors (2015) Nature, 521 (7550), pp. 61-64","Bai, Y.; Department of Engineering and Computer Science, United States; email: ybai@fullerton.ed",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,23327766,,,,"English","IEEE Trans. Multi-Scale Comput. Syst.",Article,"Final","",Scopus,2-s2.0-85040038360
"Taylor B., Marco V.S., Wolff W., Elkhatib Y., Wang Z.","57198303996;57195337351;56494455600;55777338100;35111811300;","Adaptive deep learning model selection on embedded systems",2018,"ACM SIGPLAN Notices","53","6",,"31","43",,28,"10.1145/3211332.3211336","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084192663&doi=10.1145%2f3211332.3211336&partnerID=40&md5=f68e1c029494ec839c31e89f18ca7171","MetaLab, Lancaster University, United Kingdom","Taylor, B., MetaLab, Lancaster University, United Kingdom; Marco, V.S., MetaLab, Lancaster University, United Kingdom; Wolff, W., MetaLab, Lancaster University, United Kingdom; Elkhatib, Y., MetaLab, Lancaster University, United Kingdom; Wang, Z., MetaLab, Lancaster University, United Kingdom","The recent ground-breaking advances in deep learning networks (DNNs) make them attractive for embedded systems. However, it can take a long time for DNNs to make an inference on resource-limited embedded devices. Offloading the computation into the cloud is often infeasible due to privacy concerns, high latency, or the lack of connectivity. As such, there is a critical need to find a way to effectively execute the DNN models locally on the devices. This paper presents an adaptive scheme to determine which DNN model to use for a given input, by considering the desired accuracy and inference time. Our approach employs machine learning to develop a predictive model to quickly select a pre-trained DNN to use for a given input and the optimization constraint. We achieve this by first training off-line a predictive model, and then use the learnt model to select a DNN model to use for new, unseen inputs. We apply our approach to the image classification task and evaluate it on a Jetson TX2 embedded deep learning platform using the ImageNet ILSVRC 2012 validation dataset. We consider a range of influential DNN models. Experimental results show that our approach achieves a 7.52% improvement in inference accuracy, and a 1.8x reduction in inference time over the most-capable single DNN model. © 2018 ACM.","Adaptive computing; Deep learning; Embedded systems","Classification (of information); Embedded systems; Learning systems; Adaptive scheme; Embedded device; Learning models; Learning network; Learning platform; Predictive modeling; Privacy concerns; Deep learning",,,,,"Engineering and Physical Sciences Research Council, EPSRC: EP/M01567X/1, EP/M015734/1, EP/M015793/1","This work was partly supported by the UK EPSRC under grants EP/M015734/1 (Dionasys), EP/M01567X/1 (SANDeRs), and EP/M015793/1 (DIVIDEND).",,,,,,,,,,"Allaire, J.J., Eddelbuettel, D., Golding, N., Tang, Y., (2016) TensorFlow for R, , https://tensorflow.rstudio.com/; Amodei, D., Deep speech 2: End-to-end speech recognition in english and Mandarin (2016) ICML '16; Bahdanau, D., (2014) Neural Machine Translation by Jointly Learning to Align and Translate, , 2014; Bhattacharya, S., Lane, N.D., Sparsification and separation of deep learning layers for constrained resource inference on wearables (2016) Conference on Embedded Networked Sensor Systems; Canziani, A., Paszke, A., Culurciello, E., An analysis of deep neural network models for practical applications (2016) CoRR, , (2016); Chen, S., Adaptive optimization of sparse matrix-vector multiplication on emerging many-core architectures (2018) HPCC '18; Chen, W., Compressing neural networks with the hashing trick (2015) ICML '16; Cho, K., Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014) EMNLP '14; Cummins, C., End-to-end deep learning of optimization heuristics (2017) PACT '17; Delimitrou, C., Kozyrakis, C., Quasar: Resourceefficient and qos-aware cluster management (2014) ASPLOS '14; Donahue, J., Decaf: A deep convolutional activation feature for generic visual recognition (2014) ICML '14; Krishna Emani, M., Smart, adaptive mapping of parallelism in the presence of external workload (2013) CGO '13; Krishna Emani, M., O'Boyle, M., Celebrating diversity: A mixture of experts approach for runtime mapping in dynamic environments (2015) PLDI '15; Georgiev, P., Low-resource multi-task audio sensing for mobile and embedded devices via shared deep neural network representations (2017) ACM Interact. Mob. Wearable Ubiquitous Technol, , (2017); Grewe, D., A workload-aware mapping approach for data-parallel programs (2011) HiPEAC '11; Grewe, D., OpenCL task partitioning in the presence of GPU contention (2013) LCPC '13; Grewe, D., Portable mapping of data parallel programs to OpenCL for heterogeneous systems (2013) CGO '13; Guo, T., Towards efficient deep inference for mobile applications (2017) CoRR, , abs/1707. 04610 2017; Han, S., Learning both weights and connections for efficient neural network (2015) NIPS '15; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dally, W.J., EIE: Efficient inference engine on compressed deep neural network (2016) ISCA '16; Hassaballah, M., Image features detection, description and matching (2016) Image Feature Detectors and Descriptors; He, K., Deep residual learning for image recognition (2016) CVPR '16; He, K., Identity mappings in deep residual networks (2016) ECCV '16; Howard, A.G., (2017) Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications, , 2017; Huynh, L.N., Deepmon: Mobile GPU-based deep learning framework for continuous vision applications (2017) MobiSys '17; Iandola, F.N., SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size (2016) CoRR, , abs/1602. 07360 2016; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) ICML '15; Jin, J., Dundar, A., Culurciello, E., (2015) Flattened Convolutional Neural Networks for Feedforward Acceleration, , (2015); Kang, Y., Neurosurgeon: Collaborative intelligence between the cloud and mobile edge (2017) ASPLOS '17; Klein, A., (2016) Fast Bayesian Optimization of Machine Learning Hyperparameters on Large Datasets, , 2016; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) NIPS '12; Lane, N.D., Bhattacharya, S., Georgiev, P., Forlivesi, C., Jiao, L., Qendro, L., Kawsar, F., DeepX: A software accelerator for low-power deep learning inference on mobile devices (2016) IPSN '16; Salar Latifi Oskouei, S., Cnndroid: GPU-accelerated execution of trained deep convolutional neural networks on android (2016) Multimedia Conference; Lee, H., Unsupervised feature learning for audio classification using convolutional deep belief networks (2009) NIPS '09; Sanz Marco, V., Improving spark application throughput via memory aware task co-location: A mixture of experts approach (2017) Middleware '17; Motamedi, M., Machine intelligence on resource-constrained iot devices: The case of thread granularity optimization for cnn inference (2017) ACM Trans. Embed. Comput. Syst.; Ogilvie, W.F., Fast automatic heuristic construction using active learning (2014) LCPC '14; Ogilvie, W.F., Minimizing the cost of iterative compilation with active learning (2017) CGO '17; Ali Ossia, S., Shahin Shamsabadi, A., Taheri, A., Rabiee, H.R., Lane, N., Haddadi, H., (2017) A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics, , 2017; Parkhi, O.M., Deep face recognition (2015) BMVC '15; Rallapalli, S.K., (2016) Are Very Deep Neural Networks Feasible on Mobile Devices? Technical Report, , University of Southern California; Rastegari, M., Xnor-net: Imagenet classification using binary convolutional neural networks (2016) CoRR, , abs/1603. 05279 2016; Ravi, S., (2015) ProjectionNet: Learning Efficient On-Device Deep Networks Using Neural Projections, , 2015; Ren, J., Optimise web browsing on heterogeneous mobile platforms: A machine learning based approach (2017) INFOCOM '17; Servia Rodriguez, S., Personal model training under privacy constraints (2017) CoRR, , abs/1703. 00380 2017; Russakovsky, O., Imagenet large scale visual recognition challenge (2015) IJCV '15; Samreen, F., Daleel: Simplifying cloud instance selection using machine learning (2016) NOMS '16; Silberman, N., Guadarrama, S., (2013) TensorFlow-slim Image Classification Library, , https://github.com/tensorflow/models/tree/master/research/slim; Song, M., Hu, Y., Chen, H., Li, T., Towards pervasive and user satisfactory cnn across GPU microarchitectures (2017) HPCA '17; Tobias Springenberg, J., Dosovitskiy, A., Brox, T., Riedmiller, M.A., Striving for simplicity: The all convolutional net (2014) CoRR, , abs/1412. 6806 2014; Sun, Y., Chen, Y., Deep learning face representation by joint identification-verification (2014) NIPS '14; Taylor, B., Adaptive optimization for OpenCL programs on embedded heterogeneous systems (2017) LCTES '17; Teerapittayanon, S., Distributed deep neural networks over the cloud, the edge and end devices (2017) ICDCS '17; Tournavitis, G., Towards a holistic approach to auto-parallelization: Integrating profile-driven parallelism detection and machine-learning based mapping (2009) PLDI '09; Wang, Z., Automatic and portable mapping of data parallel programs to opencl for GPU-based heterogeneous systems (2014) ACM TACO; Wang, Z., Integrating profile-driven parallelism detection and machine-learning-based mapping (2014) ACM TACO; Wang, Z., O'Boyle, M., Machine learning in compiler optimisation (2018) Proc. IEEE; Wang, Z., O'Boyle, P.M.F., Mapping parallelism to multi-cores: A machine learning based approach (2009) PPoPP '09; Wang, Z., O'Boyle, M.F.P., Partitioning streaming parallelism for multi-cores: A machine learning based approach (2010) PACT '10; Wang, Z., O'Boyle, M.F.P., Using machine learning to partition streaming programs (2013) ACM TACO (2013); Zhang, P., Auto-tuning streamed applications on intel xeon phi (2018) IPDPS '18; Zou, W.Y., Bilingual word embeddings for phrase-based machine translation (2013) EMNLP '13",,,,"Association for Computing Machinery",,,,,15232867,9781450349116,,,"English","ACM SIGPLAN Not.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85084192663
"Chen A.T.-Y., Biglari-Abhari M., Wang K.I.-K., Bouzerdoum A., Tivive F.H.C.","57190226345;7801530871;7501398184;35570413200;8571952800;","Convolutional neural network acceleration with hardware/software co-design",2018,"Applied Intelligence","48","5",,"1288","1301",,10,"10.1007/s10489-017-1007-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772982&doi=10.1007%2fs10489-017-1007-z&partnerID=40&md5=0a6aa17abd512926df29945dd3a5d7b5","Department of Electrical and Computer Engineering, The University of Auckland, Auckland, New Zealand; School of Electrical, Computer, and Telecommunications Engineering, University of Wollongong, Wollongong, Australia; College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar","Chen, A.T.-Y., Department of Electrical and Computer Engineering, The University of Auckland, Auckland, New Zealand; Biglari-Abhari, M., Department of Electrical and Computer Engineering, The University of Auckland, Auckland, New Zealand; Wang, K.I.-K., Department of Electrical and Computer Engineering, The University of Auckland, Auckland, New Zealand; Bouzerdoum, A., School of Electrical, Computer, and Telecommunications Engineering, University of Wollongong, Wollongong, Australia, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Tivive, F.H.C., School of Electrical, Computer, and Telecommunications Engineering, University of Wollongong, Wollongong, Australia","Convolutional Neural Networks (CNNs) have a broad range of applications, such as image processing and natural language processing. Inspired by the mammalian visual cortex, CNNs have been shown to achieve impressive results on a number of computer vision challenges, but often with large amounts of processing power and no timing restrictions. This paper presents a design methodology for accelerating CNNs using Hardware/Software Co-design techniques, in order to balance performance and flexibility, particularly for resource-constrained systems. The methodology is applied to a gender recognition case study, using an ARM processor and FPGA fabric to create an embedded system that can process facial images in real-time. © 2017, Springer Science+Business Media, LLC.","Co-design; Computer vision; Embedded system; FPGA; Gender recognition; Hardware acceleration; Neural network; Real-time","Computer vision; Convolution; Design; Embedded systems; Field programmable gate arrays (FPGA); Hardware; Hardware-software codesign; Image processing; Integrated circuit design; Mammals; Natural language processing systems; Neural networks; Balance performance; Co-designs; Constrained systems; Convolutional neural network; Gender recognition; Hardware acceleration; Mammalian visual cortex; Real time; Computer hardware",,,,,,,,,,,,,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Zheng, X., TensorFlow: a system for large-scale machine learning (2016) 12th USENIX symposium on operating systems design and implementation (OSDI); Tivive, F.H.C., Bouzerdoum, A., A gender recognition system using shunting inhibitory convolutional neural networks (2006) International joint conference on neural networks (IJCNN), pp 5336–5341; Chen, A.T.Y., Biglari-Abhari, M., Wang, K.I.K., Bouzerdoum, A., Tivive, F.H.C., Hardware/software co-design for a gender recognition embedded system (2016) Trends in applied knowledge-based systems and data science, vol 9799, pp. 541-552; de Michell, G., Gupta, R.K., Hardware/software co-design (1997) Proc IEEE, 85 (3), pp. 349-365; Teich, J., Hardware/software codesign: the past, the present, and predicting the future (2012) Proc IEEE, 100, pp. 1411-1430; Alt, N., Clause, C., Stechele, W., Hardware/software architecture of an algorithm for vision-based real-time vehicle detection in dark environments. In: Design, automation, and test in europe (DATE) (2008) pp 176–181; van der Wal, G., Zhang, D., Kandaswamy, I., Marakowitz, J., Kaighn, K., Zhang, J., Chai, S., FPGA acceleration for feature based processing applications. In: Conference on computer vision and pattern recognition (CVPR) (2015) pp 42–47; Tasson, D., Montagnini, A., Marzotto, R., Farenzena, M., FPGA-based pedestrian detection under strong distortions. In: Conference on computer vision and pattern recognition (CVPR) (2015) pp 65–70; Farabet, C., Poulet, C., Han, J.Y., LeCun, Y., CNP: An FPGA-based processor for convolutional networks. In: International conference on field programmable logic (FPL) (2009) pp 32–37; Sankaradas, M., Jakkula, V., Cadambi, S., Chakradhar, S., Durdanovic, I., Cosatto, E., Graf, H.P., A massively parallel coprocessor for convolutional neural networks (2009) 20th international conference on application-specific systems, architectures, and processors (ASAP), pp. 53-60; Farabet, C., Martini, B., Corda, B., Akselrod, P., Culurciello, E., LeCun, Y., NeuFlow: a runtime reconfigurable dataflow processor for vision (2011) Conference on computer vision and pattern recognition workshops (CVPR), pp 109–116; Cavigelli, L., Gschwend, D., Mayer, C., Willi, S., Muheim, B., Benini, L., Origami: a convolutional network accelerator. In: 25th great lakes symposium on VLSI (GLSVLSI) (2015) pp 199–204; Pham, P.H., Jelaca, D., Farabet, C., Martini, B., LeCun, Y., Culurciello, E., NeuFlow: dataflow vision processing system-on-a-chip. In: 55th midwest symposium on circuits and systems (MWSCAS) (2012) pp 1044–1047; Li, X., Areibi, S., A hardware/software co-design approach for face recognition. In: 16th international conference on microelectronics (ICM) (2004) pp 55–58; Che, M., Chang, Y., A hardware/software co-design of a face detection algorithm based on FPGA. In: International conference on measuring technology and mechatronics automation (ICMTMA) (2010) pp 109–112; Qiu, J., Wang, J., Yao, S., Guo, K., Li, B., Zhou, E., Yu, J., Yang, H., Going deeper with embedded FPGA platform for convolutional neural network. In: International symposium on field-programmable gate arrays (FPGA) (2016) pp 26–35; Maclean, W.J., An evaluation of the suitability of FPGAs for embedded vision systems. In: Conference on computer vision and pattern recognition workshops (CVPR) (2005) pp 131–138; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing FPGA-based accelerator design for deep convolutional neural networks. In: International symposium on field-programmable gate arrays (FPGA) (2015) pp 161–170; Gupta, S., Agrawal, A., Gopalakrishnan, K., Deep learning with limited numerical precision. In: 32nd international conference on machine learning (ICML) (2015) pp 1737–1746; Ng, C.B., Tay, Y.H., Goi, B.M., Recognizing human gender in computer vision: a survey (2012) Pacific rim international conference on artificial intelligence: trends in artificial intelligence (PRICAI), pp. 335-346; Zheng, J., Lu, B., A support vector machine classifier with automatic confidence (2011) Neurocomputing, 74 (11), pp. 1926-1935; Shan, C., Learning local binary patterns for gender classification on real-world face images (2012) Pattern Recogn Lett, 4 (33), pp. 431-437; Azarmehr, R., Laganiere, R., Lee, W.S., Xu, C., Laroche, D., Real-time embedded age and gender classification in unconstrained video. In: Conference on computer vision and pattern recognition workshops (CVPR) (2015) pp 56–64; Irick, K.M., DeBole, M., Narayanan, V., Gayasen, A., A hardware efficient support vector machine architecture for FPGA. In: 16th international symposium on field-programmable custom computing machines (FCCM) (2008) pp 304–305; Irick, K., DeBole, M., Narayanan, V., Sharma, R., Moon, H., Mummareddy, S., A unified streaming architecture for real time face detection and gender classification. In: international conference on field programmable logic and applications (FPL) (2007) pp 267–272; Ratnakar, A., More, G., Real time gender recognition on FPGA (2015) Int J Sci Eng Res, 6 (2), pp. 19-22; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: unified, real-time object detection. In: Conference on computer vision and pattern recognition (CVPR) (2016) pp 779–788; Tivive, F.H.C., Bouzerdoum, A., Phung, S.L., Iftekharuddin, K.M., Adaptive hierarchical architecture for visual recognition (2010) Appl Opt, 49 (10), pp. B1-B8; Fogel, I., Sagi, D., Gabor filters as texture discriminator (1989) Biol Cybern, 61 (2), pp. 103-113; Wu, J., An, G., Ruan, Q., Independent Gabor analysis of discriminant features fusion for face recognition (2009) IEEE Signal Processing Lett, 16 (2), pp. 97-100; Li, W., Du, Q., Gabor-filtering-based nearest regularized subspace for hyperspectral image classification (2014) IEEE J Select Topics Appl Earth Observ Rem Sens, 7 (4), pp. 1012-1022; Jones, J.P., Palmer, L., An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex (1987) J Neurophys, 58 (6), pp. 1233-1258; Daugman, J.G., Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters (1985) J Optic Soc Amer A: Optic Image Sci Vis, 2 (7), pp. 1160-1169; Naka, K.I., Rushton, W.A.H., S-potentials from colour units in the retina of fish (Cyprinidae) (1966) J Phys, 185, pp. 536-555; Hagan, M.T., Menhaj, M., Training feedforward networks with the marquardt algorithm (1994) IEEE Trans Neural Networks, 5 (6), pp. 989-993; Cesur, E., Yildiz, N., Tavsanoglu, V., On an improved FPGA implementation of CNN-based Gabor-type filters (2012) IEEE Trans Circuits Systems, 59 (11), pp. 815-819; Pauwels, K., Tomasi, M., Alonso, J.D., Ros, E., van Hulle, M.M., A comparison of FPGA and GPU for real-time phase-based optical flow, stereo, and local image features (2012) IEEE Trans Comput, 61 (7), pp. 999-1012; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning trained quantization and huffman coding (2016) International conference on learning representations (ICLR); Chen, Y., Xu, W., Zhao, R., Chen, X., Design and evaluation of a hardware/software FPGA-based system for fast image processing (2014) Photonic Sensors, 4 (3), pp. 274-280; Gudis, E., Lu, P., Berends, D., Kaighn, K., van der Wal, G., Buchanan, G., Chai, S., Piacentino, M., An embedded vision services framework for heterogeneous accelerators. In: conference on computer vision and pattern recognition workshops (CVPR) (2013) pp 598–603; Albericio, J., Judd, P., Hetherington, T., Aamodt, T., Jerger, N.E., Moshovos, A., Cnvlutin: ineffectual-neuron-free deep neural network computing. In: 43rd international symposium on comparative archives (ISCA) (2016) pp 1–13; Jesorsky, O., Kirchberg, K.J., Frischholz, R.W., Robust face detection using the Hausdorff distance. In: 3rd international conference on audio- and video-based biometric person authentication (AVBPA) (2001) pp 90–95; Pantic, M., Valstar, M., Rademaker, R., Web-based database for facial expression analysis. In: International conference on multimedia and expo (ICME), pp (2005) 317–321; Phillips, P.J., Moon, H., Rauss, P.J., Rizvi, S., The FERET evaluation methodology for face recognition algorithms (2000) IEEE Trans Pattern Anal Machine Intelligence, 22 (10), pp. 1090-1104; Thomaz, C.E., Giraldi, G.A., A new ranking method for principal components analysis and its application to face image analysis (2010) Image Vis Comput, 28 (6), pp. 902-913; Lee, P.H., Hung, J.Y., Hung, Y.P., Automatic gender recognition using fusion of facial strips. In: 20th international conference on pattern recognition (2010) pp 1140–1143; Leng, X.M., Wang, Y.D., Improving generalization for gender classification. In: 15th international conference on image processing (2008) pp 1656–1659; Moghaddam, B., Yang, M.H., Learning gender with support faces (2002) IEEE Trans Pattern Anal Machine Intelligence, 24 (5), pp. 707-711; Lu, L., Shi, P., A novel fusion-based method for expression-invariant gender classification (2009) International conference on acoustics, speech, and signal processing, pp. 1065-1068; Baluja, S., Rowley, H.A., Boosting sex identification performance (2007) Int J Comp Vision, 71 (1), pp. 111-119; Buchala, S., Loomes, M.J., Davey, N., Frank, R.J., The role of global and feature based information in gender classification of faces: a comparison of human performance and computational models (2005) Int J Neural Syst, 15, pp. 121-128; Sahin, I., Saritekin, N.K., A data path design tool for automatically mapping artificial neural networks on to FPGA-based systems (2016) J Elec Eng Tech, 11 (5), pp. 1921-1929","Chen, A.T.-Y.; Department of Electrical and Computer Engineering, New Zealand; email: andrew.chen@auckland.ac.nz",,,"Springer New York LLC",,,,,0924669X,,APITE,,"English","Appl Intell",Article,"Final","",Scopus,2-s2.0-85026772982
"Mudarakola L.P., Sastry J.K.R.","56403390400;56428811000;","A Neural Network Based Strategy (NNBS) for automated construction of test cases for testing an Embedded system using Combinatorial Techniques",2018,"International Journal of Engineering and Technology(UAE)","7","1.3",,"74","81",,6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067270771&partnerID=40&md5=397c33d415fed6913c48d4bb4751dc7a","Dept. of Computer Science and Engineering, NBKR Institute of Science and Technology Vidyanagar, Nellore, AP, India; Dept. of Electronics and Computer Science Engineering, Koneru Lakshmaiah Educational Foundation Vaddeswram, Guntur District, AP, India","Mudarakola, L.P., Dept. of Computer Science and Engineering, NBKR Institute of Science and Technology Vidyanagar, Nellore, AP, India; Sastry, J.K.R., Dept. of Electronics and Computer Science Engineering, Koneru Lakshmaiah Educational Foundation Vaddeswram, Guntur District, AP, India","Testing an embedded system is required to locate bugs in software, diminish risk, development, repairs costs and to improve performance for both users and the company. Embedded software testing tools are useful for catching defects during unit, integration and system test-ing. Embedded systems in many cases must be optimized by engaging crucial areas of the embedded systems considering all factors of the input domain. The most important concern is to build a place of test cases depend on design of the requirements that can recognize more number of faults at a least rate and point in time in the major sections of an embedded system. This paper proposes a Neural Net-work Based strategy (NNBS) to generate optimized test cases based on the considerations of the system. A tool called NNTCG (Neural Network Test Case Generator) has been build up based on the method proposed in this paper. Test cases are generated for testing an em-bedded system using NNTCG and the same are used to determine the expected output through the neural network and the output gener-ated from the actual firmware. The faulty paths within the firmware are determined when the output generated by the neural network is not same as the output generated by the firmware. © 2018 Authors.","Automated test case generation; Combinatorial testing; Embedded systems; Input domain testing; Neural networks; Output domain",,,,,,,,,,,,,,,,,"Anderson, C., Von Mayrhauser, A., Mraz, R., 'On the use of neural networks to guide software testing activities,' (1995) Proceedings of International Test Conference, pp. 720-729; Cohen, D.M., Dalal, S.R.D.M., (1996) 'Method and system for automatically generating efficient test cases for systems having in-teracting elements,', , patent 1996; Cohen, D.M., Dalal, S.R., Fredman, M.L., Patton, G.C., 'The AETG System: An Approach to Testing Based on Combina-torial Design' (1997) IEEE Transactions on Software Engineering, 23 (7), pp. 437-443; Lei, Y., Tai, K.C., 'In-parameter-order: a test generation strategy for pair wise testing,' (1998) Proceedings of Third IEEE Interna-tional High-Assurance Systems Engineering Symposium 1998, pp. 254-261; Lei, Y., Tai, K.C., A Test Generating Strategy for Pair-wise Testing' (2002) IEEE Transactions on Software Engineering; Ghazi, S.A., Ahmed, M.A., 'Pair-wise test coverage using genetic algorithms' (2003) CEC, The 2003 Congress on Evolutionary Computation, 2, pp. 1420-1424; Bryce, R., Colbourn, C.J., 'The Density Algorithm for Pair Wise Interaction Testing' (2007) Journal of Software: Testing, Veri-fication and Reliability; Li, K., Yang, Z., 'Generating Method of Pair-Wise Covering Test Data Based on ACO,' (2008) ETT and GRS, 2008 IEEE International Workshop on Geoscience and Remote Sensing and International Workshop on Education Technology and Training, 2, pp. 776-779; Wu, L., Liu, B., Jin, Y., Xie, X., 'Using back-propagation neural networks for functional software testing,' (2008) 2nd International Conference on Anti-counterfeiting, Security and Iden-tification, ASID, pp. 272-275; Singh, Y., Kaur, A., Malhotra, R., 'Predict-ing Testing Effort using Artificial Neural Network' (2008) Proceedings of the World Congress on Engineering and Computer Sci-ence(WCECS); Kuhn, R., Lei, Y., Kacker, R., 'Practical Combinato-rial Testing: beyond Pair wise' (2008) IEEE Computer Society-IT Pro-fessional, 10 (3); Chen, X., Gu, Q., Zhang, X., Chen, D., 'Build-ing Prioritized Pairwise Interaction Test Suites with Ant Colony Optimization,' (2009) QSIC, 9th International Conference on Quality Software, pp. 347-352; McCaffrey, J.D., 'Generation of pairwise test sets using a simulated bee colony algorithm,' (2009) IRI '09, IEEE International Con-ference on Information Reuse & Integration, pp. 115-119; McCaffrey, J.D., 'Generation of Pairwise Test Sets us-ing a Genetic Algorithm' (2009) 33rd Annual IEEE International Com-puter Software and Applications Conference; Kuhn, R., Kacker, R., Lei, Y., Hunter, J., (2009) 'Combi-natorial Software Testing', , IEEE, 0018-9162; Chen, X., Gu, Q., Qi, J., Chen, D., 'Ap-plying Particle Swarm Optimization to Pairwise Testing' (2010) COMP-SAC, 2010 IEEE 34th Annual Computer Software and Applica-tions Conference, pp. 107-116; Richard Kuhn, D., Kacker, R.N., Lei, Y., (2010) 'Practical combinatorial testing', , NIST Special Publication; Vudatha, C.P., Jammalamadaka, S.K.R., Duvvuri, B., Reddy, L.S.S., 'Automated Generation of Test Cases from Output Domain of an Embedded System using Genetic Algorithms' (2011) Proceedings of the 3rd Interna-tional Conference on Electronics Computer Technology (ICECT) 2011; Vudatha, C.P., Jammalamadaka, S.K.R., Nal-liboena, S., Duvvuri, B.K.K., Reddy, L.S.S., 'Automated genera-tion of test cases from output domain and critical regions of em-bedded systems using genetic algorithms,' (2011) 2nd National Confer-ence on Emerging Trends and Applications in Computer Science (NCETACS), pp. 1-6; Smilgyte, K., Nenortaite, J., 'Artificial Neural Networks Application in Software Testing Selection Method' (2011) Springer Link Lecture notes, Hybrid Artificial Intelligent Systems, Lecture Notes in Computer Science, 6678, pp. 247-254; Patil, M., Nikumbh, P.J., (2012) 'Pair-wise Testing Using Simu-lated Annealing', , Published by Elsevier Ltd; Bansal, P., Sabharwal, S., Malik, S., Arora, V., Kumar, V., 'An Approach to Test Set Generation for Pair-Wise Testing Using Genetic Algorithms,' (2013) Search Based Software Engineering, 8084, pp. 294-299; Raju, R., Subhapriya, P., 'A Neural Network Approach for Randomized Unit Testing Based On Genetic Algorithm' (2013) Interna-tional Journal of Engineering and Advanced Technology (IJEAT), 2 (3); Wu, H., Nie, C., 'An overview of search based combinatorial testing,' (2014) In Proceedings of the 7th Internation-al Workshop on Search-Based Software Testing (SBST 2014), pp. 27-30. , ACM, New York, NY, USA; Zakaria, H.L., Zamli, K.Z., 'Migrating Birds Optimiza-tion based strategies for Pair wise testing,' (2015) 9th Malaysian Software Engineering Conference (MySEC), Kuala Lumpur, pp. 19-24; Qi, R., Wang, Z., Ping, P., Li, S., 'A hybrid optimization algorithm for pair wise test suite generation,' (2015) 2015 IEEE Interna-tional Conference on Information and Automation, Lijiang, pp. 3062-3067; Yamada, A., Biere, A., Artho, C., Kitamura, T., Choi, E.H., 'Greedy combinatorial test case generation using unsatisfiable cores,' (2016) In Proceedings of the 31st IEEE/ACM International Con-ference on Automated Software Engineering (ASE), Singapore, pp. 614-624","Mudarakola, L.P.; Dept. of Computer Science and Engineering, India; email: prasad.hinduniv@gmail.com",,,"Science Publishing Corporation Inc",,,,,2227524X,,,,"English","Int. J. Eng. Technol.",Article,"Final","",Scopus,2-s2.0-85067270771
"Zheng S., Zhong Q., Chai X., Chen X., Peng L.","55414421800;55886775000;7006781157;56547791600;36119146300;","A Novel Prediction Model for Car Body Vibration Acceleration Based on Correlation Analysis and Neural Networks",2018,"Journal of Advanced Transportation","2018",,"1752070","","",,6,"10.1155/2018/1752070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059956214&doi=10.1155%2f2018%2f1752070&partnerID=40&md5=783f0a225729eba624736ebdcb69c141","School of Urban Railway Transportation, Shanghai University of Engineering Science, Shanghai, 201620, China","Zheng, S., School of Urban Railway Transportation, Shanghai University of Engineering Science, Shanghai, 201620, China; Zhong, Q., School of Urban Railway Transportation, Shanghai University of Engineering Science, Shanghai, 201620, China; Chai, X., School of Urban Railway Transportation, Shanghai University of Engineering Science, Shanghai, 201620, China; Chen, X., School of Urban Railway Transportation, Shanghai University of Engineering Science, Shanghai, 201620, China; Peng, L., School of Urban Railway Transportation, Shanghai University of Engineering Science, Shanghai, 201620, China","This paper aims to create a prediction model for car body vibration acceleration that is reliable, effective, and close to real-world conditions. Therefore, a huge amount of data on railway parameters were collected by multiple sensors, and different correlation coefficients were selected to screen out the parameters closely correlated to car body vibration acceleration. Taking the selected parameters and previous car body vibration acceleration as the inputs, a prediction model for car body vibration acceleration was established based on several training algorithms and neural network structures. Then, the model was successfully applied to predict the car body vibration acceleration of test datasets on different segments of the same railway. The results show that the proposed method overcomes the complexity and uncertainty of the multiparameter coupling analysis in traditional theoretical models. The research findings boast a great potential for application. © 2018 Shubin Zheng et al.",,"Acceleration; Forecasting; Railroad cars; Railroads; Uncertainty analysis; Correlation analysis; Correlation coefficient; Coupling analysis; Multiparameters; Multiple sensors; Neural network structures; Prediction model; Training algorithms; Vibration analysis",,,,,"18030501300; National Natural Science Foundation of China, NSFC: 51405287, 51478258","This research was funded by National Natural Science Foundation of China [Grant No. 51478258 and 51405287] and Shanghai Committee of Science and Technology [Grant No. 18030501300].",,,,,,,,,,"Hoberock, L.L., A survey of longitudinal acceleration comfort studies in ground transportation vehicles (1977) Journal of Dynamic Systems, Measurement, and Control, 99 (2), pp. 76-84; Uys, P.E., Els, P.S., Thoresson, M., Suspension settings for optimal ride comfort of off-road vehicles travelling on roads with different roughness and speeds (2007) Journal of Terramechanics, 44 (2), pp. 163-175; Shafiullah, G.M., Ali, A.B.M.S., Thompson, A., Wolfs, P.J., Predicting vertical acceleration of railway wagons using regression algorithms (2010) IEEE Transactions on Intelligent Transportation Systems, 11 (2), pp. 290-299; Wanming, Z., Zhenxing, H., Xiaolin, S., Prediction of highspeed train induced ground vibration based on train-trackground systemmodel (2010) Earthquake Engineering and Engineering Vibration, 9 (4), pp. 545-554; Czop, P., Mendrok, K., Uhl, T., Application of inverse linear parametric models in the identification of rail track irregularities (2011) Archive of Applied Mechanics, 81 (11), pp. 1541-1554; Qian, K., Liang, J., Gao, Y.H., The prediction of vibration and noise for the high-speed train based on neural network and boundary element method (2015) Journal of Vibroengineering, 17 (8), pp. 4445-4457; Connolly, D.P., Kouroussis, G., Laghrouche, O., Ho, C.L., Forde, M.C., Benchmarking railway vibrations-track, vehicle, ground and building effects (2014) Construction and Building Materials, 92, pp. 64-81; Koo, J.S., Oh, H.S., A new derailment coefficient considering dynamic and geometrical effects of a single wheelset (2014) Journal of Mechanical Science and Technology, 28 (9), pp. 3483-3498; Navik, P., Rønnquist, A., Uplift-monitoring for dynamic assessment of electrical railway contact lines (2015) Dynamics of Civil Structures, pp. 237-244; Fisher, R.A., (1958) Statistical Methods for Research Workers, , Hafner, 13th edition; Kendall, M.G., (1976) The Advanced Theory of Statistics, , Charles Griffin; Press, W.H., Teukolsky, S.A., Vetterling, W.T., Flannery, B.P., Numerical recipes in c (1995) Art of Scientific Computing, 10 (1), pp. 176-177; Best, D.J., Roberts, D.E., Algorithm AS 89:The Upper Tail Probabilities of Spearman's Rho (1975) Journal of Applied Statistics, 24 (3), pp. 377-379; (1981) Murray and Walter, Practical Optimization, , Academic Press; Powell, M.J.D., Restart procedures for the conjugate gradient method (1977) Mathematical Programming, 12 (2), pp. 241-254; Scales, L.E., (1985) Introduction to Non-Linear Optimization, , Macmillan Education, London, UK; Battiti, R., First-and second-order methods for learning: Between steepest descent and Newton'smethod (1992) Neural Computation, 4 (2), pp. 141-166; Riedmiller, M., Braun, H., A direct adaptive method for faster backpropagation learning: The RPROP algorithm (1993) Proceedings of the IEEE International Conference on Neural Networks, ICNN 1993, pp. 586-591. , USA, April; Møller, M.F., Efficient training of feed-forward neural networks (1993) DAIMI Report Series, 22 (464); Møller, M.F., A scaled conjugate gradient algorithm for fast supervised learning (1993) Neural Networks, 6 (4), pp. 525-533; Marquardt, D.W., An algorithm for least-squares estimation of nonlinear parameters (1963) Journal of the Society for Industrial & Applied Mathematics, 11 (2), pp. 431-441; Hagan, M., Menhaj, M., Training feedforward networks with the Marquardt algorithm (1994) IEEE Transactions on Neural Networks and Learning Systems, 5 (6), pp. 989-993; MacKay, D.J.C., (1992) Bayesian Interpolation, , MIT Press; Foresee, F.D., Hagan, M.T., Gauss-Newton approximation to Bayesian learning (1997) Proceedings of the IEEE International Conference on Neural Networks, 3, pp. 1930-1935; Willmott, C.J., Matsuura, K., Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance (2005) Climate Research, 30 (1), pp. 79-82; Borji, A., Cheng, M.-M., Jiang, H., Li, J., Salient object detection: A benchmark (2015) IEEE Transactions on Image Processing, 24 (12), pp. 5706-5722; Bostan, P.A., Heuvelink, G.B.M., Akyurek, S.Z., Comparison of regression and kriging techniques for mapping the average annual precipitation of Turkey (2012) International Journal of Applied EarthObservation and Geoinformation, 19 (1), pp. 115-126; Chai, X., Zheng, S., Geng, S., Zhang, L., The prediction of railway vehicle vibration based on neural network (2015) Journal of Information and Computational Science, 12 (16), pp. 5889-5899","Zheng, S.; School of Urban Railway Transportation, China; email: shubin.zheng@sues.edu.cn",,,"Hindawi Limited",,,,,01976729,,JATRD,,"English","J Adv Transp",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85059956214
"Muñoz-Organero M., Powell L., Heller B., Harpin V., Parker J.","26030525600;57191483051;7006583311;55918592800;39461946200;","Automatic extraction and detection of characteristic movement patterns in children with ADHD based on a convolutional neural network (CNN) and acceleration images",2018,"Sensors (Switzerland)","18","11","3924","","",,15,"10.3390/s18113924","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056658857&doi=10.3390%2fs18113924&partnerID=40&md5=f3e375af5a0adc7df65c1054953f287c","Telematics Engineering Department, Universidad Carlos III de Madrid, Av. Universidad, 30, Leganes, 28911, Spain; School of Health and Related Research, University of Sheffield, Regent Court, 30, Sheffield, S1 4DA, United Kingdom; Centre for Sports Engineering Research, Sheffield Hallam University, Sheffield, S10 2LW, United Kingdom; Ryegate Children’s Centre, Sheffield, S10 5GA, United Kingdom","Muñoz-Organero, M., Telematics Engineering Department, Universidad Carlos III de Madrid, Av. Universidad, 30, Leganes, 28911, Spain; Powell, L., School of Health and Related Research, University of Sheffield, Regent Court, 30, Sheffield, S1 4DA, United Kingdom; Heller, B., Centre for Sports Engineering Research, Sheffield Hallam University, Sheffield, S10 2LW, United Kingdom; Harpin, V., Ryegate Children’s Centre, Sheffield, S10 5GA, United Kingdom; Parker, J., School of Health and Related Research, University of Sheffield, Regent Court, 30, Sheffield, S1 4DA, United Kingdom","Attention deficit and hyperactivity disorder (ADHD) is a neurodevelopmental disorder, which is characterized by inattention, hyperactivity and impulsive behaviors. In particular, children have difficulty keeping still exhibiting increased fine and gross motor activity. This paper focuses on analyzing the data obtained from two tri-axial accelerometers (one on the wrist of the dominant arm and the other on the ankle of the dominant leg) worn during school hours by a group of 22 children (11 children with ADHD and 11 paired controls). Five of the 11 ADHD diagnosed children were not on medication during the study. The children were not explicitly instructed to perform any particular activity but followed a normal session at school alternating classes of little or moderate physical activity with intermediate breaks of more prominent physical activity. The tri-axial acceleration signals were converted into 2D acceleration images and a Convolutional Neural Network (CNN) was trained to recognize the differences between non-medicated ADHD children and their paired controls. The results show that there were statistically significant differences in the way the two groups moved for the wrist accelerometer (t-test p-value <0.05). For the ankle accelerometer statistical significance was only achieved between data from the non-medicated children in the experimental group and the control group. Using a Convolutional Neural Network (CNN) to automatically extract embedded acceleration patterns and provide an objective measure to help in the diagnosis of ADHD, an accuracy of 0.875 for the wrist sensor and an accuracy of 0.9375 for the ankle sensor was achieved. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","ADHD; Convolutional neural networks (CNN); Deep learning; Tri-axial accelerometers","Accelerometers; Deep learning; Deep neural networks; Neural networks; Acceleration pattern; ADHD; Automatic extraction; Convolutional neural network; Hyperactivity disorder; Statistical significance; Statistically significant difference; Triaxial accelerometer; Convolution; acceleration; accelerometry; adolescent; ankle; artificial neural network; attention deficit disorder; child; devices; diagnostic imaging; exercise; female; human; male; movement (physiology); pathophysiology; pattern recognition; physiology; wrist; Acceleration; Accelerometry; Adolescent; Ankle Joint; Attention Deficit Disorder with Hyperactivity; Child; Exercise; Female; Humans; Male; Movement; Neural Networks (Computer); Pattern Recognition, Physiological; Wrist",,,,,"Ministerio de Ciencia, Innovación y Universidades, MCIU; National Institute for Health and Care Research, NIHR; European Commission, EC; European Regional Development Fund, ERDF; Agencia Estatal de Investigación, AEI; National Institute for Health Research Collaboration for Leadership in Applied Health Research and Care Yorkshire and Humber, NIHR CLAHRC YH","This research received external funding from the “Analytics Using Sensor Datas for Flatcity” project TIN2016-77158-C4-1-R (Ministerio de Ciencia, Innovación y Universidades/ERDF, EU) funded by the Spanish Agencia Estatal de Investigación (AEI) and the European Regional Development Fund (ERDF). This research was also funded/supported by the National Institute for Health Research Collaboration for Leadership in Applied Health Research and Care Yorkshire and Humber. The views and opinions expressed are those of the authors and are not necessarily those of the National Health Service, the National Institute for Health Research, or the UK’s Department of Health.",,,,,,,,,,"Polanczyk, G., de Lima, M.S., Horta, B.L., Biederman, J., Rohde, L.A., The worldwide prevalence of ADHD: A systematic review and meta-regression analysis (2007) Am. J. Psychiatry, 164, pp. 942-948; Polanczyk, G.V., Willcutt, E.G., Salum, G.A., Kieling, C., Rohde, L.A., ADHD prevalence estimates across three decades: An updated systematic review and meta-regression analysis (2014) Int. J. Epidemiol., 43, pp. 434-442; Biederman, J., Faraone, S.V., Attention-Deficit Hyperactivity Disorder—The Lancet Available Online, , https://www.thelancet.com/journals/lancet/article/PIIS0140-6736, accessed on 13 November 2018; (2013) American Psychiatric Association. Diagnostic and Statistical Manual of Mental Disorders (DSM-5), , 5th ed.; American Psychiatric Association: Washington, DC, USA; http://apps.who.int/iris/handle/10665/37958, World Health Organization. The ICD-10 Classification of Mental and Behavioural Disorders: Clinical Descriptions and Diagnostic Guidelines; (2000) American Psychiatric Association. Diagnostic and Statistical Manual of Mental Disorders (DSM-IV-TR), , 4th ed.; American Psychiatric Association: Washington, DC, USA; www.nice.org.uk/guidance/cg72/evidence/adhd-full-guideline-241963165, National Institute for Health and Clinical Excellence. Attention Deficit Hyperactivity Disorder: the NICE Guideline on Diagnosis and Management of ADHD in Children, Young People and Adults; Lis, S., Baer, N., Stein-En-Nosse, C., Gallhofer, B., Sammer, G., Kirsch, P., Objective measurement of motor activity during cognitive performance in adults with attention-deficit/hyperactivity disorder (2010) Acta Psychiatr. Scand., 122, pp. 285-294; Castro-Cabrera, P., Gomez-Garcia, J., Restrepo, F., Moscoso, O., Castellanos-Dominguez, G., Evaluation of feature extraction techniques on event-related potentials for detection of attention-deficit/hyperactivity disorder (2010) Proceedings of the International Conference of the IEEE Engineering in Medicine and Biology, , Buenos Aires, Argentina, 31 August–4 September; O’Mahony, N., Florentino-Liano, B., Carballo, J.J., Baca-García, E., Rodríguez, A.A., Objective diagnosis of ADHD using IMUs (2014) Med. Eng. Phys., 36, pp. 922-926; Hotham, E., Haberfield, M., Hillier, S., White, J.M., Todd, G., Upper limb function in children with attention-deficit/hyperactivity disorder (ADHD) (2018) J. Neural Transm., 125, pp. 1-14; Kam, H.J., Lee, K., Cho, S.M., Shin, Y.M., Park, R.W., High-Resolution Actigraphic Analysis of ADHD: A Wide Range of Movement Variability Observation in Three School Courses—A Pilot Study (2011) Healthc. Inf. Res., 17, pp. 29-37; Lauth, G.W., Heubeck, B.G., Mackowiak, K., Observation of children with attention-deficit hyperactivity (ADHD) problems in three natural classroom contexts (2006) Br. J. Educ. Psychol., 76, pp. 385-404; Jordao, A., Torres, L.A.B., Schwartz, W.R., Novel approaches to human activity recognition based on accelerometer data (2018) Sign. Image Video Process., 12, pp. 1387-1394; Ha, S., Choi, S., Convolutional neural networks for human activity recognition using multiple accelerometer and gyroscope sensors (2016) Proceedings of the International Joint Conference on Neural Networks (IJCNN), Vancouver, BC, Canada, 24–29 July; Ha, S., Yun, J.M., Choi, S., Multi-modal convolutional neural networks for activity recognition (2015) Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics, , Kowloon, Hong Kong, China, 9–12 October; Jiang, W., Yin, Z., Human activity recognition using wearable sensors by deep convolutional neural networks (2015) Proceedings of the ACM International Conference on Multimedia, Brisbane, pp. 26-30. , Australia, October; Chen, Y., Xue, Y., A deep learning approach to human activity recognition based on single accelerometer (2015) Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics, , Kowloon, Hong Kong, China, 9–12 October; Mizell, D., Using gravity to estimate accelerometer orientation (2003) Proceedings of the Seventh IEEE International Symposium on Wearable Computers, pp. 21-23. , White Plains, NY, USA, October; Ngo, T.T., Makihara, Y., Nagahara, H., Mukaigawa, Y., Yagi, Y., Similar Gait Action Recognition using an Inertial Sensor (2015) Pattern Recognit, 48, pp. 1289-1301; Pham, C., MobiRAR: Real-time human activity recognition using mobile devices (2015) Proceedings of the Seventh International Conference on Knowledge and Systems Engineering (KSE), , Ho Chi Minh City, Vietnam, 8–10 October; Zhong, Y., Deng, Y., Sensor orientation invariant mobile gait biometrics (2014) Proceedings of the IEEE International Joint Conference on Biometrics, Clearwater, FL, USA, 29 September–2, , October; Kobayashi, T., Hasida, K., Otsu, N., Rotation invariant feature extraction from 3-D acceleration signals (2011) Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), , Prague, Czech Republic, 22–27 May; Bussing, R., Fernandez, M., Harwood, M., Hou, W., Garvan, C.W., Eyberg, S.M., Swanson, J.M., Parent and teacher SNAP-IV ratings of attention deficit hyperactivity disorder symptoms: Psychometric properties and normative ratings from a school district sample (2008) Assessment, 15, pp. 317-328; Huh, D., Sejnowski, T.J., Spectrum of power laws for curved hand movements (2015) Proc. Natl. Acad. Sci. USA, 112, pp. 3950-3958; Zawadzki, J., Siemieński, A.D.A.M., Maximal frequency, amplitude, kinetic energy and elbow joint stiffness in cyclic movements (2010) Acta Bioeng. Biomech., 12, pp. 55-64; Lecun, Y., (2018) The MNIST Database of Handwritten Digits, , http://yann.lecun.com/exdb/mnist/; https://es.mathworks.com/products/matlab.html, Mathworks. “Matlab”","Muñoz-Organero, M.; Telematics Engineering Department, Av. Universidad, 30, Spain; email: munozm@it.uc3m.es",,,"MDPI AG",,,,,14248220,,,"30441774","English","Sensors",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85056658857
"Sasi Bhanu J., Lakshmi Prasad M., Sastry J.K.R.","56285782300;56403390400;56428811000;","Combinatorial neural network based a testing of an embedded system",2018,"Journal of Advanced Research in Dynamical and Control Systems","10","7",,"605","616",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049366693&partnerID=40&md5=c7d7f6fdc028eb23262224415494fdc7","Department of computer Science and Engineering, St. Martin College of Engineering, Secundrabad, India; Dept. of Computer science and Engineering, NBKR Institute of Science and Technology, India; Dept. of Electronics and Computer science and Engineering, Koneru Lakshmaiah Educational Foundation, Vaddeswram, India","Sasi Bhanu, J., Department of computer Science and Engineering, St. Martin College of Engineering, Secundrabad, India; Lakshmi Prasad, M., Dept. of Computer science and Engineering, NBKR Institute of Science and Technology, India; Sastry, J.K.R., Dept. of Electronics and Computer science and Engineering, Koneru Lakshmaiah Educational Foundation, Vaddeswram, India","Every embedded system must be tested considering the Input, Output, Input-Output and Multioutput domain. Testing of the embedded systems is crucial as the user rejects the buggy systems very fast. Test cases are required that deal with the relationships among the input-output domains. A combinatorial method that considers both the inputs and the relationships that exists between the inputs and outputs for generating the test cases has been developed. Using the method test cases are generated that are good enough to carry exhaustive testing using different methods. Neural network are good learning models that relate the inputs to outputs and the hidden computing nodes relate to the computing relationships among the inputs and outputs. In this paper An neural network based test case generation method that considers the input-output domain has been presented. The NN model has been used for verifying the equivalence of output generated from NN model and the actual firmware which can be used as a kind of verification method. The approach has been used for testing an embedded system that monitors and controls the temperatures within the Nuclear reactor systems. © 2018, Institute of Advanced Scientific Research, Inc. All Rights reserved.","Automated test case generation; Combinatorial testing; Embedded systems; Input domain testing; Neural networks; Output domain",,,,,,,,,,,,,,,,,"Lakshmi Prasad, M., Sastry, J., A Comprehensive Survey on Combinatorial Testing (2017) PONTE Journal, 73 (2), pp. 187-261. , Oct, ISI, Scopus, Thomson Reuters); Lakshmi Prasad, M., Sastry, J., A Graph Based Strategy (GBS) For Generating Test Cases Meant For Testing Embedded Systems Using Combinatorial Approaches (2018) Journal of Advanced Research in Dynamical and Control Systems, 10, pp. 314-324. , Jan, Scopus); Lakshmi Prasad, M., Sastry, J., Testing Embedded Systems using test cases generated through Combinatorial Methods (2018) International Journal of Engineering Technology, 7 (1), pp. 146-158. , March, Scopus); Anderson, C., Von Mayrhauser, A., Mraz, R., On the use of neural networks to guide software testing activities (1995) Proceedings of International Test Conference, pp. 720-729. , 21-25 Oct; Cohen, D.M., Dalal, S.R., Method and System for Automatically Generating Efficient Test Cases for Systems Having Interacting Elements, , patent,1996; Cohen, D.M., Dalal, S.R., Fredman, M.L., Patton, G.C., The AETG System: An Approach to Testing Based on Combinatorial Design (1997) IEEE Transactions on Software Engineering, 23 (7), pp. 437-443. , July; Lei, Y., Tai, K.C., In-parameter-order: A test generation strategy for pair wise testing (1998) Proceedings of Third IEEE International High-Assurance Systems Engineering Symposium, 1998, pp. 254-261. , 13-14 Nov; Lei, Y., Tai, K.C., A Test Generating Strategy for Pair-wise Testing (2002) IEEE Transactions on Software Engineering; Ghazi, S.A., Ahmed, M.A., ""Pair-wise test coverage using genetic algorithms"", CEC (2003) The 2003 Congress on Evolutionary Computation, 2, pp. 1420-1424; Bryce, R.R., Colbourn, C.J., (2007) ""The Density Algorithm for Pair Wise Interaction Testing"", Journal of Software, , Testing, Verification and Reliability; Li, K., Yang, Z., Generating Method of Pair-Wise Covering Test Data Based on ACO (2008) ETT and GRS, 2008 IEEE International Workshop on Geoscience and Remote Sensing and International Workshop on Education Technology and Training, 2, pp. 776-779; Lilan, W., Bo, L., Yi, J., Xie, X., Using back-propagation neural networks for functional software testing (2008) 2Nd International Conference on Anti-Counterfeiting, Security and Identification, ASID, pp. 272-275; Singh, Y., Kaur, A., Malhotra, R., Predicting Testing Effort using Artificial Neural Network (2008) Proceedings of the World Congress on Engineering and Computer Science(Wcecs), , October 22-24; Kuhn, R., Lei, Y., Kacker, R., Practical Combinatorial Testing: Beyond Pair wise (2008) IEEE Computer Society - IT Professional, 10 (3); Chen, X., Qing, G., Zhang, X., Chen, D., Building Prioritized Pairwise Interaction Test Suites with Ant Colony Optimization (2009) QSIC, 9Th International Conference on Quality Software, pp. 347-352; McCaffrey, J.D., Generation of pairwise test sets using a simulated bee colony algorithm (2009) IRI '09, IEEE International Conference on Information Reuse & Integration, pp. 115-119; McCaffrey, J.D., Generation of Pairwise Test Sets using a Genetic Algorithm (2009) 33Rd Annual IEEE International Computer Software and Applications Conference; Kuhn, R., Kacker, R., Yu Lei and Justin Hunter, ""Combinatorial Software Testing"" (2009) IEEE, 0018-9162; Chen, X., Qing, G., Qi, J., Chen, D., Applying Particle Swarm Optimization to Pairwise Testing (2010) COMPSAC, 2010 IEEE 34Th Annual Computer Software and Applications Conference, pp. 107-116; Richard Kuhn, D., Kacker, R.N., Lei, Y., Practical combinatorial testing (2010) NIST Special Publication, p. 800; Vudatha, C.P., Jammalamadaka, S.K., Duvvuri, B.K.K., Reddy, L., Automated Generation of Test Cases from Output Domain of an Embedded System using Genetic Algorithms (2011) Proceedings of the 3Rd International Conference on Electronics Computer Technology (ICECT; Vudatha, C.P., Jammalamadaka, D.R., Nalliboena, S., Duvvuri, B.K.K., Reddy, L.S.S., Automated generation of test cases from output domain and critical regions of embedded systems using genetic algorithms (2011) 2Nd National Conference on Emerging Trends and Applications in Computer Science (NCETACS), pp. 1-6; Smilgyte, K., Nenortaite, J., ""Artificial Neural Networks Application in Software Testing Selection Method"", Springer Link Lecture notes (2011) Hybrid Artificial Intelligent Systems, Lecture Notes in Computer Science, 6678, pp. 247-254; Patil, M., Nikumbh, P.J., Pair-Wise Testing Using Simulated Annealing, , Published by Elsevier Ltd,2012; Bansal, P., Sabharwal, S., Malik, S., Arora, V., Kumar, V., ""An Approach to Test Set Generation for Pair-Wise Testing Using Genetic Algorithms (2013) Search Based Software Engineering, 8084, pp. 294-299; Raju, R., P.Subhapriya, ""A Neural Network Approach for Randomized Unit Testing Based On Genetic Algorithm (2013) International Journal of Engineering and Advanced Technology (IJEAT, 2 (3); Huayao, W., Nie, C., ""An overview of search based combinatorial testing (2014) In Proceedings of the 7Th International Workshop on Search-Based Software Testing (SBST 2014). ACM, pp. 27-30. , New York, NY, USA; Zakaria, H.L., Zamli, K.Z., Migrating Birds Optimization based strategies for Pair wise testing (2015) 2015 9Th Malaysian Software Engineering Conference (Mysec), pp. 19-24. , Kuala Lumpur; Qi, R., Wang, Z., Ping, P., Li, S., A hybrid optimization algorithm for pair wise test suite generation (2015) 2015 IEEE International Conference on Information and Automation, pp. 3062-3067. , Lijiang; Yamada, A., Biere, A., Artho, C., Kitamura, T., Choi, E.H., (2016) ""Greedy Combinatorial Test Case Generation Using Unsatisfiable Cores,"" in Proceedings of the 31St IEEE/ACM International Conference on Automated Software Engineering, pp. 614-624. , ASE), Singapore; Lakshmi Prasad, M., Sastry, J., Building Test Cases by Particle Swarm Optimization (PSO) For Multi Output Domain Embedded Systems Using Combinatorial Techniques Journal of Advanced Research in Dynamical and Control Systems, , May 2018 (Scopus; Lakshmi Prasad, M., Sastry, J., A Neural Network Based Strategy (NNBS) For Automated Construction Of Test Cases For Testing An Embedded System Using Combinatorial Techniques International Journal of Engineering Technology, 7 (1), pp. 74-81. , Jan 2018.(Scopus; Lakshmi Prasad, M., Sastry, J., Generating Test cases for Testing WEB sites through Neural Networks and Input Pairs (2014) International Journal of Applied Engineering Research, 9 (22). , Scopus; Lakshmi Prasad, M., Chandra Prakash, V., Generation of less number of pair wise test cases using artificial neural networks (ANN International Journal of Applied Engineering Research, 9 (22). , 2014 (Scopus); Lakshmi Prasad, M., Sastry, J., Generation of Test Cases Using Combinatorial Methods Based Multi-Output Domain of an Embedded System through the Process of Optimal Selection (2018) International Journal of Pure and Applied Mathematics, 118 (20), pp. 181-189. , March 2018 (Scopus",,,,"Institute of Advanced Scientific Research, Inc.",,,,,1943023X,,,,"English","J. Adv. Res. Dyn. Control. Syst.",Article,"Final","",Scopus,2-s2.0-85049366693
"Mudarakola, L.P., Sastry, J.K.R.","56403390400;56428811000;","A Neural Network Based Strategy (NNBS) for automated construction of test cases for testing an Embedded system using Combinatorial Techniques",2018,"International Journal of Engineering and Technology(UAE)","7","1.3",,"74","81",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042699245&partnerID=40&md5=e67ff789e79f0eef9f63e4241909cf9e",,"Mudarakola, L.P.; Sastry, J.K.R.",[No abstract available],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Int. J. Eng. Technol.",Article,"Final","",Scopus,2-s2.0-85042699245
"Moshovos A., Albericio J., Judd P., Delmas Lascorz A., Sharify S., Hetherington T., Aamodt T., Enright Jerger N.","6603721033;55062240800;56382174000;57200992345;57197708113;55247173200;6602448894;18233361500;","Value-Based Deep-Learning Acceleration",2018,"IEEE Micro","38","1",,"41","55",,5,"10.1109/MM.2018.112130309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041648322&doi=10.1109%2fMM.2018.112130309&partnerID=40&md5=3ef1255913b08889d2b1706dc6230b06","University of Toronto, Canada; NVIDIA, University of Zaragoza, Canada; University of British Columbia, Canada","Moshovos, A., University of Toronto, Canada; Albericio, J., NVIDIA, University of Zaragoza, Canada; Judd, P., University of Toronto, Canada; Delmas Lascorz, A., University of Toronto, Canada; Sharify, S., University of Toronto, Canada; Hetherington, T., University of British Columbia, Canada; Aamodt, T., University of British Columbia, Canada; Enright Jerger, N., University of Toronto, Canada","This article summarizes our recent work on value-based hardware accelerators for image classification using Deep Convolutional Neural Networks (CNNs). The presented designs exploit runtime value properties that are difficult or impossible to discern in advance. These include values that are zero or near zero and that prove ineffectual, have reduced yet variable precision needs, or have ineffectual bits. The designs offer a spectrum of choices in terms of area cost, energy efficiency, and relative performance when embedded in server class installations. More importantly, the accelerators reward advances in CNN design that increase the aforementioned properties. © 2017 IEEE.","Acceleration; convolutional neural networks; hardware","Acceleration; Computer hardware; Hardware; Navigation systems; Neural networks; Object detection; Object recognition; Program processors; Accelerator design; Algorithms implemented-in-hardware; Autonomous navigation systems; Convolutional neural network; Design styles; Hardware accelerators; Three-dimensional display; Two-dimensional displays; Deep learning",,,,,,,,,,,,,,,,"Esmaeilzadeh, H., Dark silicon and the end of multicore scaling (2011) 38th International Symposium On Computer Architecture (ISCA '11), pp. 365-376. , https://dl.acm.org/citation.cfmid=2000108; Bojarski, M., (2016) End to End Learning for Self-Driving Cars, , https://arxiv.org/abs/1604.07316, arxiv.org; Chen, Y., DaDianNao: A Machine-Learning Supercomputer (2014) 47th IEEE/ACM International Symposium On Microarchitecture (MICRO), , http://ieeexplore.ieee.org/document/7011421; Albericio, J., Cnvlutin: Ineffectual-Neuron-Free deep neural network computing (2016) 43rd ACM/IEEE International Symposium On Computer Architecture (ISCA), , http://ieeexplore.ieee.org/document/7551378; Judd, P., Stripes: Bit-serial deep neural network computing (2016) 49th IEEE/ACM International Symposium On Microarchitecture (MICRO), , http://ieeexplore.ieee.org/document/7783722; Delmas, A., (2017) Tartan: Accelerating Fully-Connected and Convolutional Layers in Deep Learning Networks by Exploiting Numerical Precision Variability, , https://arxiv.org/abs/1707.09068, arxiv.org; Delmas, A., (2017) Dynamic Stripes: Exploiting the Dynamic Precision Requirements of Activation Values in Neural Networks, , https://arxiv.org/abs/1706.00504, arxiv.org; Sharify, S., (2017) Loom: Exploiting Weight and Activation Precisions to Accelerate Convolutional Neural Networks, , https://arxiv.org/abs/1706.07853, arxiv.org; Albericio, J., Bit-pragmatic deep neural network computing (2017) 50th IEEE/ACM International Symposium On Microarchitecture (MICRO-50 '17), pp. 382-394. , https://dl.acm.org/citation.cfmid=3123982; Judd, P., (2015) Reduced-Precision Strategies for Bounded Memory in Deep Neural Nets, , https://arxiv.org/abs/1511.05236, arxiv.org; Judd, P., Proteus: Exploiting numerical precision variability in deep neural networks (2016) Workshop On Approximate Computing (WAPCO), , https://wapco.ece.uth.gr/2016/papers/SESSION2/wapco201622.pdf; Warden, P., How to quantize neural networks with tensorFlow (2016) Pete Warden's Blog, , https://petewarden.com/2016/05/03/how-to-quantize-neural-networkswith-tensorflow; Han, S., (2016) EIE: Efficient Inference Engine On Compressed Deep Neural Network, , https://arxiv.org/abs/1602.01528, arxiv.org; Iandola, F.N., (2016) SqueezeNet: AlexNet-level Accuracy with 50x Fewer Parameters and 0.5MB Model Size, , https://arxiv.org/abs/1602.07360, arxiv.org; Parashar, A., SCNN: An accelerator for compressed-sparse convolutional neural networks (2017) 44th ACM/IEEE International Symposium On Computer Architecture (ISCA), , https://www.computer.org/csdl/proceedings/isca/2017/4892/00/08192478-abs.html; Zhu, M., Gupta, S., (2017) To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression, , https://arxiv.org/abs/1710.01878, arxiv.org; Kim, J., Hwang, K., Sung, W., X1000 real-time phoneme recognition VLSI using feed-forward deep neural networks (2014) IEEE International Conference On Acoustics, Speech and Signal Processing (ICASSP), , http://ieeexplore.ieee.org/document/6855060; Courbariaux, M., Bengio, Y., David, J.P., (2015) BinaryConnect: Training Deep Neural Networks with Binary Weights during Propagations, , https://arxiv.org/abs/1511.00363, arxiv.org",,,,"IEEE Computer Society",,,,,02721732,,IEMID,,"English","IEEE Micro",Article,"Final","",Scopus,2-s2.0-85041648322
"Cheng Y., Wang D., Zhou P., Zhang T.","55421399200;57200297175;57203264243;55547106760;","Model Compression and Acceleration for Deep Neural Networks: The Principles, Progress, and Challenges",2018,"IEEE Signal Processing Magazine","35","1","8253600","126","136",,215,"10.1109/MSP.2017.2765695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040641358&doi=10.1109%2fMSP.2017.2765695&partnerID=40&md5=ef2ea7f14c57cc8b21fe9357f608e9ee","AI Foundations Lab, IBM T.J. Watson Research Center, Yorktown Heights, NY  10598, United States; Automation, Tsinghua University, Beijing, China; Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, China","Cheng, Y., AI Foundations Lab, IBM T.J. Watson Research Center, Yorktown Heights, NY  10598, United States; Wang, D., Automation, Tsinghua University, Beijing, China; Zhou, P., Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, China; Zhang, T., Automation, Tsinghua University, Beijing, China","In recent years, deep neural networks (DNNs) have received increased attention, have been applied to different applications, and achieved dramatic accuracy improvements in many tasks. These works rely on deep networks with millions or even billions of parameters, and the availability of graphics processing units (GPUs) with very high computation capability plays a key role in their success. For example, Krizhevsky et al. [1] achieved breakthrough results in the 2012 ImageNet Challenge using a network containing 60 million parameters with five convolutional layers and three fully connected layers. Usually, it takes two to three days to train the whole model on the ImagetNet data set with an NVIDIA K40 machine. In another example, the top face-verification results from the Labeled Faces in the Wild (LFW) data set were obtained with networks containing hundreds of millions of parameters, using a mix of convolutional, locally connected, and fully connected layers [2], [3]. It is also very time-consuming to train such a model to obtain a reasonable performance. In architectures that only rely on fully connected layers, the number of parameters can grow to billions [4]. © 1991-2012 IEEE.",,"Computer graphics; Convolution; Graphics processing unit; Program processors; Accuracy Improvement; Data set; Face Verification; Labeled faces in the wilds (LFW); Model compression; Deep neural networks",,,,,"National Natural Science Foundation of China, NSFC: 61401169","We would like to thank the reviewers and broader community for their feedback on this survey. In particular, we would like to thank Hong Zhao from the Department of Automation of Tsinghua University for her help on modifying this article. This research is supported by National Science Foundation of China, grant number 61401169. The corresponding author of this article is Pan Zhou.",,,,,,,,,,"Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolutional neural networks (2012) Proc. Conf. Neural Information Processing Systems, pp. 1097-1105; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014) Proc. IEEE Conf. Computer Vision Pattern Recognition, pp. 1701-1708; Sun, Y., Wang, X., Tang, X., Deeply learned face representations are sparse, selective, and robust (2015) Proc. IEEE Conf. Computer Vision Pattern Recognition, pp. 2892-2900; Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Le, Q., Mao, M., Ng, A., Large scale distributed deep networks (2012) Proc. Conf. Neural Information Processing Systems, pp. 1223-1231; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2015) Computing Res. Repository, , https://arxiv.org/pdf/1512.03385.pdf, abs/1512. 03385; Gong, Y., Liu, L., Yang, M., Bourdev, L.D., Compressing deep convolutional networks using vector quantization (2014) Computing Res. Repository, , https://arxiv.org/pdf/1412.6115.pdf, abs/1412. 6115; Jiaxiang Wu, Y.W.Q.H., Leng, C., Cheng, J., Quantized convolutional neural networks for mobile devices (2016) Proc. IEEE Conf. Computer Vision Pattern Recognition, pp. 4820-4828; Vanhoucke, V., Senior, A., Mao, M.Z., Improving the speed of neural networks on cpus (2011) Proc. Conf. Neural Information Processing Systems Deep Learning and Unsupervised Feature Learning Workshop; Gupta, S., Agrawal, A., Gopalakrishnan, K., Narayanan, P., Deep learning with limited numerical precision (2015) Proc. 32nd Int. Conf. Machine Learning, 37, pp. 1737-1746; Han, S., Mao, H., Dally, W.J., Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding (2016) Proc. Int. Conf. Learning Representations; Choi, Y., El-Khamy, M., Lee, J., Towards the limit of network quantization (2016) Computing Res. Repository, , https://arxiv.org/abs/1612.01543, abs/1612. 01543; Zhu, C., Han, S., Mao, H., Dally, W.J., (2016) Trained Ternary Quantization; Courbariaux, M., Bengio, Y., David, J., Binaryconnect: Training deep neural networks with binary weights during propagations (2015) Proc. Advances Neural Information Processing Systems Annu. Conf., pp. 3123-3131; Courbariaux, M., Bengio, Y., Binarynet: Training deep neural networks with weights and activations constrained to +1 or 1 (2016) Computing Res. Repository, , https://arxiv.org/abs/1602.02830, abs/1602. 02830; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., Xnor-net: Imagenet classification using binary convolutional neural networks (2016) Proc. European Conf. Computer Vision, pp. 525-542; Merolla, P., Appuswamy, R., Arthur, J.V., Esser, S.K., Modha, D.S., Deep neural networks are robust to weight binarization and other non-linear distortions (2016) Computing Res. Repository, , https://arxiv.org/abs/1606.01981, abs/1606. 01981; Hou, L., Yao, Q., Kwok, J.T., Loss-aware binarization of deep networks (2016) Computing Res. Repository, , https://arxiv.org/abs/1611.01600, abs/1611. 01600; Lin, Z., Courbariaux, M., Memisevic, R., Bengio, Y., Neural networks with few multiplications (2015) Computing Res. Repository, , https://arxiv.org/abs/1510.03009, abs/1510. 03009; Hanson, S.J., Pratt, L.Y., Comparing biases for minimal network construction with back-propagation (1989) Adv. Neural Inform. Process. Syst. 1, pp. 177-185; Cun, Y.L., Denker, J.S., Solla, S.A., Advances in neural information processing systems 2 (1990) Optimal Brain Damage, pp. 598-605. , D. S. Touretzky, Ed. San Mateo, CA: Morgan Kaufmann; Hassibi, B., Stork, D.G., Com, S.C.R., Second order derivatives for network pruning: Optimal brain surgeon (1993) Advances in Neural Information Processing Systems, 5, pp. 164-171. , San Mateo, CA: Morgan Kaufmann; Srinivas, S., Babu, R.V., Data-free parameter pruning for deep neural networks (2015) Proc. British Machine Vision Conf., pp. 311-3112; Han, S., Pool, J., Tran, J., Dally, W.J., Learning both weights and connections for efficient neural networks (2015) Proc. 28th Int. Conf. Neural Information Processing Systems, pp. 1135-1143; Chen, W., Wilson, J., Tyree, S., Weinberger, K.Q., Chen, Y., Compressing neural networks with the hashing trick (2015) Proc. Machine Learning Research Workshop Conf., pp. 2285-2294; Ullrich, K., Meeds, E., Welling, M., Soft weight-sharing for neural network compression (2017) Computing Res. Repository, , https://arxiv.org/abs/1702.04008, abs/1702. 04008; Lebedev, V., Lempitsky, V.S., Fast convnets using group-wise brain damage (2016) Proc. IEEE Conf. Computer Vision Pattern Recognition, pp. 2554-2564; Zhou, H., Alvarez, J.M., Porikli, F., Less is more: Towards compact CNNs (2016) Proc. European Conf. Computer Vision, pp. 662-677; Wen, W., Wu, C., Wang, Y., Chen, Y., Li, H., Learning structured sparsity in deep neural networks (2016) Adv. Neural Inform. Process. Syst., 29, pp. 2074-2082; Li, H., Kadav, A., Durdanovic, I., Samet, H., Graf, H.P., Pruning filters for efficient convnets (2016) Computing Res. Repository, , https://arxiv.org/abs/1608.08710, abs/1608. 08710; Cheng, Y., Yu, F.X., Feris, R., Kumar, S., Choudhary, A., Chang, S.-F., An exploration of parameter redundancy in deep networks with circulant projections (2015) Proc. Int. Conf. Computer Vision, pp. 2857-2865; Yang, Z., Moczulski, M., Denil, M., De Freitas, N., Smola, A., Song, L., Wang, Z., Deep fried convnets (2015) Proc. Int. Conf. Computer Vision, pp. 1476-1483; Sindhwani, V., Sainath, T., Kumar, S., Structured transforms for small-footprint deep learning (2015) Advances in Neural Information Processing Systems, 28, pp. 3088-3096. , http://papers.nips.cc/paper/5869-structured-transforms-for-small-footprint-deep-learning.pdf; Chun, J., Kailath, T., (1991) Generalized Displacement Structure for Block-Toeplitz, Toeplitz-Block, and Toeplitz-Derived Matrices, pp. 215-236. , Berlin, Germany: Springer; Rakhuba, M.V., Oseledets, I.V., Fast multidimensional convolution in low-rank tensor formats via cross approximation (2015) SIAM J. Sci. Comput., 37 (2). , http://dx.doi.org/10.1137/140958529; Rigamonti, R., Sironi, A., Lepetit, V., Fua, P., Learning separable filters (2013) Proc. IEEE Conf. Computer Vision Pattern Recognition, pp. 2754-2761; Denton, E.L., Zaremba, W., Bruna, J., LeCun, Y., Fergus, R., Exploiting linear structure within convolutional networks for efficient evaluation (2014) Adv. Neural Inform. Process. Syst., 27, pp. 1269-1277; Jaderberg, M., Vedaldi, A., Zisserman, A., Speeding up convolutional neural networks with low rank expansions (2014) Proc. British Machine Vision Conf., pp. 1-13; Lebedev, V., Ganin, Y., Rakhuba, M., Oseledets, I.V., Lempitsky, V.S., Speeding-up convolutional neural networks using fine-tuned CP-decomposition (2014) Computing Res. Repository, , https://arxiv.org/abs/1412.6553, abs/1412. 6553; Tai, C., Xiao, T., Wang, X., Weinan, E., Convolutional neural networks with low-rank regularization (2015) Computing Res. Repository, , abs/1511. 06067; Denil, M., Shakibi, B., Dinh, L., Ranzato, M., Freitas, N.D., Predicting parameters in deep learning (2013) Advances in Neural Information Processing Systems, 26, pp. 2148-2156. , http://media.nips.cc/nipsbooks/nipspapers/paper_files/nips26/1053.pdf; Sainath, T.N., Kingsbury, B., Sindhwani, V., Arisoy, E., Ramabhadran, B., Low-rank matrix factorization for deep neural network training with high-dimensional output targets (2013) Proc. IEEE Int. Conf. Acoustics Speech Signal Processing, pp. 6655-6659; Cohen, T.S., Welling, M., (2016) Group Equivariant Convolutional Networks; Zhai, S., Cheng, Y., Zhang, Z.M., Doubly convolutional neural networks (2016) Proc. Advances Neural Information Processing Systems, pp. 1082-1090; Shang, W., Sohn, K., Almeida, D., Lee, H., (2016) Understanding and Improving Convolutional Neural Networks Via Concatenated Rectified Linear Units; Li, H., Ouyang, W., Wang, X., (2016) Multi-bias Non-linear Activation in Deep Neural Networks; Dieleman, S., Fauw, J.D., Kavukcuoglu, K., Exploiting cyclic symmetry in convolutional neural networks (2016) Proc. 33rd Int. Conf. Machine Learning, 48, pp. 1889-1898; Szegedy, C., Ioffe, S., Vanhoucke, V., Inception-v4, inception-resnet and the impact of residual connections on learning (2016) Computing Res. Repository, , http://dblp.uni-trier.de/db/journals/corr/corr1602.html#SzegedyIV16, abs/1602. 07261; Wu, B., Iandola, F.N., Jin, P.H., Keutzer, K., Squeezedet: Unified, small, low power fully convolutional neural networks for real-time object detection for autonomous driving (2016) Computing Res. Repository, , https://arxiv.org/abs/1612.01051, abs/1612. 01051; Bucilua, C., Caruana, R., Niculescu-Mizil, A., Model compression (2006) Proc. 12th ACM SIGKDD Int. Conf. Knowledge Discovery Data Mining, pp. 535-541. , http://doi.acm.org/10.1145/1150402.1150464; Ba, J., Caruana, R., Do deep nets really need to be deep (2014) Adv. Neural Inform. Process. Syst., 27, pp. 2654-2662; Hinton, G.E., Vinyals, O., Dean, J., Distilling the knowledge in a neural network (2015) Computing Res. Repository, , https://arxiv.org/abs/1503.02531, abs/1503. 02531; Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y., Fitnets: Hints for thin deep nets (2014) Computing Res. Repository, , https://arxiv.org/abs/1412.6550, abs/1412. 6550; Korattikara Balan, A., Rathod, V., Murphy, K.P., Welling, M., Bayesian dark knowledge (2015) Advances in Neural Information Processing Systems, 28, pp. 3420-3428. , http://papers.nips.cc/paper/5965-bayesian-dark-knowledge.pdf; Luo, P., Zhu, Z., Liu, Z., Wang, X., Tang, X., Face model compression by distilling knowledge from neurons (2016) Proc. 30th AAAI Conf. Artificial Intelligence, pp. 3560-3566; Chen, T., Goodfellow, I.J., Shlens, J., Net2net: Accelerating learning via knowledge transfer (2015) Computing Res. Repository, , https://arxiv.org/abs/1511.05641, abs/1511. 05641; Zagoruyko, S., Komodakis, N., Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer (2016) Computing Res. Repository, , http://arxiv.org/abs/1612.03928, abs/1612. 03928; Almahairi, A., Ballas, N., Cooijmans, T., Zheng, Y., Larochelle, H., Courville, A.C., Dynamic capacity networks (2016) Proc. 33rd Int. Conf. Machine Learning, pp. 2549-2558; Shazeer, N., Mirhoseini, A., Maziarz, K., Davis, A., Le, Q., Hinton, G., Dean, J., (2017) Outrageously Large Neural Networks: The Sparsely-gated Mixture-of-experts Layer, , https://openreview.net/pdf?id=B1ckMDqlg; Wu, D., Pigou, L., Kindermans, P., Le, N.D., Shao, L., Dambre, J., Odobez, J., Deep dynamic neural networks for multimodal gesture segmentation and recognition (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (8), pp. 1583-1597; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proc. IEEE Computer Vision Pattern Recognition., , http://arxiv.org/abs/1409.4842; Huang, G., Sun, Y., Liu, Z., Sedra, D., Weinberger, K.Q., Deep networks with stochastic depth (2016) Computing Res. Repository; Yamada, Y., Iwamura, M., Kise, K., Deep pyramidal residual networks with separated stochastic depth (2016) Computing Res. Repository, , http://arxiv.org/abs/1612.01230, abs/1612. 01230; Mathieu, M., Henaff, M., Lecun, Y., Fast training of convolutional networks through FFTs (2014) Computing Res. Repository; Lavin, A., Gray, S., Fast algorithms for convolutional neural networks (2016) Proc. IEEE Conf. Computer Vision Pattern Recognition, pp. 4013-4021; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, pp. 2278-2324; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M.A., Striving for simplicity: The all convolutional net (2014) Computing Res. Repository, , https://arxiv.org/abs/1412.6806, abs/1412. 6806; Lin, M., Chen, Q., Yan, S., Network in network (2014) Proc. Int. Conf. Learning Representations, , https://arxiv.org/abs/1312.4400; Simonyan, K., Zisserman, A., Very deep convolutional networks for largescale image recognition (2014) Computing Res. Repository, , https://arxiv.org/abs/1409.1556, abs/1409. 1556; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition; Cheng, Y., Yu, F.X., Feris, R.S., Kumar, S., Choudhary, A.N., Chang, S., An exploration of parameter redundancy in deep networks with circulant projections (2015) Proc. IEEE Int. Conf. Computer Vision, pp. 2857-2865; Moczulski, M., Denil, M., Appleyard, J., De Freitas, N., ACDC: A structured efficient linear layer (2016) Proc. Int. Conf. Learning Representations; Andrychowicz, M., Denil, M., Colmenarejo, S.G., Hoffman, M.W., Pfau, D., Schaul, T., De Freitas, N., Learning to learn by gradient descent by gradient descent (2016) Proc. Neural Information Processing Systems Conf., pp. 3981-3989; Ha, D., Dai, A., Le, Q., Hypernetworks (2016) Proc. Int. Conf. Learning Representations; Alvarez, J.M., Salzmann, M., Learning the number of neurons in deep networks (2016) Proc. Neural Information Processing Systems Conf., pp. 2270-2278; Wang, Y., Xu, C., Xu, C., Tao, D., Beyond filters: Compact feature map for portable deep model (2017) Proc. 34th Int. Conf. Machine Learning, pp. 3703-3711; Kim, Y.-D., Park, E., Yoo, S., Choi, T., Yang, L., Shin, D., Compression of deep convolutional neural networks for fast and low power mobile applications (2015) Computing Res. Repository, , https://arxiv.org/abs/1511.06530, abs/1511. 06530; (2016) Caffe2: A New Lightweight, Modular, and Scalable Deep Learning Framework, , https://caffe2.ai/, Facebook, Inc",,,,"Institute of Electrical and Electronics Engineers Inc.",,,,,10535888,,ISPRE,,"English","IEEE Signal Process Mag",Article,"Final","",Scopus,2-s2.0-85040641358
"Andri R., Cavigelli L., Rossi D., Benini L.","56333567600;56136598900;7103169675;35556997000;","Yoda NN: An architecture for ultralow power binary-weight CNN acceleration",2018,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","37","1","7878541","48","60",,108,"10.1109/TCAD.2017.2682138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040180801&doi=10.1109%2fTCAD.2017.2682138&partnerID=40&md5=c34949cdd0e85a8757aac110d8b5c745","Integrated Systems Laboratory, ETH Zurich, Zürich, 8092, Switzerland; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, 40136, Italy","Andri, R., Integrated Systems Laboratory, ETH Zurich, Zürich, 8092, Switzerland; Cavigelli, L., Integrated Systems Laboratory, ETH Zurich, Zürich, 8092, Switzerland; Rossi, D., Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, 40136, Italy; Benini, L., Integrated Systems Laboratory, ETH Zurich, Zürich, 8092, Switzerland, Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, 40136, Italy","Convolutional neural networks (CNNs) have revolutionized the world of computer vision over the last few years, pushing image classification beyond human accuracy. The computational effort of today's CNNs requires power-hungry parallel processors or GP-GPUs. Recent developments in CNN accelerators for system-on-chip integration have reduced energy consumption significantly. Unfortunately, even these highly optimized devices are above the power envelope imposed by mobile and deeply embedded applications and face hard limitations caused by CNN weight I/O and storage. This prevents the adoption of CNNs in future ultralow power Internet of Things end-nodes for near-sensor analytics. Recent algorithmic and theoretical advancements enable competitive classification accuracy even when limiting CNNs to binary (1) weights during training. These new findings bring major optimization opportunities in the arithmetic core by removing the need for expensive multiplications, as well as reducing I/O bandwidth and storage. In this paper, we present an accelerator optimized for binary-weight CNNs that achieves 1.5 TOp/s at 1.2 V on a core area of only 1.33 million gate equivalent (MGE) or 1.9 mm2 and with a power dissipation of 895 μW in UMC 65-nm technology at 0.6 V. Our accelerator significantly outperforms the state-of-the-art in terms of energy and area efficiency achieving 61.2 TOp/s/W@0.6 V and 1.1 TOp/s/MGE@1.2 V, respectively. © 2017 IEEE.","ASIC; binary weights; convolutional neural networks (CNNs); hardware accelerator; Internet of Things (IoT).","Application specific integrated circuits; Bins; Convolution; Energy gap; Energy utilization; Internet of things; Neural networks; Program processors; System-on-chip; binary weights; Classification accuracy; Computational effort; Convolutional neural network; Embedded application; Hardware accelerators; Internet of Things (IOT); System-on-chip integration; Acceleration",,,,,"ERC-AdG-291125; Seventh Framework Programme, FP7: 291125; Schweizerischer Nationalfonds zur F&#x00F6;rderung der Wissenschaftlichen Forschung, SNF: 162524","Manuscript received September 14, 2016; revised December 30, 2016 and February 20, 2017; accepted February 26, 2017. Date of publication March 14, 2017; date of current version December 20, 2017. This work was supported in part by the Swiss National Science Foundation under Grant 162524 (MicroLearn: Micropower Deep Learning), in part by the Armasuisse Science and Technology, and in part by the ERC MultiTherman Project under Grant ERC-AdG-291125. This paper was recommended by Associate Editor X. Li.",,,,,,,,,,"Lucas, G., (2016) Yoda, , www.starwars.com/databank/yoda; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1106-1114; Wu, R., Yan, S., Shan, Y., Dang, Q., Sun, G., (2015) Deep Image: Scaling Up Image Recognition, , arXiv preprint arXiv:1501.02876, Jan; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , arXiv preprint arXiv:1512.03385, Dec; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., DeepFace: Closing the gap to human-level performance in face verification (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1701-1708. , Columbus, OH, USA, Jun; Hannun, A.Y., (2014) Deep Speech: Scaling Up End-to-end Speech Recognition, , arXiv preprint arXiv:1412.5567, Dec; Weston, J., Chopra, S., Bordes, A., (2014) Memory Networks, , arXiv:1410.3916, Oct; Weston, J., (2016) Dialog-based Language Learning, , arXiv preprint arXiv:1604.06045, Apr; Mnih, V., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), pp. 529-533. , Feb; Zastrow, M., Machine outsmarts man in battle of the decade (2016) New Sci., 229 (3065), p. 21; Coates, A., Deep learning with cots HPC systems (2013) Proc. 30th Int. Conf. Mach. Learn. (ICML), 28, pp. 1337-1345. , Atlanta, GA, USA, May; Farabet, C., Couprie, C., Najman, L., Le Cun, Y., Learning hierarchical features for scene labeling (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (8), pp. 1915-1929. , Aug; Cavigelli, L., Magno, M., Benini, L., Accelerating real-time embedded scene labeling with convolutional networks (2015) Proc. 52nd Annu. Design Autom. Conf. (DAC), pp. 1-6. , San Francisco, CA, USA; Ovtcharov, K., Accelerating deep convolutional neural networks using specialized hardware (2015) Microsoft Res. Whitepaper, 2 (11); Cavigelli, L., Benini, L., (2016) Origami: A 803 GOp/s/W Convolutional Network Accelerator, , arXiv preprint arXiv:1512.04295, Jan; Farabet, C., NeuFlow: A runtime reconfigurable dataflow processor for vision (2011) Proc. CVPR WORKSHOPS, pp. 109-116. , Colorado Springs, CO, USA, Jun; Conti, F., Benini, L., A ultra-low-energy convolution engine for fast brain-inspired vision in multicore clusters (2015) Proc. Design Autom. Test Europe Conf. Exhibit., pp. 683-688. , Grenoble, France; Du, Z., ShiDianNao: Shifting vision processing closer to the sensor (2015) Proc. ACM SIGARCH Comput. Archit. News, pp. 92-104. , Portland, OR, USA; Qadeer, W., Convolution engine: Balancing efficiency & flexibility in specialized computing (2013) Proc. ISCA, pp. 24-35. , Tel Aviv, Israel; Sung, W., Shin, S., Hwang, K., (2015) Resiliency of Deep Neural Networks under Quantization, , arXiv preprint arXiv:1511.06488, Nov; Gysel, P., Motamedi, M., Ghiasi, S., (2016) Hardware-oriented Approximation of Convolutional Neural Networks, , arXiv preprint arXiv:1604.03168, May; Courbariaux, M., Bengio, Y., David, J.-P., BinaryConnect: Training deep neural networks with binary weights during propagations (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 3105-3113. , Montreal, QC, Canada; Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., (2016) XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks, , arXiv preprint arXiv:1603.05279, Mar; Courbariaux, M., Bengio, Y., (2016) BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1, , arXiv preprint arXiv:1602.02830, Mar; Lin, Z., Courbariaux, M., Memisevic, R., Bengio, Y., (2016) Neural Networks with Few Multiplications, , arXiv preprint arXiv:1510.03009, Feb; Teman, A., Rossi, D., Meinerzhagen, P., Benini, L., Burg, A., Power, area, and performance optimization of standard cell memory arrays through controlled placement (2016) ACM Trans. Design Autom. Electron. Syst., 21 (4). , Art. no. 59; Park, S., 14.1 A 126.1mw real-time natural UI/UX processor with embedded deep-learning core for low-power smart glasses (2016) Proc. IEEE Int. Solid-State Circuits Conf. (ISSCC), pp. 254-255. , San Francisco, CA, USA, Jan; Park, S., 4.6 A1.93TOPS/W scalable deep learning/inference processor with tetra-parallel MIMD architecture for big-data applications (2015) IEEE Int. Solid-State Circuits Conf. Dig. Tech. Papers (ISSCC), pp. 1-3. , San Francisco, CA, USA, Feb; Wan, L., Zeiler, M., Zhang, S., Cun, Y.L., Fergus, R., Regularization of neural networks using dropconnect (2013) Proc. 30th Int. Conf. Mach. Learn. (ICML), 28, pp. 1058-1066. , Atlanta, GA, USA, May; Lee, C.-Y., (2015) Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree, , arXiv preprint arXiv:1509.08985, Sep; Graham, B., (2014) Fractional Max-pooling, , arXiv preprint arXiv:1412.607, Dec; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , arXiv preprint arXiv:1409.1556, Sep; Lin, D.D., Talathi, S.S., Annapureddy, V.S., (2015) Fixed Point Quantization of Deep Convolutional Networks, , arXiv preprint arXiv:1511.06393, Nov; Moons, B., De Brabandere, B., Van Gool, L., Verhelst, M., (2016) Energy Efficient ConvNets Through Approximate Computing, , arXiv preprint arXiv:1603.06777, Mar; Wu, X., (2016) High Performance Binarized Neural Networks Trained on the ImageNet Classification Task, , arXiv preprint arXiv:1604.03058, Apr; Merolla, P., Appuswamy, R., Arthur, J., Esser, S.K., Modha, D., (2016) Deep Neural Networks Are Robust to Weight Binarization and Other Non-linear Distortions, , arXiv preprint arXiv:1606.01981, Jun; Chintala, S., (2016) Convnet-Benchmarks, , https://github.com/soumith/convnet-benchmarks; Jouppi, N., (2016) Google Supercharges Machine Learning Tasks with TPU Custom Chip, , https://cloudplatform.googleblog.com/2016/05/Google-superchargesmachine-learning-tasks-with-custom-chip.html; (2014) Ins-03510-c1 Datasheet, Datasheet of Myriad 2 Vision Processor, , http://uploads.movidius.com/1441734401-Myriad-2-product-brief.pdf, Movidius, San Mateo, CA, USA; Jaehyeong, S., 14.6 A 1.42TOPS/W deep convolutional neural network recognition processor for intelligent IOE systems (2016) Proc. IEEE Int. Solid-State Circuits Conf. (ISSCC), pp. 264-265. , San Francisco, CA, USA, Apr; Chen, Y.-H., Krishna, T., Emer, J.S., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks (2016) Proc. IEEE Int. Solid-State Circuits Conf. (ISSCC), pp. 262-263. , San Francisco, CA, USA, Jan; Pham, P.-H., NeuFlow: Dataflow vision processing system-on-achip (2012) Proc. IEEE 55th Int. Midwest Symp. Circuits Syst. (MWSCAS), pp. 1044-1047. , Boise, ID, USA, Aug; Reagen, B., Minerva: Enabling low-power, highly-accurate deep neural network accelerators (2016) Proc. 43rd Int. Symp. Comput. Archit. (ISCA), pp. 267-278. , Seoul, South Korea; Albericio, J., Cnvlutin: Ineffectual-neuron-free deep neural network computing (2016) Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit. (ISCA), pp. 1-13. , Seoul, South Korea, Jun; Gokhale, V., Jin, J., Dundar, A., Martini, B., Culurciello, E., A 240 G-ops/s mobile coprocessor for deep neural networks (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops, pp. 696-701. , Columbus, OH, USA; Han, S., Mao, H., Dally, W.J., (2015) Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding, , arXiv preprint arXiv:1510.00149, Oct; Han, S., (2016) EIE: Efficient Inference Engine on Compressed Deep Neural Network, , arXiv preprint arXiv:1602.01528, Feb; Li Kam Wa, R., Hou, Y., Gao, J., Polansky, M., Zhong, L., Redeye: Analog convnet image sensor architecture for continuous mobile vision (2016) Proc. ISCA, 43, pp. 255-266. , Seoul, South Korea; Shafiee, A., ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) Proc. ISCA, pp. 14-26. , Seoul, South Korea; Cavigelli, L., Origami: A convolutional network accelerator (2015) Proc. 25th Edition Great Lakes Symp. VLSI, pp. 199-204. , Pittsburgh, PA, USA; Pullini, A., A heterogeneous multi-core system-on-chip for energy efficient brain inspired vision (2016) Proc. IEEE Int. Symp. Circuits Syst. (ISCAS), , Montreal, QC, Canada Art. no. 2910; Chen, T., DianNao: A small-footprint high-throughput accelerator for ubiquitous machine-learning (2014) SIGARCH Comput. Archit. News, 42 (1), pp. 269-284. , Mar; Gould, S., Fulton, R., Koller, D., Decomposing a scene into geometric and semantically consistent regions (2009) Proc. ICCV, pp. 1-8. , Kyoto, Japan","Andri, R.; Integrated Systems Laboratory, Switzerland; email: renzo.andri@iis.ee.ethz.ch",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,02780070,,ITCSD,,"English","IEEE Trans Comput Aided Des Integr Circuits Syst",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85040180801
"Jung D., Lee S., Rhee W., Ahn J.H.","56719052000;57192519983;57201527562;7403019527;","Partitioning Compute Units in CNN Acceleration for Statistical Memory Traffic Shaping",2018,"IEEE Computer Architecture Letters","17","1",,"72","75",,3,"10.1109/LCA.2017.2773055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035139161&doi=10.1109%2fLCA.2017.2773055&partnerID=40&md5=8857a020939a81cda7ed1707285e429f","Department of Transdisciplinary Studies, Seoul National University, Seoul, 151-742, South Korea","Jung, D., Department of Transdisciplinary Studies, Seoul National University, Seoul, 151-742, South Korea; Lee, S., Department of Transdisciplinary Studies, Seoul National University, Seoul, 151-742, South Korea; Rhee, W., Department of Transdisciplinary Studies, Seoul National University, Seoul, 151-742, South Korea; Ahn, J.H., Department of Transdisciplinary Studies, Seoul National University, Seoul, 151-742, South Korea","Convolutional Neural Networks (CNNs) have become the default choice for processing visual information, and the design complexity of CNNs has been steadily increasing to improve accuracy. To cope with the massive amount of computation needed for such complex CNNs, the latest solutions utilize blocking of an image over the available dimensions (e.g., horizontal, vertical, channel, and kernel) and batching of multiple input images to improve data reuse in the memory hierarchy. While there has been a large collection of works on maximizing data reuse, only a few studies have focused on the memory bottleneck problem caused by limited bandwidth. Bandwidth bottleneck can easily occur in CNN acceleration as CNN layers have different sizes with varying computation needs and as batching is typically performed over each layer of CNN for an ideal data reuse. In this case, the data transfer demand for a layer can be relatively low or high compared to the computation requirement of the layer, and therefore temporal fluctuations in memory access can be induced eventually causing bandwidth problems. In this paper, we first show that there exists a high degree of fluctuation in memory access to computation ratio depending on CNN layers and functions in the layer being processed by the compute units (cores), where the compute units are tightly synchronized to maximize data reuse. Then we propose a strategy of partitioning the compute units where the cores within each partition process a batch of input data in a synchronous manner to maximize data reuse but different partitions run asynchronously. Because the partitions stay asynchronous and typically process different CNN layers at any given moment, the memory access traffic sizes of the partitions become statistically shuffled. Thus, the partitioning of compute units and asynchronous use of them make the total memory access traffic size be smoothened over time, and the degree of partitioning determines a tradeoff between data reuse efficiency and memory bandwidth utilization efficiency. We call this smoothing statistical memory traffic shaping, and we show that it can lead to 8.0 percent of performance gain on a commercial 64-core processor when running ResNet-50. © 2017 IEEE.","CNN; comput units; memory bottleneck; partitioning; traffic shaping","Acceleration; Bandwidth; Computer architecture; Convolution; Data transfer; Image enhancement; Neural networks; Computational model; Convolutional neural network; Kernel; Memory bandwidths; Performance Gain; Statistical memory; Temporal fluctuation; Transfer demands; Memory architecture",,,,,,,,,,,,,,,,"Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , Cambridge, MA, USA: MIT Press; (2017) NVIDIA Tesla V100 GPU Architecture, , http://www.nvidia.com/volta, [Online]; Sodani, A., Knights landing: Second generation intel xeon phi product (2016) IEEE Micro, 36 (2), pp. 34-46. , Mar./Apr; Caulfield, A.M., A Cloud-scale acceleration architecture (2016) Proc. 49th Annu. IEEE/ACM Int. Symp. Microarchit., pp. 1-13; Jouppi, N.P., In-datacenter performance analysis of a tensor processing unit (2017) Proc. 37th Annu. Int. Symp. Comput. Archit., pp. 1-12; Shen, Y., Ferdman, M., Milder, P., Escher: A CNN accelerator with flexible buffering to minimize off-chip transfer (2017) Proc. IEEE 25th Annu. Int. Symp. Field-Programmable Custom Comput. Mach., pp. 93-100; Yang, X., (2016) A Systematic Approach to Blocking Convolutional Neural Networks, , https://arxiv.org/abs/1606.04209; Szegedy, C., Ioffe, S., Vanhoucke, V., (2016) Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, , https://arxiv.org/abs/1602.07261; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778; Son, Y.H., Microbank: Architecting through-silicon interposer-based main memory systems (2014) Proc. Int. Conf. High Perform. Comput. Netw. Storage Anal., pp. 1059-1070; Tanenbaum, A.S., (2010) Computer Networks, , Upper Saddle River, NJ, USA: Prentice Hall; Foley, D., Danskin, J., Ultra-performance pascal GPU and NVLink interconnect (2017) IEEE Micro, 37 (2), pp. 7-17. , Mar/Apr; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , https://arxiv.org/abs/1409.1556; (2016) Intel(R) Math Kernel Library for Deep Neural Networks, , https://github.com/01org/mkl-dnn, Intel, [Online]; Szegedy, C., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1-9; Jia, Y., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding, , https://arxiv.org/abs/1408.5093","Ahn, J.H.; Department of Transdisciplinary Studies, South Korea; email: gajh@snu.ac.kr",,,"Institute of Electrical and Electronics Engineers Inc.",,,,,15566056,,,,"English","IEEE Comput. Archit. Lett.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85035139161
"Bong K., Choi S., Kim C., Yoo H.-J.","55658301500;56110040400;56663345600;7201373390;","Low-Power Convolutional Neural Network Processor for a Face-Recognition System",2017,"IEEE Micro","37","6","8119708","30","38",,23,"10.1109/MM.2017.4241350","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038106848&doi=10.1109%2fMM.2017.4241350&partnerID=40&md5=9c4d355dcb37605437464784c201a067","Korea Advanced Institute of Science and Technology, South Korea","Bong, K., Korea Advanced Institute of Science and Technology, South Korea; Choi, S., Korea Advanced Institute of Science and Technology, South Korea; Kim, C., Korea Advanced Institute of Science and Technology, South Korea; Yoo, H.-J., Korea Advanced Institute of Science and Technology, South Korea","The authors propose a low-power convolutional neural network (CNN)-based face recognition system for user authentication in smart devices. The system comprises two chips: an always-on functional CMOS image sensor (CIS) for imaging and face detection (FD) and a low-power CNN processor (CNNP) for face verification (FV). A functional CIS integrated with an FD accelerator enables event-driven chip-to-chip communication for face images only when there is a face. To achieve low power consumption in FD while maintaining the memory size required for the FD processing not to exceed the on-chip memory size, the authors present two-stage FD using an analog FD unit and a digital FD unit. For the event-driven FV, the CNNP adopts dynamic voltage and frequency scaling to minimize the power consumption when the number of faces in input images changes dynamically. In addition, tensor decomposition is used to reduce a CNN's workload, and the CNNP architecture based on transpose-read SRAM (T-SRAM) allows low power consumption by reducing the local memory access. Implemented in 65-nm CMOS technology, the 3.30 3.36 mmsup2/sup functional CIS and the 4 4 mmsup2/sup CNNP consume 0.62 mW to evaluate one face at 1 frame per second and achieve 97 percent accuracy in the LFW dataset. © 1981-2012 IEEE.","application-based system; authentication; face recognition; image processing and computer vision; low-power design; neural nets; special-purpose system","Authentication; CMOS integrated circuits; Convolution; Dynamic frequency scaling; Electric power supplies to apparatus; Electric power utilization; Finite difference method; Image processing; Low power electronics; Memory architecture; Neural networks; Semiconductor devices; Static random access storage; Voltage scaling; Chip-to-chip communications; Convolutional neural network; Dynamic voltage and frequency scaling; Face recognition systems; Image processing and computer vision; Low-power consumption; Low-power design; special-purpose system; Face recognition",,,,,"Ministry of Science, ICT and Future Planning, MSIP: 2016-0-00207; Institute for Information and Communications Technology Promotion, IITP","This work was supported by an Institute for Information & Communications Technology Promotion (IITP) grant funded by the Korean government (MSIP) (no. 2016-0-00207).",,,,,,,,,,"Evans, D., (2011) The Internet of Things: How the Next Evolution of the Internet Is Changing Everything, , white paper, Cisco IBSG, Apr; Andrews, G., Przywara, L., (2015) Keeping Always-on Systems on for Low-Energy Internet-of-Things Applications, , report, Cadence Design Systems; Bong, K., A 0.62mw ultra-low-power convolutional-neural-network face-recognition processor and a cis integrated with always-on haar-like face detector (2017) Proc. IEEE Int'l Solid-State Circuits Conf., pp. 248-249; Moons, B., Envision: A 0.26-to-10 tops/w subword-parallel dynamic-voltage-accuracy-frequency-scalable cnn processor in 28nm fdsoi (2017) Proc. IEEE Int'l Solid-State Circuits Conf., pp. 246-247; Choi, J., Always-on CMOS image sensor for mobile and wearable devices (2016) IEEE J. Solid-State Circuits, 51 (1), pp. 130-140; Jeon, D., A 23mw face recognition accelerator in 40nm CMOS with mostly-read 5t memory (2015) Proc. IEEE Symp. VLSI Circuits, pp. C48-C49; Jaderberg, M., (2014) Speeding Up Convolutional Neural Networks with Low Rank Expansions, , arXiv:1405.3866; Viola, P., Rapid object detection using a boosted cascade of simple features (2001) Proc. IEEE CS Conf. Computer Vision and Pattern Recognition; Huang, G.B., (2007) Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments, , tech. report 07-49, College of Information and Computer Sciences, Univ. Massachusetts, Amherst, Oct; Bigas, M., Review of CMOS image sensors (2006) Microelectronics J., 37 (5), pp. 433-451",,,,"IEEE Computer Society",,,,,02721732,,IEMID,,"English","IEEE Micro",Article,"Final","",Scopus,2-s2.0-85038106848
"Gong T., Fan T., Guo J., Cai Z.","7006880795;57189701604;57189699855;7402905027;","GPU-based parallel optimization of immune convolutional neural network and embedded system",2017,"Engineering Applications of Artificial Intelligence","62",,,"384","395",,25,"10.1016/j.engappai.2016.08.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995489085&doi=10.1016%2fj.engappai.2016.08.019&partnerID=40&md5=68a5c69a34f58b4a2d27796acb14081a","College of Information Science and Technology, Engineering Research Center of Digitized Textile & Fashion Technology for Ministry of Education, Donghua University, Shanghai, 201620, China; College of Information and Engineering, Central South University, Changsha, Hunan  410083, China","Gong, T., College of Information Science and Technology, Engineering Research Center of Digitized Textile & Fashion Technology for Ministry of Education, Donghua University, Shanghai, 201620, China; Fan, T., College of Information Science and Technology, Engineering Research Center of Digitized Textile & Fashion Technology for Ministry of Education, Donghua University, Shanghai, 201620, China; Guo, J., College of Information Science and Technology, Engineering Research Center of Digitized Textile & Fashion Technology for Ministry of Education, Donghua University, Shanghai, 201620, China; Cai, Z., College of Information and Engineering, Central South University, Changsha, Hunan  410083, China","Up to now, the image recognition system has been utilized more and more widely in the security monitoring, the industrial intelligent monitoring, the unmanned vehicle, and even the space exploration. In designing the image recognition system, the traditional convolutional neural network has some defects such as long training time, easy over-fitting and high misclassification rate. In order to overcome these defects, we firstly used the immune mechanism to improve the convolutional neural network and put forward a novel immune convolutional neural network algorithm, after we analyzed the network structure and parameters of the convolutional neural network. Our algorithm not only integrated the location data of the network nodes and the adjustable parameters, but also dynamically adjusted the smoothing factor of the basis function. In addition, we utilized the NVIDIA GPU (Graphics Processing Unit) to accelerate the new immune convolutional neural network (ICNN) in parallel computing and built a real-time embedded image recognition system for this ICNN. The immune convolutional neural network algorithm was improved with CUDA programming and was tested with the sample data in the GPU-based environment. The GPU-based implementation of the novel immune convolutional neural network algorithm was made with the cuDNN, which was designed by NVIDIA for GPU-based accelerating of DNNs in machine learning. Experimental results show that our new immune convolutional neural network has higher recognition rate, more stable performance and faster computing speed than the traditional convolutional neural network. © 2016 Elsevier Ltd","Convolutional neural network; Embedded system; Image recognition; Immune algorithm; Parallel computing; Security monitoring","Artificial intelligence; Computer graphics; Computer graphics equipment; Defects; Embedded systems; Image recognition; Learning systems; Neural networks; Optimization; Parallel processing systems; Parameter estimation; Program processors; Space research; Adjustable parameters; Convolutional neural network; Graphics Processing Unit; Image recognition system; Immune algorithms; Intelligent monitoring; Misclassification rates; Security monitoring; Convolution",,,,,"X12071306; Natural Science Foundation of Shanghai: 13ZR1400200; National Natural Science Foundation of China, NSFC: 61271114, 61673007; Fundamental Research Funds for the Central Universities","This work was supported by the grants from National Natural Science Foundation of China ( 61673007 , 61271114 ), Natural Science Foundation of Shanghai ( 13ZR1400200 ), Key Reform Project in Shanghai University Undergraduate Education ( X12071306 ) and the Fundamental Research Funds for the Central Universities at Donghua Univ . ( 2232013A3-09 ).",,,,,,,,,,"Alonso, F.R., Oliveira, D.Q., Zambroni de Souza, A.C., Artificial Immune Systems Optimization Approach for Multiobjective Distribution System Reconfiguration (2015) IEEE Trans. Power Syst., 30 (2), pp. 840-847; Azarov, I.S., Vashkevich, M.I., Petrovskii, A.A., Real-time voice conversion using artificial neural network with rectified linear units (2014) Neurocomput. Dev. Appl., 5, pp. 18-28; Benninger, B., Google Glass, Ultrasound and Palpation: The Anatomy Teacher of the Future? (2015) Clin. Anat., 28 (2), pp. 152-155; Biswas, A., Moosaei, H., Eslami, M., Optical soliton perturbation with extended tanh function method (2014) Optoelectron. Adv. Materials-rapid Commun., 8 (11-12), pp. 1029-1034; de Castro, L.N., Timmis, J., (2002) Aritificial Immune Systems: A New computational Intelligence Approach, , Springer London; Chen, M.H., Chang, P.-C., Wu, J.-L., A population-based incremental learning approach with artificial immune system for network intrusion detection (2016) Eng. Appl. Artif. Intell., 51, pp. 171-181; Deng, J.Y., Mao, Z.Y., Luo, Y.H., Algorithm for pattern recognition based on artificial immune network (2008) J. South China Univ. Technol. (Nat. Sci. Ed.), 1, pp. 99-104; Farmer, J.D., Packard, N.H., Perelson, A.S., The immune system, adaptation and machine learning (1986) Physica D, 22 (1-3), pp. 187-204; Feng, S., Caire, R., Cortazar, B., Immunochromatographic Diagnostic Test Analysis Using Google Glass (2014) ACS Nano, 8 (3), pp. 3069-3079; Fernandez-Leon, J.A., Acosta, G.G., Rozenfeld, A., How simple autonomous decisions evolve into robust behaviours?: A review from neurorobotics, cognitive, self-organized and artificial immune systems fields (2014) BioSystems, 124, pp. 7-20; Hunt, J.E., Cooke, D.E., A novel fuzzy logic approach to contrast enhancement (2000) Pattern Recognit., 33 (5), pp. 809-819; Jerne, N.K., Towards a network theory of the immune system (1974) Ann. Immunol., 125C (1-2). , 373-89; Kouzinopoulos, C.S., Assael, J.A.M., Pyrgiotis, T.K., A Hybrid Parallel Implementation of the Aho-Corasick and Wu-Manber Algorithms Using NVIDIA CUDA and MPI Evaluated on a Biological Sequence Database (2015) Int. J. Artif. Intell. Tools, 24 (1), p. 1540001; Kyo, S., Okazaki, S., Arai, T., An integrated memory array processor for embedded image recognition systems (2007) IEEE Trans. Comput., 56 (5), pp. 622-634; Li, W.Y., Face recognition technology research based on ARM architecture embedded (Thesis paper) (2008), East China Normal University; Lima, F.P.A., Lotufo, A.D.P., Minussi, C.R., Wavelet-artificial immune system algorithm applied to voltage disturbance diagnosis in electrical distribution systems (2015) IET Gener., Transm. Distrib., 9 (11), p. 1104; Luo, R.Y., Yin, Q., A Novel Parallel Clustering Algorithm Based on Artificial Immune Network Using nVidia CUDA Framework (2011), Proceedings of International Conference on Ergonomics and Health Aspects of Work with Computers (EHAWC)/14th International Conference on Human-Computer Interaction (HCI), Lecture Notes in Computer Science, 6761, 598-607; Muhamad, A.S., Deris, S., An artificial immune system for solving production scheduling problems: a review (2013) Artif. Intell. Rev., 39, pp. 97-108; Park, J.S., Kim, H.E., Kim, L.S., A 182mW 94.3 f/s in Full HD Pattern-Matching Based Image Recognition Accelerator for an Embedded Vision System in 0.13-mu m CMOS Technology (2013) IEEE Trans. Circuits Syst. Video Technol., 23 (5), pp. 832-845; Payne, S.J., Arrol, H.P., Hunt, S.V., Automated classification and analysis of the calcium response of single T lymphocytes using a neural network approach (2005) IEEE Trans. Neural Netw., 16 (4), pp. 949-958; Sunny, M.V.N., Dwivedi, R., Das, R.R., Gases/Odors Identification With Artificial Immune Recognition System Using Thick Film Gas Sensor Array Responses (2013) IEEE Sens. J., 13 (8), pp. 3039-3045; Thumati, B.T., Halligan, G.R., Jagannathan, S., A Novel Fault Diagnostics and Prediction Scheme Using a Nonlinear Observer With Artificial Immune System as an Online Approximator (2013) IEEE Trans. Control Syst. Technol., 21 (3), pp. 569-578; Yang, H., Li, T., Hu, X.L., Wang, F., Zou, Y., A Survey of Artificial Immune System Based Intrusion Detection (2014) Sci. World J., Artic. ID, p. 11. , (pages); Zhang, W.W., Yen, G.G., He, Z.S., An artificial immune system inspired by the fundamental principle of the vertebrate immune system, for solving constrained optimization problems, is proposed (2014) IEEE Trans. Cybern., 44 (2), pp. 185-198; Zhao, Z.H., Yang, S.P., Ma, Z.Q., License Plate Character Recognition Based on Convolutional Neural Network LeNet-5 (2010) J. Syst. Simul., 22 (3), pp. 638-641","Gong, T.; College of Information Science and Technology, China; email: taogong@dhu.edu.cn",,,"Elsevier Ltd",,,,,09521976,,EAAIE,,"English","Eng Appl Artif Intell",Article,"Final","",Scopus,2-s2.0-84995489085
"Gao M., Pu J., Yang X., Horowitz M., Kozyrakis C.","57189076610;55815572700;57194762857;7401749711;6602525246;","TETRIS: Scalable and efficient neural network acceleration with 3D memory",2017,"ACM SIGPLAN Notices","52","4",,"751","764",,103,"10.1145/3037697.3037702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084520353&doi=10.1145%2f3037697.3037702&partnerID=40&md5=bfd1d8e8ad175810c363434f5c8a4c8e","Stanford University, Stanford, CA, United States","Gao, M., Stanford University, Stanford, CA, United States; Pu, J., Stanford University, Stanford, CA, United States; Yang, X., Stanford University, Stanford, CA, United States; Horowitz, M., Stanford University, Stanford, CA, United States; Kozyrakis, C., Stanford University, Stanford, CA, United States","The high accuracy of deep neural networks (NNs) has led to the development of NN accelerators that improve performance by two orders of magnitude. However, scaling these accelerators for higher performance with increasingly larger NNs exacerbates the cost and energy overheads of their memory systems, including the on-chip SRAM buffers and the off-chip DRAM channels. This paper presents the hardware architecture and software scheduling and partitioning techniques for TETRIS, a scalable NN accelerator using 3D memory. First, we show that the high throughput and low energy characteristics of 3D memory allow us to rebalance the NN accelerator design, using more area for processing elements and less area for SRAM buffers. Second, we move portions of the NN computations close to the DRAM banks to decrease bandwidth pressure and increase performance and energy efficiency. Third, we show that despite the use of small SRAM buffers, the presence of 3D memory simplifies dataflow scheduling for NN computations. We present an analytical scheduling scheme that matches the efficiency of schedules derived through exhaustive search. Finally, we develop a hybrid partitioning scheme that parallelizes the NN computations over multiple accelerators. Overall, we show that TETRIS improves mthe performance by 4.1x and reduces the energy by 1.5x over NN accelerators with conventional, low-power DRAM memory systems. © 2017 ACM.","3d memory; Acceleration; Dataflow scheduling; Neural networks; Partitioning","Acceleration; Deep neural networks; Dynamic random access storage; Energy efficiency; Scheduling; Static random access storage; Data-flow scheduling; Energy characteristics; Hardware architecture; Hybrid partitioning; Improve performance; Neural networks (NNS); Partitioning techniques; Processing elements; Multitasking",,,,,"National Science Foundation, NSF: 1408911, SHF-1408911","The authors want to thank the anonymous reviewers for their insightful comments. This work was supported by the Stanford Pervasive Parallelism Lab, the Stanford Platform Lab, and NSF grant SHF-1408911.",,,,,,,,,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Zheng, X., Tensorflow: A system for large-scale machine learning (2016) 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI, pp. 265-283; Ahn, J., Hong, S., Yoo, S., Mutlu, O., Choi, K., A scalable processing-in-memory accelerator for parallel graph processing (2015) 42nd International Symposium on Computer Architecture (ISCA, pp. 105-117; Albericio, J., Judd, P., Hetherington, T., Aamodt, T., Jerger, N.E., Moshovos, A., Cnvlutin: Ineffectual-neuron-free deep neural network computing (2016) 43rd Annual International Symposium on Computer Architecture (ISCA, pp. 1-13; Balasubramonian, R., Chang, J., Manning, T., Moreno, J.H., Murphy, R., Nair, R., Swanson, S., Near-data processing: Insights from a micro-46 workshop (2014) IEEE Micro, 34 (4), pp. 36-42; Chen, T., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., Temam, O., Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning (2014) 19th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS, pp. 269-284; Chen, Y., Luo, T., Liu, S., Zhang, S., He, L., Wang, J., Li, L., Temam, O., Dadi-Annao: A machine-learning supercomputer (2014) 47th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO, pp. 609-622; Chen, Y.-H., Emer, J., Sze, V., Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks (2016) 43rd Annual International Symposium on Computer Architecture (ISCA, pp. 367-379; Chen, Y.-H., Krishna, T., Emer, J., Sze, V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convo-lutional neural networks (2016) IEEE International Solid-State Circuits Conference (ISSCC, pp. 262-263; Chi, P., Li, S., Xu, C., Zhang, T., Zhao, J., Liu, Y., Wang, Y., Xie, Y., Prime: A novel processing-in-memory architecture for neural network computation in reram-based main memory (2016) 43rd International Symposium on Computer Architecture (ISCA, pp. 27-39; Choi, K., Coarse-grained reconfigurable array: Architecture and application mapping (2011) IPSJ Transactions on System LSI Design Methodology, 4, pp. 31-46; Dean, J., Corrado, G.S., Monga, R., Chen, K., Devin, M., Le, Q.V., Mao, M.Z., Ng, A.Y., Large scale distributed deep networks (2012) 25th International Conference on Neural Information Processing Systems (NIPS, pp. 1223-1231; Du, Z., Fasthuber, R., Chen, T., Ienne, P., Li, L., Luo, T., Feng, X., Temam, O., Shidiannao: Shifting vision processing closer to the sensor (2015) 42nd Annual International Symposium on Computer Architecture (ISCA, pp. 92-104; Dundar, A., Jin, J., Gokhale, V., Martini, B., Culurciello, E., Memory access optimized routing scheme for deep networks on a mobile coprocessor (2014) 2014 IEEE High Performance Extreme Computing Conference (HPEC, pp. 1-6; Eckert, Y., Jayasena, N., Loh, G.H., Thermal feasibility of die-stacked processing in memory (2014) 2nd Workshop on Near-Data Processing (WoNDP; Farabet, C., Martini, B., Corda, B., Akselrod, P., Culurciello, E., LeCun, Y., Neuflow: A runtime reconfigurable dataflow processor for vision (2011) 2011 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW, pp. 109-116; Gao, M., Kozyrakis, C., Hrl: Efficient and flexible re-configurable logic for near-data processing (2016) 22nd IEEE International Symposium on High Performance Computer Architecture (HPCA, pp. 126-137; Gao, M., Ayers, G., Kozyrakis, C., Practical near-data processing for in-memory analytics frameworks (2015) 2015 International Conference on Parallel Architecture and Compilation (PACT, pp. 113-124; Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M.A., Dall, W.J., Eie: Efficient inference engine on compressed deep neural network (2016) 43rd Annual International Symposium on Computer Architecture (ISCA, pp. 243-254; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , arXiv preprint; (2014) Hybrid Memory Cube Specification 2.1, , Hybrid Memory Cube Consortium; Jeddeloh, J., Keeth, B., Hybrid memory cube new dram architecture increases density and performance (2012) 2012 Symposium on VLSI Technology (VLSIT, pp. 87-88; (2015) High Bandwidth Memory (HBM) DRAM, , JEDEC Standard JESD235A; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Gir-Shick, R., Guadarrama, S., Darrell, T., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding, , arXiv preprint; Kahng, A.B., Li, B., Peh, L.-S., Samadi, K., Orion 2.0: A fast and accurate noc power and area model for early-stage design space exploration (2009) Conference on Design, Automation and Test in Europe (DATE, pp. 423-428; Kim, D., Kung, J., Chai, S., Yalamanchili, S., Mukhopad-Hyay, S., Neurocube: A programmable digital neuromorphic architecture with high-density 3d memory (2016) 43rd Annual International Symposium on Computer Architecture (ISCA, pp. 380-392; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) 25th International Conference on Neural Information Processing Systems (NIPS, pp. 1097-1105; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Lee, D.U., Kim, K.W., Kim, K.W., Kim, H., Kim, J.Y., Park, Y.J., Kim, J.H., Hong, S., 25.2 A 1.2V 8Gb 8-channel 128GB/s High-Bandwidth Memory (HBM) Stacked DRAM with Effective Microbump I/O Test Methods Using 29nm Process and TSV (2014) IEEE International Solid-State Circuits Conference (ISSCC, pp. 432-433; Li, S., Chen, K., Ahn, J.H., Brockman, J.B., Jouppi, N.P., Cacti-p: Architecture-level modeling for sram-based structures with advanced leakage reduction techniques (2011) 2011 IEEE/ACM International Conference on Computer-Aided Design (ICCAD, pp. 694-701; Mei, B., Vernalde, S., Verkest, D., De Man, H., Lauwereins, R., Adres: An architecture with tightly coupled vliw processor and coarse-grained reconfigurable matrix (2003) 13th International Conference on Field Programmable Logic and Application (FPL, pp. 61-70; (2007) TN-41-01: Calculating Memory System Power for DDR3, , https://www.micron.com/support/tools-And-utilities/power-calc, Micron Technology Inc; (2014) Mobile LPDDR3 SDRAM: 178-Ball Single-Channel Mobile LPDDR3 SDRAM Features, , https://www.micron.com/products/dram/lpdram/16Gb, Micron Technology Inc; Park, S., Bong, K., Shin, D., Lee, J., Choi, S., Yoo, H.-J., A 1.93tops/w scalable deep learning/inference processor with tetra-parallel mimd architecture for big-data applications (2015) IEEE International Solid-State Circuits Conference (ISSCC, pp. 1-3; Peemen, M., Setio, A.A., Mesman, B., Corporaal, H., Memory-centric accelerator design for convolutional neural networks (2013) 31st International Conference on Computer Design (ICCD, pp. 13-19; Pugsley, S.H., Jestes, J., Zhang, H., Balasubramonian, R., Srinivasan, V., Buyuktosunoglu, A., Davis, A., Li, F., Ndc: Analyzing the impact of 3d-stacked memory+logic devices on mapreduce workloads (2014) International Symposium on Performance Analysis of Systems and Software (ISPASS, pp. 190-200; Reagen, B., Whatmough, P., Adolf, R., Rama, S., Lee, H., Lee, S.K., Hernández-Lobato, J.M., Brooks, D., Minerva: Enabling low-power, highly-Accurate deep neural network accelerators (2016) 43rd Annual International Symposium on Computer Architecture (ISCA, pp. 267-278; Sanchez, D., Kozyrakis, C., Zsim: Fast and accurate microarchitectural simulation of thousand-core systems (2013) 40th International Symposium on Computer Architecture (ISCA, pp. 475-486; Seshadri, V., Kim, Y., Fallin, C., Lee, D., Ausavarungnirun, R., Pekhimenko, G., Luo, Y., Mowry, T.C., Rowclone: Fast and energy-efficient in-dram bulk data copy and initialization (2013) 46th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO, pp. 185-197; Seshadri, V., Hsieh, K., Boroumand, A., Lee, D., Kozuch, M.A., Mutlu, O., Gibbons, P.B., Mowry, T.C., Fast bulk bitwise and and or in dram (2015) Computer Architecture Letters, 14 (2), pp. 127-131; Shafiee, A., Nag, A., Muralimanohar, N., Balasubramonian, R., Strachan, J.P., Hu, M., Williams, R.S., Srikumar, V., Isaac: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars (2016) 43rd International Symposium on Computer Architecture (ISCA, pp. 14-26; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , arXiv preprint; Singh, H., Lee, M.-H., Lu, G., Bagherzadeh, N., Kurdahi, F.J., Filho, E.M.C., Morphosys: An integrated reconfigurable system for data-parallel and computation-intensive applications (2000) IEEE Transactions Computers, 49 (5), pp. 465-481; Vogelsang, T., Understanding the energy consumption of dynamic random access memories (2010) 43rd Annual ACM/IEEE International Symposium on Microarchitecture (MICRO, pp. 363-374; Weis, C., Wehn, N., Igor, L., Benini, L., Design space exploration for 3d-stacked drams (2011) Design, Automation Test in Europe Conference Exhibition (DATE, pp. 1-6; Yang, X., Pu, J., Rister, B.B., Bhagdikar, N., Richardson, S., Kvatinsky, S., Ragan-Kelley, J., Horowitz, M., (2016) A Systematic Approach to Blocking Convolutional Neural Networks, , arXiv preprint; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) 13th European Conference on Computer Vision (ECCV, pp. 818-833; Zhang, C., Li, P., Sun, G., Guan, Y., Xiao, B., Cong, J., Optimizing fpga-based accelerator design for deep convolu-tional neural networks (2015) 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA, pp. 161-170",,,,"Association for Computing Machinery",,,,,15232867,,,,"English","ACM SIGPLAN Not.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85084520353
"Li S., Dou Y., Niu X., Lv Q., Wang Q.","57192465091;15131095400;38663051000;48761577600;57209560852;","A fast and memory saved GPU acceleration algorithm of convolutional neural networks for target detection",2017,"Neurocomputing","230",,,"48","59",,23,"10.1016/j.neucom.2016.11.046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009274672&doi=10.1016%2fj.neucom.2016.11.046&partnerID=40&md5=a48aca888416c992f3d38bc20bba5ebd","National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China","Li, S., National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China, School of Computer, National University of Defense Technology, Changsha, China; Dou, Y., National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China, School of Computer, National University of Defense Technology, Changsha, China; Niu, X., National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China, School of Computer, National University of Defense Technology, Changsha, China; Lv, Q., National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China, School of Computer, National University of Defense Technology, Changsha, China; Wang, Q., National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China, School of Computer, National University of Defense Technology, Changsha, China","Target detection is a hard real-time task for video and image processing. This task has recently been accomplished through the feedforward process of convolutional neural networks (CNN), which is usually accelerated by general-purpose graphic units (GPUs). However, there are two challenges for this task. One is that the running speed remains to be improved. The other is that we probably use a deeper and larger CNN model, but a more sophisticated model may not be trained well due to the shortage of GPU memory. In this paper, we present two scheduling algorithms to solve the aforementioned challenges for improving the system performance holistically. The first one is an efficient image combination algorithm used to accelerate the feedforward process of CNN. The other is a light-memory-cost algorithm used to train an arbitrarily large CNN model for a GPU device with a limited memory. We run our experiments on a GTX980 card and use a CNN model with 8 GB of model parameters, which is larger than the size of the global memory of a GPU. Compared with that of cuDNNv3, a high speedup of 6.97x is obtained in the detection task. © 2016 Elsevier B.V.","Convolutional neural networks; GPU; Target detection","Convolution; Image processing; Neural networks; Program processors; Scheduling algorithms; Target tracking; Video signal processing; Convolutional neural network; Detection tasks; GPU accelerations; Hard real-time task; Image combination; Limited memory; Model parameters; Running speed; Feedforward neural networks; algorithm; Article; artificial neural network; convolutional neural network; Fourier transform translating algorithm; general purpose graphic unit; high speed image combination algorithm; image processing; information processing; mathematical computing; mathematical model; mathematical parameters; matrix multiplication translating algorithm; performance",,,,,,,,,,,,,,,,"Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, Vol. 1, IEEE, pp. 886-893; Lowe, D.G., Object recognition from local scale-invariant features (1999) Computer vision, 1999. The Proceedings of the Seventh IEEE International Conference on, Vol. 2, Ieee, pp. 1150-1157; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Vedaldi, A., Lenc, K., Matconvnet: Convolutional neural networks for matlab (2015) Proceedings of the 23rd Annual ACM Conference on Multimedia Conference, ACM, pp. 689-692; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) Proceedings of the ACM International Conference on Multimedia, ACM, pp. 675-678; Bergstra, J., Bastien, F., Breuleux, O., Lamblin, P., Pascanu, R., Delalleau, O., Desjardins, G., Bergeron, A., Theano: Deep learning on gpus with python (2011), in: NIPS 2011, BigLearning Workshop, Granada, Spain; Chetlur, S., Woolley, C., Vandermersch, P., Cohen, J., Tran, J., Catanzaro, B., Shelhamer, E., cudnn: Efficient primitives for deep learning arXiv preprint arXiv:1410.0759; Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y., Overfeat: Integrated recognition, localization and detection using convolutional networks arXiv preprint arXiv:1312.6229; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; LeCun, Y., Huang, F.J., Bottou, L., Learning methods for generic object recognition with invariance to pose and lighting (2004), Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on, Vol. 2, IEEE, pp. II–97; Lv, Q., Niu, X., Dou, Y., Xu, J., Lei, Y., Classification of hyperspectral remote sensing image using hierarchical local-receptive-field-based extreme learning machine (2016) IEEE Geosci. Remote Sens. Lett., 13 (3), pp. 434-438; Lavin, A., maxdnn: An efficient convolution kernel for deep learning with maxwell gpus arXiv preprint arXiv:1501.06633; Mathieu, M., Henaff, M., LeCun, Y., Fast training of convolutional networks through ffts arXiv preprint arXiv:1312.5851; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; LeCun, Y., Cortes, C., Burges, C.J., The mnist database of handwritten digits (1998); Krizhevsky, A., Hinton, G., Convolutional deep belief networks on cifar-10, Unpublished manuscript 40; Nayar, S., Nene, S., Murase, H., Columbia object image library (coil 100), Department of Comp. Science, Columbia University, Tech. Rep. CUCS-006-96; Griffin, G., Holub, A., Perona, P., Caltech-256 object category dataset; Alexe, B., Deselaers, T., Ferrari, V., Measuring the objectness of image windows (2012) IEEE Trans. Pattern Anal. Mach. Intell., 34 (11), pp. 2189-2202; Uijlings, J.R., van de Sande, K.E., Gevers, T., Smeulders, A.W., Selective search for object recognition (2013) Int. J. Comput. Vis., 104 (2), pp. 154-171; Endres, I., Hoiem, D., Category independent object proposals (2010) Computer Vision–ECCV 2010, Springer, pp. 575-588; Carreira, J., Sminchisescu, C., Cpmc: automatic object segmentation using constrained parametric min-cuts (2012) IEEE Trans. Pattern Anal. Mach. Intell., 34 (7), pp. 1312-1328; Arbeláez, P., Pont-Tuset, J., Barron, J., Marques, F., Malik, J., Multiscale combinatorial grouping (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 328-335; Deng, J., Berg, A., Satheesh, S., Su, H., Khosla, A., Fei-Fei, L., (2012), Imagenet large scale visual recognition competition 2012 (ilsvrc2012); Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition arXiv preprint arXiv:1409.1556","Li, S.; National Laboratory for Parallel and Distributed Processing, China; email: lishijienudt@163.com",,,"Elsevier B.V.",,,,,09252312,,NRCGE,,"English","Neurocomputing",Article,"Final","",Scopus,2-s2.0-85009274672
"Constantin J., Bigand A., Constantin I.","7006214794;6602780591;55329546000;","Pooling spike neural network for acceleration of global illumination rendering",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10305 LNCS",,,"199","211",,,"10.1007/978-3-319-59153-7_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020544107&doi=10.1007%2f978-3-319-59153-7_18&partnerID=40&md5=08f9eaa7025e210fb301138499176f26","Laboratoire de Physique Appliquée, Université Libanaise, Faculté des Sciences 2, Campus Fanar, Jdeideh, BP 90656, Lebanon; LISIC, ULCO, 50 rue F. Buisson, BP 719, Calais Cedex, 62228, France; Applied Mathematics Department, Lebanese University, Faculty of Sciences 2, Campus Fanar, Jdeideh, BP 90656, Lebanon","Constantin, J., Laboratoire de Physique Appliquée, Université Libanaise, Faculté des Sciences 2, Campus Fanar, Jdeideh, BP 90656, Lebanon, Applied Mathematics Department, Lebanese University, Faculty of Sciences 2, Campus Fanar, Jdeideh, BP 90656, Lebanon; Bigand, A., LISIC, ULCO, 50 rue F. Buisson, BP 719, Calais Cedex, 62228, France; Constantin, I., Laboratoire de Physique Appliquée, Université Libanaise, Faculté des Sciences 2, Campus Fanar, Jdeideh, BP 90656, Lebanon, Applied Mathematics Department, Lebanese University, Faculty of Sciences 2, Campus Fanar, Jdeideh, BP 90656, Lebanon","The generation of photo-realistic images is a major topic in computer graphics. By using the principles of physical light propagation, images that are indistinguishable from real photographs can be generated. However, this computation is a very time-consuming task. When simulating the real behavior of light, individual images can take hours to be of sufficient quality. This paper proposes a bio-inspired architecture with spiking neurons for acceleration of global illumination rendering. This architecture with functional parts of sparse encoding, learning and decoding consists of a robust convergence measure on blocks. Feature, concatenation and prediction pooling coupled with three pooling operators: convolution, average and standard deviation are used in order to separate noise from signal. The pooling spike neural network (PSNN) represents a nonlinear mapping from stochastic noise features of rendering images to their quality visual scores. The system dynamic, that computes a learning parameter for each image based on its level of noise, is a consistent temporal framework where the precise timing of spikes is employed for information processing. The experiments are conducted on a global illumination set which contains diverse image distortions and large number of images with different noise levels. The result of this study is a system composed from only two spike pattern association neurons (SPANs) suitably adopted to the quality assessment task that accurately predict the quality of images with a high agreement with respect to human psycho-visual scores. The proposed spike neural network has also been compared with support vector machine (SVM). The obtained results show that the proposed method gives promising efficiency. © Springer International Publishing AG 2017.","Dynamic learning; Global illumination; Pooling spike neural network; Pooling strategies; Sparse coding; Support vector machine","Computer graphics; Memory architecture; Network architecture; Neural networks; Stochastic systems; Support vector machines; Bio-inspired architectures; Dynamic learning; Global illumination; Learning parameters; Photorealistic images; Pooling strategies; Sparse coding; Time-consuming tasks; Rendering (computer graphics)",,,,,"Université Libanaise: 428/2015","This project has been funded with support from the Lebanese University under grant number 428/2015. We would like to thank the LISIC laboratory at the Littoral cote d’Opale University for providing us with the data used in our experiments.",,,,,,,,,,"Ikeda, S., Watanabe, S., Raytchev, B., Tamaki, T., Kaneda, K., Spectral rendering of interference phenomena caused by multilayer films under global illumination environment (2015) ITE Trans. Media Technol. Appl., 3 (1), pp. 76-84; Hedman, P., Karras, T., Lehtinen, J., Sequential Monte Carlo instant radiosity (2016) Proceedings of the 20th ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, pp. 121-128; Parker, S.G., Bigler, J., Dietrich, A., Friedrich, H., Hoberock, J., Luebke, D., McAllister, D., Stich, M., OptiX: A general purpose ray tracing engine (2010) ACM Trans. Graph., p. 29; Thiedemann, S., Henrich, N., Grosch, T., Muller, S., Voxel-based global illumination (2011) I3D, pp. 103-110; Volevich, V., Myszkowski, K., Khodulev, A., Kopylov, A., Using the visual differences predictor to improve performance of progressive global illumination computation (2000) ACM Trans. Graph., 19 (1), pp. 122-161; Shi, J., Yan, Q., Xu, L., Jia, J., Hierarchical image saliency detection on extended CSSD (2015) IEEE Trans. Pattern Anal. Mach. Intell., 38 (4), pp. 717-729; Demirtas, A., Reibman, A., Jafarkhani, H., Full-reference quality estimation for images with different spatial resolutions (2014) IEEE Trans. Image Process., 23 (5), pp. 2069-2080; Delepoulle, S., Bigand, A., Renaud, C., A no-reference computer generated images quality metrics and its application to denoising (2012) IEEE Intelligent Systems IS12 Conference, 1, pp. 67-73; Constantin, J., Bigand, A., Constantin, I., Hamad, D., Image noise detection in global illumination methods based on FRVM (2015) Neurocomputing, 64, pp. 82-95; Constantin, J., Constantin, I., Rammouz, R., Bigand, A., Hamad, D., Perception of noise in global illumination algorithms based on spiking neural network (2015) The IEEE Third International Conference on Technological Advances in Electrical, Electronics and Computer Engineering, pp. 68-73; Makandar, A., Halalli, B., Image enhancement techniques using highpass and lowpass filters (2015) Int. J. Comput. Appl., 109 (14), pp. 21-27; Dawood, F., Rahmat, R., Kadiman, S., Abdullah, L., Zamrin, M., Effect comparison of speckle noise reduction filters on 2D echocardiographic (2012) World Acad. Sci. Eng. Technol., 6 (9), pp. 425-430; Biswas, P., Sarkar, A., Mynuddin, M., Deblurring images using a Wiener filter (2015) Int. J. Comput. Appl., 109 (7), pp. 36-38; Gao, D., Liao, Z., Lv, Z., Lu, Y., Multi-scale statistical signal processing of cutting force in cutting tool condition monitoring (2015) Int. J. Adv. Manuf. Technol., 90 (9), pp. 1843-1853; Mohemmed, A., Lu, G., Kasabov, N., Evaluating SPAN incremental learning for handwritten digit recognition (2012) ICONIP 2012. LNCS, 7665, pp. 670-677. , Huang, T., Zeng, Z., Li, C., Leung, C.S. (eds.), Springer, Heidelberg; Qiang, Y., Huajin, T., Kay, C.T., Haoyong, Y., A brain inspired spiking neural network model with temporal encoding and learning (2014) Neurocomputing, 138, pp. 3-13; Hu, J., Tang, H., Tan, K.C., Li, H., Shi, L., A spike-timing-based integrated model for pattern recognition (2013) Neural Comput., 251 (2), pp. 450-472; Pavlidis, N., Tasoulis, D., Plagianakos, V.P., Vrahatis, M., Spiking neural network training using evolutionary algorithms (2005) IEEE Int. Joint Conf. Neural Netw., 4, pp. 2190-2194; Qu, H., Xie, X., Liu, Y., Zhang, M., Lu, L., Improved perception based spiking neuron learning rule for real-time user authentication (2015) Neurocomputing, 151, pp. 310-318","Constantin, J.; Laboratoire de Physique Appliquée, Campus Fanar, Lebanon; email: cjoseph@ul.edu.lb","Catala A.Rojas I.Joya G.","","Springer Verlag","14th International Work-Conference on Artificial Neural Networks, IWANN 2017","14 June 2017 through 16 June 2017",,192889,03029743,9783319591520,,,"English","Lect. Notes Comput. Sci.",Article,"Final","",Scopus,2-s2.0-85020544107
